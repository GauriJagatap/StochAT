{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Adversarial Training (StochAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vanila SGD: \n",
    "MNIST - 99%+ (most cnns), CIFAR10 - 93%+ (resnet18), 96%+ (wideresnet) \n",
    "\n",
    "MNIST:\n",
    "\n",
    "adversarial attacks: \n",
    "l-inf @ eps = 80/255 @20 steps: TRADES - 96.07% - (4 layer cnn), MART 96.4%, MMA 95.5%, PGD - 96.01% - (4 layer cnn)\n",
    "\n",
    "adversarial attacks:\n",
    "l-2 @ eps = 32/255 (check): TRADES, MMA, PGD\n",
    "\n",
    "CIFAR10:\n",
    "\n",
    "adversarial attacks: \n",
    "l-inf @ eps = 8/255 @20 steps: \n",
    "TRADES 53-56% - (WRN-34-10), MART 57-58% (WRN-34-10), MMA 47%, PGD 48% - (WRN-32-10)// 49% - (WRN-34-10), Std - 0.03%\n",
    "https://openreview.net/pdf?id=rklOg6EFwS (Table 4)\n",
    "\n",
    "adversarial attacks: \n",
    "l-inf @ eps = 8/255 @20 steps: \n",
    "[ResNet10] TRADES 45.4%, MART 46.6%, MMA 37.26%, PGD 42.27%, Std 0.14%\n",
    "\n",
    "Benign accuracies: TRADES 84.92%, MART 83.62%, MMA 84.36, PGD 87.14%, Std 95.8% [wideresnet]\n",
    "https://openreview.net/pdf?id=Ms9zjhVB5R (Table 1)\n",
    "\n",
    "adversarial attacks:\n",
    "l-2 @ eps = 32/255 (check): TRADES, MART, MMA, PGD\n",
    "\n",
    "TBD: CWinf attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained models for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download pretrained models and place in ../trainedmodels/MNIST or ../trainedmodels/CIFAR10 respectively\n",
    "\n",
    "### TRADES :\n",
    "https://github.com/yaodongyu/TRADES (MNIST: small cnn, CIFAR10: WideResNet34)\n",
    "### MMA : \n",
    "https://github.com/BorealisAI/mma_training (MNIST: lenet5, CIFAR10: WideResNet28)\n",
    "### MART :\n",
    " https://github.com/YisenWang/MART (CIFAR10: ResNet18 and WideResNet34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from multiprocessing import cpu_count\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import olympic\n",
    "from typing import Union, Callable, Tuple\n",
    "import sys\n",
    "sys.path.append('../adversarial/')\n",
    "sys.path.append('../architectures/')\n",
    "from functional import boundary, iterated_fgsm, local_search, pgd, entropySmoothing\n",
    "from ESGD_utils import *\n",
    "import pickle\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse, math, random\n",
    "import ESGD_optim\n",
    "from trades import trades_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place data folders outside working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 4, 'pin_memory': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['test_batch_size'] = 128\n",
    "args['train_batch_size'] = 128\n",
    "args['no_cuda'] = False\n",
    "args['epsilon'] = 0.031\n",
    "args['num_steps'] = 10\n",
    "args['step_size'] = 0.007\n",
    "args['random'] =True,\n",
    "args['white_box_attack']=True\n",
    "args['log_interval'] = 100\n",
    "args['beta'] = 6.0\n",
    "args['seed'] = 1\n",
    "args['lr'] = 0.1\n",
    "args['momentum'] = 0.9\n",
    "args['epochs'] = 5\n",
    "args['batch_size'] = 128\n",
    "args['save_freq'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = 'CIFAR10' # [MNIST, CIFAR10]\n",
    "if dataset == 'MNIST':\n",
    "    transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "    train = datasets.MNIST('../../data/MNIST', train=True, transform=transform, download=True)\n",
    "    val = datasets.MNIST('../../data/MNIST', train=False, transform=transform, download=True)\n",
    "elif dataset == 'CIFAR10':\n",
    "    # setup data loader\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train = datasets.CIFAR10('../../data/CIFAR10', train=True, transform=transform_train, download=True)\n",
    "    val = datasets.CIFAR10('../../data/CIFAR10', train=False, transform=transform_test, download=True)\n",
    "    \n",
    "train_loader = DataLoader(train, batch_size=args['test_batch_size'], shuffle=True, **kwargs)\n",
    "val_loader = DataLoader(val, batch_size=args['train_batch_size'], shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    RandomCrop(size=(32, 32), padding=4)\n",
       "    RandomHorizontalFlip(p=0.5)\n",
       "    ToTensor()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALIZE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='CIFAR10':\n",
    "    #[ResNet18,ResNet34,ResNet50,WideResNet]\n",
    "    from resnet import ResNet18,ResNet34,ResNet50\n",
    "    from wideresnet import WideResNet\n",
    "    Net = WideResNet\n",
    "    NetName = 'WideResNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wideresnet.WideResNet"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM SEED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd54bd6e110>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = args['seed']\n",
    "torch.set_num_threads(2)\n",
    "if DEVICE=='cuda':\n",
    "    torch.cuda.set_device(-1)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    cudnn.benchmark = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataentropy(method,model, device, train_loader, adversary,L,step,eps,norm,random):\n",
    "    totalloss = 0\n",
    "    totalcorrect = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        ypred = model(data)\n",
    "        \n",
    "        sgd_loss = nn.CrossEntropyLoss()\n",
    "        # calculate robust loss per batch\n",
    "        loss, correct = batchentropy(model,sgd_loss,data,target,adversary,L,step,eps,norm)\n",
    "        totalcorrect += correct\n",
    "    print('robust train accuracy:',100*totalcorrect/len(train_loader.dataset))   \n",
    "    print('data entropy:', totalloss/len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchentropy(model, loss_fn, x, y, adversary, L, step, eps, norm):\n",
    "    \"\"\"Performs a single update against a specified adversary\"\"\"\n",
    "    model.train()\n",
    "    # Adversial perturbation\n",
    "    alpha=0.9\n",
    "    loss = 0\n",
    "    \n",
    "    for l in range(L):     \n",
    "        \n",
    "        if l==0: ## initialize using random perturbation of true x, run for one epoch\n",
    "            k=1\n",
    "            random=True\n",
    "            xp = None\n",
    "            projector=False\n",
    "        elif l>0 and l<L-1: ## initialize with previous iterate of adversarial perturbation, run one epoch\n",
    "            k=1\n",
    "            random=False\n",
    "            xp=x_adv\n",
    "            projector = False\n",
    "        elif l == L-1: ## initialize with previous iterate, run one epoch, project to epsilon ball\n",
    "            k=1\n",
    "            random=False\n",
    "            xp = x_adv\n",
    "            projector=True\n",
    "            \n",
    "        x_adv = adversary(model, x, y, loss_fn, xp=xp, step=step, eps=eps, norm=norm, random=random, ep=1e-3,projector=projector)\n",
    "        \n",
    "        y_pred = model(x_adv)\n",
    "        pred = y_pred.max(1, keepdim=True)[1]\n",
    "        correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "        loss = (1-alpha)*loss + alpha*loss_fn(y_pred, y)\n",
    "\n",
    "    return loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../SmallCNN_MNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST_model-nn-epoch23-robacc96.pt  model-nn-epoch27-robacc96.pt\r\n",
      "model-nn-epoch10-robacc52.pt       model-nn-epoch28-robacc83.pt\r\n",
      "model-nn-epoch10-robacc75.pt       model-nn-epoch28-robacc90.pt\r\n",
      "model-nn-epoch10-robacc81.pt       model-nn-epoch28-robacc96.pt\r\n",
      "model-nn-epoch10-robacc83.pt       model-nn-epoch29-robacc83.pt\r\n",
      "model-nn-epoch10-robacc88.pt       model-nn-epoch29-robacc90.pt\r\n",
      "model-nn-epoch10-robacc89.pt       model-nn-epoch29-robacc96.pt\r\n",
      "model-nn-epoch10-robacc94.pt       model-nn-epoch2-robacc10.pt\r\n",
      "model-nn-epoch10-robacc95.pt       model-nn-epoch2-robacc11.pt\r\n",
      "model-nn-epoch11-robacc82.pt       model-nn-epoch2-robacc50.pt\r\n",
      "model-nn-epoch11-robacc89.pt       model-nn-epoch2-robacc56.pt\r\n",
      "model-nn-epoch11-robacc94.pt       model-nn-epoch2-robacc62.pt\r\n",
      "model-nn-epoch11-robacc95.pt       model-nn-epoch2-robacc67.pt\r\n",
      "model-nn-epoch11-robacc96.pt       model-nn-epoch2-robacc70.pt\r\n",
      "model-nn-epoch12-robacc81.pt       model-nn-epoch2-robacc73.pt\r\n",
      "model-nn-epoch12-robacc89.pt       model-nn-epoch2-robacc74.pt\r\n",
      "model-nn-epoch12-robacc94.pt       model-nn-epoch2-robacc78.pt\r\n",
      "model-nn-epoch12-robacc95.pt       model-nn-epoch2-robacc85.pt\r\n",
      "model-nn-epoch12-robacc96.pt       model-nn-epoch2-robacc86.pt\r\n",
      "model-nn-epoch13-robacc82.pt       model-nn-epoch2-robacc89.pt\r\n",
      "model-nn-epoch13-robacc89.pt       model-nn-epoch2-robacc94.pt\r\n",
      "model-nn-epoch13-robacc94.pt       model-nn-epoch2-robacc95.pt\r\n",
      "model-nn-epoch13-robacc96.pt       model-nn-epoch30-robacc84.pt\r\n",
      "model-nn-epoch14-robacc82.pt       model-nn-epoch30-robacc90.pt\r\n",
      "model-nn-epoch14-robacc89.pt       model-nn-epoch30-robacc96.pt\r\n",
      "model-nn-epoch14-robacc94.pt       model-nn-epoch3-robacc10.pt\r\n",
      "model-nn-epoch14-robacc95.pt       model-nn-epoch3-robacc11.pt\r\n",
      "model-nn-epoch15-robacc82.pt       model-nn-epoch3-robacc44.pt\r\n",
      "model-nn-epoch15-robacc89.pt       model-nn-epoch3-robacc68.pt\r\n",
      "model-nn-epoch15-robacc94.pt       model-nn-epoch3-robacc69.pt\r\n",
      "model-nn-epoch15-robacc95.pt       model-nn-epoch3-robacc71.pt\r\n",
      "model-nn-epoch16-robacc82.pt       model-nn-epoch3-robacc74.pt\r\n",
      "model-nn-epoch16-robacc89.pt       model-nn-epoch3-robacc79.pt\r\n",
      "model-nn-epoch16-robacc94.pt       model-nn-epoch3-robacc80.pt\r\n",
      "model-nn-epoch16-robacc96.pt       model-nn-epoch3-robacc81.pt\r\n",
      "model-nn-epoch17-robacc82.pt       model-nn-epoch3-robacc85.pt\r\n",
      "model-nn-epoch17-robacc89.pt       model-nn-epoch3-robacc89.pt\r\n",
      "model-nn-epoch17-robacc94.pt       model-nn-epoch3-robacc90.pt\r\n",
      "model-nn-epoch17-robacc96.pt       model-nn-epoch3-robacc92.pt\r\n",
      "model-nn-epoch18-robacc83.pt       model-nn-epoch3-robacc95.pt\r\n",
      "model-nn-epoch18-robacc89.pt       model-nn-epoch4-robacc50.pt\r\n",
      "model-nn-epoch18-robacc90.pt       model-nn-epoch4-robacc67.pt\r\n",
      "model-nn-epoch18-robacc94.pt       model-nn-epoch4-robacc73.pt\r\n",
      "model-nn-epoch18-robacc96.pt       model-nn-epoch4-robacc83.pt\r\n",
      "model-nn-epoch19-robacc83.pt       model-nn-epoch4-robacc86.pt\r\n",
      "model-nn-epoch19-robacc89.pt       model-nn-epoch4-robacc89.pt\r\n",
      "model-nn-epoch19-robacc94.pt       model-nn-epoch4-robacc92.pt\r\n",
      "model-nn-epoch19-robacc95.pt       model-nn-epoch4-robacc93.pt\r\n",
      "model-nn-epoch1-robacc10.pt        model-nn-epoch4-robacc94.pt\r\n",
      "model-nn-epoch1-robacc11.pt        model-nn-epoch4-robacc95.pt\r\n",
      "model-nn-epoch1-robacc24.pt        model-nn-epoch5-robacc51.pt\r\n",
      "model-nn-epoch1-robacc44.pt        model-nn-epoch5-robacc68.pt\r\n",
      "model-nn-epoch1-robacc49.pt        model-nn-epoch5-robacc76.pt\r\n",
      "model-nn-epoch1-robacc51.pt        model-nn-epoch5-robacc77.pt\r\n",
      "model-nn-epoch1-robacc55.pt        model-nn-epoch5-robacc85.pt\r\n",
      "model-nn-epoch1-robacc56.pt        model-nn-epoch5-robacc87.pt\r\n",
      "model-nn-epoch1-robacc68.pt        model-nn-epoch5-robacc93.pt\r\n",
      "model-nn-epoch1-robacc69.pt        model-nn-epoch5-robacc94.pt\r\n",
      "model-nn-epoch1-robacc72.pt        model-nn-epoch5-robacc95.pt\r\n",
      "model-nn-epoch1-robacc73.pt        model-nn-epoch6-robacc51.pt\r\n",
      "model-nn-epoch1-robacc74.pt        model-nn-epoch6-robacc68.pt\r\n",
      "model-nn-epoch1-robacc83.pt        model-nn-epoch6-robacc77.pt\r\n",
      "model-nn-epoch1-robacc87.pt        model-nn-epoch6-robacc79.pt\r\n",
      "model-nn-epoch1-robacc94.pt        model-nn-epoch6-robacc86.pt\r\n",
      "model-nn-epoch1-robacc95.pt        model-nn-epoch6-robacc87.pt\r\n",
      "model-nn-epoch20-robacc83.pt       model-nn-epoch6-robacc93.pt\r\n",
      "model-nn-epoch20-robacc89.pt       model-nn-epoch6-robacc95.pt\r\n",
      "model-nn-epoch20-robacc90.pt       model-nn-epoch7-robacc53.pt\r\n",
      "model-nn-epoch20-robacc95.pt       model-nn-epoch7-robacc66.pt\r\n",
      "model-nn-epoch20-robacc96.pt       model-nn-epoch7-robacc79.pt\r\n",
      "model-nn-epoch21-robacc83.pt       model-nn-epoch7-robacc81.pt\r\n",
      "model-nn-epoch21-robacc90.pt       model-nn-epoch7-robacc87.pt\r\n",
      "model-nn-epoch21-robacc96.pt       model-nn-epoch7-robacc88.pt\r\n",
      "model-nn-epoch22-robacc83.pt       model-nn-epoch7-robacc94.pt\r\n",
      "model-nn-epoch22-robacc90.pt       model-nn-epoch7-robacc95.pt\r\n",
      "model-nn-epoch22-robacc96.pt       model-nn-epoch8-robacc53.pt\r\n",
      "model-nn-epoch23-robacc83.pt       model-nn-epoch8-robacc68.pt\r\n",
      "model-nn-epoch23-robacc90.pt       model-nn-epoch8-robacc81.pt\r\n",
      "model-nn-epoch24-robacc83.pt       model-nn-epoch8-robacc83.pt\r\n",
      "model-nn-epoch24-robacc90.pt       model-nn-epoch8-robacc88.pt\r\n",
      "model-nn-epoch24-robacc96.pt       model-nn-epoch8-robacc93.pt\r\n",
      "model-nn-epoch25-robacc83.pt       model-nn-epoch8-robacc95.pt\r\n",
      "model-nn-epoch25-robacc90.pt       model-nn-epoch9-robacc52.pt\r\n",
      "model-nn-epoch25-robacc96.pt       model-nn-epoch9-robacc75.pt\r\n",
      "model-nn-epoch26-robacc83.pt       model-nn-epoch9-robacc81.pt\r\n",
      "model-nn-epoch26-robacc90.pt       model-nn-epoch9-robacc83.pt\r\n",
      "model-nn-epoch26-robacc96.pt       model-nn-epoch9-robacc89.pt\r\n",
      "model-nn-epoch27-robacc84.pt       model-nn-epoch9-robacc94.pt\r\n",
      "model-nn-epoch27-robacc90.pt       model-nn-epoch9-robacc95.pt\r\n"
     ]
    }
   ],
   "source": [
    "ls ../SmallCNN_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SATInf = Net().to(DEVICE)\n",
    "#model_SATInf = nn.DataParallel(model_SATInf)\n",
    "#load state dict here\n",
    "#w = 46\n",
    "#string = '../WRN_ATENT_lr0p1_decay/model-nn-epoch'+str(76)+'-robacc57'+'.pt' #//trained till 49 in WRN_ATTENT, till 74 in WRN_ATTENT2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../WRN_ATENT_lr0p1_decay/model-nn-epoch76-robacc57.pt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(WrappedModel, self).__init__()\n",
    "        self.module = module # that I actually define.\n",
    "    def forward(self, x):\n",
    "        return self.module(x)\n",
    "\n",
    "model = getattr(models, args.model)(args)\n",
    "model = WrappedModel(model)\n",
    "state_dict = torch.load(modelname)['state_dict']\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " net.module.load_state_dict(pertained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for WideResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"block1.layer.0.bn1.weight\", \"block1.layer.0.bn1.bias\", \"block1.layer.0.bn1.running_mean\", \"block1.layer.0.bn1.running_var\", \"block1.layer.0.conv1.weight\", \"block1.layer.0.bn2.weight\", \"block1.layer.0.bn2.bias\", \"block1.layer.0.bn2.running_mean\", \"block1.layer.0.bn2.running_var\", \"block1.layer.0.conv2.weight\", \"block1.layer.0.convShortcut.weight\", \"block1.layer.1.bn1.weight\", \"block1.layer.1.bn1.bias\", \"block1.layer.1.bn1.running_mean\", \"block1.layer.1.bn1.running_var\", \"block1.layer.1.conv1.weight\", \"block1.layer.1.bn2.weight\", \"block1.layer.1.bn2.bias\", \"block1.layer.1.bn2.running_mean\", \"block1.layer.1.bn2.running_var\", \"block1.layer.1.conv2.weight\", \"block1.layer.2.bn1.weight\", \"block1.layer.2.bn1.bias\", \"block1.layer.2.bn1.running_mean\", \"block1.layer.2.bn1.running_var\", \"block1.layer.2.conv1.weight\", \"block1.layer.2.bn2.weight\", \"block1.layer.2.bn2.bias\", \"block1.layer.2.bn2.running_mean\", \"block1.layer.2.bn2.running_var\", \"block1.layer.2.conv2.weight\", \"block1.layer.3.bn1.weight\", \"block1.layer.3.bn1.bias\", \"block1.layer.3.bn1.running_mean\", \"block1.layer.3.bn1.running_var\", \"block1.layer.3.conv1.weight\", \"block1.layer.3.bn2.weight\", \"block1.layer.3.bn2.bias\", \"block1.layer.3.bn2.running_mean\", \"block1.layer.3.bn2.running_var\", \"block1.layer.3.conv2.weight\", \"block1.layer.4.bn1.weight\", \"block1.layer.4.bn1.bias\", \"block1.layer.4.bn1.running_mean\", \"block1.layer.4.bn1.running_var\", \"block1.layer.4.conv1.weight\", \"block1.layer.4.bn2.weight\", \"block1.layer.4.bn2.bias\", \"block1.layer.4.bn2.running_mean\", \"block1.layer.4.bn2.running_var\", \"block1.layer.4.conv2.weight\", \"sub_block1.layer.0.bn1.weight\", \"sub_block1.layer.0.bn1.bias\", \"sub_block1.layer.0.bn1.running_mean\", \"sub_block1.layer.0.bn1.running_var\", \"sub_block1.layer.0.conv1.weight\", \"sub_block1.layer.0.bn2.weight\", \"sub_block1.layer.0.bn2.bias\", \"sub_block1.layer.0.bn2.running_mean\", \"sub_block1.layer.0.bn2.running_var\", \"sub_block1.layer.0.conv2.weight\", \"sub_block1.layer.0.convShortcut.weight\", \"sub_block1.layer.1.bn1.weight\", \"sub_block1.layer.1.bn1.bias\", \"sub_block1.layer.1.bn1.running_mean\", \"sub_block1.layer.1.bn1.running_var\", \"sub_block1.layer.1.conv1.weight\", \"sub_block1.layer.1.bn2.weight\", \"sub_block1.layer.1.bn2.bias\", \"sub_block1.layer.1.bn2.running_mean\", \"sub_block1.layer.1.bn2.running_var\", \"sub_block1.layer.1.conv2.weight\", \"sub_block1.layer.2.bn1.weight\", \"sub_block1.layer.2.bn1.bias\", \"sub_block1.layer.2.bn1.running_mean\", \"sub_block1.layer.2.bn1.running_var\", \"sub_block1.layer.2.conv1.weight\", \"sub_block1.layer.2.bn2.weight\", \"sub_block1.layer.2.bn2.bias\", \"sub_block1.layer.2.bn2.running_mean\", \"sub_block1.layer.2.bn2.running_var\", \"sub_block1.layer.2.conv2.weight\", \"sub_block1.layer.3.bn1.weight\", \"sub_block1.layer.3.bn1.bias\", \"sub_block1.layer.3.bn1.running_mean\", \"sub_block1.layer.3.bn1.running_var\", \"sub_block1.layer.3.conv1.weight\", \"sub_block1.layer.3.bn2.weight\", \"sub_block1.layer.3.bn2.bias\", \"sub_block1.layer.3.bn2.running_mean\", \"sub_block1.layer.3.bn2.running_var\", \"sub_block1.layer.3.conv2.weight\", \"sub_block1.layer.4.bn1.weight\", \"sub_block1.layer.4.bn1.bias\", \"sub_block1.layer.4.bn1.running_mean\", \"sub_block1.layer.4.bn1.running_var\", \"sub_block1.layer.4.conv1.weight\", \"sub_block1.layer.4.bn2.weight\", \"sub_block1.layer.4.bn2.bias\", \"sub_block1.layer.4.bn2.running_mean\", \"sub_block1.layer.4.bn2.running_var\", \"sub_block1.layer.4.conv2.weight\", \"block2.layer.0.bn1.weight\", \"block2.layer.0.bn1.bias\", \"block2.layer.0.bn1.running_mean\", \"block2.layer.0.bn1.running_var\", \"block2.layer.0.conv1.weight\", \"block2.layer.0.bn2.weight\", \"block2.layer.0.bn2.bias\", \"block2.layer.0.bn2.running_mean\", \"block2.layer.0.bn2.running_var\", \"block2.layer.0.conv2.weight\", \"block2.layer.0.convShortcut.weight\", \"block2.layer.1.bn1.weight\", \"block2.layer.1.bn1.bias\", \"block2.layer.1.bn1.running_mean\", \"block2.layer.1.bn1.running_var\", \"block2.layer.1.conv1.weight\", \"block2.layer.1.bn2.weight\", \"block2.layer.1.bn2.bias\", \"block2.layer.1.bn2.running_mean\", \"block2.layer.1.bn2.running_var\", \"block2.layer.1.conv2.weight\", \"block2.layer.2.bn1.weight\", \"block2.layer.2.bn1.bias\", \"block2.layer.2.bn1.running_mean\", \"block2.layer.2.bn1.running_var\", \"block2.layer.2.conv1.weight\", \"block2.layer.2.bn2.weight\", \"block2.layer.2.bn2.bias\", \"block2.layer.2.bn2.running_mean\", \"block2.layer.2.bn2.running_var\", \"block2.layer.2.conv2.weight\", \"block2.layer.3.bn1.weight\", \"block2.layer.3.bn1.bias\", \"block2.layer.3.bn1.running_mean\", \"block2.layer.3.bn1.running_var\", \"block2.layer.3.conv1.weight\", \"block2.layer.3.bn2.weight\", \"block2.layer.3.bn2.bias\", \"block2.layer.3.bn2.running_mean\", \"block2.layer.3.bn2.running_var\", \"block2.layer.3.conv2.weight\", \"block2.layer.4.bn1.weight\", \"block2.layer.4.bn1.bias\", \"block2.layer.4.bn1.running_mean\", \"block2.layer.4.bn1.running_var\", \"block2.layer.4.conv1.weight\", \"block2.layer.4.bn2.weight\", \"block2.layer.4.bn2.bias\", \"block2.layer.4.bn2.running_mean\", \"block2.layer.4.bn2.running_var\", \"block2.layer.4.conv2.weight\", \"block3.layer.0.bn1.weight\", \"block3.layer.0.bn1.bias\", \"block3.layer.0.bn1.running_mean\", \"block3.layer.0.bn1.running_var\", \"block3.layer.0.conv1.weight\", \"block3.layer.0.bn2.weight\", \"block3.layer.0.bn2.bias\", \"block3.layer.0.bn2.running_mean\", \"block3.layer.0.bn2.running_var\", \"block3.layer.0.conv2.weight\", \"block3.layer.0.convShortcut.weight\", \"block3.layer.1.bn1.weight\", \"block3.layer.1.bn1.bias\", \"block3.layer.1.bn1.running_mean\", \"block3.layer.1.bn1.running_var\", \"block3.layer.1.conv1.weight\", \"block3.layer.1.bn2.weight\", \"block3.layer.1.bn2.bias\", \"block3.layer.1.bn2.running_mean\", \"block3.layer.1.bn2.running_var\", \"block3.layer.1.conv2.weight\", \"block3.layer.2.bn1.weight\", \"block3.layer.2.bn1.bias\", \"block3.layer.2.bn1.running_mean\", \"block3.layer.2.bn1.running_var\", \"block3.layer.2.conv1.weight\", \"block3.layer.2.bn2.weight\", \"block3.layer.2.bn2.bias\", \"block3.layer.2.bn2.running_mean\", \"block3.layer.2.bn2.running_var\", \"block3.layer.2.conv2.weight\", \"block3.layer.3.bn1.weight\", \"block3.layer.3.bn1.bias\", \"block3.layer.3.bn1.running_mean\", \"block3.layer.3.bn1.running_var\", \"block3.layer.3.conv1.weight\", \"block3.layer.3.bn2.weight\", \"block3.layer.3.bn2.bias\", \"block3.layer.3.bn2.running_mean\", \"block3.layer.3.bn2.running_var\", \"block3.layer.3.conv2.weight\", \"block3.layer.4.bn1.weight\", \"block3.layer.4.bn1.bias\", \"block3.layer.4.bn1.running_mean\", \"block3.layer.4.bn1.running_var\", \"block3.layer.4.conv1.weight\", \"block3.layer.4.bn2.weight\", \"block3.layer.4.bn2.bias\", \"block3.layer.4.bn2.running_mean\", \"block3.layer.4.bn2.running_var\", \"block3.layer.4.conv2.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"module.conv1.weight\", \"module.block1.layer.0.bn1.weight\", \"module.block1.layer.0.bn1.bias\", \"module.block1.layer.0.bn1.running_mean\", \"module.block1.layer.0.bn1.running_var\", \"module.block1.layer.0.bn1.num_batches_tracked\", \"module.block1.layer.0.conv1.weight\", \"module.block1.layer.0.bn2.weight\", \"module.block1.layer.0.bn2.bias\", \"module.block1.layer.0.bn2.running_mean\", \"module.block1.layer.0.bn2.running_var\", \"module.block1.layer.0.bn2.num_batches_tracked\", \"module.block1.layer.0.conv2.weight\", \"module.block1.layer.0.convShortcut.weight\", \"module.block1.layer.1.bn1.weight\", \"module.block1.layer.1.bn1.bias\", \"module.block1.layer.1.bn1.running_mean\", \"module.block1.layer.1.bn1.running_var\", \"module.block1.layer.1.bn1.num_batches_tracked\", \"module.block1.layer.1.conv1.weight\", \"module.block1.layer.1.bn2.weight\", \"module.block1.layer.1.bn2.bias\", \"module.block1.layer.1.bn2.running_mean\", \"module.block1.layer.1.bn2.running_var\", \"module.block1.layer.1.bn2.num_batches_tracked\", \"module.block1.layer.1.conv2.weight\", \"module.block1.layer.2.bn1.weight\", \"module.block1.layer.2.bn1.bias\", \"module.block1.layer.2.bn1.running_mean\", \"module.block1.layer.2.bn1.running_var\", \"module.block1.layer.2.bn1.num_batches_tracked\", \"module.block1.layer.2.conv1.weight\", \"module.block1.layer.2.bn2.weight\", \"module.block1.layer.2.bn2.bias\", \"module.block1.layer.2.bn2.running_mean\", \"module.block1.layer.2.bn2.running_var\", \"module.block1.layer.2.bn2.num_batches_tracked\", \"module.block1.layer.2.conv2.weight\", \"module.block1.layer.3.bn1.weight\", \"module.block1.layer.3.bn1.bias\", \"module.block1.layer.3.bn1.running_mean\", \"module.block1.layer.3.bn1.running_var\", \"module.block1.layer.3.bn1.num_batches_tracked\", \"module.block1.layer.3.conv1.weight\", \"module.block1.layer.3.bn2.weight\", \"module.block1.layer.3.bn2.bias\", \"module.block1.layer.3.bn2.running_mean\", \"module.block1.layer.3.bn2.running_var\", \"module.block1.layer.3.bn2.num_batches_tracked\", \"module.block1.layer.3.conv2.weight\", \"module.block1.layer.4.bn1.weight\", \"module.block1.layer.4.bn1.bias\", \"module.block1.layer.4.bn1.running_mean\", \"module.block1.layer.4.bn1.running_var\", \"module.block1.layer.4.bn1.num_batches_tracked\", \"module.block1.layer.4.conv1.weight\", \"module.block1.layer.4.bn2.weight\", \"module.block1.layer.4.bn2.bias\", \"module.block1.layer.4.bn2.running_mean\", \"module.block1.layer.4.bn2.running_var\", \"module.block1.layer.4.bn2.num_batches_tracked\", \"module.block1.layer.4.conv2.weight\", \"module.sub_block1.layer.0.bn1.weight\", \"module.sub_block1.layer.0.bn1.bias\", \"module.sub_block1.layer.0.bn1.running_mean\", \"module.sub_block1.layer.0.bn1.running_var\", \"module.sub_block1.layer.0.bn1.num_batches_tracked\", \"module.sub_block1.layer.0.conv1.weight\", \"module.sub_block1.layer.0.bn2.weight\", \"module.sub_block1.layer.0.bn2.bias\", \"module.sub_block1.layer.0.bn2.running_mean\", \"module.sub_block1.layer.0.bn2.running_var\", \"module.sub_block1.layer.0.bn2.num_batches_tracked\", \"module.sub_block1.layer.0.conv2.weight\", \"module.sub_block1.layer.0.convShortcut.weight\", \"module.sub_block1.layer.1.bn1.weight\", \"module.sub_block1.layer.1.bn1.bias\", \"module.sub_block1.layer.1.bn1.running_mean\", \"module.sub_block1.layer.1.bn1.running_var\", \"module.sub_block1.layer.1.bn1.num_batches_tracked\", \"module.sub_block1.layer.1.conv1.weight\", \"module.sub_block1.layer.1.bn2.weight\", \"module.sub_block1.layer.1.bn2.bias\", \"module.sub_block1.layer.1.bn2.running_mean\", \"module.sub_block1.layer.1.bn2.running_var\", \"module.sub_block1.layer.1.bn2.num_batches_tracked\", \"module.sub_block1.layer.1.conv2.weight\", \"module.sub_block1.layer.2.bn1.weight\", \"module.sub_block1.layer.2.bn1.bias\", \"module.sub_block1.layer.2.bn1.running_mean\", \"module.sub_block1.layer.2.bn1.running_var\", \"module.sub_block1.layer.2.bn1.num_batches_tracked\", \"module.sub_block1.layer.2.conv1.weight\", \"module.sub_block1.layer.2.bn2.weight\", \"module.sub_block1.layer.2.bn2.bias\", \"module.sub_block1.layer.2.bn2.running_mean\", \"module.sub_block1.layer.2.bn2.running_var\", \"module.sub_block1.layer.2.bn2.num_batches_tracked\", \"module.sub_block1.layer.2.conv2.weight\", \"module.sub_block1.layer.3.bn1.weight\", \"module.sub_block1.layer.3.bn1.bias\", \"module.sub_block1.layer.3.bn1.running_mean\", \"module.sub_block1.layer.3.bn1.running_var\", \"module.sub_block1.layer.3.bn1.num_batches_tracked\", \"module.sub_block1.layer.3.conv1.weight\", \"module.sub_block1.layer.3.bn2.weight\", \"module.sub_block1.layer.3.bn2.bias\", \"module.sub_block1.layer.3.bn2.running_mean\", \"module.sub_block1.layer.3.bn2.running_var\", \"module.sub_block1.layer.3.bn2.num_batches_tracked\", \"module.sub_block1.layer.3.conv2.weight\", \"module.sub_block1.layer.4.bn1.weight\", \"module.sub_block1.layer.4.bn1.bias\", \"module.sub_block1.layer.4.bn1.running_mean\", \"module.sub_block1.layer.4.bn1.running_var\", \"module.sub_block1.layer.4.bn1.num_batches_tracked\", \"module.sub_block1.layer.4.conv1.weight\", \"module.sub_block1.layer.4.bn2.weight\", \"module.sub_block1.layer.4.bn2.bias\", \"module.sub_block1.layer.4.bn2.running_mean\", \"module.sub_block1.layer.4.bn2.running_var\", \"module.sub_block1.layer.4.bn2.num_batches_tracked\", \"module.sub_block1.layer.4.conv2.weight\", \"module.block2.layer.0.bn1.weight\", \"module.block2.layer.0.bn1.bias\", \"module.block2.layer.0.bn1.running_mean\", \"module.block2.layer.0.bn1.running_var\", \"module.block2.layer.0.bn1.num_batches_tracked\", \"module.block2.layer.0.conv1.weight\", \"module.block2.layer.0.bn2.weight\", \"module.block2.layer.0.bn2.bias\", \"module.block2.layer.0.bn2.running_mean\", \"module.block2.layer.0.bn2.running_var\", \"module.block2.layer.0.bn2.num_batches_tracked\", \"module.block2.layer.0.conv2.weight\", \"module.block2.layer.0.convShortcut.weight\", \"module.block2.layer.1.bn1.weight\", \"module.block2.layer.1.bn1.bias\", \"module.block2.layer.1.bn1.running_mean\", \"module.block2.layer.1.bn1.running_var\", \"module.block2.layer.1.bn1.num_batches_tracked\", \"module.block2.layer.1.conv1.weight\", \"module.block2.layer.1.bn2.weight\", \"module.block2.layer.1.bn2.bias\", \"module.block2.layer.1.bn2.running_mean\", \"module.block2.layer.1.bn2.running_var\", \"module.block2.layer.1.bn2.num_batches_tracked\", \"module.block2.layer.1.conv2.weight\", \"module.block2.layer.2.bn1.weight\", \"module.block2.layer.2.bn1.bias\", \"module.block2.layer.2.bn1.running_mean\", \"module.block2.layer.2.bn1.running_var\", \"module.block2.layer.2.bn1.num_batches_tracked\", \"module.block2.layer.2.conv1.weight\", \"module.block2.layer.2.bn2.weight\", \"module.block2.layer.2.bn2.bias\", \"module.block2.layer.2.bn2.running_mean\", \"module.block2.layer.2.bn2.running_var\", \"module.block2.layer.2.bn2.num_batches_tracked\", \"module.block2.layer.2.conv2.weight\", \"module.block2.layer.3.bn1.weight\", \"module.block2.layer.3.bn1.bias\", \"module.block2.layer.3.bn1.running_mean\", \"module.block2.layer.3.bn1.running_var\", \"module.block2.layer.3.bn1.num_batches_tracked\", \"module.block2.layer.3.conv1.weight\", \"module.block2.layer.3.bn2.weight\", \"module.block2.layer.3.bn2.bias\", \"module.block2.layer.3.bn2.running_mean\", \"module.block2.layer.3.bn2.running_var\", \"module.block2.layer.3.bn2.num_batches_tracked\", \"module.block2.layer.3.conv2.weight\", \"module.block2.layer.4.bn1.weight\", \"module.block2.layer.4.bn1.bias\", \"module.block2.layer.4.bn1.running_mean\", \"module.block2.layer.4.bn1.running_var\", \"module.block2.layer.4.bn1.num_batches_tracked\", \"module.block2.layer.4.conv1.weight\", \"module.block2.layer.4.bn2.weight\", \"module.block2.layer.4.bn2.bias\", \"module.block2.layer.4.bn2.running_mean\", \"module.block2.layer.4.bn2.running_var\", \"module.block2.layer.4.bn2.num_batches_tracked\", \"module.block2.layer.4.conv2.weight\", \"module.block3.layer.0.bn1.weight\", \"module.block3.layer.0.bn1.bias\", \"module.block3.layer.0.bn1.running_mean\", \"module.block3.layer.0.bn1.running_var\", \"module.block3.layer.0.bn1.num_batches_tracked\", \"module.block3.layer.0.conv1.weight\", \"module.block3.layer.0.bn2.weight\", \"module.block3.layer.0.bn2.bias\", \"module.block3.layer.0.bn2.running_mean\", \"module.block3.layer.0.bn2.running_var\", \"module.block3.layer.0.bn2.num_batches_tracked\", \"module.block3.layer.0.conv2.weight\", \"module.block3.layer.0.convShortcut.weight\", \"module.block3.layer.1.bn1.weight\", \"module.block3.layer.1.bn1.bias\", \"module.block3.layer.1.bn1.running_mean\", \"module.block3.layer.1.bn1.running_var\", \"module.block3.layer.1.bn1.num_batches_tracked\", \"module.block3.layer.1.conv1.weight\", \"module.block3.layer.1.bn2.weight\", \"module.block3.layer.1.bn2.bias\", \"module.block3.layer.1.bn2.running_mean\", \"module.block3.layer.1.bn2.running_var\", \"module.block3.layer.1.bn2.num_batches_tracked\", \"module.block3.layer.1.conv2.weight\", \"module.block3.layer.2.bn1.weight\", \"module.block3.layer.2.bn1.bias\", \"module.block3.layer.2.bn1.running_mean\", \"module.block3.layer.2.bn1.running_var\", \"module.block3.layer.2.bn1.num_batches_tracked\", \"module.block3.layer.2.conv1.weight\", \"module.block3.layer.2.bn2.weight\", \"module.block3.layer.2.bn2.bias\", \"module.block3.layer.2.bn2.running_mean\", \"module.block3.layer.2.bn2.running_var\", \"module.block3.layer.2.bn2.num_batches_tracked\", \"module.block3.layer.2.conv2.weight\", \"module.block3.layer.3.bn1.weight\", \"module.block3.layer.3.bn1.bias\", \"module.block3.layer.3.bn1.running_mean\", \"module.block3.layer.3.bn1.running_var\", \"module.block3.layer.3.bn1.num_batches_tracked\", \"module.block3.layer.3.conv1.weight\", \"module.block3.layer.3.bn2.weight\", \"module.block3.layer.3.bn2.bias\", \"module.block3.layer.3.bn2.running_mean\", \"module.block3.layer.3.bn2.running_var\", \"module.block3.layer.3.bn2.num_batches_tracked\", \"module.block3.layer.3.conv2.weight\", \"module.block3.layer.4.bn1.weight\", \"module.block3.layer.4.bn1.bias\", \"module.block3.layer.4.bn1.running_mean\", \"module.block3.layer.4.bn1.running_var\", \"module.block3.layer.4.bn1.num_batches_tracked\", \"module.block3.layer.4.conv1.weight\", \"module.block3.layer.4.bn2.weight\", \"module.block3.layer.4.bn2.bias\", \"module.block3.layer.4.bn2.running_mean\", \"module.block3.layer.4.bn2.running_var\", \"module.block3.layer.4.bn2.num_batches_tracked\", \"module.block3.layer.4.conv2.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.fc.weight\", \"module.fc.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4cf4db2496e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_SATInf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#eval_train(model_SATInf, DEVICE, train_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1045\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for WideResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"block1.layer.0.bn1.weight\", \"block1.layer.0.bn1.bias\", \"block1.layer.0.bn1.running_mean\", \"block1.layer.0.bn1.running_var\", \"block1.layer.0.conv1.weight\", \"block1.layer.0.bn2.weight\", \"block1.layer.0.bn2.bias\", \"block1.layer.0.bn2.running_mean\", \"block1.layer.0.bn2.running_var\", \"block1.layer.0.conv2.weight\", \"block1.layer.0.convShortcut.weight\", \"block1.layer.1.bn1.weight\", \"block1.layer.1.bn1.bias\", \"block1.layer.1.bn1.running_mean\", \"block1.layer.1.bn1.running_var\", \"block1.layer.1.conv1.weight\", \"block1.layer.1.bn2.weight\", \"block1.layer.1.bn2.bias\", \"block1.layer.1.bn2.running_mean\", \"block1.layer.1.bn2.running_var\", \"block1.layer.1.conv2.weight\", \"block1.layer.2.bn1.weight\", \"block1.layer.2.bn1.bias\", \"block1.layer.2.bn1.running_mean\", \"block1.layer.2.bn1.running_var\", \"block1.layer.2.conv1.weight\", \"block1.layer.2.bn2.weight\", \"block1.layer.2.bn2.bias\", \"block1.layer.2.bn2.running_mean\", \"block1.layer.2.bn2.running_var\", \"block1.layer.2.conv2.weight\", \"block1.layer.3.bn1.weight\", \"block1.layer.3.bn1.bias\", \"block1.layer.3.bn1.running_mean\", \"block1.layer.3.bn1.running_var\", \"block1.layer.3.conv1.weight\", \"block1.layer.3.bn2.weight\", \"block1.layer.3.bn2.bias\", \"block1.layer.3.bn2.running_mean\", \"block1.layer.3.bn2.running_var\", \"block1.layer.3.conv2.weight\", \"block1.layer.4.bn1.weight\", \"block1.layer.4.bn1.bias\", \"block1.layer.4.bn1.running_mean\", \"block1.layer.4.bn1.running_var\", \"block1.layer.4.conv1.weight\", \"block1.layer.4.bn2.weight\", \"block1.layer.4.bn2.bias\", \"block1.layer.4.bn2.running_mean\", \"block1.layer.4.bn2.running_var\", \"block1.layer.4.conv2.weight\", \"sub_block1.layer.0.bn1.weight\", \"sub_block1.layer.0.bn1.bias\", \"sub_block1.layer.0.bn1.running_mean\", \"sub_block1.layer.0.bn1.running_var\", \"sub_block1.layer.0.conv1.weight\", \"sub_block1.layer.0.bn2.weight\", \"sub_block1.layer.0.bn2.bias\", \"sub_block1.layer.0.bn2.running_mean\", \"sub_block1.layer.0.bn2.running_var\", \"sub_block1.layer.0.conv2.weight\", \"sub_block1.layer.0.convShortcut.weight\", \"sub_block1.layer.1.bn1.weight\", \"sub_block1.layer.1.bn1.bias\", \"sub_block1.layer.1.bn1.running_mean\", \"sub_block1.layer.1.bn1.running_var\", \"sub_block1.layer.1.conv1.weight\", \"sub_block1.layer.1.bn2.weight\", \"sub_block1.layer.1.bn2.bias\", \"sub_block1.layer.1.bn2.running_mean\", \"sub_block1.layer.1.bn2.running_var\", \"sub_block1.layer.1.conv2.weight\", \"sub_block1.layer.2.bn1.weight\", \"sub_block1.layer.2.bn1.bias\", \"sub_block1.layer.2.bn1.running_mean\", \"sub_block1.layer.2.bn1.running_var\", \"sub_block1.layer.2.conv1.weight\", \"sub_block1.layer.2.bn2.weight\", \"sub_block1.layer.2.bn2.bias\", \"sub_block1.layer.2.bn2.running_mean\", \"sub_block1.layer.2.bn2.running_var\", \"sub_block1.layer.2.conv2.weight\", \"sub_block1.layer.3.bn1.weight\", \"sub_block1.layer.3.bn1.bias\", \"sub_block1.layer.3.bn1.running_mean\", \"sub_block1.layer.3.bn1.running_var\", \"sub_block1.layer.3.conv1.weight\", \"sub_block1.layer.3.bn2.weight\", \"sub_block1.layer.3.bn2.bias\", \"sub_block1.layer.3.bn2.running_mean\", \"sub_block1.layer.3.bn2.running_var\", \"sub_block1.layer.3.conv2.weight\", \"sub_block1.layer.4.bn1.weight\", \"sub_block1.layer.4.bn1.bias\", \"sub_block1.layer.4.bn1.running_mean\", \"sub_block1.layer.4.bn1.running_var\", \"sub_block1.layer.4.conv1.weight\", \"sub_block1.layer.4.bn2.weight\", \"sub_block1.layer.4.bn2.bias\", \"sub_block1.layer.4.bn2.running_mean\", \"sub_block1.layer.4.bn2.running_var\", \"sub_block1.layer.4.conv2.weight\", \"block2.layer.0.bn1.weight\", \"block2.layer.0.bn1.bias\", \"block2.layer.0.bn1.running_mean\", \"block2.layer.0.bn1.running_var\", \"block2.layer.0.conv1.weight\", \"block2.layer.0.bn2.weight\", \"block2.layer.0.bn2.bias\", \"block2.layer.0.bn2.running_mean\", \"block2.layer.0.bn2.running_var\", \"block2.layer.0.conv2.weight\", \"block2.layer.0.convShortcut.weight\", \"block2.layer.1.bn1.weight\", \"block2.layer.1.bn1.bias\", \"block2.layer.1.bn1.running_mean\", \"block2.layer.1.bn1.running_var\", \"block2.layer.1.conv1.weight\", \"block2.layer.1.bn2.weight\", \"block2.layer.1.bn2.bias\", \"block2.layer.1.bn2.running_mean\", \"block2.layer.1.bn2.running_var\", \"block2.layer.1.conv2.weight\", \"block2.layer.2.bn1.weight\", \"block2.layer.2.bn1.bias\", \"block2.layer.2.bn1.running_mean\", \"block2.layer.2.bn1.running_var\", \"block2.layer.2.conv1.weight\", \"block2.layer.2.bn2.weight\", \"block2.layer.2.bn2.bias\", \"block2.layer.2.bn2.running_mean\", \"block2.layer.2.bn2.running_var\", \"block2.layer.2.conv2.weight\", \"block2.layer.3.bn1.weight\", \"block2.layer.3.bn1.bias\", \"block2.layer.3.bn1.running_mean\", \"block2.layer.3.bn1.running_var\", \"block2.layer.3.conv1.weight\", \"block2.layer.3.bn2.weight\", \"block2.layer.3.bn2.bias\", \"block2.layer.3.bn2.running_mean\", \"block2.layer.3.bn2.running_var\", \"block2.layer.3.conv2.weight\", \"block2.layer.4.bn1.weight\", \"block2.layer.4.bn1.bias\", \"block2.layer.4.bn1.running_mean\", \"block2.layer.4.bn1.running_var\", \"block2.layer.4.conv1.weight\", \"block2.layer.4.bn2.weight\", \"block2.layer.4.bn2.bias\", \"block2.layer.4.bn2.running_mean\", \"block2.layer.4.bn2.running_var\", \"block2.layer.4.conv2.weight\", \"block3.layer.0.bn1.weight\", \"block3.layer.0.bn1.bias\", \"block3.layer.0.bn1.running_mean\", \"block3.layer.0.bn1.running_var\", \"block3.layer.0.conv1.weight\", \"block3.layer.0.bn2.weight\", \"block3.layer.0.bn2.bias\", \"block3.layer.0.bn2.running_mean\", \"block3.layer.0.bn2.running_var\", \"block3.layer.0.conv2.weight\", \"block3.layer.0.convShortcut.weight\", \"block3.layer.1.bn1.weight\", \"block3.layer.1.bn1.bias\", \"block3.layer.1.bn1.running_mean\", \"block3.layer.1.bn1.running_var\", \"block3.layer.1.conv1.weight\", \"block3.layer.1.bn2.weight\", \"block3.layer.1.bn2.bias\", \"block3.layer.1.bn2.running_mean\", \"block3.layer.1.bn2.running_var\", \"block3.layer.1.conv2.weight\", \"block3.layer.2.bn1.weight\", \"block3.layer.2.bn1.bias\", \"block3.layer.2.bn1.running_mean\", \"block3.layer.2.bn1.running_var\", \"block3.layer.2.conv1.weight\", \"block3.layer.2.bn2.weight\", \"block3.layer.2.bn2.bias\", \"block3.layer.2.bn2.running_mean\", \"block3.layer.2.bn2.running_var\", \"block3.layer.2.conv2.weight\", \"block3.layer.3.bn1.weight\", \"block3.layer.3.bn1.bias\", \"block3.layer.3.bn1.running_mean\", \"block3.layer.3.bn1.running_var\", \"block3.layer.3.conv1.weight\", \"block3.layer.3.bn2.weight\", \"block3.layer.3.bn2.bias\", \"block3.layer.3.bn2.running_mean\", \"block3.layer.3.bn2.running_var\", \"block3.layer.3.conv2.weight\", \"block3.layer.4.bn1.weight\", \"block3.layer.4.bn1.bias\", \"block3.layer.4.bn1.running_mean\", \"block3.layer.4.bn1.running_var\", \"block3.layer.4.conv1.weight\", \"block3.layer.4.bn2.weight\", \"block3.layer.4.bn2.bias\", \"block3.layer.4.bn2.running_mean\", \"block3.layer.4.bn2.running_var\", \"block3.layer.4.conv2.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"fc.weight\", \"fc.bias\". \n\tUnexpected key(s) in state_dict: \"module.conv1.weight\", \"module.block1.layer.0.bn1.weight\", \"module.block1.layer.0.bn1.bias\", \"module.block1.layer.0.bn1.running_mean\", \"module.block1.layer.0.bn1.running_var\", \"module.block1.layer.0.bn1.num_batches_tracked\", \"module.block1.layer.0.conv1.weight\", \"module.block1.layer.0.bn2.weight\", \"module.block1.layer.0.bn2.bias\", \"module.block1.layer.0.bn2.running_mean\", \"module.block1.layer.0.bn2.running_var\", \"module.block1.layer.0.bn2.num_batches_tracked\", \"module.block1.layer.0.conv2.weight\", \"module.block1.layer.0.convShortcut.weight\", \"module.block1.layer.1.bn1.weight\", \"module.block1.layer.1.bn1.bias\", \"module.block1.layer.1.bn1.running_mean\", \"module.block1.layer.1.bn1.running_var\", \"module.block1.layer.1.bn1.num_batches_tracked\", \"module.block1.layer.1.conv1.weight\", \"module.block1.layer.1.bn2.weight\", \"module.block1.layer.1.bn2.bias\", \"module.block1.layer.1.bn2.running_mean\", \"module.block1.layer.1.bn2.running_var\", \"module.block1.layer.1.bn2.num_batches_tracked\", \"module.block1.layer.1.conv2.weight\", \"module.block1.layer.2.bn1.weight\", \"module.block1.layer.2.bn1.bias\", \"module.block1.layer.2.bn1.running_mean\", \"module.block1.layer.2.bn1.running_var\", \"module.block1.layer.2.bn1.num_batches_tracked\", \"module.block1.layer.2.conv1.weight\", \"module.block1.layer.2.bn2.weight\", \"module.block1.layer.2.bn2.bias\", \"module.block1.layer.2.bn2.running_mean\", \"module.block1.layer.2.bn2.running_var\", \"module.block1.layer.2.bn2.num_batches_tracked\", \"module.block1.layer.2.conv2.weight\", \"module.block1.layer.3.bn1.weight\", \"module.block1.layer.3.bn1.bias\", \"module.block1.layer.3.bn1.running_mean\", \"module.block1.layer.3.bn1.running_var\", \"module.block1.layer.3.bn1.num_batches_tracked\", \"module.block1.layer.3.conv1.weight\", \"module.block1.layer.3.bn2.weight\", \"module.block1.layer.3.bn2.bias\", \"module.block1.layer.3.bn2.running_mean\", \"module.block1.layer.3.bn2.running_var\", \"module.block1.layer.3.bn2.num_batches_tracked\", \"module.block1.layer.3.conv2.weight\", \"module.block1.layer.4.bn1.weight\", \"module.block1.layer.4.bn1.bias\", \"module.block1.layer.4.bn1.running_mean\", \"module.block1.layer.4.bn1.running_var\", \"module.block1.layer.4.bn1.num_batches_tracked\", \"module.block1.layer.4.conv1.weight\", \"module.block1.layer.4.bn2.weight\", \"module.block1.layer.4.bn2.bias\", \"module.block1.layer.4.bn2.running_mean\", \"module.block1.layer.4.bn2.running_var\", \"module.block1.layer.4.bn2.num_batches_tracked\", \"module.block1.layer.4.conv2.weight\", \"module.sub_block1.layer.0.bn1.weight\", \"module.sub_block1.layer.0.bn1.bias\", \"module.sub_block1.layer.0.bn1.running_mean\", \"module.sub_block1.layer.0.bn1.running_var\", \"module.sub_block1.layer.0.bn1.num_batches_tracked\", \"module.sub_block1.layer.0.conv1.weight\", \"module.sub_block1.layer.0.bn2.weight\", \"module.sub_block1.layer.0.bn2.bias\", \"module.sub_block1.layer.0.bn2.running_mean\", \"module.sub_block1.layer.0.bn2.running_var\", \"module.sub_block1.layer.0.bn2.num_batches_tracked\", \"module.sub_block1.layer.0.conv2.weight\", \"module.sub_block1.layer.0.convShortcut.weight\", \"module.sub_block1.layer.1.bn1.weight\", \"module.sub_block1.layer.1.bn1.bias\", \"module.sub_block1.layer.1.bn1.running_mean\", \"module.sub_block1.layer.1.bn1.running_var\", \"module.sub_block1.layer.1.bn1.num_batches_tracked\", \"module.sub_block1.layer.1.conv1.weight\", \"module.sub_block1.layer.1.bn2.weight\", \"module.sub_block1.layer.1.bn2.bias\", \"module.sub_block1.layer.1.bn2.running_mean\", \"module.sub_block1.layer.1.bn2.running_var\", \"module.sub_block1.layer.1.bn2.num_batches_tracked\", \"module.sub_block1.layer.1.conv2.weight\", \"module.sub_block1.layer.2.bn1.weight\", \"module.sub_block1.layer.2.bn1.bias\", \"module.sub_block1.layer.2.bn1.running_mean\", \"module.sub_block1.layer.2.bn1.running_var\", \"module.sub_block1.layer.2.bn1.num_batches_tracked\", \"module.sub_block1.layer.2.conv1.weight\", \"module.sub_block1.layer.2.bn2.weight\", \"module.sub_block1.layer.2.bn2.bias\", \"module.sub_block1.layer.2.bn2.running_mean\", \"module.sub_block1.layer.2.bn2.running_var\", \"module.sub_block1.layer.2.bn2.num_batches_tracked\", \"module.sub_block1.layer.2.conv2.weight\", \"module.sub_block1.layer.3.bn1.weight\", \"module.sub_block1.layer.3.bn1.bias\", \"module.sub_block1.layer.3.bn1.running_mean\", \"module.sub_block1.layer.3.bn1.running_var\", \"module.sub_block1.layer.3.bn1.num_batches_tracked\", \"module.sub_block1.layer.3.conv1.weight\", \"module.sub_block1.layer.3.bn2.weight\", \"module.sub_block1.layer.3.bn2.bias\", \"module.sub_block1.layer.3.bn2.running_mean\", \"module.sub_block1.layer.3.bn2.running_var\", \"module.sub_block1.layer.3.bn2.num_batches_tracked\", \"module.sub_block1.layer.3.conv2.weight\", \"module.sub_block1.layer.4.bn1.weight\", \"module.sub_block1.layer.4.bn1.bias\", \"module.sub_block1.layer.4.bn1.running_mean\", \"module.sub_block1.layer.4.bn1.running_var\", \"module.sub_block1.layer.4.bn1.num_batches_tracked\", \"module.sub_block1.layer.4.conv1.weight\", \"module.sub_block1.layer.4.bn2.weight\", \"module.sub_block1.layer.4.bn2.bias\", \"module.sub_block1.layer.4.bn2.running_mean\", \"module.sub_block1.layer.4.bn2.running_var\", \"module.sub_block1.layer.4.bn2.num_batches_tracked\", \"module.sub_block1.layer.4.conv2.weight\", \"module.block2.layer.0.bn1.weight\", \"module.block2.layer.0.bn1.bias\", \"module.block2.layer.0.bn1.running_mean\", \"module.block2.layer.0.bn1.running_var\", \"module.block2.layer.0.bn1.num_batches_tracked\", \"module.block2.layer.0.conv1.weight\", \"module.block2.layer.0.bn2.weight\", \"module.block2.layer.0.bn2.bias\", \"module.block2.layer.0.bn2.running_mean\", \"module.block2.layer.0.bn2.running_var\", \"module.block2.layer.0.bn2.num_batches_tracked\", \"module.block2.layer.0.conv2.weight\", \"module.block2.layer.0.convShortcut.weight\", \"module.block2.layer.1.bn1.weight\", \"module.block2.layer.1.bn1.bias\", \"module.block2.layer.1.bn1.running_mean\", \"module.block2.layer.1.bn1.running_var\", \"module.block2.layer.1.bn1.num_batches_tracked\", \"module.block2.layer.1.conv1.weight\", \"module.block2.layer.1.bn2.weight\", \"module.block2.layer.1.bn2.bias\", \"module.block2.layer.1.bn2.running_mean\", \"module.block2.layer.1.bn2.running_var\", \"module.block2.layer.1.bn2.num_batches_tracked\", \"module.block2.layer.1.conv2.weight\", \"module.block2.layer.2.bn1.weight\", \"module.block2.layer.2.bn1.bias\", \"module.block2.layer.2.bn1.running_mean\", \"module.block2.layer.2.bn1.running_var\", \"module.block2.layer.2.bn1.num_batches_tracked\", \"module.block2.layer.2.conv1.weight\", \"module.block2.layer.2.bn2.weight\", \"module.block2.layer.2.bn2.bias\", \"module.block2.layer.2.bn2.running_mean\", \"module.block2.layer.2.bn2.running_var\", \"module.block2.layer.2.bn2.num_batches_tracked\", \"module.block2.layer.2.conv2.weight\", \"module.block2.layer.3.bn1.weight\", \"module.block2.layer.3.bn1.bias\", \"module.block2.layer.3.bn1.running_mean\", \"module.block2.layer.3.bn1.running_var\", \"module.block2.layer.3.bn1.num_batches_tracked\", \"module.block2.layer.3.conv1.weight\", \"module.block2.layer.3.bn2.weight\", \"module.block2.layer.3.bn2.bias\", \"module.block2.layer.3.bn2.running_mean\", \"module.block2.layer.3.bn2.running_var\", \"module.block2.layer.3.bn2.num_batches_tracked\", \"module.block2.layer.3.conv2.weight\", \"module.block2.layer.4.bn1.weight\", \"module.block2.layer.4.bn1.bias\", \"module.block2.layer.4.bn1.running_mean\", \"module.block2.layer.4.bn1.running_var\", \"module.block2.layer.4.bn1.num_batches_tracked\", \"module.block2.layer.4.conv1.weight\", \"module.block2.layer.4.bn2.weight\", \"module.block2.layer.4.bn2.bias\", \"module.block2.layer.4.bn2.running_mean\", \"module.block2.layer.4.bn2.running_var\", \"module.block2.layer.4.bn2.num_batches_tracked\", \"module.block2.layer.4.conv2.weight\", \"module.block3.layer.0.bn1.weight\", \"module.block3.layer.0.bn1.bias\", \"module.block3.layer.0.bn1.running_mean\", \"module.block3.layer.0.bn1.running_var\", \"module.block3.layer.0.bn1.num_batches_tracked\", \"module.block3.layer.0.conv1.weight\", \"module.block3.layer.0.bn2.weight\", \"module.block3.layer.0.bn2.bias\", \"module.block3.layer.0.bn2.running_mean\", \"module.block3.layer.0.bn2.running_var\", \"module.block3.layer.0.bn2.num_batches_tracked\", \"module.block3.layer.0.conv2.weight\", \"module.block3.layer.0.convShortcut.weight\", \"module.block3.layer.1.bn1.weight\", \"module.block3.layer.1.bn1.bias\", \"module.block3.layer.1.bn1.running_mean\", \"module.block3.layer.1.bn1.running_var\", \"module.block3.layer.1.bn1.num_batches_tracked\", \"module.block3.layer.1.conv1.weight\", \"module.block3.layer.1.bn2.weight\", \"module.block3.layer.1.bn2.bias\", \"module.block3.layer.1.bn2.running_mean\", \"module.block3.layer.1.bn2.running_var\", \"module.block3.layer.1.bn2.num_batches_tracked\", \"module.block3.layer.1.conv2.weight\", \"module.block3.layer.2.bn1.weight\", \"module.block3.layer.2.bn1.bias\", \"module.block3.layer.2.bn1.running_mean\", \"module.block3.layer.2.bn1.running_var\", \"module.block3.layer.2.bn1.num_batches_tracked\", \"module.block3.layer.2.conv1.weight\", \"module.block3.layer.2.bn2.weight\", \"module.block3.layer.2.bn2.bias\", \"module.block3.layer.2.bn2.running_mean\", \"module.block3.layer.2.bn2.running_var\", \"module.block3.layer.2.bn2.num_batches_tracked\", \"module.block3.layer.2.conv2.weight\", \"module.block3.layer.3.bn1.weight\", \"module.block3.layer.3.bn1.bias\", \"module.block3.layer.3.bn1.running_mean\", \"module.block3.layer.3.bn1.running_var\", \"module.block3.layer.3.bn1.num_batches_tracked\", \"module.block3.layer.3.conv1.weight\", \"module.block3.layer.3.bn2.weight\", \"module.block3.layer.3.bn2.bias\", \"module.block3.layer.3.bn2.running_mean\", \"module.block3.layer.3.bn2.running_var\", \"module.block3.layer.3.bn2.num_batches_tracked\", \"module.block3.layer.3.conv2.weight\", \"module.block3.layer.4.bn1.weight\", \"module.block3.layer.4.bn1.bias\", \"module.block3.layer.4.bn1.running_mean\", \"module.block3.layer.4.bn1.running_var\", \"module.block3.layer.4.bn1.num_batches_tracked\", \"module.block3.layer.4.conv1.weight\", \"module.block3.layer.4.bn2.weight\", \"module.block3.layer.4.bn2.bias\", \"module.block3.layer.4.bn2.running_mean\", \"module.block3.layer.4.bn2.running_var\", \"module.block3.layer.4.bn2.num_batches_tracked\", \"module.block3.layer.4.conv2.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.fc.weight\", \"module.fc.bias\". "
     ]
    }
   ],
   "source": [
    "model_SATInf.module.load_state_dict(torch.load(string,map_location='cpu'))\n",
    "#eval_train(model_SATInf, DEVICE, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_adv_test_whitebox(model_SATInf, DEVICE, val_loader)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-33bc3f71c499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchentropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_SATInf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madversary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentropySmoothing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.007\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.031\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-ae3e404d8577>\u001b[0m in \u001b[0;36mdataentropy\u001b[0;34m(method, model, device, train_loader, adversary, L, step, eps, norm, random)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msgd_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_device_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 raise RuntimeError(\"module must have its parameters and buffers \"\n\u001b[0m\u001b[1;32m    148\u001b[0m                                    \u001b[0;34m\"on device {} (device_ids[0]) but found one of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                                    \"them on device: {}\".format(self.src_device_obj, t.device))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu"
     ]
    }
   ],
   "source": [
    "\n",
    "dataentropy(batchentropy,model_SATInf, DEVICE, train_loader, adversary=entropySmoothing,L=10,step=0.007,eps=0.031,norm='inf',random=False)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
