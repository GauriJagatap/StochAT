{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescentPyTorch, CarliniLInfMethod, CarliniL2Method, AutoAttack\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import sys\n",
    "sys.path.append('../architectures/')\n",
    "sys.path.append('../adversarial/')\n",
    "import small_cnn\n",
    "from small_cnn import SmallCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from advertorch_examples.models import LeNet5Madry\n",
    "Net = LeNet5Madry\n",
    "NetName = 'LeNet5Madry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../trainedmodels/model_best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(path)['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd = torch.load('BEST_model-nn-epoch74-robacc57.pt')\n",
    "# model = WideResNet(depth=34)\n",
    "# model = nn.DataParallel(model)\n",
    "# model.load_state_dict(sd)\n",
    "# torch.save(model.module.state_dict(), 'best_atent_model_74.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallCNN().to(device)\n",
    "#model.load_state_dict(torch.load('MNIST_models/LINF003BEST_model-nn-epoch23-robacc96.pt'))\n",
    "#model.load_state_dict(torch.load('MNIST_models/model_mnist_smallcnn_trades.pt'))\n",
    "#enum=49 #41 48 #49\n",
    "path = '../trainedmodels/MNIST/SmallCNN_ESGD_ep20_lr0.01.pt'\n",
    "#model.load_state_dict(torch.load(path))\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "optim = torch.optim.SGD(params = model.parameters(), lr=0.01)\n",
    "model = model.to(device)\n",
    "pytorch_clf = PyTorchClassifier(model, loss=loss, optimizer=optim, input_shape=(1,32,32), nb_classes=10, device_type='gpu', clip_values=(0,1), preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MNIST('../../data/', download=True, train=False, transform=Compose([ToTensor()]))\n",
    "dl = DataLoader(ds, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-ab219a8a2be6>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  preds2 = torch.argmax(torch.tensor(model(x)), axis=-1).cpu()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9924\n"
     ]
    }
   ],
   "source": [
    "correct = 0.0\n",
    "correct_2 = 0.0\n",
    "for x, y in dl:\n",
    "    x = x.to(device)\n",
    "    #y = y.to(device)\n",
    "    #preds = torch.argmax(torch.tensor(pytorch_clf.predict(x.cpu().detach())), dim=-1)\n",
    "    #correct+=preds.eq(y.view_as(preds)).sum().item()\n",
    "    preds2 = torch.argmax(torch.tensor(model(x)), axis=-1).cpu()\n",
    "    correct_2+=preds2.eq(y.view_as(preds2)).sum().item()\n",
    "    #correct += (preds==y).sum()\n",
    "#print(correct/10000.0)\n",
    "print(correct_2/10000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack = ProjectedGradientDescentPyTorch(pytorch_clf, norm=np.inf, eps=0.3, eps_step=0.01, num_random_init=10, max_iter=40, batch_size=128, verbose=False)\n",
    "attack = CarliniLInfMethod(pytorch_clf, learning_rate=0.3, max_iter=40,  eps=0.3, batch_size=128,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9924\n",
      "0.3465\n"
     ]
    }
   ],
   "source": [
    "correct = 0.0\n",
    "correct_2 = 0.0\n",
    "epsilons = []\n",
    "for x, y in dl:\n",
    "    x = x.to(device)\n",
    "    #y = y.to(device)\n",
    "    preds = torch.argmax(torch.tensor(pytorch_clf.predict(x.cpu())), dim=-1)\n",
    "    x_adv = attack.generate(x.cpu())\n",
    "    preds2 = torch.argmax(torch.tensor(pytorch_clf.predict(x_adv)), dim=-1)\n",
    "    tmp_eps = torch.norm(torch.tensor(x_adv).view(-1, 28*28*1).cpu() - x.view(-1, 28*28*1).cpu(), dim=1, p=np.inf)\n",
    "    epsilons.extend(tmp_eps.tolist())\n",
    "    correct+=preds.eq(y.view_as(preds)).sum().item()\n",
    "    correct_2 += preds2.eq(y.view_as(preds)).sum().item()\n",
    "    #correct += (preds==y).sum()\n",
    "print(correct/10000.0)\n",
    "print(correct_2/10000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['random'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pgd_whitebox(model,\n",
    "                  X,\n",
    "                  y,\n",
    "                  epsilon=2,\n",
    "                  norm=2,\n",
    "                  num_steps=40,\n",
    "                  step_size=0.25):\n",
    "    out = model(X)\n",
    "    err = (out.data.max(1)[1] != y.data).float().sum()\n",
    "    X_pgd = Variable(X.data, requires_grad=True)\n",
    "    if args['random']:\n",
    "        random_noise = torch.FloatTensor(*X_pgd.shape).uniform_(-epsilon, epsilon).to(device)\n",
    "        X_pgd = Variable(X_pgd.data + random_noise, requires_grad=True)\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        opt = optim.SGD([X_pgd], lr=1e-3)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            loss = nn.CrossEntropyLoss()(model(X_pgd), y)\n",
    "        loss.backward()\n",
    "        if norm=='inf':\n",
    "            eta = step_size * X_pgd.grad.data.sign()\n",
    "            X_pgd = Variable(X_pgd.data + eta, requires_grad=True)\n",
    "            eta = torch.clamp(X_pgd.data - X.data, -epsilon, epsilon)\n",
    "            X_pgd = Variable(X.data + eta, requires_grad=True)\n",
    "        elif norm==2:\n",
    "            #print('l2 attack')\n",
    "            eta = step_size * X_pgd.grad.data / X_pgd.grad.view(X_pgd.shape[0], -1).norm(2, dim=-1)\\\n",
    "                    .view(-1, 1, 1, 1)\n",
    "            X_pgd = Variable(X_pgd.data + eta, requires_grad=True)\n",
    "            X_pgd = project(X, X_pgd, norm, epsilon)            \n",
    "        X_pgd = Variable(torch.clamp(X_pgd, 0, 1.0), requires_grad=True)\n",
    "        #print('distance of attack:',torch.norm(X_pgd-X)/np.sqrt(128))\n",
    "    err_pgd = (model(X_pgd).data.max(1)[1] != y.data).float().sum()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_pgd = nn.CrossEntropyLoss()(model(X_pgd), y)\n",
    "    #print('err pgd (white-box): ', err_pgd)\n",
    "    return err, err_pgd, loss_pgd.item()\n",
    "\n",
    "def eval_adv_test_whitebox(model, device, test_loader):\n",
    "    \"\"\"\n",
    "    evaluate model by white-box attack\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    robust_err_total = 0\n",
    "    natural_err_total = 0\n",
    "    lossrob  = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # pgd attack\n",
    "        X, y = Variable(data, requires_grad=True), Variable(target)\n",
    "        err_natural, err_robust, losspgd = _pgd_whitebox(model, X, y)\n",
    "        robust_err_total += err_robust\n",
    "        natural_err_total += err_natural\n",
    "        lossrob = lossrob + losspgd\n",
    "    rob = 100-100*robust_err_total.item()/len(test_loader.dataset)   \n",
    "    lossrob /= len(test_loader)\n",
    "    print('robust test loss:',lossrob)\n",
    "    print('natural_acc_total: ', 100-100*natural_err_total.item()/len(test_loader.dataset))\n",
    "    print('robust_acc_total: ', rob)\n",
    "    return rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robust test loss: 8.217267715478245\n",
      "natural_acc_total:  99.24\n",
      "robust_acc_total:  19.120000000000005\n"
     ]
    }
   ],
   "source": [
    "rob = eval_adv_test_whitebox(model,'cuda', dl)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack = ProjectedGradientDescentPyTorch(pytorch_clf, norm=np.inf, eps=0.3, eps_step=0.01, num_random_init=10, max_iter=40, batch_size=128)\n",
    "# attack = CarliniLInfMethod(pytorch_clf, learning_rate=0.01, max_iter=40,  eps=0.3, batch_size=128, verbose=False)\n",
    "attack = ProjectedGradientDescentPyTorch(pytorch_clf, norm=2, eps=2, eps_step=4, num_random_init=1, max_iter=40, batch_size=128,verbose=False)\n",
    "#attack = CarliniL2Method(pytorch_clf, learning_rate=0.01, max_iter=40,  eps=2, batch_size=128, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9924\n",
      "0.4204\n"
     ]
    }
   ],
   "source": [
    "correct = 0.0\n",
    "correct_2 = 0.0\n",
    "epsilons = []\n",
    "for x, y in dl:\n",
    "    x = x.to(device)\n",
    "    #y = y.to(device)\n",
    "    preds = torch.argmax(torch.tensor(pytorch_clf.predict(x.cpu())), dim=-1)\n",
    "    x_adv = attack.generate(x.cpu())\n",
    "    preds2 = torch.argmax(torch.tensor(pytorch_clf.predict(x_adv)), dim=-1)\n",
    "    tmp_eps = torch.norm(torch.tensor(x_adv).view(-1, 28*28*1).cpu() - x.view(-1, 28*28*1).cpu(), dim=1, p=np.inf)\n",
    "    epsilons.extend(tmp_eps.tolist())\n",
    "    correct+=preds.eq(y.view_as(preds)).sum().item()\n",
    "    correct_2 += preds2.eq(y.view_as(preds)).sum().item()\n",
    "    #correct += (preds==y).sum()\n",
    "print(correct/10000.0)\n",
    "print(correct_2/10000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pgd_inf_mnist_atent', epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from foolbox.attacks import LinfDeepFoolAttack\n",
    "from foolbox.models import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fb = PyTorchModel(model, bounds=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
