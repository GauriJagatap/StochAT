{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ATENT as attack on pretrained CIFAR10 WRN34-10 ATENT model [Table 6 of paper]\n",
    "\n",
    "Notebook contains printed result from evaluation of pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append('../adversarial/')\n",
    "sys.path.append('../architectures/')\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functional import entropySmoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET TRAINING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "#data loading\n",
    "args['seed'] = 1\n",
    "args['test_batch_size'] = 128\n",
    "args['train_batch_size'] = 128\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True}\n",
    "args['no_cuda'] = False\n",
    "\n",
    "if not args['no_cuda']:\n",
    "    if torch.cuda.is_available():\n",
    "        DEVICE = 'cuda'\n",
    "    else:\n",
    "        DEVICE = 'cpu'\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "\n",
    "# params for SGLD/PGD attack (inner loop)\n",
    "args['attacktype'] = 'ATENT' #['PGD','ATENT']\n",
    "args['attack'] = 'l_inf'\n",
    "args['norm'] = 'inf'\n",
    "args['epsilon'] = 0.031\n",
    "args['num_steps'] = 20\n",
    "args['step_size'] = 0.003\n",
    "args['random'] =True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = 'CIFAR10' # [MNIST, CIFAR10]\n",
    "\n",
    "# setup data loader\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train = datasets.CIFAR10('../../data/CIFAR10', train=True, transform=transform_train, download=True)\n",
    "val = datasets.CIFAR10('../../data/CIFAR10', train=False, transform=transform_test, download=True)\n",
    "    \n",
    "train_loader = DataLoader(train, batch_size=args['test_batch_size'], shuffle=True, **kwargs)\n",
    "val_loader = DataLoader(val, batch_size=args['train_batch_size'], shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='CIFAR10':\n",
    "    #[ResNet18,ResNet34,ResNet50,WideResNet]\n",
    "    from resnet import ResNet18,ResNet34,ResNet50\n",
    "    from wideresnet import WideResNet\n",
    "    Net = WideResNet\n",
    "    NetName = 'WideResNet34'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET RANDOM SEED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f24701e0f10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_num_threads(2)\n",
    "if DEVICE=='cuda':\n",
    "    torch.cuda.set_device(-1)\n",
    "    torch.cuda.manual_seed(args['seed'])\n",
    "    cudnn.benchmark = True\n",
    "random.seed(args['seed'])\n",
    "np.random.seed(args['seed'])\n",
    "torch.manual_seed(args['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHITEBOX L-INF ATTACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pgd_whitebox(model,\n",
    "                  X,\n",
    "                  y,\n",
    "                  epsilon=args['epsilon'],\n",
    "                  num_steps=args['num_steps'],\n",
    "                  step_size=args['step_size']\n",
    "                 ):\n",
    "    out = model(X)\n",
    "    err = (out.data.max(1)[1] != y.data).float().sum()\n",
    "    X_pgd = Variable(X.data, requires_grad=True)\n",
    "    if args['random']:\n",
    "        random_noise = torch.FloatTensor(*X_pgd.shape).uniform_(-epsilon, epsilon).to(DEVICE)\n",
    "        X_pgd = Variable(X_pgd.data + random_noise, requires_grad=True)\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        opt = optim.SGD([X_pgd], lr=1e-3)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            loss = nn.CrossEntropyLoss()(model(X_pgd), y)\n",
    "        loss.backward()\n",
    "        eta = step_size * X_pgd.grad.data.sign()\n",
    "        X_pgd = Variable(X_pgd.data + eta, requires_grad=True)\n",
    "        eta = torch.clamp(X_pgd.data - X.data, -epsilon, epsilon)\n",
    "        X_pgd = Variable(X.data + eta, requires_grad=True)\n",
    "        X_pgd = Variable(torch.clamp(X_pgd, 0, 1.0), requires_grad=True)\n",
    "    err_pgd = (model(X_pgd).data.max(1)[1] != y.data).float().sum()\n",
    "    with torch.no_grad():\n",
    "        loss_pgd = nn.CrossEntropyLoss()(model(X_pgd), y)\n",
    "    return err, err_pgd, loss_pgd.item()\n",
    "\n",
    "def eval_adv_test_whitebox(model, device, test_loader,attacktype):\n",
    "    \"\"\"\n",
    "    evaluate model by white-box attack\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    robust_err_total = 0\n",
    "    natural_err_total = 0\n",
    "    lossrob = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # pgd attack\n",
    "        X, y = Variable(data, requires_grad=True), Variable(target)\n",
    "        if attacktype == 'ATENT':\n",
    "            err_natural, err_robust, losspgd = _atent_whitebox(model, X, y)\n",
    "        elif attacktype == 'PGD':\n",
    "            err_natural, err_robust, losspgd = _pgd_whitebox(model, X, y)        \n",
    "        robust_err_total += err_robust\n",
    "        natural_err_total += err_natural\n",
    "        lossrob = lossrob + losspgd\n",
    "    rob = 100-100*robust_err_total.item()/len(test_loader.dataset)   \n",
    "    lossrob /= len(test_loader)\n",
    "    print('robust test loss:',lossrob)\n",
    "    print('natural_acc_total: ', 100-100*natural_err_total.item()/len(test_loader.dataset))\n",
    "    print('robust_acc_total: ', rob)    \n",
    "    return rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _atent_whitebox(model,\n",
    "                  x,\n",
    "                  y,\n",
    "                  eps=args['epsilon'],\n",
    "                  L=args['num_steps'],\n",
    "                  step=args['step_size'],\n",
    "                  norm = args['norm']\n",
    "                   ):\n",
    "    # Adversial perturbation\n",
    "    alpha=0.9\n",
    "    loss = 0\n",
    "    out = model(x)    \n",
    "    err = (out.data.max(1)[1] != y.data).float().sum()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for l in range(L):     \n",
    "        \n",
    "        if l==0: # initialize using random perturbation of true x, run for one epoch\n",
    "            random=True\n",
    "            xp = None\n",
    "            projector=False\n",
    "        elif l>0 and l<L-1: # initialize with previous iterate of adversarial perturbation, run one epoch\n",
    "            random=False\n",
    "            xp=x_adv\n",
    "            projector = False\n",
    "        elif l == L-1: # initialize with previous iterate, run one epoch, project to epsilon ball\n",
    "            random=False\n",
    "            xp = x_adv\n",
    "            projector=True\n",
    "            \n",
    "        x_adv,bfl = entropySmoothing(model, x, y, loss_fn, xp=xp, step=step, eps=eps, norm=norm, random=random, ep=1e-3,projector=projector)\n",
    "        loss = (1-alpha)*loss + alpha*loss_fn(out, y)\n",
    "        \n",
    "    err_pgd = (model(x_adv).data.max(1)[1] != y.data).float().sum()\n",
    "        \n",
    "    return err, err_pgd, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD FROM CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ATENT = Net().to(DEVICE)\n",
    "model_ATENT = nn.DataParallel(model_ATENT)\n",
    "#load state dict here\n",
    "pathstr = '../trainedmodels/CIFAR10/BEST_model-nn-epoch76-robacc57.pt\n",
    "model_ATENT.load_state_dict(torch.load(pathstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ATENT as attack ... \n",
      "robust test loss: 0.5295534843130957\n",
      "natural_acc_total:  85.67\n",
      "robust_acc_total:  60.5\n"
     ]
    }
   ],
   "source": [
    "print('Running '+args['attacktype']+' as attack ... ')\n",
    "rob = eval_adv_test_whitebox(model_ATENT, DEVICE, val_loader,args['attacktype'])            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
