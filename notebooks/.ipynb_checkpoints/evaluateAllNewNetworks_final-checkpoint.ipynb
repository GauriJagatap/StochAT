{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Adversarial Training (StochAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from multiprocessing import cpu_count\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import olympic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Union, Callable, Tuple\n",
    "sys.path.append('../adversarial/')\n",
    "sys.path.append('../architectures/')\n",
    "from functional import boundary, iterated_fgsm, local_search, pgd, entropySmoothing\n",
    "from ESGD_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "import argparse, math, random\n",
    "import ESGD_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trades import trades_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'MNIST' # [MNIST, CIFAR10]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "bsz = 128\n",
    "if dataset == 'MNIST':\n",
    "    train = datasets.MNIST('../../data/MNIST', train=True, transform=transform, download=True)\n",
    "    val = datasets.MNIST('../../data/MNIST', train=False, transform=transform, download=True)\n",
    "elif dataset == 'CIFAR10':\n",
    "    train = datasets.CIFAR10('../../data/CIFAR10', train=True, transform=transform, download=True)\n",
    "    val = datasets.CIFAR10('../../data/CIFAR10', train=False, transform=transform, download=True)\n",
    "    \n",
    "train_loader = DataLoader(train, batch_size=128, num_workers=cpu_count(),drop_last=True)\n",
    "val_loader = DataLoader(val, batch_size=128, num_workers=cpu_count(),drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALIZE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='MNIST':\n",
    "    from net_mnist import Net, NetSoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='CIFAR10':\n",
    "    #[ResNet18,ResNet34,ResNet50,WideResNet]\n",
    "    from resnet import ResNet18,ResNet34,ResNet50\n",
    "    from wideresnet import WideResNet\n",
    "    Net = ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM SEED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa8a0c79570>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.set_num_threads(2)\n",
    "if DEVICE=='cuda':\n",
    "    torch.cuda.set_device(-1)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    cudnn.benchmark = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD PRETRAINED OR TRAIN NEW MODELS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSGD = True\n",
    "TrainESGD = True\n",
    "TrainL2 = True\n",
    "TrainLInf = True\n",
    "TrainSAT2 = True\n",
    "TrainSATInf = True\n",
    "TrainTRADES = True\n",
    "TrainMART = False\n",
    "TrainMMA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN NAIVE MODEL USING SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 468/468 [00:02<00:00, 196.50it/s, loss=0.973, accuracy=0.672, val_loss=0.193, val_accuracy=0.941]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:02<00:00, 192.97it/s, loss=0.397, accuracy=0.878, val_loss=0.121, val_accuracy=0.961]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:02<00:00, 205.85it/s, loss=0.309, accuracy=0.908, val_loss=0.107, val_accuracy=0.966]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:02<00:00, 202.72it/s, loss=0.269, accuracy=0.92, val_loss=0.0888, val_accuracy=0.97]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:02<00:00, 206.54it/s, loss=0.246, accuracy=0.927, val_loss=0.079, val_accuracy=0.974]\n",
      "Epoch 6: 100%|██████████| 468/468 [00:02<00:00, 200.15it/s, loss=0.226, accuracy=0.933, val_loss=0.0746, val_accuracy=0.977]\n",
      "Epoch 7: 100%|██████████| 468/468 [00:02<00:00, 200.59it/s, loss=0.207, accuracy=0.938, val_loss=0.0664, val_accuracy=0.979]\n",
      "Epoch 8: 100%|██████████| 468/468 [00:02<00:00, 197.09it/s, loss=0.198, accuracy=0.94, val_loss=0.0638, val_accuracy=0.979]\n",
      "Epoch 9: 100%|██████████| 468/468 [00:02<00:00, 196.31it/s, loss=0.186, accuracy=0.945, val_loss=0.0607, val_accuracy=0.98]\n",
      "Epoch 10: 100%|██████████| 468/468 [00:02<00:00, 203.35it/s, loss=0.181, accuracy=0.948, val_loss=0.0569, val_accuracy=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accuracy': 0.981270032051282}\n"
     ]
    }
   ],
   "source": [
    "if TrainSGD:\n",
    "    ## initialize model\n",
    "    model_SGD = NetSoft().to(DEVICE)\n",
    "    ## training params\n",
    "    lr = 0.1\n",
    "    optimiser = optim.SGD(model_SGD.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    epochs = 10\n",
    "    ## train model\n",
    "    history_natural = olympic.fit(\n",
    "        model_SGD,\n",
    "        optimiser,\n",
    "        loss_fn,\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5)\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation accuracy\n",
    "    print('final validation accuracy:')\n",
    "    valscore = olympic.evaluate(model_SGD, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    print(valscore)\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/SGD_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_SGD,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING ENTROPY SGD (ESGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_training(model, optimiser, loss_fn, x, y, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    def helper():\n",
    "        def feval():\n",
    "            #x, y = Variable(x), Variable(y.squeeze())\n",
    "            bsz = x.size(0)\n",
    "            optimiser.zero_grad()\n",
    "            yh = model(x)\n",
    "            f = loss_fn.forward(yh, y)\n",
    "            f.backward()\n",
    "\n",
    "            yp = yh.argmax(axis=1)\n",
    "            prec1 = 100*torch.sum(yp == y)//bsz\n",
    "            err = 100.-prec1.item()\n",
    "\n",
    "            return (f.data.item(), err)\n",
    "        return feval\n",
    "\n",
    "    loss, err = optimiser.step(helper(), model, loss_fn)\n",
    "    loss = torch.tensor(loss)\n",
    "    return loss, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../adversarial/ESGD_optim.py:98: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  mdw.mul_(mom).add_(1-damp, dw)\n",
      "Epoch 1: 100%|██████████| 468/468 [00:02<00:00, 161.94it/s, loss=0.577, accuracy=0.817, val_loss=0.123, val_accuracy=0.962]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:02<00:00, 164.65it/s, loss=0.329, accuracy=0.9, val_loss=0.0973, val_accuracy=0.971]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:02<00:00, 165.74it/s, loss=0.306, accuracy=0.91, val_loss=0.0991, val_accuracy=0.972]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:02<00:00, 165.80it/s, loss=0.292, accuracy=0.916, val_loss=0.0765, val_accuracy=0.98]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:02<00:00, 165.27it/s, loss=0.279, accuracy=0.92, val_loss=0.0741, val_accuracy=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9792668269230769\n"
     ]
    }
   ],
   "source": [
    "if TrainESGD:\n",
    "    ## initialize model\n",
    "    model_ESGD = NetSoft().to(DEVICE)\n",
    "    ## training parameters\n",
    "    lr = 0.1 \n",
    "    l2 = 0.0 #l2 regularization\n",
    "    L = 0    #langevin iterations\n",
    "    gamma = 1e-4 \n",
    "    scoping = 1e-3\n",
    "    noise = 1e-4\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    epochs = 5\n",
    "    optimiser = ESGD_optim.EntropySGD(model_ESGD.parameters(),\n",
    "            config = dict(lr=lr, momentum=0.9, nesterov=True, weight_decay=l2,\n",
    "            L=L, eps=noise, g0=gamma, g1=scoping))\n",
    "    ## train model\n",
    "    history_natural = olympic.fit(\n",
    "        model_ESGD,\n",
    "        optimiser,\n",
    "        loss_fn,\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=entropy_training,\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5)\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation accuracy\n",
    "    print('final validation accuracy:')\n",
    "    valacc = olympic.evaluate(model_ESGD, val_loader, metrics=['accuracy'],\n",
    "                         prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    print(valacc['val_accuracy'])\n",
    "    ## save trained model\n",
    "    modelname = '../trainedmodels/'+dataset+'/ESGD_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_ESGD,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING PGD SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infnorm(x):\n",
    "    infn = torch.max(torch.abs(x.detach().cpu()))\n",
    "    return infn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training(model, optimiser, loss_fn, x, y, epoch, adversary, k, step, eps, norm, random):\n",
    "    \"\"\"Performs a single update against a specified adversary\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    # Adversial perturbation\n",
    "    x_adv = adversary(model, x, y, loss_fn, k=k, step=step, eps=eps, norm=norm, random=True)\n",
    "    #print('l2:',torch.norm(x_adv.detach().cpu()-x.detach().cpu())/np.sqrt(x.detach().cpu().size(0)))    \n",
    "    #print('linf:',infnorm(x_adv.detach().cpu()-x.detach().cpu())/infnorm(x))    \n",
    "\n",
    "    optimiser.zero_grad()\n",
    "    y_pred = model(x_adv)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    return loss, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l2 ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 468/468 [00:03<00:00, 118.89it/s, loss=2.21, accuracy=0.211, val_loss=1.76, val_accuracy=0.631]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:03<00:00, 120.16it/s, loss=1.26, accuracy=0.59, val_loss=0.551, val_accuracy=0.85]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:03<00:00, 120.86it/s, loss=0.809, accuracy=0.741, val_loss=0.377, val_accuracy=0.892]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:03<00:00, 123.91it/s, loss=0.656, accuracy=0.795, val_loss=0.294, val_accuracy=0.916]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:03<00:00, 121.20it/s, loss=0.585, accuracy=0.82, val_loss=0.253, val_accuracy=0.927]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9269831730769231\n"
     ]
    }
   ],
   "source": [
    "if TrainL2:\n",
    "    ## initialize model\n",
    "    adv_model_l2 = NetSoft().to(DEVICE)\n",
    "    lr = 0.01\n",
    "    optimiser = optim.SGD(adv_model_l2.parameters(), lr=lr)\n",
    "    epochs = 5\n",
    "    ## train model\n",
    "    training_history_l2 = olympic.fit(\n",
    "        adv_model_l2,\n",
    "        optimiser,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=adversarial_training,\n",
    "        update_fn_kwargs={'adversary': pgd, 'k': 2, 'step': 0.05, 'eps': 1.0, 'norm': 2, 'random':True},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_delta=0.005, monitor='val_accuracy')\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation accuracy\n",
    "    print('final validation accuracy:')\n",
    "    valacc = olympic.evaluate(adv_model_l2, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    print(valacc['val_accuracy'])\n",
    "    ## save trained model\n",
    "    modelname = '../trainedmodels/'+dataset+'/AT2_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(adv_model_l2,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linf ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 468/468 [00:03<00:00, 129.08it/s, loss=2.3, accuracy=0.126, val_loss=2.24, val_accuracy=0.429]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:03<00:00, 132.89it/s, loss=2.03, accuracy=0.312, val_loss=1.13, val_accuracy=0.74]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:03<00:00, 133.42it/s, loss=1.32, accuracy=0.556, val_loss=0.56, val_accuracy=0.85]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:03<00:00, 132.20it/s, loss=1.04, accuracy=0.65, val_loss=0.415, val_accuracy=0.896]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:03<00:00, 129.36it/s, loss=0.9, accuracy=0.704, val_loss=0.334, val_accuracy=0.915]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if TrainLInf:\n",
    "    ## initialize model\n",
    "    adv_model_linf = NetSoft().to(DEVICE)\n",
    "    ## train params\n",
    "    lr = 0.01\n",
    "    optimiser = optim.SGD(adv_model_linf.parameters(), lr=lr)\n",
    "    epochs = 5\n",
    "    ## train model\n",
    "    training_history_linf = olympic.fit(\n",
    "        adv_model_linf,\n",
    "        optimiser,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=adversarial_training,\n",
    "        update_fn_kwargs={'adversary': iterated_fgsm,'k': 2, 'step': 0.05, 'eps': 0.1, 'norm': 'inf', 'random':True},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_delta=0.005, monitor='val_accuracy')\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation\n",
    "    print('final validation accuracy:')\n",
    "    valacc = olympic.evaluate(adv_model_linf, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    \n",
    "    ## save trained model\n",
    "    modelname = '../trainedmodels/'+dataset+'/ATInf_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(adv_model_linf,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training_entropy(model, optimiser, loss_fn, x, y, epoch, adversary, k, step, eps, norm, gamma):\n",
    "    \"\"\"Performs a single update against a specified adversary\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # Adversial perturbation\n",
    "    #alpha = 0.8\n",
    "    N = 1\n",
    "    loss = 0\n",
    "    for l in range(N):\n",
    "        x_adv = adversary(model, x, y, loss_fn, k=k, step=step, eps=eps, norm=norm, random=True, gamma=gamma)\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        y_pred = model(x_adv)\n",
    "        loss = loss + loss_fn(y_pred,y)\n",
    "        #loss = (1-alpha)*loss + alpha*loss_fn(y_pred, y)\n",
    "    loss = loss/N\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    return loss, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 468/468 [00:04<00:00, 116.79it/s, loss=2.28, accuracy=0.152, val_loss=2.17, val_accuracy=0.47]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:03<00:00, 118.56it/s, loss=1.65, accuracy=0.462, val_loss=0.683, val_accuracy=0.825]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:03<00:00, 117.27it/s, loss=0.896, accuracy=0.714, val_loss=0.398, val_accuracy=0.892]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:03<00:00, 118.69it/s, loss=0.695, accuracy=0.785, val_loss=0.31, val_accuracy=0.913]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:04<00:00, 115.59it/s, loss=0.595, accuracy=0.816, val_loss=0.255, val_accuracy=0.927]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if TrainSAT2:\n",
    "    ## initialize model\n",
    "    model_SAT2 = NetSoft().to(DEVICE)\n",
    "    ## train params\n",
    "    lr = 0.01\n",
    "    optimiser = optim.SGD(model_SAT2.parameters(), lr=lr)\n",
    "    epochs = 5\n",
    "    ## train model\n",
    "    training_history_entropySmoothing = olympic.fit(\n",
    "        model_SAT2,\n",
    "        optimiser,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=adversarial_training_entropy,\n",
    "        update_fn_kwargs={'adversary': entropySmoothing, 'k': 2, 'step': 0.05, 'eps': 1.0, 'norm': 2, 'gamma':1e-5},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_delta=0.005, monitor='val_accuracy')\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation\n",
    "    print('final validation accuracy:')\n",
    "    olympic.evaluate(model_SAT2, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/SAT2_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_SAT2,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 468/468 [00:03<00:00, 123.15it/s, loss=2.22, accuracy=0.201, val_loss=1.83, val_accuracy=0.591]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:03<00:00, 121.94it/s, loss=1.43, accuracy=0.525, val_loss=0.613, val_accuracy=0.841]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:03<00:00, 122.64it/s, loss=0.89, accuracy=0.709, val_loss=0.392, val_accuracy=0.896]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:03<00:00, 122.90it/s, loss=0.726, accuracy=0.771, val_loss=0.307, val_accuracy=0.913]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:03<00:00, 122.39it/s, loss=0.637, accuracy=0.801, val_loss=0.264, val_accuracy=0.925]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if TrainSATInf:\n",
    "    ## initialize model\n",
    "    model_SATInf = NetSoft().to(DEVICE)\n",
    "    ## train params\n",
    "    lr = 0.01\n",
    "    optimiser = optim.SGD(model_SATInf.parameters(), lr=lr)\n",
    "    epochs = 5\n",
    "    ## train model\n",
    "    training_history_entropySmoothing = olympic.fit(\n",
    "        model_SATInf,\n",
    "        optimiser,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=adversarial_training_entropy,\n",
    "        update_fn_kwargs={'adversary': entropySmoothing, 'k': 2, 'step': 0.05, 'eps': 0.1, 'norm': 'inf', 'gamma':1e-5},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_delta=0.005, monitor='val_accuracy')\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation\n",
    "    print('final validation accuracy:')\n",
    "    olympic.evaluate(model_SATInf, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/SATInf_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_SATInf,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING TRADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['test_batch_size'] = 128\n",
    "args['no_cuda'] = False\n",
    "args['epsilon'] = 0.3\n",
    "args['num_steps'] = 5\n",
    "args['step_size'] = 0.01\n",
    "args['random'] =True,\n",
    "args['model_path']='./checkpoints/model_mnist_smallcnn.pt'\n",
    "args['source_model_path'] ='./checkpoints/model_mnist_smallcnn.pt'\n",
    "args['target_model_path'] = './checkpoints/model_mnist_smallcnn.pt'\n",
    "args['white_box_attack']=True\n",
    "args['log_interval'] = 100\n",
    "args['beta'] = 1.0\n",
    "args['log_interval'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calculate robust loss\n",
    "        loss = trades_loss(model=model,\n",
    "                           x_natural=data,\n",
    "                           y=target,\n",
    "                           optimizer=optimizer,\n",
    "                           step_size=args['step_size'],\n",
    "                           epsilon=args['epsilon'],\n",
    "                           perturb_steps=args['num_steps'],\n",
    "                           beta=args['beta'],\n",
    "                           distance = 'l_2')\n",
    "        \n",
    "\n",
    "        #print('outloss pre step:',loss)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        optimizer.step()\n",
    "        #print('outloss post step:',loss.item())\n",
    "\n",
    "        # print progress\n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_train(model, device, train_loader):\n",
    "    model.eval()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            train_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print('Training: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        train_loss, correct, len(train_loader.dataset),\n",
    "        100. * correct / len(train_loader.dataset)))\n",
    "    training_accuracy = correct / len(train_loader.dataset)\n",
    "    return train_loss, training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauri/.local/lib/python3.8/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306984\n",
      "Train Epoch: 1 [128/60000 (0%)]\tLoss: 2.296862\n",
      "Train Epoch: 1 [256/60000 (0%)]\tLoss: 2.301613\n",
      "Train Epoch: 1 [384/60000 (1%)]\tLoss: 2.299722\n",
      "Train Epoch: 1 [512/60000 (1%)]\tLoss: 2.315302\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.305764\n",
      "Train Epoch: 1 [768/60000 (1%)]\tLoss: 2.306420\n",
      "Train Epoch: 1 [896/60000 (1%)]\tLoss: 2.314331\n",
      "Train Epoch: 1 [1024/60000 (2%)]\tLoss: 2.311337\n",
      "Train Epoch: 1 [1152/60000 (2%)]\tLoss: 2.294602\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.305999\n",
      "Train Epoch: 1 [1408/60000 (2%)]\tLoss: 2.312844\n",
      "Train Epoch: 1 [1536/60000 (3%)]\tLoss: 2.291073\n",
      "Train Epoch: 1 [1664/60000 (3%)]\tLoss: 2.304793\n",
      "Train Epoch: 1 [1792/60000 (3%)]\tLoss: 2.310278\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.301413\n",
      "Train Epoch: 1 [2048/60000 (3%)]\tLoss: 2.304006\n",
      "Train Epoch: 1 [2176/60000 (4%)]\tLoss: 2.300539\n",
      "Train Epoch: 1 [2304/60000 (4%)]\tLoss: 2.302885\n",
      "Train Epoch: 1 [2432/60000 (4%)]\tLoss: 2.302083\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.295130\n",
      "Train Epoch: 1 [2688/60000 (4%)]\tLoss: 2.305964\n",
      "Train Epoch: 1 [2816/60000 (5%)]\tLoss: 2.303977\n",
      "Train Epoch: 1 [2944/60000 (5%)]\tLoss: 2.300716\n",
      "Train Epoch: 1 [3072/60000 (5%)]\tLoss: 2.290028\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.309671\n",
      "Train Epoch: 1 [3328/60000 (6%)]\tLoss: 2.295816\n",
      "Train Epoch: 1 [3456/60000 (6%)]\tLoss: 2.307115\n",
      "Train Epoch: 1 [3584/60000 (6%)]\tLoss: 2.297179\n",
      "Train Epoch: 1 [3712/60000 (6%)]\tLoss: 2.291954\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.309320\n",
      "Train Epoch: 1 [3968/60000 (7%)]\tLoss: 2.297604\n",
      "Train Epoch: 1 [4096/60000 (7%)]\tLoss: 2.296226\n",
      "Train Epoch: 1 [4224/60000 (7%)]\tLoss: 2.302537\n",
      "Train Epoch: 1 [4352/60000 (7%)]\tLoss: 2.289370\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.298866\n",
      "Train Epoch: 1 [4608/60000 (8%)]\tLoss: 2.296605\n",
      "Train Epoch: 1 [4736/60000 (8%)]\tLoss: 2.293006\n",
      "Train Epoch: 1 [4864/60000 (8%)]\tLoss: 2.304394\n",
      "Train Epoch: 1 [4992/60000 (8%)]\tLoss: 2.301077\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.300137\n",
      "Train Epoch: 1 [5248/60000 (9%)]\tLoss: 2.304439\n",
      "Train Epoch: 1 [5376/60000 (9%)]\tLoss: 2.304138\n",
      "Train Epoch: 1 [5504/60000 (9%)]\tLoss: 2.312087\n",
      "Train Epoch: 1 [5632/60000 (9%)]\tLoss: 2.298209\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.298174\n",
      "Train Epoch: 1 [5888/60000 (10%)]\tLoss: 2.297739\n",
      "Train Epoch: 1 [6016/60000 (10%)]\tLoss: 2.295539\n",
      "Train Epoch: 1 [6144/60000 (10%)]\tLoss: 2.305153\n",
      "Train Epoch: 1 [6272/60000 (10%)]\tLoss: 2.297119\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.289709\n",
      "Train Epoch: 1 [6528/60000 (11%)]\tLoss: 2.298548\n",
      "Train Epoch: 1 [6656/60000 (11%)]\tLoss: 2.300339\n",
      "Train Epoch: 1 [6784/60000 (11%)]\tLoss: 2.294642\n",
      "Train Epoch: 1 [6912/60000 (12%)]\tLoss: 2.302586\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.290642\n",
      "Train Epoch: 1 [7168/60000 (12%)]\tLoss: 2.301025\n",
      "Train Epoch: 1 [7296/60000 (12%)]\tLoss: 2.302253\n",
      "Train Epoch: 1 [7424/60000 (12%)]\tLoss: 2.298853\n",
      "Train Epoch: 1 [7552/60000 (13%)]\tLoss: 2.296004\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.286462\n",
      "Train Epoch: 1 [7808/60000 (13%)]\tLoss: 2.308223\n",
      "Train Epoch: 1 [7936/60000 (13%)]\tLoss: 2.291991\n",
      "Train Epoch: 1 [8064/60000 (13%)]\tLoss: 2.304863\n",
      "Train Epoch: 1 [8192/60000 (14%)]\tLoss: 2.298209\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.295758\n",
      "Train Epoch: 1 [8448/60000 (14%)]\tLoss: 2.302133\n",
      "Train Epoch: 1 [8576/60000 (14%)]\tLoss: 2.289156\n",
      "Train Epoch: 1 [8704/60000 (15%)]\tLoss: 2.293960\n",
      "Train Epoch: 1 [8832/60000 (15%)]\tLoss: 2.285636\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.300541\n",
      "Train Epoch: 1 [9088/60000 (15%)]\tLoss: 2.289891\n",
      "Train Epoch: 1 [9216/60000 (15%)]\tLoss: 2.295643\n",
      "Train Epoch: 1 [9344/60000 (16%)]\tLoss: 2.311261\n",
      "Train Epoch: 1 [9472/60000 (16%)]\tLoss: 2.295401\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.284727\n",
      "Train Epoch: 1 [9728/60000 (16%)]\tLoss: 2.288955\n",
      "Train Epoch: 1 [9856/60000 (16%)]\tLoss: 2.288838\n",
      "Train Epoch: 1 [9984/60000 (17%)]\tLoss: 2.287816\n",
      "Train Epoch: 1 [10112/60000 (17%)]\tLoss: 2.298735\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.306188\n",
      "Train Epoch: 1 [10368/60000 (17%)]\tLoss: 2.283316\n",
      "Train Epoch: 1 [10496/60000 (18%)]\tLoss: 2.291311\n",
      "Train Epoch: 1 [10624/60000 (18%)]\tLoss: 2.294564\n",
      "Train Epoch: 1 [10752/60000 (18%)]\tLoss: 2.291286\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.288965\n",
      "Train Epoch: 1 [11008/60000 (18%)]\tLoss: 2.288106\n",
      "Train Epoch: 1 [11136/60000 (19%)]\tLoss: 2.293125\n",
      "Train Epoch: 1 [11264/60000 (19%)]\tLoss: 2.297791\n",
      "Train Epoch: 1 [11392/60000 (19%)]\tLoss: 2.292397\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.306428\n",
      "Train Epoch: 1 [11648/60000 (19%)]\tLoss: 2.301650\n",
      "Train Epoch: 1 [11776/60000 (20%)]\tLoss: 2.300636\n",
      "Train Epoch: 1 [11904/60000 (20%)]\tLoss: 2.297713\n",
      "Train Epoch: 1 [12032/60000 (20%)]\tLoss: 2.290550\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.291132\n",
      "Train Epoch: 1 [12288/60000 (21%)]\tLoss: 2.295327\n",
      "Train Epoch: 1 [12416/60000 (21%)]\tLoss: 2.285999\n",
      "Train Epoch: 1 [12544/60000 (21%)]\tLoss: 2.296805\n",
      "Train Epoch: 1 [12672/60000 (21%)]\tLoss: 2.295589\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.286664\n",
      "Train Epoch: 1 [12928/60000 (22%)]\tLoss: 2.286218\n",
      "Train Epoch: 1 [13056/60000 (22%)]\tLoss: 2.297516\n",
      "Train Epoch: 1 [13184/60000 (22%)]\tLoss: 2.288687\n",
      "Train Epoch: 1 [13312/60000 (22%)]\tLoss: 2.290955\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.290466\n",
      "Train Epoch: 1 [13568/60000 (23%)]\tLoss: 2.280094\n",
      "Train Epoch: 1 [13696/60000 (23%)]\tLoss: 2.295090\n",
      "Train Epoch: 1 [13824/60000 (23%)]\tLoss: 2.295398\n",
      "Train Epoch: 1 [13952/60000 (23%)]\tLoss: 2.285385\n",
      "Train Epoch: 1 [14080/60000 (24%)]\tLoss: 2.295492\n",
      "Train Epoch: 1 [14208/60000 (24%)]\tLoss: 2.288213\n",
      "Train Epoch: 1 [14336/60000 (24%)]\tLoss: 2.287492\n",
      "Train Epoch: 1 [14464/60000 (24%)]\tLoss: 2.293920\n",
      "Train Epoch: 1 [14592/60000 (24%)]\tLoss: 2.293285\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.289538\n",
      "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 2.291728\n",
      "Train Epoch: 1 [14976/60000 (25%)]\tLoss: 2.282580\n",
      "Train Epoch: 1 [15104/60000 (25%)]\tLoss: 2.292122\n",
      "Train Epoch: 1 [15232/60000 (25%)]\tLoss: 2.291218\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.282611\n",
      "Train Epoch: 1 [15488/60000 (26%)]\tLoss: 2.292384\n",
      "Train Epoch: 1 [15616/60000 (26%)]\tLoss: 2.291614\n",
      "Train Epoch: 1 [15744/60000 (26%)]\tLoss: 2.295838\n",
      "Train Epoch: 1 [15872/60000 (26%)]\tLoss: 2.298714\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.284127\n",
      "Train Epoch: 1 [16128/60000 (27%)]\tLoss: 2.289295\n",
      "Train Epoch: 1 [16256/60000 (27%)]\tLoss: 2.286209\n",
      "Train Epoch: 1 [16384/60000 (27%)]\tLoss: 2.287388\n",
      "Train Epoch: 1 [16512/60000 (28%)]\tLoss: 2.287718\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.282964\n",
      "Train Epoch: 1 [16768/60000 (28%)]\tLoss: 2.290572\n",
      "Train Epoch: 1 [16896/60000 (28%)]\tLoss: 2.288029\n",
      "Train Epoch: 1 [17024/60000 (28%)]\tLoss: 2.287263\n",
      "Train Epoch: 1 [17152/60000 (29%)]\tLoss: 2.287484\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.291452\n",
      "Train Epoch: 1 [17408/60000 (29%)]\tLoss: 2.300331\n",
      "Train Epoch: 1 [17536/60000 (29%)]\tLoss: 2.294150\n",
      "Train Epoch: 1 [17664/60000 (29%)]\tLoss: 2.287123\n",
      "Train Epoch: 1 [17792/60000 (30%)]\tLoss: 2.284379\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.286918\n",
      "Train Epoch: 1 [18048/60000 (30%)]\tLoss: 2.286417\n",
      "Train Epoch: 1 [18176/60000 (30%)]\tLoss: 2.281417\n",
      "Train Epoch: 1 [18304/60000 (31%)]\tLoss: 2.290898\n",
      "Train Epoch: 1 [18432/60000 (31%)]\tLoss: 2.287812\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.285237\n",
      "Train Epoch: 1 [18688/60000 (31%)]\tLoss: 2.284597\n",
      "Train Epoch: 1 [18816/60000 (31%)]\tLoss: 2.292165\n",
      "Train Epoch: 1 [18944/60000 (32%)]\tLoss: 2.284476\n",
      "Train Epoch: 1 [19072/60000 (32%)]\tLoss: 2.295326\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.283992\n",
      "Train Epoch: 1 [19328/60000 (32%)]\tLoss: 2.286898\n",
      "Train Epoch: 1 [19456/60000 (32%)]\tLoss: 2.281214\n",
      "Train Epoch: 1 [19584/60000 (33%)]\tLoss: 2.286569\n",
      "Train Epoch: 1 [19712/60000 (33%)]\tLoss: 2.283755\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.283755\n",
      "Train Epoch: 1 [19968/60000 (33%)]\tLoss: 2.292687\n",
      "Train Epoch: 1 [20096/60000 (34%)]\tLoss: 2.282930\n",
      "Train Epoch: 1 [20224/60000 (34%)]\tLoss: 2.277289\n",
      "Train Epoch: 1 [20352/60000 (34%)]\tLoss: 2.277321\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.278499\n",
      "Train Epoch: 1 [20608/60000 (34%)]\tLoss: 2.279438\n",
      "Train Epoch: 1 [20736/60000 (35%)]\tLoss: 2.284080\n",
      "Train Epoch: 1 [20864/60000 (35%)]\tLoss: 2.283916\n",
      "Train Epoch: 1 [20992/60000 (35%)]\tLoss: 2.280484\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.281658\n",
      "Train Epoch: 1 [21248/60000 (35%)]\tLoss: 2.278455\n",
      "Train Epoch: 1 [21376/60000 (36%)]\tLoss: 2.285768\n",
      "Train Epoch: 1 [21504/60000 (36%)]\tLoss: 2.278281\n",
      "Train Epoch: 1 [21632/60000 (36%)]\tLoss: 2.277831\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.272024\n",
      "Train Epoch: 1 [21888/60000 (37%)]\tLoss: 2.280843\n",
      "Train Epoch: 1 [22016/60000 (37%)]\tLoss: 2.275190\n",
      "Train Epoch: 1 [22144/60000 (37%)]\tLoss: 2.282823\n",
      "Train Epoch: 1 [22272/60000 (37%)]\tLoss: 2.281430\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.288346\n",
      "Train Epoch: 1 [22528/60000 (38%)]\tLoss: 2.278592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [22656/60000 (38%)]\tLoss: 2.280075\n",
      "Train Epoch: 1 [22784/60000 (38%)]\tLoss: 2.292664\n",
      "Train Epoch: 1 [22912/60000 (38%)]\tLoss: 2.275429\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.279511\n",
      "Train Epoch: 1 [23168/60000 (39%)]\tLoss: 2.284936\n",
      "Train Epoch: 1 [23296/60000 (39%)]\tLoss: 2.271880\n",
      "Train Epoch: 1 [23424/60000 (39%)]\tLoss: 2.283242\n",
      "Train Epoch: 1 [23552/60000 (39%)]\tLoss: 2.283988\n",
      "Train Epoch: 1 [23680/60000 (40%)]\tLoss: 2.280494\n",
      "Train Epoch: 1 [23808/60000 (40%)]\tLoss: 2.280482\n",
      "Train Epoch: 1 [23936/60000 (40%)]\tLoss: 2.282231\n",
      "Train Epoch: 1 [24064/60000 (40%)]\tLoss: 2.274110\n",
      "Train Epoch: 1 [24192/60000 (40%)]\tLoss: 2.277295\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.283407\n",
      "Train Epoch: 1 [24448/60000 (41%)]\tLoss: 2.272648\n",
      "Train Epoch: 1 [24576/60000 (41%)]\tLoss: 2.277533\n",
      "Train Epoch: 1 [24704/60000 (41%)]\tLoss: 2.280505\n",
      "Train Epoch: 1 [24832/60000 (41%)]\tLoss: 2.287986\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.273162\n",
      "Train Epoch: 1 [25088/60000 (42%)]\tLoss: 2.280904\n",
      "Train Epoch: 1 [25216/60000 (42%)]\tLoss: 2.274546\n",
      "Train Epoch: 1 [25344/60000 (42%)]\tLoss: 2.275323\n",
      "Train Epoch: 1 [25472/60000 (43%)]\tLoss: 2.274606\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.271204\n",
      "Train Epoch: 1 [25728/60000 (43%)]\tLoss: 2.277926\n",
      "Train Epoch: 1 [25856/60000 (43%)]\tLoss: 2.281893\n",
      "Train Epoch: 1 [25984/60000 (43%)]\tLoss: 2.278909\n",
      "Train Epoch: 1 [26112/60000 (44%)]\tLoss: 2.269154\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.283935\n",
      "Train Epoch: 1 [26368/60000 (44%)]\tLoss: 2.279950\n",
      "Train Epoch: 1 [26496/60000 (44%)]\tLoss: 2.269022\n",
      "Train Epoch: 1 [26624/60000 (44%)]\tLoss: 2.268058\n",
      "Train Epoch: 1 [26752/60000 (45%)]\tLoss: 2.268264\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.276709\n",
      "Train Epoch: 1 [27008/60000 (45%)]\tLoss: 2.282175\n",
      "Train Epoch: 1 [27136/60000 (45%)]\tLoss: 2.268685\n",
      "Train Epoch: 1 [27264/60000 (46%)]\tLoss: 2.262390\n",
      "Train Epoch: 1 [27392/60000 (46%)]\tLoss: 2.277486\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.274414\n",
      "Train Epoch: 1 [27648/60000 (46%)]\tLoss: 2.267462\n",
      "Train Epoch: 1 [27776/60000 (46%)]\tLoss: 2.275539\n",
      "Train Epoch: 1 [27904/60000 (47%)]\tLoss: 2.274356\n",
      "Train Epoch: 1 [28032/60000 (47%)]\tLoss: 2.257374\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.262803\n",
      "Train Epoch: 1 [28288/60000 (47%)]\tLoss: 2.282218\n",
      "Train Epoch: 1 [28416/60000 (47%)]\tLoss: 2.268889\n",
      "Train Epoch: 1 [28544/60000 (48%)]\tLoss: 2.280669\n",
      "Train Epoch: 1 [28672/60000 (48%)]\tLoss: 2.276877\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.272889\n",
      "Train Epoch: 1 [28928/60000 (48%)]\tLoss: 2.270688\n",
      "Train Epoch: 1 [29056/60000 (49%)]\tLoss: 2.272472\n",
      "Train Epoch: 1 [29184/60000 (49%)]\tLoss: 2.274732\n",
      "Train Epoch: 1 [29312/60000 (49%)]\tLoss: 2.265483\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.266203\n",
      "Train Epoch: 1 [29568/60000 (49%)]\tLoss: 2.268691\n",
      "Train Epoch: 1 [29696/60000 (50%)]\tLoss: 2.287658\n",
      "Train Epoch: 1 [29824/60000 (50%)]\tLoss: 2.292843\n",
      "Train Epoch: 1 [29952/60000 (50%)]\tLoss: 2.274293\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.275773\n",
      "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 2.271388\n",
      "Train Epoch: 1 [30336/60000 (51%)]\tLoss: 2.260585\n",
      "Train Epoch: 1 [30464/60000 (51%)]\tLoss: 2.274998\n",
      "Train Epoch: 1 [30592/60000 (51%)]\tLoss: 2.264923\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.260786\n",
      "Train Epoch: 1 [30848/60000 (51%)]\tLoss: 2.271670\n",
      "Train Epoch: 1 [30976/60000 (52%)]\tLoss: 2.266082\n",
      "Train Epoch: 1 [31104/60000 (52%)]\tLoss: 2.261388\n",
      "Train Epoch: 1 [31232/60000 (52%)]\tLoss: 2.275068\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.275337\n",
      "Train Epoch: 1 [31488/60000 (53%)]\tLoss: 2.273165\n",
      "Train Epoch: 1 [31616/60000 (53%)]\tLoss: 2.265371\n",
      "Train Epoch: 1 [31744/60000 (53%)]\tLoss: 2.267474\n",
      "Train Epoch: 1 [31872/60000 (53%)]\tLoss: 2.270955\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.260451\n",
      "Train Epoch: 1 [32128/60000 (54%)]\tLoss: 2.282649\n",
      "Train Epoch: 1 [32256/60000 (54%)]\tLoss: 2.273981\n",
      "Train Epoch: 1 [32384/60000 (54%)]\tLoss: 2.266769\n",
      "Train Epoch: 1 [32512/60000 (54%)]\tLoss: 2.276499\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 2.259630\n",
      "Train Epoch: 1 [32768/60000 (55%)]\tLoss: 2.259896\n",
      "Train Epoch: 1 [32896/60000 (55%)]\tLoss: 2.248671\n",
      "Train Epoch: 1 [33024/60000 (55%)]\tLoss: 2.286094\n",
      "Train Epoch: 1 [33152/60000 (55%)]\tLoss: 2.262742\n",
      "Train Epoch: 1 [33280/60000 (56%)]\tLoss: 2.266241\n",
      "Train Epoch: 1 [33408/60000 (56%)]\tLoss: 2.267535\n",
      "Train Epoch: 1 [33536/60000 (56%)]\tLoss: 2.261612\n",
      "Train Epoch: 1 [33664/60000 (56%)]\tLoss: 2.253906\n",
      "Train Epoch: 1 [33792/60000 (56%)]\tLoss: 2.246258\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.263395\n",
      "Train Epoch: 1 [34048/60000 (57%)]\tLoss: 2.262133\n",
      "Train Epoch: 1 [34176/60000 (57%)]\tLoss: 2.253714\n",
      "Train Epoch: 1 [34304/60000 (57%)]\tLoss: 2.258560\n",
      "Train Epoch: 1 [34432/60000 (57%)]\tLoss: 2.277095\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.263700\n",
      "Train Epoch: 1 [34688/60000 (58%)]\tLoss: 2.253453\n",
      "Train Epoch: 1 [34816/60000 (58%)]\tLoss: 2.258873\n",
      "Train Epoch: 1 [34944/60000 (58%)]\tLoss: 2.264141\n",
      "Train Epoch: 1 [35072/60000 (59%)]\tLoss: 2.260730\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.264564\n",
      "Train Epoch: 1 [35328/60000 (59%)]\tLoss: 2.249883\n",
      "Train Epoch: 1 [35456/60000 (59%)]\tLoss: 2.262614\n",
      "Train Epoch: 1 [35584/60000 (59%)]\tLoss: 2.244811\n",
      "Train Epoch: 1 [35712/60000 (60%)]\tLoss: 2.248631\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.253171\n",
      "Train Epoch: 1 [35968/60000 (60%)]\tLoss: 2.256032\n",
      "Train Epoch: 1 [36096/60000 (60%)]\tLoss: 2.245811\n",
      "Train Epoch: 1 [36224/60000 (60%)]\tLoss: 2.243170\n",
      "Train Epoch: 1 [36352/60000 (61%)]\tLoss: 2.253076\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 2.260533\n",
      "Train Epoch: 1 [36608/60000 (61%)]\tLoss: 2.240580\n",
      "Train Epoch: 1 [36736/60000 (61%)]\tLoss: 2.234606\n",
      "Train Epoch: 1 [36864/60000 (62%)]\tLoss: 2.243047\n",
      "Train Epoch: 1 [36992/60000 (62%)]\tLoss: 2.261485\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.250299\n",
      "Train Epoch: 1 [37248/60000 (62%)]\tLoss: 2.244007\n",
      "Train Epoch: 1 [37376/60000 (62%)]\tLoss: 2.261443\n",
      "Train Epoch: 1 [37504/60000 (63%)]\tLoss: 2.259943\n",
      "Train Epoch: 1 [37632/60000 (63%)]\tLoss: 2.228092\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 2.252823\n",
      "Train Epoch: 1 [37888/60000 (63%)]\tLoss: 2.258094\n",
      "Train Epoch: 1 [38016/60000 (63%)]\tLoss: 2.247919\n",
      "Train Epoch: 1 [38144/60000 (64%)]\tLoss: 2.261106\n",
      "Train Epoch: 1 [38272/60000 (64%)]\tLoss: 2.257332\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.236158\n",
      "Train Epoch: 1 [38528/60000 (64%)]\tLoss: 2.266202\n",
      "Train Epoch: 1 [38656/60000 (65%)]\tLoss: 2.262776\n",
      "Train Epoch: 1 [38784/60000 (65%)]\tLoss: 2.246353\n",
      "Train Epoch: 1 [38912/60000 (65%)]\tLoss: 2.249081\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 2.237433\n",
      "Train Epoch: 1 [39168/60000 (65%)]\tLoss: 2.242686\n",
      "Train Epoch: 1 [39296/60000 (66%)]\tLoss: 2.254459\n",
      "Train Epoch: 1 [39424/60000 (66%)]\tLoss: 2.248996\n",
      "Train Epoch: 1 [39552/60000 (66%)]\tLoss: 2.248093\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 2.261368\n",
      "Train Epoch: 1 [39808/60000 (66%)]\tLoss: 2.241514\n",
      "Train Epoch: 1 [39936/60000 (67%)]\tLoss: 2.245436\n",
      "Train Epoch: 1 [40064/60000 (67%)]\tLoss: 2.231570\n",
      "Train Epoch: 1 [40192/60000 (67%)]\tLoss: 2.252610\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 2.233025\n",
      "Train Epoch: 1 [40448/60000 (68%)]\tLoss: 2.245657\n",
      "Train Epoch: 1 [40576/60000 (68%)]\tLoss: 2.247348\n",
      "Train Epoch: 1 [40704/60000 (68%)]\tLoss: 2.257815\n",
      "Train Epoch: 1 [40832/60000 (68%)]\tLoss: 2.231877\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.224654\n",
      "Train Epoch: 1 [41088/60000 (69%)]\tLoss: 2.242036\n",
      "Train Epoch: 1 [41216/60000 (69%)]\tLoss: 2.248105\n",
      "Train Epoch: 1 [41344/60000 (69%)]\tLoss: 2.245825\n",
      "Train Epoch: 1 [41472/60000 (69%)]\tLoss: 2.268466\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 2.249188\n",
      "Train Epoch: 1 [41728/60000 (70%)]\tLoss: 2.244941\n",
      "Train Epoch: 1 [41856/60000 (70%)]\tLoss: 2.254232\n",
      "Train Epoch: 1 [41984/60000 (70%)]\tLoss: 2.244754\n",
      "Train Epoch: 1 [42112/60000 (70%)]\tLoss: 2.248994\n",
      "Train Epoch: 1 [42240/60000 (71%)]\tLoss: 2.256063\n",
      "Train Epoch: 1 [42368/60000 (71%)]\tLoss: 2.219090\n",
      "Train Epoch: 1 [42496/60000 (71%)]\tLoss: 2.240088\n",
      "Train Epoch: 1 [42624/60000 (71%)]\tLoss: 2.260379\n",
      "Train Epoch: 1 [42752/60000 (71%)]\tLoss: 2.241117\n",
      "Train Epoch: 1 [42880/60000 (72%)]\tLoss: 2.245068\n",
      "Train Epoch: 1 [43008/60000 (72%)]\tLoss: 2.250035\n",
      "Train Epoch: 1 [43136/60000 (72%)]\tLoss: 2.222200\n",
      "Train Epoch: 1 [43264/60000 (72%)]\tLoss: 2.228958\n",
      "Train Epoch: 1 [43392/60000 (72%)]\tLoss: 2.235742\n",
      "Train Epoch: 1 [43520/60000 (73%)]\tLoss: 2.240418\n",
      "Train Epoch: 1 [43648/60000 (73%)]\tLoss: 2.234204\n",
      "Train Epoch: 1 [43776/60000 (73%)]\tLoss: 2.234373\n",
      "Train Epoch: 1 [43904/60000 (73%)]\tLoss: 2.242520\n",
      "Train Epoch: 1 [44032/60000 (74%)]\tLoss: 2.252928\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 2.233921\n",
      "Train Epoch: 1 [44288/60000 (74%)]\tLoss: 2.235693\n",
      "Train Epoch: 1 [44416/60000 (74%)]\tLoss: 2.231959\n",
      "Train Epoch: 1 [44544/60000 (74%)]\tLoss: 2.231462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [44672/60000 (75%)]\tLoss: 2.224964\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.238142\n",
      "Train Epoch: 1 [44928/60000 (75%)]\tLoss: 2.231721\n",
      "Train Epoch: 1 [45056/60000 (75%)]\tLoss: 2.225406\n",
      "Train Epoch: 1 [45184/60000 (75%)]\tLoss: 2.223253\n",
      "Train Epoch: 1 [45312/60000 (76%)]\tLoss: 2.219129\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 2.220951\n",
      "Train Epoch: 1 [45568/60000 (76%)]\tLoss: 2.208453\n",
      "Train Epoch: 1 [45696/60000 (76%)]\tLoss: 2.211915\n",
      "Train Epoch: 1 [45824/60000 (76%)]\tLoss: 2.247065\n",
      "Train Epoch: 1 [45952/60000 (77%)]\tLoss: 2.218020\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 2.228865\n",
      "Train Epoch: 1 [46208/60000 (77%)]\tLoss: 2.245008\n",
      "Train Epoch: 1 [46336/60000 (77%)]\tLoss: 2.217327\n",
      "Train Epoch: 1 [46464/60000 (78%)]\tLoss: 2.208501\n",
      "Train Epoch: 1 [46592/60000 (78%)]\tLoss: 2.210084\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 2.235343\n",
      "Train Epoch: 1 [46848/60000 (78%)]\tLoss: 2.215467\n",
      "Train Epoch: 1 [46976/60000 (78%)]\tLoss: 2.227422\n",
      "Train Epoch: 1 [47104/60000 (79%)]\tLoss: 2.201626\n",
      "Train Epoch: 1 [47232/60000 (79%)]\tLoss: 2.242929\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 2.232848\n",
      "Train Epoch: 1 [47488/60000 (79%)]\tLoss: 2.229015\n",
      "Train Epoch: 1 [47616/60000 (79%)]\tLoss: 2.212103\n",
      "Train Epoch: 1 [47744/60000 (80%)]\tLoss: 2.197206\n",
      "Train Epoch: 1 [47872/60000 (80%)]\tLoss: 2.221811\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.219071\n",
      "Train Epoch: 1 [48128/60000 (80%)]\tLoss: 2.210132\n",
      "Train Epoch: 1 [48256/60000 (81%)]\tLoss: 2.209416\n",
      "Train Epoch: 1 [48384/60000 (81%)]\tLoss: 2.206353\n",
      "Train Epoch: 1 [48512/60000 (81%)]\tLoss: 2.193129\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 2.205713\n",
      "Train Epoch: 1 [48768/60000 (81%)]\tLoss: 2.199228\n",
      "Train Epoch: 1 [48896/60000 (82%)]\tLoss: 2.237936\n",
      "Train Epoch: 1 [49024/60000 (82%)]\tLoss: 2.239880\n",
      "Train Epoch: 1 [49152/60000 (82%)]\tLoss: 2.220475\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 2.219921\n",
      "Train Epoch: 1 [49408/60000 (82%)]\tLoss: 2.203964\n",
      "Train Epoch: 1 [49536/60000 (83%)]\tLoss: 2.230806\n",
      "Train Epoch: 1 [49664/60000 (83%)]\tLoss: 2.207012\n",
      "Train Epoch: 1 [49792/60000 (83%)]\tLoss: 2.195133\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 2.203540\n",
      "Train Epoch: 1 [50048/60000 (84%)]\tLoss: 2.204904\n",
      "Train Epoch: 1 [50176/60000 (84%)]\tLoss: 2.220978\n",
      "Train Epoch: 1 [50304/60000 (84%)]\tLoss: 2.229783\n",
      "Train Epoch: 1 [50432/60000 (84%)]\tLoss: 2.197741\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 2.203649\n",
      "Train Epoch: 1 [50688/60000 (85%)]\tLoss: 2.197156\n",
      "Train Epoch: 1 [50816/60000 (85%)]\tLoss: 2.198843\n",
      "Train Epoch: 1 [50944/60000 (85%)]\tLoss: 2.209231\n",
      "Train Epoch: 1 [51072/60000 (85%)]\tLoss: 2.237074\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.194639\n",
      "Train Epoch: 1 [51328/60000 (86%)]\tLoss: 2.181401\n",
      "Train Epoch: 1 [51456/60000 (86%)]\tLoss: 2.171473\n",
      "Train Epoch: 1 [51584/60000 (86%)]\tLoss: 2.190502\n",
      "Train Epoch: 1 [51712/60000 (86%)]\tLoss: 2.210158\n",
      "Train Epoch: 1 [51840/60000 (87%)]\tLoss: 2.193242\n",
      "Train Epoch: 1 [51968/60000 (87%)]\tLoss: 2.182127\n",
      "Train Epoch: 1 [52096/60000 (87%)]\tLoss: 2.229229\n",
      "Train Epoch: 1 [52224/60000 (87%)]\tLoss: 2.206947\n",
      "Train Epoch: 1 [52352/60000 (87%)]\tLoss: 2.171402\n",
      "Train Epoch: 1 [52480/60000 (88%)]\tLoss: 2.142904\n",
      "Train Epoch: 1 [52608/60000 (88%)]\tLoss: 2.178424\n",
      "Train Epoch: 1 [52736/60000 (88%)]\tLoss: 2.201999\n",
      "Train Epoch: 1 [52864/60000 (88%)]\tLoss: 2.196000\n",
      "Train Epoch: 1 [52992/60000 (88%)]\tLoss: 2.187556\n",
      "Train Epoch: 1 [53120/60000 (89%)]\tLoss: 2.207675\n",
      "Train Epoch: 1 [53248/60000 (89%)]\tLoss: 2.155624\n",
      "Train Epoch: 1 [53376/60000 (89%)]\tLoss: 2.202087\n",
      "Train Epoch: 1 [53504/60000 (89%)]\tLoss: 2.182407\n",
      "Train Epoch: 1 [53632/60000 (90%)]\tLoss: 2.200571\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 2.163116\n",
      "Train Epoch: 1 [53888/60000 (90%)]\tLoss: 2.204553\n",
      "Train Epoch: 1 [54016/60000 (90%)]\tLoss: 2.207486\n",
      "Train Epoch: 1 [54144/60000 (90%)]\tLoss: 2.178442\n",
      "Train Epoch: 1 [54272/60000 (91%)]\tLoss: 2.169089\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 2.183588\n",
      "Train Epoch: 1 [54528/60000 (91%)]\tLoss: 2.156610\n",
      "Train Epoch: 1 [54656/60000 (91%)]\tLoss: 2.186085\n",
      "Train Epoch: 1 [54784/60000 (91%)]\tLoss: 2.193013\n",
      "Train Epoch: 1 [54912/60000 (92%)]\tLoss: 2.200111\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 2.157659\n",
      "Train Epoch: 1 [55168/60000 (92%)]\tLoss: 2.134315\n",
      "Train Epoch: 1 [55296/60000 (92%)]\tLoss: 2.194059\n",
      "Train Epoch: 1 [55424/60000 (93%)]\tLoss: 2.167509\n",
      "Train Epoch: 1 [55552/60000 (93%)]\tLoss: 2.163375\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 2.166396\n",
      "Train Epoch: 1 [55808/60000 (93%)]\tLoss: 2.156502\n",
      "Train Epoch: 1 [55936/60000 (93%)]\tLoss: 2.165783\n",
      "Train Epoch: 1 [56064/60000 (94%)]\tLoss: 2.188120\n",
      "Train Epoch: 1 [56192/60000 (94%)]\tLoss: 2.183930\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 2.163882\n",
      "Train Epoch: 1 [56448/60000 (94%)]\tLoss: 2.156850\n",
      "Train Epoch: 1 [56576/60000 (94%)]\tLoss: 2.151442\n",
      "Train Epoch: 1 [56704/60000 (95%)]\tLoss: 2.140503\n",
      "Train Epoch: 1 [56832/60000 (95%)]\tLoss: 2.149251\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 2.200717\n",
      "Train Epoch: 1 [57088/60000 (95%)]\tLoss: 2.146589\n",
      "Train Epoch: 1 [57216/60000 (96%)]\tLoss: 2.200778\n",
      "Train Epoch: 1 [57344/60000 (96%)]\tLoss: 2.158754\n",
      "Train Epoch: 1 [57472/60000 (96%)]\tLoss: 2.187749\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.161816\n",
      "Train Epoch: 1 [57728/60000 (96%)]\tLoss: 2.152331\n",
      "Train Epoch: 1 [57856/60000 (97%)]\tLoss: 2.138615\n",
      "Train Epoch: 1 [57984/60000 (97%)]\tLoss: 2.173999\n",
      "Train Epoch: 1 [58112/60000 (97%)]\tLoss: 2.137710\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 2.178664\n",
      "Train Epoch: 1 [58368/60000 (97%)]\tLoss: 2.163090\n",
      "Train Epoch: 1 [58496/60000 (98%)]\tLoss: 2.128535\n",
      "Train Epoch: 1 [58624/60000 (98%)]\tLoss: 2.152628\n",
      "Train Epoch: 1 [58752/60000 (98%)]\tLoss: 2.130894\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 2.116902\n",
      "Train Epoch: 1 [59008/60000 (99%)]\tLoss: 2.083756\n",
      "Train Epoch: 1 [59136/60000 (99%)]\tLoss: 2.115020\n",
      "Train Epoch: 1 [59264/60000 (99%)]\tLoss: 2.200232\n",
      "Train Epoch: 1 [59392/60000 (99%)]\tLoss: 2.084787\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 2.126225\n",
      "Train Epoch: 1 [59648/60000 (100%)]\tLoss: 2.166033\n",
      "Train Epoch: 1 [59776/60000 (100%)]\tLoss: 2.112753\n",
      "================================================================\n",
      "Training: Average loss: 2.0742, Accuracy: 37876/60000 (63%)\n",
      "Test: Average loss: 2.0669, Accuracy: 6373/10000 (64%)\n",
      "================================================================\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.103805\n",
      "Train Epoch: 2 [128/60000 (0%)]\tLoss: 2.104804\n",
      "Train Epoch: 2 [256/60000 (0%)]\tLoss: 2.182788\n",
      "Train Epoch: 2 [384/60000 (1%)]\tLoss: 2.172671\n",
      "Train Epoch: 2 [512/60000 (1%)]\tLoss: 2.175133\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 2.143730\n",
      "Train Epoch: 2 [768/60000 (1%)]\tLoss: 2.157791\n",
      "Train Epoch: 2 [896/60000 (1%)]\tLoss: 2.202971\n",
      "Train Epoch: 2 [1024/60000 (2%)]\tLoss: 2.184453\n",
      "Train Epoch: 2 [1152/60000 (2%)]\tLoss: 2.176883\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 2.160345\n",
      "Train Epoch: 2 [1408/60000 (2%)]\tLoss: 2.145196\n",
      "Train Epoch: 2 [1536/60000 (3%)]\tLoss: 2.105025\n",
      "Train Epoch: 2 [1664/60000 (3%)]\tLoss: 2.106369\n",
      "Train Epoch: 2 [1792/60000 (3%)]\tLoss: 2.121894\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 2.117392\n",
      "Train Epoch: 2 [2048/60000 (3%)]\tLoss: 2.089467\n",
      "Train Epoch: 2 [2176/60000 (4%)]\tLoss: 2.114915\n",
      "Train Epoch: 2 [2304/60000 (4%)]\tLoss: 2.156788\n",
      "Train Epoch: 2 [2432/60000 (4%)]\tLoss: 2.113271\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 2.107441\n",
      "Train Epoch: 2 [2688/60000 (4%)]\tLoss: 2.127621\n",
      "Train Epoch: 2 [2816/60000 (5%)]\tLoss: 2.120337\n",
      "Train Epoch: 2 [2944/60000 (5%)]\tLoss: 2.136084\n",
      "Train Epoch: 2 [3072/60000 (5%)]\tLoss: 2.125337\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 2.120754\n",
      "Train Epoch: 2 [3328/60000 (6%)]\tLoss: 2.098581\n",
      "Train Epoch: 2 [3456/60000 (6%)]\tLoss: 2.148600\n",
      "Train Epoch: 2 [3584/60000 (6%)]\tLoss: 2.110518\n",
      "Train Epoch: 2 [3712/60000 (6%)]\tLoss: 2.067532\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 2.096172\n",
      "Train Epoch: 2 [3968/60000 (7%)]\tLoss: 2.134263\n",
      "Train Epoch: 2 [4096/60000 (7%)]\tLoss: 2.088216\n",
      "Train Epoch: 2 [4224/60000 (7%)]\tLoss: 2.081301\n",
      "Train Epoch: 2 [4352/60000 (7%)]\tLoss: 2.118519\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 2.038771\n",
      "Train Epoch: 2 [4608/60000 (8%)]\tLoss: 2.103996\n",
      "Train Epoch: 2 [4736/60000 (8%)]\tLoss: 2.120104\n",
      "Train Epoch: 2 [4864/60000 (8%)]\tLoss: 2.132779\n",
      "Train Epoch: 2 [4992/60000 (8%)]\tLoss: 2.106404\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 2.095128\n",
      "Train Epoch: 2 [5248/60000 (9%)]\tLoss: 2.055603\n",
      "Train Epoch: 2 [5376/60000 (9%)]\tLoss: 2.098083\n",
      "Train Epoch: 2 [5504/60000 (9%)]\tLoss: 2.076014\n",
      "Train Epoch: 2 [5632/60000 (9%)]\tLoss: 2.098893\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 2.115543\n",
      "Train Epoch: 2 [5888/60000 (10%)]\tLoss: 2.064274\n",
      "Train Epoch: 2 [6016/60000 (10%)]\tLoss: 2.067681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [6144/60000 (10%)]\tLoss: 2.117373\n",
      "Train Epoch: 2 [6272/60000 (10%)]\tLoss: 2.127830\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 2.099058\n",
      "Train Epoch: 2 [6528/60000 (11%)]\tLoss: 2.044782\n",
      "Train Epoch: 2 [6656/60000 (11%)]\tLoss: 2.057832\n",
      "Train Epoch: 2 [6784/60000 (11%)]\tLoss: 2.145565\n",
      "Train Epoch: 2 [6912/60000 (12%)]\tLoss: 2.049542\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 2.091748\n",
      "Train Epoch: 2 [7168/60000 (12%)]\tLoss: 2.119197\n",
      "Train Epoch: 2 [7296/60000 (12%)]\tLoss: 2.121116\n",
      "Train Epoch: 2 [7424/60000 (12%)]\tLoss: 2.118136\n",
      "Train Epoch: 2 [7552/60000 (13%)]\tLoss: 2.107317\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 2.107777\n",
      "Train Epoch: 2 [7808/60000 (13%)]\tLoss: 2.048890\n",
      "Train Epoch: 2 [7936/60000 (13%)]\tLoss: 2.030258\n",
      "Train Epoch: 2 [8064/60000 (13%)]\tLoss: 2.062024\n",
      "Train Epoch: 2 [8192/60000 (14%)]\tLoss: 2.069755\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 2.097136\n",
      "Train Epoch: 2 [8448/60000 (14%)]\tLoss: 2.053003\n",
      "Train Epoch: 2 [8576/60000 (14%)]\tLoss: 2.101554\n",
      "Train Epoch: 2 [8704/60000 (15%)]\tLoss: 2.083863\n",
      "Train Epoch: 2 [8832/60000 (15%)]\tLoss: 2.051058\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 1.988234\n",
      "Train Epoch: 2 [9088/60000 (15%)]\tLoss: 2.036846\n",
      "Train Epoch: 2 [9216/60000 (15%)]\tLoss: 2.059747\n",
      "Train Epoch: 2 [9344/60000 (16%)]\tLoss: 2.080165\n",
      "Train Epoch: 2 [9472/60000 (16%)]\tLoss: 2.035983\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 1.973285\n",
      "Train Epoch: 2 [9728/60000 (16%)]\tLoss: 2.065640\n",
      "Train Epoch: 2 [9856/60000 (16%)]\tLoss: 2.048413\n",
      "Train Epoch: 2 [9984/60000 (17%)]\tLoss: 2.051152\n",
      "Train Epoch: 2 [10112/60000 (17%)]\tLoss: 2.047434\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 2.012859\n",
      "Train Epoch: 2 [10368/60000 (17%)]\tLoss: 2.034793\n",
      "Train Epoch: 2 [10496/60000 (18%)]\tLoss: 2.004269\n",
      "Train Epoch: 2 [10624/60000 (18%)]\tLoss: 2.026886\n",
      "Train Epoch: 2 [10752/60000 (18%)]\tLoss: 2.038818\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 2.034482\n",
      "Train Epoch: 2 [11008/60000 (18%)]\tLoss: 2.017775\n",
      "Train Epoch: 2 [11136/60000 (19%)]\tLoss: 2.047077\n",
      "Train Epoch: 2 [11264/60000 (19%)]\tLoss: 2.026926\n",
      "Train Epoch: 2 [11392/60000 (19%)]\tLoss: 2.028591\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 2.064996\n",
      "Train Epoch: 2 [11648/60000 (19%)]\tLoss: 2.055360\n",
      "Train Epoch: 2 [11776/60000 (20%)]\tLoss: 2.038364\n",
      "Train Epoch: 2 [11904/60000 (20%)]\tLoss: 1.992821\n",
      "Train Epoch: 2 [12032/60000 (20%)]\tLoss: 2.023804\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 2.033803\n",
      "Train Epoch: 2 [12288/60000 (21%)]\tLoss: 2.065770\n",
      "Train Epoch: 2 [12416/60000 (21%)]\tLoss: 2.008219\n",
      "Train Epoch: 2 [12544/60000 (21%)]\tLoss: 2.050131\n",
      "Train Epoch: 2 [12672/60000 (21%)]\tLoss: 2.045643\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.055607\n",
      "Train Epoch: 2 [12928/60000 (22%)]\tLoss: 2.117824\n",
      "Train Epoch: 2 [13056/60000 (22%)]\tLoss: 2.060975\n",
      "Train Epoch: 2 [13184/60000 (22%)]\tLoss: 1.983855\n",
      "Train Epoch: 2 [13312/60000 (22%)]\tLoss: 2.085582\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 1.985307\n",
      "Train Epoch: 2 [13568/60000 (23%)]\tLoss: 2.004375\n",
      "Train Epoch: 2 [13696/60000 (23%)]\tLoss: 1.969454\n",
      "Train Epoch: 2 [13824/60000 (23%)]\tLoss: 2.081104\n",
      "Train Epoch: 2 [13952/60000 (23%)]\tLoss: 2.058601\n",
      "Train Epoch: 2 [14080/60000 (24%)]\tLoss: 1.981647\n",
      "Train Epoch: 2 [14208/60000 (24%)]\tLoss: 1.999335\n",
      "Train Epoch: 2 [14336/60000 (24%)]\tLoss: 1.972291\n",
      "Train Epoch: 2 [14464/60000 (24%)]\tLoss: 1.989146\n",
      "Train Epoch: 2 [14592/60000 (24%)]\tLoss: 2.069852\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 1.969859\n",
      "Train Epoch: 2 [14848/60000 (25%)]\tLoss: 1.978190\n",
      "Train Epoch: 2 [14976/60000 (25%)]\tLoss: 1.970178\n",
      "Train Epoch: 2 [15104/60000 (25%)]\tLoss: 2.001229\n",
      "Train Epoch: 2 [15232/60000 (25%)]\tLoss: 1.948899\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 1.967494\n",
      "Train Epoch: 2 [15488/60000 (26%)]\tLoss: 1.961318\n",
      "Train Epoch: 2 [15616/60000 (26%)]\tLoss: 1.982634\n",
      "Train Epoch: 2 [15744/60000 (26%)]\tLoss: 2.050929\n",
      "Train Epoch: 2 [15872/60000 (26%)]\tLoss: 2.053306\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.046443\n",
      "Train Epoch: 2 [16128/60000 (27%)]\tLoss: 2.012889\n",
      "Train Epoch: 2 [16256/60000 (27%)]\tLoss: 2.002656\n",
      "Train Epoch: 2 [16384/60000 (27%)]\tLoss: 1.974328\n",
      "Train Epoch: 2 [16512/60000 (28%)]\tLoss: 1.909076\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 1.958924\n",
      "Train Epoch: 2 [16768/60000 (28%)]\tLoss: 2.060653\n",
      "Train Epoch: 2 [16896/60000 (28%)]\tLoss: 2.042968\n",
      "Train Epoch: 2 [17024/60000 (28%)]\tLoss: 1.940710\n",
      "Train Epoch: 2 [17152/60000 (29%)]\tLoss: 1.990194\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 1.947504\n",
      "Train Epoch: 2 [17408/60000 (29%)]\tLoss: 1.997922\n",
      "Train Epoch: 2 [17536/60000 (29%)]\tLoss: 2.026333\n",
      "Train Epoch: 2 [17664/60000 (29%)]\tLoss: 2.043142\n",
      "Train Epoch: 2 [17792/60000 (30%)]\tLoss: 1.988614\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 1.945144\n",
      "Train Epoch: 2 [18048/60000 (30%)]\tLoss: 1.887599\n",
      "Train Epoch: 2 [18176/60000 (30%)]\tLoss: 1.908440\n",
      "Train Epoch: 2 [18304/60000 (31%)]\tLoss: 1.997601\n",
      "Train Epoch: 2 [18432/60000 (31%)]\tLoss: 1.974657\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 1.941514\n",
      "Train Epoch: 2 [18688/60000 (31%)]\tLoss: 1.973097\n",
      "Train Epoch: 2 [18816/60000 (31%)]\tLoss: 1.959550\n",
      "Train Epoch: 2 [18944/60000 (32%)]\tLoss: 1.980556\n",
      "Train Epoch: 2 [19072/60000 (32%)]\tLoss: 2.020065\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.934142\n",
      "Train Epoch: 2 [19328/60000 (32%)]\tLoss: 1.899049\n",
      "Train Epoch: 2 [19456/60000 (32%)]\tLoss: 1.865307\n",
      "Train Epoch: 2 [19584/60000 (33%)]\tLoss: 1.946224\n",
      "Train Epoch: 2 [19712/60000 (33%)]\tLoss: 1.911514\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 1.916746\n",
      "Train Epoch: 2 [19968/60000 (33%)]\tLoss: 1.942141\n",
      "Train Epoch: 2 [20096/60000 (34%)]\tLoss: 1.959893\n",
      "Train Epoch: 2 [20224/60000 (34%)]\tLoss: 1.983577\n",
      "Train Epoch: 2 [20352/60000 (34%)]\tLoss: 1.893839\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 1.908334\n",
      "Train Epoch: 2 [20608/60000 (34%)]\tLoss: 1.900031\n",
      "Train Epoch: 2 [20736/60000 (35%)]\tLoss: 1.922155\n",
      "Train Epoch: 2 [20864/60000 (35%)]\tLoss: 2.035431\n",
      "Train Epoch: 2 [20992/60000 (35%)]\tLoss: 1.867208\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 1.877457\n",
      "Train Epoch: 2 [21248/60000 (35%)]\tLoss: 1.900554\n",
      "Train Epoch: 2 [21376/60000 (36%)]\tLoss: 1.900472\n",
      "Train Epoch: 2 [21504/60000 (36%)]\tLoss: 1.977751\n",
      "Train Epoch: 2 [21632/60000 (36%)]\tLoss: 1.926509\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 1.788071\n",
      "Train Epoch: 2 [21888/60000 (37%)]\tLoss: 1.782644\n",
      "Train Epoch: 2 [22016/60000 (37%)]\tLoss: 1.903257\n",
      "Train Epoch: 2 [22144/60000 (37%)]\tLoss: 1.933095\n",
      "Train Epoch: 2 [22272/60000 (37%)]\tLoss: 1.892827\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 1.914902\n",
      "Train Epoch: 2 [22528/60000 (38%)]\tLoss: 1.957585\n",
      "Train Epoch: 2 [22656/60000 (38%)]\tLoss: 1.905238\n",
      "Train Epoch: 2 [22784/60000 (38%)]\tLoss: 1.877606\n",
      "Train Epoch: 2 [22912/60000 (38%)]\tLoss: 1.774729\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 1.942480\n",
      "Train Epoch: 2 [23168/60000 (39%)]\tLoss: 1.856737\n",
      "Train Epoch: 2 [23296/60000 (39%)]\tLoss: 1.878726\n",
      "Train Epoch: 2 [23424/60000 (39%)]\tLoss: 1.852253\n",
      "Train Epoch: 2 [23552/60000 (39%)]\tLoss: 1.898831\n",
      "Train Epoch: 2 [23680/60000 (40%)]\tLoss: 1.921637\n",
      "Train Epoch: 2 [23808/60000 (40%)]\tLoss: 1.910061\n",
      "Train Epoch: 2 [23936/60000 (40%)]\tLoss: 1.926773\n",
      "Train Epoch: 2 [24064/60000 (40%)]\tLoss: 1.843948\n",
      "Train Epoch: 2 [24192/60000 (40%)]\tLoss: 1.919520\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 1.866298\n",
      "Train Epoch: 2 [24448/60000 (41%)]\tLoss: 1.826849\n",
      "Train Epoch: 2 [24576/60000 (41%)]\tLoss: 1.794024\n",
      "Train Epoch: 2 [24704/60000 (41%)]\tLoss: 1.953129\n",
      "Train Epoch: 2 [24832/60000 (41%)]\tLoss: 1.916793\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 1.841134\n",
      "Train Epoch: 2 [25088/60000 (42%)]\tLoss: 1.857539\n",
      "Train Epoch: 2 [25216/60000 (42%)]\tLoss: 1.846045\n",
      "Train Epoch: 2 [25344/60000 (42%)]\tLoss: 1.859373\n",
      "Train Epoch: 2 [25472/60000 (43%)]\tLoss: 1.823834\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.846817\n",
      "Train Epoch: 2 [25728/60000 (43%)]\tLoss: 1.833744\n",
      "Train Epoch: 2 [25856/60000 (43%)]\tLoss: 1.887156\n",
      "Train Epoch: 2 [25984/60000 (43%)]\tLoss: 1.826493\n",
      "Train Epoch: 2 [26112/60000 (44%)]\tLoss: 1.848240\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 1.768488\n",
      "Train Epoch: 2 [26368/60000 (44%)]\tLoss: 1.933289\n",
      "Train Epoch: 2 [26496/60000 (44%)]\tLoss: 1.837279\n",
      "Train Epoch: 2 [26624/60000 (44%)]\tLoss: 1.832675\n",
      "Train Epoch: 2 [26752/60000 (45%)]\tLoss: 1.857547\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 1.830487\n",
      "Train Epoch: 2 [27008/60000 (45%)]\tLoss: 1.894934\n",
      "Train Epoch: 2 [27136/60000 (45%)]\tLoss: 1.867240\n",
      "Train Epoch: 2 [27264/60000 (46%)]\tLoss: 1.836286\n",
      "Train Epoch: 2 [27392/60000 (46%)]\tLoss: 1.841504\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 1.759049\n",
      "Train Epoch: 2 [27648/60000 (46%)]\tLoss: 1.830497\n",
      "Train Epoch: 2 [27776/60000 (46%)]\tLoss: 1.816513\n",
      "Train Epoch: 2 [27904/60000 (47%)]\tLoss: 1.789738\n",
      "Train Epoch: 2 [28032/60000 (47%)]\tLoss: 1.657033\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 1.770800\n",
      "Train Epoch: 2 [28288/60000 (47%)]\tLoss: 1.835364\n",
      "Train Epoch: 2 [28416/60000 (47%)]\tLoss: 1.842245\n",
      "Train Epoch: 2 [28544/60000 (48%)]\tLoss: 1.804524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [28672/60000 (48%)]\tLoss: 1.830768\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 1.783298\n",
      "Train Epoch: 2 [28928/60000 (48%)]\tLoss: 1.905145\n",
      "Train Epoch: 2 [29056/60000 (49%)]\tLoss: 1.922223\n",
      "Train Epoch: 2 [29184/60000 (49%)]\tLoss: 1.750807\n",
      "Train Epoch: 2 [29312/60000 (49%)]\tLoss: 1.770967\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 1.729061\n",
      "Train Epoch: 2 [29568/60000 (49%)]\tLoss: 1.770158\n",
      "Train Epoch: 2 [29696/60000 (50%)]\tLoss: 1.884751\n",
      "Train Epoch: 2 [29824/60000 (50%)]\tLoss: 1.909884\n",
      "Train Epoch: 2 [29952/60000 (50%)]\tLoss: 1.858840\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 1.958355\n",
      "Train Epoch: 2 [30208/60000 (50%)]\tLoss: 1.735425\n",
      "Train Epoch: 2 [30336/60000 (51%)]\tLoss: 1.838262\n",
      "Train Epoch: 2 [30464/60000 (51%)]\tLoss: 1.913623\n",
      "Train Epoch: 2 [30592/60000 (51%)]\tLoss: 1.837665\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.843752\n",
      "Train Epoch: 2 [30848/60000 (51%)]\tLoss: 1.802750\n",
      "Train Epoch: 2 [30976/60000 (52%)]\tLoss: 1.816552\n",
      "Train Epoch: 2 [31104/60000 (52%)]\tLoss: 1.746221\n",
      "Train Epoch: 2 [31232/60000 (52%)]\tLoss: 1.928265\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 1.867337\n",
      "Train Epoch: 2 [31488/60000 (53%)]\tLoss: 1.797028\n",
      "Train Epoch: 2 [31616/60000 (53%)]\tLoss: 1.877502\n",
      "Train Epoch: 2 [31744/60000 (53%)]\tLoss: 1.787572\n",
      "Train Epoch: 2 [31872/60000 (53%)]\tLoss: 1.733044\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.850554\n",
      "Train Epoch: 2 [32128/60000 (54%)]\tLoss: 1.904661\n",
      "Train Epoch: 2 [32256/60000 (54%)]\tLoss: 1.872214\n",
      "Train Epoch: 2 [32384/60000 (54%)]\tLoss: 1.891518\n",
      "Train Epoch: 2 [32512/60000 (54%)]\tLoss: 1.746695\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 1.840984\n",
      "Train Epoch: 2 [32768/60000 (55%)]\tLoss: 1.781025\n",
      "Train Epoch: 2 [32896/60000 (55%)]\tLoss: 1.828159\n",
      "Train Epoch: 2 [33024/60000 (55%)]\tLoss: 1.810374\n",
      "Train Epoch: 2 [33152/60000 (55%)]\tLoss: 1.804496\n",
      "Train Epoch: 2 [33280/60000 (56%)]\tLoss: 1.793445\n",
      "Train Epoch: 2 [33408/60000 (56%)]\tLoss: 1.776422\n",
      "Train Epoch: 2 [33536/60000 (56%)]\tLoss: 1.759963\n",
      "Train Epoch: 2 [33664/60000 (56%)]\tLoss: 1.773921\n",
      "Train Epoch: 2 [33792/60000 (56%)]\tLoss: 1.663741\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 1.744699\n",
      "Train Epoch: 2 [34048/60000 (57%)]\tLoss: 1.798368\n",
      "Train Epoch: 2 [34176/60000 (57%)]\tLoss: 1.648825\n",
      "Train Epoch: 2 [34304/60000 (57%)]\tLoss: 1.791298\n",
      "Train Epoch: 2 [34432/60000 (57%)]\tLoss: 1.739826\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 1.762858\n",
      "Train Epoch: 2 [34688/60000 (58%)]\tLoss: 1.823506\n",
      "Train Epoch: 2 [34816/60000 (58%)]\tLoss: 1.987745\n",
      "Train Epoch: 2 [34944/60000 (58%)]\tLoss: 1.781384\n",
      "Train Epoch: 2 [35072/60000 (59%)]\tLoss: 1.812928\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 1.840126\n",
      "Train Epoch: 2 [35328/60000 (59%)]\tLoss: 1.691405\n",
      "Train Epoch: 2 [35456/60000 (59%)]\tLoss: 1.684813\n",
      "Train Epoch: 2 [35584/60000 (59%)]\tLoss: 1.799372\n",
      "Train Epoch: 2 [35712/60000 (60%)]\tLoss: 1.752081\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 1.710196\n",
      "Train Epoch: 2 [35968/60000 (60%)]\tLoss: 1.816317\n",
      "Train Epoch: 2 [36096/60000 (60%)]\tLoss: 1.723813\n",
      "Train Epoch: 2 [36224/60000 (60%)]\tLoss: 1.623343\n",
      "Train Epoch: 2 [36352/60000 (61%)]\tLoss: 1.712186\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 1.717694\n",
      "Train Epoch: 2 [36608/60000 (61%)]\tLoss: 1.616681\n",
      "Train Epoch: 2 [36736/60000 (61%)]\tLoss: 1.728211\n",
      "Train Epoch: 2 [36864/60000 (62%)]\tLoss: 1.710071\n",
      "Train Epoch: 2 [36992/60000 (62%)]\tLoss: 1.840839\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 1.715733\n",
      "Train Epoch: 2 [37248/60000 (62%)]\tLoss: 1.846576\n",
      "Train Epoch: 2 [37376/60000 (62%)]\tLoss: 1.762283\n",
      "Train Epoch: 2 [37504/60000 (63%)]\tLoss: 1.692894\n",
      "Train Epoch: 2 [37632/60000 (63%)]\tLoss: 1.620888\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 1.735371\n",
      "Train Epoch: 2 [37888/60000 (63%)]\tLoss: 1.686607\n",
      "Train Epoch: 2 [38016/60000 (63%)]\tLoss: 1.747227\n",
      "Train Epoch: 2 [38144/60000 (64%)]\tLoss: 1.705650\n",
      "Train Epoch: 2 [38272/60000 (64%)]\tLoss: 1.833340\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.685033\n",
      "Train Epoch: 2 [38528/60000 (64%)]\tLoss: 1.841069\n",
      "Train Epoch: 2 [38656/60000 (65%)]\tLoss: 1.682407\n",
      "Train Epoch: 2 [38784/60000 (65%)]\tLoss: 1.680609\n",
      "Train Epoch: 2 [38912/60000 (65%)]\tLoss: 1.642969\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 1.546183\n",
      "Train Epoch: 2 [39168/60000 (65%)]\tLoss: 1.669539\n",
      "Train Epoch: 2 [39296/60000 (66%)]\tLoss: 1.756779\n",
      "Train Epoch: 2 [39424/60000 (66%)]\tLoss: 1.780446\n",
      "Train Epoch: 2 [39552/60000 (66%)]\tLoss: 1.698936\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 1.825810\n",
      "Train Epoch: 2 [39808/60000 (66%)]\tLoss: 1.799417\n",
      "Train Epoch: 2 [39936/60000 (67%)]\tLoss: 1.721075\n",
      "Train Epoch: 2 [40064/60000 (67%)]\tLoss: 1.660076\n",
      "Train Epoch: 2 [40192/60000 (67%)]\tLoss: 1.726493\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 1.612629\n",
      "Train Epoch: 2 [40448/60000 (68%)]\tLoss: 1.745970\n",
      "Train Epoch: 2 [40576/60000 (68%)]\tLoss: 1.788345\n",
      "Train Epoch: 2 [40704/60000 (68%)]\tLoss: 1.660885\n",
      "Train Epoch: 2 [40832/60000 (68%)]\tLoss: 1.631917\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.658168\n",
      "Train Epoch: 2 [41088/60000 (69%)]\tLoss: 1.716018\n",
      "Train Epoch: 2 [41216/60000 (69%)]\tLoss: 1.758112\n",
      "Train Epoch: 2 [41344/60000 (69%)]\tLoss: 1.770990\n",
      "Train Epoch: 2 [41472/60000 (69%)]\tLoss: 1.805298\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 1.611911\n",
      "Train Epoch: 2 [41728/60000 (70%)]\tLoss: 1.723031\n",
      "Train Epoch: 2 [41856/60000 (70%)]\tLoss: 1.760572\n",
      "Train Epoch: 2 [41984/60000 (70%)]\tLoss: 1.707439\n",
      "Train Epoch: 2 [42112/60000 (70%)]\tLoss: 1.801395\n",
      "Train Epoch: 2 [42240/60000 (71%)]\tLoss: 1.865914\n",
      "Train Epoch: 2 [42368/60000 (71%)]\tLoss: 1.675836\n",
      "Train Epoch: 2 [42496/60000 (71%)]\tLoss: 1.711837\n",
      "Train Epoch: 2 [42624/60000 (71%)]\tLoss: 1.689425\n",
      "Train Epoch: 2 [42752/60000 (71%)]\tLoss: 1.667848\n",
      "Train Epoch: 2 [42880/60000 (72%)]\tLoss: 1.697133\n",
      "Train Epoch: 2 [43008/60000 (72%)]\tLoss: 1.802502\n",
      "Train Epoch: 2 [43136/60000 (72%)]\tLoss: 1.672860\n",
      "Train Epoch: 2 [43264/60000 (72%)]\tLoss: 1.627833\n",
      "Train Epoch: 2 [43392/60000 (72%)]\tLoss: 1.682052\n",
      "Train Epoch: 2 [43520/60000 (73%)]\tLoss: 1.599679\n",
      "Train Epoch: 2 [43648/60000 (73%)]\tLoss: 1.753839\n",
      "Train Epoch: 2 [43776/60000 (73%)]\tLoss: 1.703615\n",
      "Train Epoch: 2 [43904/60000 (73%)]\tLoss: 1.655470\n",
      "Train Epoch: 2 [44032/60000 (74%)]\tLoss: 1.729868\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 1.756243\n",
      "Train Epoch: 2 [44288/60000 (74%)]\tLoss: 1.707528\n",
      "Train Epoch: 2 [44416/60000 (74%)]\tLoss: 1.597591\n",
      "Train Epoch: 2 [44544/60000 (74%)]\tLoss: 1.576211\n",
      "Train Epoch: 2 [44672/60000 (75%)]\tLoss: 1.727989\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.695727\n",
      "Train Epoch: 2 [44928/60000 (75%)]\tLoss: 1.588948\n",
      "Train Epoch: 2 [45056/60000 (75%)]\tLoss: 1.794563\n",
      "Train Epoch: 2 [45184/60000 (75%)]\tLoss: 1.639111\n",
      "Train Epoch: 2 [45312/60000 (76%)]\tLoss: 1.710990\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 1.671904\n",
      "Train Epoch: 2 [45568/60000 (76%)]\tLoss: 1.593352\n",
      "Train Epoch: 2 [45696/60000 (76%)]\tLoss: 1.691845\n",
      "Train Epoch: 2 [45824/60000 (76%)]\tLoss: 1.707062\n",
      "Train Epoch: 2 [45952/60000 (77%)]\tLoss: 1.620783\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 1.655476\n",
      "Train Epoch: 2 [46208/60000 (77%)]\tLoss: 1.650086\n",
      "Train Epoch: 2 [46336/60000 (77%)]\tLoss: 1.695611\n",
      "Train Epoch: 2 [46464/60000 (78%)]\tLoss: 1.534738\n",
      "Train Epoch: 2 [46592/60000 (78%)]\tLoss: 1.583310\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 1.618772\n",
      "Train Epoch: 2 [46848/60000 (78%)]\tLoss: 1.593727\n",
      "Train Epoch: 2 [46976/60000 (78%)]\tLoss: 1.644236\n",
      "Train Epoch: 2 [47104/60000 (79%)]\tLoss: 1.719700\n",
      "Train Epoch: 2 [47232/60000 (79%)]\tLoss: 1.694447\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 1.677624\n",
      "Train Epoch: 2 [47488/60000 (79%)]\tLoss: 1.728789\n",
      "Train Epoch: 2 [47616/60000 (79%)]\tLoss: 1.606624\n",
      "Train Epoch: 2 [47744/60000 (80%)]\tLoss: 1.566172\n",
      "Train Epoch: 2 [47872/60000 (80%)]\tLoss: 1.688500\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.588971\n",
      "Train Epoch: 2 [48128/60000 (80%)]\tLoss: 1.502777\n",
      "Train Epoch: 2 [48256/60000 (81%)]\tLoss: 1.600626\n",
      "Train Epoch: 2 [48384/60000 (81%)]\tLoss: 1.600397\n",
      "Train Epoch: 2 [48512/60000 (81%)]\tLoss: 1.553713\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 1.552507\n",
      "Train Epoch: 2 [48768/60000 (81%)]\tLoss: 1.589921\n",
      "Train Epoch: 2 [48896/60000 (82%)]\tLoss: 1.702944\n",
      "Train Epoch: 2 [49024/60000 (82%)]\tLoss: 1.696273\n",
      "Train Epoch: 2 [49152/60000 (82%)]\tLoss: 1.695594\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 1.633913\n",
      "Train Epoch: 2 [49408/60000 (82%)]\tLoss: 1.760581\n",
      "Train Epoch: 2 [49536/60000 (83%)]\tLoss: 1.803113\n",
      "Train Epoch: 2 [49664/60000 (83%)]\tLoss: 1.728737\n",
      "Train Epoch: 2 [49792/60000 (83%)]\tLoss: 1.626840\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 1.622475\n",
      "Train Epoch: 2 [50048/60000 (84%)]\tLoss: 1.609264\n",
      "Train Epoch: 2 [50176/60000 (84%)]\tLoss: 1.576796\n",
      "Train Epoch: 2 [50304/60000 (84%)]\tLoss: 1.758357\n",
      "Train Epoch: 2 [50432/60000 (84%)]\tLoss: 1.673692\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 1.600754\n",
      "Train Epoch: 2 [50688/60000 (85%)]\tLoss: 1.683418\n",
      "Train Epoch: 2 [50816/60000 (85%)]\tLoss: 1.610650\n",
      "Train Epoch: 2 [50944/60000 (85%)]\tLoss: 1.617922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [51072/60000 (85%)]\tLoss: 1.589620\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.619777\n",
      "Train Epoch: 2 [51328/60000 (86%)]\tLoss: 1.581535\n",
      "Train Epoch: 2 [51456/60000 (86%)]\tLoss: 1.492258\n",
      "Train Epoch: 2 [51584/60000 (86%)]\tLoss: 1.552118\n",
      "Train Epoch: 2 [51712/60000 (86%)]\tLoss: 1.644328\n",
      "Train Epoch: 2 [51840/60000 (87%)]\tLoss: 1.713613\n",
      "Train Epoch: 2 [51968/60000 (87%)]\tLoss: 1.652043\n",
      "Train Epoch: 2 [52096/60000 (87%)]\tLoss: 1.700860\n",
      "Train Epoch: 2 [52224/60000 (87%)]\tLoss: 1.572742\n",
      "Train Epoch: 2 [52352/60000 (87%)]\tLoss: 1.544599\n",
      "Train Epoch: 2 [52480/60000 (88%)]\tLoss: 1.462863\n",
      "Train Epoch: 2 [52608/60000 (88%)]\tLoss: 1.636984\n",
      "Train Epoch: 2 [52736/60000 (88%)]\tLoss: 1.727044\n",
      "Train Epoch: 2 [52864/60000 (88%)]\tLoss: 1.586764\n",
      "Train Epoch: 2 [52992/60000 (88%)]\tLoss: 1.562785\n",
      "Train Epoch: 2 [53120/60000 (89%)]\tLoss: 1.603533\n",
      "Train Epoch: 2 [53248/60000 (89%)]\tLoss: 1.489451\n",
      "Train Epoch: 2 [53376/60000 (89%)]\tLoss: 1.498428\n",
      "Train Epoch: 2 [53504/60000 (89%)]\tLoss: 1.686831\n",
      "Train Epoch: 2 [53632/60000 (90%)]\tLoss: 1.633700\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 1.475517\n",
      "Train Epoch: 2 [53888/60000 (90%)]\tLoss: 1.625004\n",
      "Train Epoch: 2 [54016/60000 (90%)]\tLoss: 1.662097\n",
      "Train Epoch: 2 [54144/60000 (90%)]\tLoss: 1.576941\n",
      "Train Epoch: 2 [54272/60000 (91%)]\tLoss: 1.544165\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 1.482876\n",
      "Train Epoch: 2 [54528/60000 (91%)]\tLoss: 1.529004\n",
      "Train Epoch: 2 [54656/60000 (91%)]\tLoss: 1.489548\n",
      "Train Epoch: 2 [54784/60000 (91%)]\tLoss: 1.629127\n",
      "Train Epoch: 2 [54912/60000 (92%)]\tLoss: 1.686095\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 1.488467\n",
      "Train Epoch: 2 [55168/60000 (92%)]\tLoss: 1.531667\n",
      "Train Epoch: 2 [55296/60000 (92%)]\tLoss: 1.571089\n",
      "Train Epoch: 2 [55424/60000 (93%)]\tLoss: 1.491631\n",
      "Train Epoch: 2 [55552/60000 (93%)]\tLoss: 1.548247\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 1.489354\n",
      "Train Epoch: 2 [55808/60000 (93%)]\tLoss: 1.530727\n",
      "Train Epoch: 2 [55936/60000 (93%)]\tLoss: 1.467544\n",
      "Train Epoch: 2 [56064/60000 (94%)]\tLoss: 1.616456\n",
      "Train Epoch: 2 [56192/60000 (94%)]\tLoss: 1.585073\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 1.605252\n",
      "Train Epoch: 2 [56448/60000 (94%)]\tLoss: 1.544670\n",
      "Train Epoch: 2 [56576/60000 (94%)]\tLoss: 1.510673\n",
      "Train Epoch: 2 [56704/60000 (95%)]\tLoss: 1.474377\n",
      "Train Epoch: 2 [56832/60000 (95%)]\tLoss: 1.502755\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 1.557347\n",
      "Train Epoch: 2 [57088/60000 (95%)]\tLoss: 1.548867\n",
      "Train Epoch: 2 [57216/60000 (96%)]\tLoss: 1.821779\n",
      "Train Epoch: 2 [57344/60000 (96%)]\tLoss: 1.589342\n",
      "Train Epoch: 2 [57472/60000 (96%)]\tLoss: 1.534403\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.511701\n",
      "Train Epoch: 2 [57728/60000 (96%)]\tLoss: 1.538145\n",
      "Train Epoch: 2 [57856/60000 (97%)]\tLoss: 1.460355\n",
      "Train Epoch: 2 [57984/60000 (97%)]\tLoss: 1.611189\n",
      "Train Epoch: 2 [58112/60000 (97%)]\tLoss: 1.423405\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 1.528809\n",
      "Train Epoch: 2 [58368/60000 (97%)]\tLoss: 1.545578\n",
      "Train Epoch: 2 [58496/60000 (98%)]\tLoss: 1.565901\n",
      "Train Epoch: 2 [58624/60000 (98%)]\tLoss: 1.437994\n",
      "Train Epoch: 2 [58752/60000 (98%)]\tLoss: 1.562483\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 1.300178\n",
      "Train Epoch: 2 [59008/60000 (99%)]\tLoss: 1.385122\n",
      "Train Epoch: 2 [59136/60000 (99%)]\tLoss: 1.445576\n",
      "Train Epoch: 2 [59264/60000 (99%)]\tLoss: 1.627483\n",
      "Train Epoch: 2 [59392/60000 (99%)]\tLoss: 1.554465\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 1.479540\n",
      "Train Epoch: 2 [59648/60000 (100%)]\tLoss: 1.608657\n",
      "Train Epoch: 2 [59776/60000 (100%)]\tLoss: 1.504056\n",
      "================================================================\n",
      "Training: Average loss: 1.0727, Accuracy: 49242/60000 (82%)\n",
      "Test: Average loss: 1.0481, Accuracy: 8344/10000 (83%)\n",
      "================================================================\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.465341\n",
      "Train Epoch: 3 [128/60000 (0%)]\tLoss: 1.502524\n",
      "Train Epoch: 3 [256/60000 (0%)]\tLoss: 1.494024\n",
      "Train Epoch: 3 [384/60000 (1%)]\tLoss: 1.519029\n",
      "Train Epoch: 3 [512/60000 (1%)]\tLoss: 1.586609\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 1.517393\n",
      "Train Epoch: 3 [768/60000 (1%)]\tLoss: 1.620207\n",
      "Train Epoch: 3 [896/60000 (1%)]\tLoss: 1.627195\n",
      "Train Epoch: 3 [1024/60000 (2%)]\tLoss: 1.716843\n",
      "Train Epoch: 3 [1152/60000 (2%)]\tLoss: 1.611615\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 1.657379\n",
      "Train Epoch: 3 [1408/60000 (2%)]\tLoss: 1.548334\n",
      "Train Epoch: 3 [1536/60000 (3%)]\tLoss: 1.572333\n",
      "Train Epoch: 3 [1664/60000 (3%)]\tLoss: 1.512273\n",
      "Train Epoch: 3 [1792/60000 (3%)]\tLoss: 1.405672\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 1.484079\n",
      "Train Epoch: 3 [2048/60000 (3%)]\tLoss: 1.492568\n",
      "Train Epoch: 3 [2176/60000 (4%)]\tLoss: 1.466470\n",
      "Train Epoch: 3 [2304/60000 (4%)]\tLoss: 1.477516\n",
      "Train Epoch: 3 [2432/60000 (4%)]\tLoss: 1.489954\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 1.437016\n",
      "Train Epoch: 3 [2688/60000 (4%)]\tLoss: 1.466802\n",
      "Train Epoch: 3 [2816/60000 (5%)]\tLoss: 1.504768\n",
      "Train Epoch: 3 [2944/60000 (5%)]\tLoss: 1.545625\n",
      "Train Epoch: 3 [3072/60000 (5%)]\tLoss: 1.504468\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 1.458143\n",
      "Train Epoch: 3 [3328/60000 (6%)]\tLoss: 1.593934\n",
      "Train Epoch: 3 [3456/60000 (6%)]\tLoss: 1.559108\n",
      "Train Epoch: 3 [3584/60000 (6%)]\tLoss: 1.402809\n",
      "Train Epoch: 3 [3712/60000 (6%)]\tLoss: 1.491441\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 1.453652\n",
      "Train Epoch: 3 [3968/60000 (7%)]\tLoss: 1.513921\n",
      "Train Epoch: 3 [4096/60000 (7%)]\tLoss: 1.536373\n",
      "Train Epoch: 3 [4224/60000 (7%)]\tLoss: 1.500646\n",
      "Train Epoch: 3 [4352/60000 (7%)]\tLoss: 1.429317\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 1.320632\n",
      "Train Epoch: 3 [4608/60000 (8%)]\tLoss: 1.429326\n",
      "Train Epoch: 3 [4736/60000 (8%)]\tLoss: 1.562622\n",
      "Train Epoch: 3 [4864/60000 (8%)]\tLoss: 1.578779\n",
      "Train Epoch: 3 [4992/60000 (8%)]\tLoss: 1.612477\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 1.598559\n",
      "Train Epoch: 3 [5248/60000 (9%)]\tLoss: 1.418307\n",
      "Train Epoch: 3 [5376/60000 (9%)]\tLoss: 1.432915\n",
      "Train Epoch: 3 [5504/60000 (9%)]\tLoss: 1.517896\n",
      "Train Epoch: 3 [5632/60000 (9%)]\tLoss: 1.518472\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 1.600443\n",
      "Train Epoch: 3 [5888/60000 (10%)]\tLoss: 1.471780\n",
      "Train Epoch: 3 [6016/60000 (10%)]\tLoss: 1.390538\n",
      "Train Epoch: 3 [6144/60000 (10%)]\tLoss: 1.532270\n",
      "Train Epoch: 3 [6272/60000 (10%)]\tLoss: 1.483495\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.502679\n",
      "Train Epoch: 3 [6528/60000 (11%)]\tLoss: 1.385425\n",
      "Train Epoch: 3 [6656/60000 (11%)]\tLoss: 1.453048\n",
      "Train Epoch: 3 [6784/60000 (11%)]\tLoss: 1.675014\n",
      "Train Epoch: 3 [6912/60000 (12%)]\tLoss: 1.478061\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 1.559806\n",
      "Train Epoch: 3 [7168/60000 (12%)]\tLoss: 1.596886\n",
      "Train Epoch: 3 [7296/60000 (12%)]\tLoss: 1.542888\n",
      "Train Epoch: 3 [7424/60000 (12%)]\tLoss: 1.512390\n",
      "Train Epoch: 3 [7552/60000 (13%)]\tLoss: 1.470183\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 1.496835\n",
      "Train Epoch: 3 [7808/60000 (13%)]\tLoss: 1.494635\n",
      "Train Epoch: 3 [7936/60000 (13%)]\tLoss: 1.388997\n",
      "Train Epoch: 3 [8064/60000 (13%)]\tLoss: 1.442961\n",
      "Train Epoch: 3 [8192/60000 (14%)]\tLoss: 1.645304\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 1.575752\n",
      "Train Epoch: 3 [8448/60000 (14%)]\tLoss: 1.468601\n",
      "Train Epoch: 3 [8576/60000 (14%)]\tLoss: 1.545776\n",
      "Train Epoch: 3 [8704/60000 (15%)]\tLoss: 1.531016\n",
      "Train Epoch: 3 [8832/60000 (15%)]\tLoss: 1.559011\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 1.277944\n",
      "Train Epoch: 3 [9088/60000 (15%)]\tLoss: 1.452805\n",
      "Train Epoch: 3 [9216/60000 (15%)]\tLoss: 1.422773\n",
      "Train Epoch: 3 [9344/60000 (16%)]\tLoss: 1.467973\n",
      "Train Epoch: 3 [9472/60000 (16%)]\tLoss: 1.492557\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 1.403476\n",
      "Train Epoch: 3 [9728/60000 (16%)]\tLoss: 1.464361\n",
      "Train Epoch: 3 [9856/60000 (16%)]\tLoss: 1.419686\n",
      "Train Epoch: 3 [9984/60000 (17%)]\tLoss: 1.507867\n",
      "Train Epoch: 3 [10112/60000 (17%)]\tLoss: 1.480755\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 1.401301\n",
      "Train Epoch: 3 [10368/60000 (17%)]\tLoss: 1.360500\n",
      "Train Epoch: 3 [10496/60000 (18%)]\tLoss: 1.476793\n",
      "Train Epoch: 3 [10624/60000 (18%)]\tLoss: 1.410480\n",
      "Train Epoch: 3 [10752/60000 (18%)]\tLoss: 1.414463\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 1.334412\n",
      "Train Epoch: 3 [11008/60000 (18%)]\tLoss: 1.416656\n",
      "Train Epoch: 3 [11136/60000 (19%)]\tLoss: 1.551714\n",
      "Train Epoch: 3 [11264/60000 (19%)]\tLoss: 1.390355\n",
      "Train Epoch: 3 [11392/60000 (19%)]\tLoss: 1.405961\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 1.582284\n",
      "Train Epoch: 3 [11648/60000 (19%)]\tLoss: 1.561943\n",
      "Train Epoch: 3 [11776/60000 (20%)]\tLoss: 1.480446\n",
      "Train Epoch: 3 [11904/60000 (20%)]\tLoss: 1.435000\n",
      "Train Epoch: 3 [12032/60000 (20%)]\tLoss: 1.476650\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 1.519185\n",
      "Train Epoch: 3 [12288/60000 (21%)]\tLoss: 1.509750\n",
      "Train Epoch: 3 [12416/60000 (21%)]\tLoss: 1.400618\n",
      "Train Epoch: 3 [12544/60000 (21%)]\tLoss: 1.608471\n",
      "Train Epoch: 3 [12672/60000 (21%)]\tLoss: 1.419527\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.397541\n",
      "Train Epoch: 3 [12928/60000 (22%)]\tLoss: 1.628093\n",
      "Train Epoch: 3 [13056/60000 (22%)]\tLoss: 1.661935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [13184/60000 (22%)]\tLoss: 1.402325\n",
      "Train Epoch: 3 [13312/60000 (22%)]\tLoss: 1.498176\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 1.334030\n",
      "Train Epoch: 3 [13568/60000 (23%)]\tLoss: 1.481858\n",
      "Train Epoch: 3 [13696/60000 (23%)]\tLoss: 1.425492\n",
      "Train Epoch: 3 [13824/60000 (23%)]\tLoss: 1.548652\n",
      "Train Epoch: 3 [13952/60000 (23%)]\tLoss: 1.593307\n",
      "Train Epoch: 3 [14080/60000 (24%)]\tLoss: 1.413580\n",
      "Train Epoch: 3 [14208/60000 (24%)]\tLoss: 1.612691\n",
      "Train Epoch: 3 [14336/60000 (24%)]\tLoss: 1.503004\n",
      "Train Epoch: 3 [14464/60000 (24%)]\tLoss: 1.505240\n",
      "Train Epoch: 3 [14592/60000 (24%)]\tLoss: 1.543779\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 1.572675\n",
      "Train Epoch: 3 [14848/60000 (25%)]\tLoss: 1.438109\n",
      "Train Epoch: 3 [14976/60000 (25%)]\tLoss: 1.332200\n",
      "Train Epoch: 3 [15104/60000 (25%)]\tLoss: 1.500387\n",
      "Train Epoch: 3 [15232/60000 (25%)]\tLoss: 1.461321\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 1.403428\n",
      "Train Epoch: 3 [15488/60000 (26%)]\tLoss: 1.351022\n",
      "Train Epoch: 3 [15616/60000 (26%)]\tLoss: 1.486539\n",
      "Train Epoch: 3 [15744/60000 (26%)]\tLoss: 1.581314\n",
      "Train Epoch: 3 [15872/60000 (26%)]\tLoss: 1.592976\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.552770\n",
      "Train Epoch: 3 [16128/60000 (27%)]\tLoss: 1.387646\n",
      "Train Epoch: 3 [16256/60000 (27%)]\tLoss: 1.439909\n",
      "Train Epoch: 3 [16384/60000 (27%)]\tLoss: 1.373278\n",
      "Train Epoch: 3 [16512/60000 (28%)]\tLoss: 1.350798\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 1.520422\n",
      "Train Epoch: 3 [16768/60000 (28%)]\tLoss: 1.572858\n",
      "Train Epoch: 3 [16896/60000 (28%)]\tLoss: 1.534875\n",
      "Train Epoch: 3 [17024/60000 (28%)]\tLoss: 1.376624\n",
      "Train Epoch: 3 [17152/60000 (29%)]\tLoss: 1.557585\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 1.342106\n",
      "Train Epoch: 3 [17408/60000 (29%)]\tLoss: 1.408233\n",
      "Train Epoch: 3 [17536/60000 (29%)]\tLoss: 1.559278\n",
      "Train Epoch: 3 [17664/60000 (29%)]\tLoss: 1.478206\n",
      "Train Epoch: 3 [17792/60000 (30%)]\tLoss: 1.592209\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 1.392723\n",
      "Train Epoch: 3 [18048/60000 (30%)]\tLoss: 1.401695\n",
      "Train Epoch: 3 [18176/60000 (30%)]\tLoss: 1.345756\n",
      "Train Epoch: 3 [18304/60000 (31%)]\tLoss: 1.442570\n",
      "Train Epoch: 3 [18432/60000 (31%)]\tLoss: 1.508223\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 1.421526\n",
      "Train Epoch: 3 [18688/60000 (31%)]\tLoss: 1.297722\n",
      "Train Epoch: 3 [18816/60000 (31%)]\tLoss: 1.328506\n",
      "Train Epoch: 3 [18944/60000 (32%)]\tLoss: 1.324010\n",
      "Train Epoch: 3 [19072/60000 (32%)]\tLoss: 1.515668\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.405319\n",
      "Train Epoch: 3 [19328/60000 (32%)]\tLoss: 1.347609\n",
      "Train Epoch: 3 [19456/60000 (32%)]\tLoss: 1.357550\n",
      "Train Epoch: 3 [19584/60000 (33%)]\tLoss: 1.347406\n",
      "Train Epoch: 3 [19712/60000 (33%)]\tLoss: 1.359454\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 1.370667\n",
      "Train Epoch: 3 [19968/60000 (33%)]\tLoss: 1.348080\n",
      "Train Epoch: 3 [20096/60000 (34%)]\tLoss: 1.417514\n",
      "Train Epoch: 3 [20224/60000 (34%)]\tLoss: 1.377881\n",
      "Train Epoch: 3 [20352/60000 (34%)]\tLoss: 1.269962\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 1.404925\n",
      "Train Epoch: 3 [20608/60000 (34%)]\tLoss: 1.384704\n",
      "Train Epoch: 3 [20736/60000 (35%)]\tLoss: 1.480834\n",
      "Train Epoch: 3 [20864/60000 (35%)]\tLoss: 1.597671\n",
      "Train Epoch: 3 [20992/60000 (35%)]\tLoss: 1.409363\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 1.384128\n",
      "Train Epoch: 3 [21248/60000 (35%)]\tLoss: 1.340296\n",
      "Train Epoch: 3 [21376/60000 (36%)]\tLoss: 1.397790\n",
      "Train Epoch: 3 [21504/60000 (36%)]\tLoss: 1.405818\n",
      "Train Epoch: 3 [21632/60000 (36%)]\tLoss: 1.377971\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 1.305820\n",
      "Train Epoch: 3 [21888/60000 (37%)]\tLoss: 1.250495\n",
      "Train Epoch: 3 [22016/60000 (37%)]\tLoss: 1.328860\n",
      "Train Epoch: 3 [22144/60000 (37%)]\tLoss: 1.528684\n",
      "Train Epoch: 3 [22272/60000 (37%)]\tLoss: 1.381633\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 1.535287\n",
      "Train Epoch: 3 [22528/60000 (38%)]\tLoss: 1.468709\n",
      "Train Epoch: 3 [22656/60000 (38%)]\tLoss: 1.449854\n",
      "Train Epoch: 3 [22784/60000 (38%)]\tLoss: 1.317298\n",
      "Train Epoch: 3 [22912/60000 (38%)]\tLoss: 1.280829\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 1.414355\n",
      "Train Epoch: 3 [23168/60000 (39%)]\tLoss: 1.333836\n",
      "Train Epoch: 3 [23296/60000 (39%)]\tLoss: 1.279193\n",
      "Train Epoch: 3 [23424/60000 (39%)]\tLoss: 1.451696\n",
      "Train Epoch: 3 [23552/60000 (39%)]\tLoss: 1.441939\n",
      "Train Epoch: 3 [23680/60000 (40%)]\tLoss: 1.529710\n",
      "Train Epoch: 3 [23808/60000 (40%)]\tLoss: 1.432234\n",
      "Train Epoch: 3 [23936/60000 (40%)]\tLoss: 1.479563\n",
      "Train Epoch: 3 [24064/60000 (40%)]\tLoss: 1.373091\n",
      "Train Epoch: 3 [24192/60000 (40%)]\tLoss: 1.522819\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 1.392835\n",
      "Train Epoch: 3 [24448/60000 (41%)]\tLoss: 1.368691\n",
      "Train Epoch: 3 [24576/60000 (41%)]\tLoss: 1.411033\n",
      "Train Epoch: 3 [24704/60000 (41%)]\tLoss: 1.518831\n",
      "Train Epoch: 3 [24832/60000 (41%)]\tLoss: 1.492891\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 1.321265\n",
      "Train Epoch: 3 [25088/60000 (42%)]\tLoss: 1.434527\n",
      "Train Epoch: 3 [25216/60000 (42%)]\tLoss: 1.409586\n",
      "Train Epoch: 3 [25344/60000 (42%)]\tLoss: 1.288185\n",
      "Train Epoch: 3 [25472/60000 (43%)]\tLoss: 1.311598\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.415439\n",
      "Train Epoch: 3 [25728/60000 (43%)]\tLoss: 1.394757\n",
      "Train Epoch: 3 [25856/60000 (43%)]\tLoss: 1.324965\n",
      "Train Epoch: 3 [25984/60000 (43%)]\tLoss: 1.299363\n",
      "Train Epoch: 3 [26112/60000 (44%)]\tLoss: 1.434349\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 1.388262\n",
      "Train Epoch: 3 [26368/60000 (44%)]\tLoss: 1.540111\n",
      "Train Epoch: 3 [26496/60000 (44%)]\tLoss: 1.385850\n",
      "Train Epoch: 3 [26624/60000 (44%)]\tLoss: 1.572807\n",
      "Train Epoch: 3 [26752/60000 (45%)]\tLoss: 1.241835\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 1.340731\n",
      "Train Epoch: 3 [27008/60000 (45%)]\tLoss: 1.362226\n",
      "Train Epoch: 3 [27136/60000 (45%)]\tLoss: 1.510051\n",
      "Train Epoch: 3 [27264/60000 (46%)]\tLoss: 1.380389\n",
      "Train Epoch: 3 [27392/60000 (46%)]\tLoss: 1.403323\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 1.350072\n",
      "Train Epoch: 3 [27648/60000 (46%)]\tLoss: 1.310749\n",
      "Train Epoch: 3 [27776/60000 (46%)]\tLoss: 1.424625\n",
      "Train Epoch: 3 [27904/60000 (47%)]\tLoss: 1.272223\n",
      "Train Epoch: 3 [28032/60000 (47%)]\tLoss: 1.317210\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 1.441983\n",
      "Train Epoch: 3 [28288/60000 (47%)]\tLoss: 1.350051\n",
      "Train Epoch: 3 [28416/60000 (47%)]\tLoss: 1.351748\n",
      "Train Epoch: 3 [28544/60000 (48%)]\tLoss: 1.390174\n",
      "Train Epoch: 3 [28672/60000 (48%)]\tLoss: 1.439781\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 1.409439\n",
      "Train Epoch: 3 [28928/60000 (48%)]\tLoss: 1.446969\n",
      "Train Epoch: 3 [29056/60000 (49%)]\tLoss: 1.533243\n",
      "Train Epoch: 3 [29184/60000 (49%)]\tLoss: 1.408594\n",
      "Train Epoch: 3 [29312/60000 (49%)]\tLoss: 1.293362\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 1.258666\n",
      "Train Epoch: 3 [29568/60000 (49%)]\tLoss: 1.349895\n",
      "Train Epoch: 3 [29696/60000 (50%)]\tLoss: 1.457208\n",
      "Train Epoch: 3 [29824/60000 (50%)]\tLoss: 1.570961\n",
      "Train Epoch: 3 [29952/60000 (50%)]\tLoss: 1.534584\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 1.466025\n",
      "Train Epoch: 3 [30208/60000 (50%)]\tLoss: 1.366489\n",
      "Train Epoch: 3 [30336/60000 (51%)]\tLoss: 1.271793\n",
      "Train Epoch: 3 [30464/60000 (51%)]\tLoss: 1.487768\n",
      "Train Epoch: 3 [30592/60000 (51%)]\tLoss: 1.506071\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 1.430137\n",
      "Train Epoch: 3 [30848/60000 (51%)]\tLoss: 1.388088\n",
      "Train Epoch: 3 [30976/60000 (52%)]\tLoss: 1.405440\n",
      "Train Epoch: 3 [31104/60000 (52%)]\tLoss: 1.362743\n",
      "Train Epoch: 3 [31232/60000 (52%)]\tLoss: 1.530048\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 1.446268\n",
      "Train Epoch: 3 [31488/60000 (53%)]\tLoss: 1.294051\n",
      "Train Epoch: 3 [31616/60000 (53%)]\tLoss: 1.483147\n",
      "Train Epoch: 3 [31744/60000 (53%)]\tLoss: 1.396683\n",
      "Train Epoch: 3 [31872/60000 (53%)]\tLoss: 1.233460\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.370770\n",
      "Train Epoch: 3 [32128/60000 (54%)]\tLoss: 1.452838\n",
      "Train Epoch: 3 [32256/60000 (54%)]\tLoss: 1.604987\n",
      "Train Epoch: 3 [32384/60000 (54%)]\tLoss: 1.457975\n",
      "Train Epoch: 3 [32512/60000 (54%)]\tLoss: 1.274998\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 1.310790\n",
      "Train Epoch: 3 [32768/60000 (55%)]\tLoss: 1.346202\n",
      "Train Epoch: 3 [32896/60000 (55%)]\tLoss: 1.363763\n",
      "Train Epoch: 3 [33024/60000 (55%)]\tLoss: 1.399521\n",
      "Train Epoch: 3 [33152/60000 (55%)]\tLoss: 1.382593\n",
      "Train Epoch: 3 [33280/60000 (56%)]\tLoss: 1.378465\n",
      "Train Epoch: 3 [33408/60000 (56%)]\tLoss: 1.383785\n",
      "Train Epoch: 3 [33536/60000 (56%)]\tLoss: 1.399611\n",
      "Train Epoch: 3 [33664/60000 (56%)]\tLoss: 1.396609\n",
      "Train Epoch: 3 [33792/60000 (56%)]\tLoss: 1.220667\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 1.257606\n",
      "Train Epoch: 3 [34048/60000 (57%)]\tLoss: 1.280714\n",
      "Train Epoch: 3 [34176/60000 (57%)]\tLoss: 1.267535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [34304/60000 (57%)]\tLoss: 1.400682\n",
      "Train Epoch: 3 [34432/60000 (57%)]\tLoss: 1.356450\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 1.462356\n",
      "Train Epoch: 3 [34688/60000 (58%)]\tLoss: 1.555747\n",
      "Train Epoch: 3 [34816/60000 (58%)]\tLoss: 1.479523\n",
      "Train Epoch: 3 [34944/60000 (58%)]\tLoss: 1.300501\n",
      "Train Epoch: 3 [35072/60000 (59%)]\tLoss: 1.394978\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 1.407902\n",
      "Train Epoch: 3 [35328/60000 (59%)]\tLoss: 1.305326\n",
      "Train Epoch: 3 [35456/60000 (59%)]\tLoss: 1.352494\n",
      "Train Epoch: 3 [35584/60000 (59%)]\tLoss: 1.394271\n",
      "Train Epoch: 3 [35712/60000 (60%)]\tLoss: 1.205280\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 1.258844\n",
      "Train Epoch: 3 [35968/60000 (60%)]\tLoss: 1.456295\n",
      "Train Epoch: 3 [36096/60000 (60%)]\tLoss: 1.319268\n",
      "Train Epoch: 3 [36224/60000 (60%)]\tLoss: 1.256676\n",
      "Train Epoch: 3 [36352/60000 (61%)]\tLoss: 1.357022\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 1.287446\n",
      "Train Epoch: 3 [36608/60000 (61%)]\tLoss: 1.253179\n",
      "Train Epoch: 3 [36736/60000 (61%)]\tLoss: 1.283235\n",
      "Train Epoch: 3 [36864/60000 (62%)]\tLoss: 1.239379\n",
      "Train Epoch: 3 [36992/60000 (62%)]\tLoss: 1.353029\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 1.339184\n",
      "Train Epoch: 3 [37248/60000 (62%)]\tLoss: 1.535001\n",
      "Train Epoch: 3 [37376/60000 (62%)]\tLoss: 1.525712\n",
      "Train Epoch: 3 [37504/60000 (63%)]\tLoss: 1.363027\n",
      "Train Epoch: 3 [37632/60000 (63%)]\tLoss: 1.215558\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 1.404824\n",
      "Train Epoch: 3 [37888/60000 (63%)]\tLoss: 1.266701\n",
      "Train Epoch: 3 [38016/60000 (63%)]\tLoss: 1.248746\n",
      "Train Epoch: 3 [38144/60000 (64%)]\tLoss: 1.259671\n",
      "Train Epoch: 3 [38272/60000 (64%)]\tLoss: 1.275063\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.306805\n",
      "Train Epoch: 3 [38528/60000 (64%)]\tLoss: 1.439255\n",
      "Train Epoch: 3 [38656/60000 (65%)]\tLoss: 1.243597\n",
      "Train Epoch: 3 [38784/60000 (65%)]\tLoss: 1.383307\n",
      "Train Epoch: 3 [38912/60000 (65%)]\tLoss: 1.284607\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 1.380965\n",
      "Train Epoch: 3 [39168/60000 (65%)]\tLoss: 1.281512\n",
      "Train Epoch: 3 [39296/60000 (66%)]\tLoss: 1.523193\n",
      "Train Epoch: 3 [39424/60000 (66%)]\tLoss: 1.508397\n",
      "Train Epoch: 3 [39552/60000 (66%)]\tLoss: 1.283402\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 1.414650\n",
      "Train Epoch: 3 [39808/60000 (66%)]\tLoss: 1.365203\n",
      "Train Epoch: 3 [39936/60000 (67%)]\tLoss: 1.377335\n",
      "Train Epoch: 3 [40064/60000 (67%)]\tLoss: 1.303067\n",
      "Train Epoch: 3 [40192/60000 (67%)]\tLoss: 1.308764\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 1.317130\n",
      "Train Epoch: 3 [40448/60000 (68%)]\tLoss: 1.322000\n",
      "Train Epoch: 3 [40576/60000 (68%)]\tLoss: 1.402540\n",
      "Train Epoch: 3 [40704/60000 (68%)]\tLoss: 1.371554\n",
      "Train Epoch: 3 [40832/60000 (68%)]\tLoss: 1.193631\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 1.311321\n",
      "Train Epoch: 3 [41088/60000 (69%)]\tLoss: 1.284806\n",
      "Train Epoch: 3 [41216/60000 (69%)]\tLoss: 1.429355\n",
      "Train Epoch: 3 [41344/60000 (69%)]\tLoss: 1.414222\n",
      "Train Epoch: 3 [41472/60000 (69%)]\tLoss: 1.484021\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 1.346727\n",
      "Train Epoch: 3 [41728/60000 (70%)]\tLoss: 1.339201\n",
      "Train Epoch: 3 [41856/60000 (70%)]\tLoss: 1.218240\n",
      "Train Epoch: 3 [41984/60000 (70%)]\tLoss: 1.402662\n",
      "Train Epoch: 3 [42112/60000 (70%)]\tLoss: 1.478153\n",
      "Train Epoch: 3 [42240/60000 (71%)]\tLoss: 1.532837\n",
      "Train Epoch: 3 [42368/60000 (71%)]\tLoss: 1.412620\n",
      "Train Epoch: 3 [42496/60000 (71%)]\tLoss: 1.455232\n",
      "Train Epoch: 3 [42624/60000 (71%)]\tLoss: 1.300773\n",
      "Train Epoch: 3 [42752/60000 (71%)]\tLoss: 1.312658\n",
      "Train Epoch: 3 [42880/60000 (72%)]\tLoss: 1.397677\n",
      "Train Epoch: 3 [43008/60000 (72%)]\tLoss: 1.478809\n",
      "Train Epoch: 3 [43136/60000 (72%)]\tLoss: 1.355705\n",
      "Train Epoch: 3 [43264/60000 (72%)]\tLoss: 1.185201\n",
      "Train Epoch: 3 [43392/60000 (72%)]\tLoss: 1.191427\n",
      "Train Epoch: 3 [43520/60000 (73%)]\tLoss: 1.197216\n",
      "Train Epoch: 3 [43648/60000 (73%)]\tLoss: 1.287801\n",
      "Train Epoch: 3 [43776/60000 (73%)]\tLoss: 1.272519\n",
      "Train Epoch: 3 [43904/60000 (73%)]\tLoss: 1.365428\n",
      "Train Epoch: 3 [44032/60000 (74%)]\tLoss: 1.393176\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 1.351311\n",
      "Train Epoch: 3 [44288/60000 (74%)]\tLoss: 1.426365\n",
      "Train Epoch: 3 [44416/60000 (74%)]\tLoss: 1.304059\n",
      "Train Epoch: 3 [44544/60000 (74%)]\tLoss: 1.175389\n",
      "Train Epoch: 3 [44672/60000 (75%)]\tLoss: 1.318445\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.381616\n",
      "Train Epoch: 3 [44928/60000 (75%)]\tLoss: 1.401920\n",
      "Train Epoch: 3 [45056/60000 (75%)]\tLoss: 1.349866\n",
      "Train Epoch: 3 [45184/60000 (75%)]\tLoss: 1.298540\n",
      "Train Epoch: 3 [45312/60000 (76%)]\tLoss: 1.270683\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 1.343691\n",
      "Train Epoch: 3 [45568/60000 (76%)]\tLoss: 1.206762\n",
      "Train Epoch: 3 [45696/60000 (76%)]\tLoss: 1.218417\n",
      "Train Epoch: 3 [45824/60000 (76%)]\tLoss: 1.391616\n",
      "Train Epoch: 3 [45952/60000 (77%)]\tLoss: 1.387313\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 1.316705\n",
      "Train Epoch: 3 [46208/60000 (77%)]\tLoss: 1.326678\n",
      "Train Epoch: 3 [46336/60000 (77%)]\tLoss: 1.428115\n",
      "Train Epoch: 3 [46464/60000 (78%)]\tLoss: 1.168561\n",
      "Train Epoch: 3 [46592/60000 (78%)]\tLoss: 1.297517\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 1.333453\n",
      "Train Epoch: 3 [46848/60000 (78%)]\tLoss: 1.258292\n",
      "Train Epoch: 3 [46976/60000 (78%)]\tLoss: 1.237159\n",
      "Train Epoch: 3 [47104/60000 (79%)]\tLoss: 1.227621\n",
      "Train Epoch: 3 [47232/60000 (79%)]\tLoss: 1.372488\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 1.441919\n",
      "Train Epoch: 3 [47488/60000 (79%)]\tLoss: 1.487821\n",
      "Train Epoch: 3 [47616/60000 (79%)]\tLoss: 1.304564\n",
      "Train Epoch: 3 [47744/60000 (80%)]\tLoss: 1.186983\n",
      "Train Epoch: 3 [47872/60000 (80%)]\tLoss: 1.422585\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.256871\n",
      "Train Epoch: 3 [48128/60000 (80%)]\tLoss: 1.196130\n",
      "Train Epoch: 3 [48256/60000 (81%)]\tLoss: 1.310963\n",
      "Train Epoch: 3 [48384/60000 (81%)]\tLoss: 1.192205\n",
      "Train Epoch: 3 [48512/60000 (81%)]\tLoss: 1.276969\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 1.238629\n",
      "Train Epoch: 3 [48768/60000 (81%)]\tLoss: 1.207011\n",
      "Train Epoch: 3 [48896/60000 (82%)]\tLoss: 1.512110\n",
      "Train Epoch: 3 [49024/60000 (82%)]\tLoss: 1.396342\n",
      "Train Epoch: 3 [49152/60000 (82%)]\tLoss: 1.443902\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 1.117319\n",
      "Train Epoch: 3 [49408/60000 (82%)]\tLoss: 1.475649\n",
      "Train Epoch: 3 [49536/60000 (83%)]\tLoss: 1.477296\n",
      "Train Epoch: 3 [49664/60000 (83%)]\tLoss: 1.271417\n",
      "Train Epoch: 3 [49792/60000 (83%)]\tLoss: 1.298540\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 1.306011\n",
      "Train Epoch: 3 [50048/60000 (84%)]\tLoss: 1.251829\n",
      "Train Epoch: 3 [50176/60000 (84%)]\tLoss: 1.290288\n",
      "Train Epoch: 3 [50304/60000 (84%)]\tLoss: 1.525593\n",
      "Train Epoch: 3 [50432/60000 (84%)]\tLoss: 1.238616\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 1.289062\n",
      "Train Epoch: 3 [50688/60000 (85%)]\tLoss: 1.318000\n",
      "Train Epoch: 3 [50816/60000 (85%)]\tLoss: 1.216894\n",
      "Train Epoch: 3 [50944/60000 (85%)]\tLoss: 1.177551\n",
      "Train Epoch: 3 [51072/60000 (85%)]\tLoss: 1.346563\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.480614\n",
      "Train Epoch: 3 [51328/60000 (86%)]\tLoss: 1.193761\n",
      "Train Epoch: 3 [51456/60000 (86%)]\tLoss: 1.097290\n",
      "Train Epoch: 3 [51584/60000 (86%)]\tLoss: 1.251167\n",
      "Train Epoch: 3 [51712/60000 (86%)]\tLoss: 1.312582\n",
      "Train Epoch: 3 [51840/60000 (87%)]\tLoss: 1.293483\n",
      "Train Epoch: 3 [51968/60000 (87%)]\tLoss: 1.457830\n",
      "Train Epoch: 3 [52096/60000 (87%)]\tLoss: 1.465033\n",
      "Train Epoch: 3 [52224/60000 (87%)]\tLoss: 1.253617\n",
      "Train Epoch: 3 [52352/60000 (87%)]\tLoss: 1.114980\n",
      "Train Epoch: 3 [52480/60000 (88%)]\tLoss: 1.051763\n",
      "Train Epoch: 3 [52608/60000 (88%)]\tLoss: 1.399659\n",
      "Train Epoch: 3 [52736/60000 (88%)]\tLoss: 1.470330\n",
      "Train Epoch: 3 [52864/60000 (88%)]\tLoss: 1.442160\n",
      "Train Epoch: 3 [52992/60000 (88%)]\tLoss: 1.281985\n",
      "Train Epoch: 3 [53120/60000 (89%)]\tLoss: 1.308561\n",
      "Train Epoch: 3 [53248/60000 (89%)]\tLoss: 1.283731\n",
      "Train Epoch: 3 [53376/60000 (89%)]\tLoss: 1.237472\n",
      "Train Epoch: 3 [53504/60000 (89%)]\tLoss: 1.348151\n",
      "Train Epoch: 3 [53632/60000 (90%)]\tLoss: 1.280462\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 1.159038\n",
      "Train Epoch: 3 [53888/60000 (90%)]\tLoss: 1.323132\n",
      "Train Epoch: 3 [54016/60000 (90%)]\tLoss: 1.335619\n",
      "Train Epoch: 3 [54144/60000 (90%)]\tLoss: 1.154303\n",
      "Train Epoch: 3 [54272/60000 (91%)]\tLoss: 1.288624\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 1.118999\n",
      "Train Epoch: 3 [54528/60000 (91%)]\tLoss: 1.277657\n",
      "Train Epoch: 3 [54656/60000 (91%)]\tLoss: 1.220930\n",
      "Train Epoch: 3 [54784/60000 (91%)]\tLoss: 1.356417\n",
      "Train Epoch: 3 [54912/60000 (92%)]\tLoss: 1.331483\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 1.193832\n",
      "Train Epoch: 3 [55168/60000 (92%)]\tLoss: 1.172530\n",
      "Train Epoch: 3 [55296/60000 (92%)]\tLoss: 1.264311\n",
      "Train Epoch: 3 [55424/60000 (93%)]\tLoss: 1.258071\n",
      "Train Epoch: 3 [55552/60000 (93%)]\tLoss: 1.238486\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 1.150635\n",
      "Train Epoch: 3 [55808/60000 (93%)]\tLoss: 1.086091\n",
      "Train Epoch: 3 [55936/60000 (93%)]\tLoss: 1.198296\n",
      "Train Epoch: 3 [56064/60000 (94%)]\tLoss: 1.226654\n",
      "Train Epoch: 3 [56192/60000 (94%)]\tLoss: 1.293981\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 1.165542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56448/60000 (94%)]\tLoss: 1.310464\n",
      "Train Epoch: 3 [56576/60000 (94%)]\tLoss: 1.335332\n",
      "Train Epoch: 3 [56704/60000 (95%)]\tLoss: 1.169059\n",
      "Train Epoch: 3 [56832/60000 (95%)]\tLoss: 1.193006\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 1.278722\n",
      "Train Epoch: 3 [57088/60000 (95%)]\tLoss: 1.240184\n",
      "Train Epoch: 3 [57216/60000 (96%)]\tLoss: 1.482271\n",
      "Train Epoch: 3 [57344/60000 (96%)]\tLoss: 1.231536\n",
      "Train Epoch: 3 [57472/60000 (96%)]\tLoss: 1.139239\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.426372\n",
      "Train Epoch: 3 [57728/60000 (96%)]\tLoss: 1.376134\n",
      "Train Epoch: 3 [57856/60000 (97%)]\tLoss: 1.162246\n",
      "Train Epoch: 3 [57984/60000 (97%)]\tLoss: 1.242147\n",
      "Train Epoch: 3 [58112/60000 (97%)]\tLoss: 1.054925\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 1.056360\n",
      "Train Epoch: 3 [58368/60000 (97%)]\tLoss: 1.191705\n",
      "Train Epoch: 3 [58496/60000 (98%)]\tLoss: 1.085744\n",
      "Train Epoch: 3 [58624/60000 (98%)]\tLoss: 1.119882\n",
      "Train Epoch: 3 [58752/60000 (98%)]\tLoss: 1.273721\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 1.020870\n",
      "Train Epoch: 3 [59008/60000 (99%)]\tLoss: 1.047795\n",
      "Train Epoch: 3 [59136/60000 (99%)]\tLoss: 1.126836\n",
      "Train Epoch: 3 [59264/60000 (99%)]\tLoss: 1.255701\n",
      "Train Epoch: 3 [59392/60000 (99%)]\tLoss: 1.091674\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 1.088379\n",
      "Train Epoch: 3 [59648/60000 (100%)]\tLoss: 1.325401\n",
      "Train Epoch: 3 [59776/60000 (100%)]\tLoss: 1.134108\n",
      "================================================================\n",
      "Training: Average loss: 0.6414, Accuracy: 51935/60000 (87%)\n",
      "Test: Average loss: 0.6192, Accuracy: 8759/10000 (88%)\n",
      "================================================================\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.190070\n",
      "Train Epoch: 4 [128/60000 (0%)]\tLoss: 1.279266\n",
      "Train Epoch: 4 [256/60000 (0%)]\tLoss: 1.119939\n",
      "Train Epoch: 4 [384/60000 (1%)]\tLoss: 1.280869\n",
      "Train Epoch: 4 [512/60000 (1%)]\tLoss: 1.293295\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 1.237784\n",
      "Train Epoch: 4 [768/60000 (1%)]\tLoss: 1.339541\n",
      "Train Epoch: 4 [896/60000 (1%)]\tLoss: 1.485203\n",
      "Train Epoch: 4 [1024/60000 (2%)]\tLoss: 1.484199\n",
      "Train Epoch: 4 [1152/60000 (2%)]\tLoss: 1.301369\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 1.395715\n",
      "Train Epoch: 4 [1408/60000 (2%)]\tLoss: 1.239473\n",
      "Train Epoch: 4 [1536/60000 (3%)]\tLoss: 1.347831\n",
      "Train Epoch: 4 [1664/60000 (3%)]\tLoss: 1.202298\n",
      "Train Epoch: 4 [1792/60000 (3%)]\tLoss: 1.153746\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 1.183127\n",
      "Train Epoch: 4 [2048/60000 (3%)]\tLoss: 1.185673\n",
      "Train Epoch: 4 [2176/60000 (4%)]\tLoss: 1.262347\n",
      "Train Epoch: 4 [2304/60000 (4%)]\tLoss: 1.286267\n",
      "Train Epoch: 4 [2432/60000 (4%)]\tLoss: 1.190308\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 1.249341\n",
      "Train Epoch: 4 [2688/60000 (4%)]\tLoss: 1.183707\n",
      "Train Epoch: 4 [2816/60000 (5%)]\tLoss: 1.275946\n",
      "Train Epoch: 4 [2944/60000 (5%)]\tLoss: 1.280869\n",
      "Train Epoch: 4 [3072/60000 (5%)]\tLoss: 1.220229\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 1.096233\n",
      "Train Epoch: 4 [3328/60000 (6%)]\tLoss: 1.338140\n",
      "Train Epoch: 4 [3456/60000 (6%)]\tLoss: 1.302297\n",
      "Train Epoch: 4 [3584/60000 (6%)]\tLoss: 1.286709\n",
      "Train Epoch: 4 [3712/60000 (6%)]\tLoss: 1.338341\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 1.156081\n",
      "Train Epoch: 4 [3968/60000 (7%)]\tLoss: 1.314683\n",
      "Train Epoch: 4 [4096/60000 (7%)]\tLoss: 1.218928\n",
      "Train Epoch: 4 [4224/60000 (7%)]\tLoss: 1.141385\n",
      "Train Epoch: 4 [4352/60000 (7%)]\tLoss: 1.221119\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 1.083752\n",
      "Train Epoch: 4 [4608/60000 (8%)]\tLoss: 1.280822\n",
      "Train Epoch: 4 [4736/60000 (8%)]\tLoss: 1.321157\n",
      "Train Epoch: 4 [4864/60000 (8%)]\tLoss: 1.229870\n",
      "Train Epoch: 4 [4992/60000 (8%)]\tLoss: 1.346800\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 1.367676\n",
      "Train Epoch: 4 [5248/60000 (9%)]\tLoss: 1.282451\n",
      "Train Epoch: 4 [5376/60000 (9%)]\tLoss: 1.146840\n",
      "Train Epoch: 4 [5504/60000 (9%)]\tLoss: 1.292372\n",
      "Train Epoch: 4 [5632/60000 (9%)]\tLoss: 1.188678\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 1.248357\n",
      "Train Epoch: 4 [5888/60000 (10%)]\tLoss: 1.146625\n",
      "Train Epoch: 4 [6016/60000 (10%)]\tLoss: 1.091214\n",
      "Train Epoch: 4 [6144/60000 (10%)]\tLoss: 1.247228\n",
      "Train Epoch: 4 [6272/60000 (10%)]\tLoss: 1.150706\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 1.104652\n",
      "Train Epoch: 4 [6528/60000 (11%)]\tLoss: 1.012193\n",
      "Train Epoch: 4 [6656/60000 (11%)]\tLoss: 1.214670\n",
      "Train Epoch: 4 [6784/60000 (11%)]\tLoss: 1.368177\n",
      "Train Epoch: 4 [6912/60000 (12%)]\tLoss: 1.179641\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 1.210556\n",
      "Train Epoch: 4 [7168/60000 (12%)]\tLoss: 1.405629\n",
      "Train Epoch: 4 [7296/60000 (12%)]\tLoss: 1.321560\n",
      "Train Epoch: 4 [7424/60000 (12%)]\tLoss: 1.235628\n",
      "Train Epoch: 4 [7552/60000 (13%)]\tLoss: 1.271182\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 1.190150\n",
      "Train Epoch: 4 [7808/60000 (13%)]\tLoss: 1.446896\n",
      "Train Epoch: 4 [7936/60000 (13%)]\tLoss: 1.254692\n",
      "Train Epoch: 4 [8064/60000 (13%)]\tLoss: 1.087638\n",
      "Train Epoch: 4 [8192/60000 (14%)]\tLoss: 1.412875\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 1.276196\n",
      "Train Epoch: 4 [8448/60000 (14%)]\tLoss: 1.184355\n",
      "Train Epoch: 4 [8576/60000 (14%)]\tLoss: 1.394558\n",
      "Train Epoch: 4 [8704/60000 (15%)]\tLoss: 1.346555\n",
      "Train Epoch: 4 [8832/60000 (15%)]\tLoss: 1.365080\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 1.089564\n",
      "Train Epoch: 4 [9088/60000 (15%)]\tLoss: 1.233865\n",
      "Train Epoch: 4 [9216/60000 (15%)]\tLoss: 1.197392\n",
      "Train Epoch: 4 [9344/60000 (16%)]\tLoss: 1.221223\n",
      "Train Epoch: 4 [9472/60000 (16%)]\tLoss: 1.152032\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 1.087020\n",
      "Train Epoch: 4 [9728/60000 (16%)]\tLoss: 1.161859\n",
      "Train Epoch: 4 [9856/60000 (16%)]\tLoss: 1.095516\n",
      "Train Epoch: 4 [9984/60000 (17%)]\tLoss: 1.208225\n",
      "Train Epoch: 4 [10112/60000 (17%)]\tLoss: 1.171463\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 1.147729\n",
      "Train Epoch: 4 [10368/60000 (17%)]\tLoss: 1.129995\n",
      "Train Epoch: 4 [10496/60000 (18%)]\tLoss: 1.134955\n",
      "Train Epoch: 4 [10624/60000 (18%)]\tLoss: 1.170306\n",
      "Train Epoch: 4 [10752/60000 (18%)]\tLoss: 1.217577\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 1.276228\n",
      "Train Epoch: 4 [11008/60000 (18%)]\tLoss: 1.232653\n",
      "Train Epoch: 4 [11136/60000 (19%)]\tLoss: 1.232707\n",
      "Train Epoch: 4 [11264/60000 (19%)]\tLoss: 1.079853\n",
      "Train Epoch: 4 [11392/60000 (19%)]\tLoss: 1.014501\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 1.433056\n",
      "Train Epoch: 4 [11648/60000 (19%)]\tLoss: 1.389103\n",
      "Train Epoch: 4 [11776/60000 (20%)]\tLoss: 1.302592\n",
      "Train Epoch: 4 [11904/60000 (20%)]\tLoss: 1.278560\n",
      "Train Epoch: 4 [12032/60000 (20%)]\tLoss: 1.234699\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 1.273311\n",
      "Train Epoch: 4 [12288/60000 (21%)]\tLoss: 1.326910\n",
      "Train Epoch: 4 [12416/60000 (21%)]\tLoss: 1.360878\n",
      "Train Epoch: 4 [12544/60000 (21%)]\tLoss: 1.384688\n",
      "Train Epoch: 4 [12672/60000 (21%)]\tLoss: 1.147811\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.151294\n",
      "Train Epoch: 4 [12928/60000 (22%)]\tLoss: 1.478779\n",
      "Train Epoch: 4 [13056/60000 (22%)]\tLoss: 1.360507\n",
      "Train Epoch: 4 [13184/60000 (22%)]\tLoss: 1.126778\n",
      "Train Epoch: 4 [13312/60000 (22%)]\tLoss: 1.318108\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 1.145709\n",
      "Train Epoch: 4 [13568/60000 (23%)]\tLoss: 1.227220\n",
      "Train Epoch: 4 [13696/60000 (23%)]\tLoss: 1.301883\n",
      "Train Epoch: 4 [13824/60000 (23%)]\tLoss: 1.173312\n",
      "Train Epoch: 4 [13952/60000 (23%)]\tLoss: 1.330003\n",
      "Train Epoch: 4 [14080/60000 (24%)]\tLoss: 1.209578\n",
      "Train Epoch: 4 [14208/60000 (24%)]\tLoss: 1.410368\n",
      "Train Epoch: 4 [14336/60000 (24%)]\tLoss: 1.477160\n",
      "Train Epoch: 4 [14464/60000 (24%)]\tLoss: 1.331328\n",
      "Train Epoch: 4 [14592/60000 (24%)]\tLoss: 1.341014\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 1.399961\n",
      "Train Epoch: 4 [14848/60000 (25%)]\tLoss: 1.133025\n",
      "Train Epoch: 4 [14976/60000 (25%)]\tLoss: 1.081511\n",
      "Train Epoch: 4 [15104/60000 (25%)]\tLoss: 1.278987\n",
      "Train Epoch: 4 [15232/60000 (25%)]\tLoss: 1.217141\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 1.138374\n",
      "Train Epoch: 4 [15488/60000 (26%)]\tLoss: 1.085396\n",
      "Train Epoch: 4 [15616/60000 (26%)]\tLoss: 1.271071\n",
      "Train Epoch: 4 [15744/60000 (26%)]\tLoss: 1.398769\n",
      "Train Epoch: 4 [15872/60000 (26%)]\tLoss: 1.341484\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.306223\n",
      "Train Epoch: 4 [16128/60000 (27%)]\tLoss: 1.211635\n",
      "Train Epoch: 4 [16256/60000 (27%)]\tLoss: 1.088295\n",
      "Train Epoch: 4 [16384/60000 (27%)]\tLoss: 1.224540\n",
      "Train Epoch: 4 [16512/60000 (28%)]\tLoss: 1.137360\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 1.266795\n",
      "Train Epoch: 4 [16768/60000 (28%)]\tLoss: 1.416181\n",
      "Train Epoch: 4 [16896/60000 (28%)]\tLoss: 1.359970\n",
      "Train Epoch: 4 [17024/60000 (28%)]\tLoss: 1.160191\n",
      "Train Epoch: 4 [17152/60000 (29%)]\tLoss: 1.279833\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 1.129499\n",
      "Train Epoch: 4 [17408/60000 (29%)]\tLoss: 1.172760\n",
      "Train Epoch: 4 [17536/60000 (29%)]\tLoss: 1.421800\n",
      "Train Epoch: 4 [17664/60000 (29%)]\tLoss: 1.317659\n",
      "Train Epoch: 4 [17792/60000 (30%)]\tLoss: 1.293574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 1.207654\n",
      "Train Epoch: 4 [18048/60000 (30%)]\tLoss: 1.132084\n",
      "Train Epoch: 4 [18176/60000 (30%)]\tLoss: 1.096261\n",
      "Train Epoch: 4 [18304/60000 (31%)]\tLoss: 1.268672\n",
      "Train Epoch: 4 [18432/60000 (31%)]\tLoss: 1.197523\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 1.302903\n",
      "Train Epoch: 4 [18688/60000 (31%)]\tLoss: 1.152578\n",
      "Train Epoch: 4 [18816/60000 (31%)]\tLoss: 1.170304\n",
      "Train Epoch: 4 [18944/60000 (32%)]\tLoss: 1.306533\n",
      "Train Epoch: 4 [19072/60000 (32%)]\tLoss: 1.338907\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 1.180876\n",
      "Train Epoch: 4 [19328/60000 (32%)]\tLoss: 1.314431\n",
      "Train Epoch: 4 [19456/60000 (32%)]\tLoss: 1.279646\n",
      "Train Epoch: 4 [19584/60000 (33%)]\tLoss: 1.093232\n",
      "Train Epoch: 4 [19712/60000 (33%)]\tLoss: 1.011479\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 1.249761\n",
      "Train Epoch: 4 [19968/60000 (33%)]\tLoss: 1.309470\n",
      "Train Epoch: 4 [20096/60000 (34%)]\tLoss: 1.406680\n",
      "Train Epoch: 4 [20224/60000 (34%)]\tLoss: 1.209715\n",
      "Train Epoch: 4 [20352/60000 (34%)]\tLoss: 1.112756\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 1.145663\n",
      "Train Epoch: 4 [20608/60000 (34%)]\tLoss: 1.212629\n",
      "Train Epoch: 4 [20736/60000 (35%)]\tLoss: 1.248071\n",
      "Train Epoch: 4 [20864/60000 (35%)]\tLoss: 1.412333\n",
      "Train Epoch: 4 [20992/60000 (35%)]\tLoss: 1.312078\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 1.105315\n",
      "Train Epoch: 4 [21248/60000 (35%)]\tLoss: 1.147816\n",
      "Train Epoch: 4 [21376/60000 (36%)]\tLoss: 1.119985\n",
      "Train Epoch: 4 [21504/60000 (36%)]\tLoss: 1.065364\n",
      "Train Epoch: 4 [21632/60000 (36%)]\tLoss: 1.373716\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 1.005160\n",
      "Train Epoch: 4 [21888/60000 (37%)]\tLoss: 1.060884\n",
      "Train Epoch: 4 [22016/60000 (37%)]\tLoss: 1.217480\n",
      "Train Epoch: 4 [22144/60000 (37%)]\tLoss: 1.275847\n",
      "Train Epoch: 4 [22272/60000 (37%)]\tLoss: 1.147639\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 1.428293\n",
      "Train Epoch: 4 [22528/60000 (38%)]\tLoss: 1.420090\n",
      "Train Epoch: 4 [22656/60000 (38%)]\tLoss: 1.234691\n",
      "Train Epoch: 4 [22784/60000 (38%)]\tLoss: 1.174580\n",
      "Train Epoch: 4 [22912/60000 (38%)]\tLoss: 1.169247\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 1.252732\n",
      "Train Epoch: 4 [23168/60000 (39%)]\tLoss: 1.175147\n",
      "Train Epoch: 4 [23296/60000 (39%)]\tLoss: 1.103704\n",
      "Train Epoch: 4 [23424/60000 (39%)]\tLoss: 1.193373\n",
      "Train Epoch: 4 [23552/60000 (39%)]\tLoss: 1.175086\n",
      "Train Epoch: 4 [23680/60000 (40%)]\tLoss: 1.241359\n",
      "Train Epoch: 4 [23808/60000 (40%)]\tLoss: 1.240931\n",
      "Train Epoch: 4 [23936/60000 (40%)]\tLoss: 1.273572\n",
      "Train Epoch: 4 [24064/60000 (40%)]\tLoss: 1.216120\n",
      "Train Epoch: 4 [24192/60000 (40%)]\tLoss: 1.249317\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 1.170467\n",
      "Train Epoch: 4 [24448/60000 (41%)]\tLoss: 1.240222\n",
      "Train Epoch: 4 [24576/60000 (41%)]\tLoss: 1.399993\n",
      "Train Epoch: 4 [24704/60000 (41%)]\tLoss: 1.482194\n",
      "Train Epoch: 4 [24832/60000 (41%)]\tLoss: 1.309294\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 1.151063\n",
      "Train Epoch: 4 [25088/60000 (42%)]\tLoss: 1.144822\n",
      "Train Epoch: 4 [25216/60000 (42%)]\tLoss: 1.348822\n",
      "Train Epoch: 4 [25344/60000 (42%)]\tLoss: 1.014599\n",
      "Train Epoch: 4 [25472/60000 (43%)]\tLoss: 1.011120\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.223237\n",
      "Train Epoch: 4 [25728/60000 (43%)]\tLoss: 1.190504\n",
      "Train Epoch: 4 [25856/60000 (43%)]\tLoss: 1.197312\n",
      "Train Epoch: 4 [25984/60000 (43%)]\tLoss: 1.034378\n",
      "Train Epoch: 4 [26112/60000 (44%)]\tLoss: 1.143431\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 1.169244\n",
      "Train Epoch: 4 [26368/60000 (44%)]\tLoss: 1.315694\n",
      "Train Epoch: 4 [26496/60000 (44%)]\tLoss: 1.321826\n",
      "Train Epoch: 4 [26624/60000 (44%)]\tLoss: 1.344954\n",
      "Train Epoch: 4 [26752/60000 (45%)]\tLoss: 1.172732\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 1.259099\n",
      "Train Epoch: 4 [27008/60000 (45%)]\tLoss: 1.176624\n",
      "Train Epoch: 4 [27136/60000 (45%)]\tLoss: 1.502766\n",
      "Train Epoch: 4 [27264/60000 (46%)]\tLoss: 1.187552\n",
      "Train Epoch: 4 [27392/60000 (46%)]\tLoss: 1.238915\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 1.292972\n",
      "Train Epoch: 4 [27648/60000 (46%)]\tLoss: 1.145106\n",
      "Train Epoch: 4 [27776/60000 (46%)]\tLoss: 1.114696\n",
      "Train Epoch: 4 [27904/60000 (47%)]\tLoss: 1.103855\n",
      "Train Epoch: 4 [28032/60000 (47%)]\tLoss: 0.968668\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 1.249409\n",
      "Train Epoch: 4 [28288/60000 (47%)]\tLoss: 1.219123\n",
      "Train Epoch: 4 [28416/60000 (47%)]\tLoss: 1.220104\n",
      "Train Epoch: 4 [28544/60000 (48%)]\tLoss: 1.159756\n",
      "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 1.239822\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 1.225604\n",
      "Train Epoch: 4 [28928/60000 (48%)]\tLoss: 1.229410\n",
      "Train Epoch: 4 [29056/60000 (49%)]\tLoss: 1.436774\n",
      "Train Epoch: 4 [29184/60000 (49%)]\tLoss: 1.215310\n",
      "Train Epoch: 4 [29312/60000 (49%)]\tLoss: 1.203140\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 1.027252\n",
      "Train Epoch: 4 [29568/60000 (49%)]\tLoss: 1.154795\n",
      "Train Epoch: 4 [29696/60000 (50%)]\tLoss: 1.319763\n",
      "Train Epoch: 4 [29824/60000 (50%)]\tLoss: 1.361165\n",
      "Train Epoch: 4 [29952/60000 (50%)]\tLoss: 1.282644\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 1.313286\n",
      "Train Epoch: 4 [30208/60000 (50%)]\tLoss: 1.221361\n",
      "Train Epoch: 4 [30336/60000 (51%)]\tLoss: 1.200964\n",
      "Train Epoch: 4 [30464/60000 (51%)]\tLoss: 1.245884\n",
      "Train Epoch: 4 [30592/60000 (51%)]\tLoss: 1.261685\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 1.215868\n",
      "Train Epoch: 4 [30848/60000 (51%)]\tLoss: 1.215061\n",
      "Train Epoch: 4 [30976/60000 (52%)]\tLoss: 1.125221\n",
      "Train Epoch: 4 [31104/60000 (52%)]\tLoss: 1.061421\n",
      "Train Epoch: 4 [31232/60000 (52%)]\tLoss: 1.348490\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 1.302935\n",
      "Train Epoch: 4 [31488/60000 (53%)]\tLoss: 1.188126\n",
      "Train Epoch: 4 [31616/60000 (53%)]\tLoss: 1.477159\n",
      "Train Epoch: 4 [31744/60000 (53%)]\tLoss: 1.182438\n",
      "Train Epoch: 4 [31872/60000 (53%)]\tLoss: 1.141497\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.216744\n",
      "Train Epoch: 4 [32128/60000 (54%)]\tLoss: 1.355267\n",
      "Train Epoch: 4 [32256/60000 (54%)]\tLoss: 1.434236\n",
      "Train Epoch: 4 [32384/60000 (54%)]\tLoss: 1.396458\n",
      "Train Epoch: 4 [32512/60000 (54%)]\tLoss: 1.077739\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 1.162232\n",
      "Train Epoch: 4 [32768/60000 (55%)]\tLoss: 1.149714\n",
      "Train Epoch: 4 [32896/60000 (55%)]\tLoss: 1.237149\n",
      "Train Epoch: 4 [33024/60000 (55%)]\tLoss: 1.316193\n",
      "Train Epoch: 4 [33152/60000 (55%)]\tLoss: 1.237276\n",
      "Train Epoch: 4 [33280/60000 (56%)]\tLoss: 1.265730\n",
      "Train Epoch: 4 [33408/60000 (56%)]\tLoss: 1.187510\n",
      "Train Epoch: 4 [33536/60000 (56%)]\tLoss: 1.059007\n",
      "Train Epoch: 4 [33664/60000 (56%)]\tLoss: 1.117642\n",
      "Train Epoch: 4 [33792/60000 (56%)]\tLoss: 0.984533\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 1.100834\n",
      "Train Epoch: 4 [34048/60000 (57%)]\tLoss: 1.144794\n",
      "Train Epoch: 4 [34176/60000 (57%)]\tLoss: 1.145869\n",
      "Train Epoch: 4 [34304/60000 (57%)]\tLoss: 1.056136\n",
      "Train Epoch: 4 [34432/60000 (57%)]\tLoss: 1.178395\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 1.240182\n",
      "Train Epoch: 4 [34688/60000 (58%)]\tLoss: 1.365016\n",
      "Train Epoch: 4 [34816/60000 (58%)]\tLoss: 1.285467\n",
      "Train Epoch: 4 [34944/60000 (58%)]\tLoss: 1.018611\n",
      "Train Epoch: 4 [35072/60000 (59%)]\tLoss: 1.125259\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 1.273345\n",
      "Train Epoch: 4 [35328/60000 (59%)]\tLoss: 1.087144\n",
      "Train Epoch: 4 [35456/60000 (59%)]\tLoss: 1.140023\n",
      "Train Epoch: 4 [35584/60000 (59%)]\tLoss: 1.201645\n",
      "Train Epoch: 4 [35712/60000 (60%)]\tLoss: 1.169329\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 1.196835\n",
      "Train Epoch: 4 [35968/60000 (60%)]\tLoss: 1.321149\n",
      "Train Epoch: 4 [36096/60000 (60%)]\tLoss: 1.080438\n",
      "Train Epoch: 4 [36224/60000 (60%)]\tLoss: 1.029762\n",
      "Train Epoch: 4 [36352/60000 (61%)]\tLoss: 1.249833\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 1.194926\n",
      "Train Epoch: 4 [36608/60000 (61%)]\tLoss: 1.107435\n",
      "Train Epoch: 4 [36736/60000 (61%)]\tLoss: 1.179216\n",
      "Train Epoch: 4 [36864/60000 (62%)]\tLoss: 1.110254\n",
      "Train Epoch: 4 [36992/60000 (62%)]\tLoss: 1.255572\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 1.137069\n",
      "Train Epoch: 4 [37248/60000 (62%)]\tLoss: 1.362349\n",
      "Train Epoch: 4 [37376/60000 (62%)]\tLoss: 1.405177\n",
      "Train Epoch: 4 [37504/60000 (63%)]\tLoss: 1.219332\n",
      "Train Epoch: 4 [37632/60000 (63%)]\tLoss: 1.166099\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 1.287014\n",
      "Train Epoch: 4 [37888/60000 (63%)]\tLoss: 1.196255\n",
      "Train Epoch: 4 [38016/60000 (63%)]\tLoss: 1.096530\n",
      "Train Epoch: 4 [38144/60000 (64%)]\tLoss: 1.256178\n",
      "Train Epoch: 4 [38272/60000 (64%)]\tLoss: 1.235625\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.085011\n",
      "Train Epoch: 4 [38528/60000 (64%)]\tLoss: 1.288616\n",
      "Train Epoch: 4 [38656/60000 (65%)]\tLoss: 1.079179\n",
      "Train Epoch: 4 [38784/60000 (65%)]\tLoss: 1.052713\n",
      "Train Epoch: 4 [38912/60000 (65%)]\tLoss: 1.074648\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.965249\n",
      "Train Epoch: 4 [39168/60000 (65%)]\tLoss: 1.107655\n",
      "Train Epoch: 4 [39296/60000 (66%)]\tLoss: 1.442287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [39424/60000 (66%)]\tLoss: 1.295762\n",
      "Train Epoch: 4 [39552/60000 (66%)]\tLoss: 1.080608\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 1.252315\n",
      "Train Epoch: 4 [39808/60000 (66%)]\tLoss: 1.233636\n",
      "Train Epoch: 4 [39936/60000 (67%)]\tLoss: 1.105808\n",
      "Train Epoch: 4 [40064/60000 (67%)]\tLoss: 1.116897\n",
      "Train Epoch: 4 [40192/60000 (67%)]\tLoss: 1.185127\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 1.067316\n",
      "Train Epoch: 4 [40448/60000 (68%)]\tLoss: 1.218182\n",
      "Train Epoch: 4 [40576/60000 (68%)]\tLoss: 1.160460\n",
      "Train Epoch: 4 [40704/60000 (68%)]\tLoss: 1.129543\n",
      "Train Epoch: 4 [40832/60000 (68%)]\tLoss: 0.940666\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 1.215525\n",
      "Train Epoch: 4 [41088/60000 (69%)]\tLoss: 1.107597\n",
      "Train Epoch: 4 [41216/60000 (69%)]\tLoss: 1.467473\n",
      "Train Epoch: 4 [41344/60000 (69%)]\tLoss: 1.334416\n",
      "Train Epoch: 4 [41472/60000 (69%)]\tLoss: 1.375512\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 1.058829\n",
      "Train Epoch: 4 [41728/60000 (70%)]\tLoss: 1.084842\n",
      "Train Epoch: 4 [41856/60000 (70%)]\tLoss: 1.140875\n",
      "Train Epoch: 4 [41984/60000 (70%)]\tLoss: 1.154198\n",
      "Train Epoch: 4 [42112/60000 (70%)]\tLoss: 1.287763\n",
      "Train Epoch: 4 [42240/60000 (71%)]\tLoss: 1.352825\n",
      "Train Epoch: 4 [42368/60000 (71%)]\tLoss: 1.216532\n",
      "Train Epoch: 4 [42496/60000 (71%)]\tLoss: 1.157350\n",
      "Train Epoch: 4 [42624/60000 (71%)]\tLoss: 1.210032\n",
      "Train Epoch: 4 [42752/60000 (71%)]\tLoss: 1.130352\n",
      "Train Epoch: 4 [42880/60000 (72%)]\tLoss: 1.300050\n",
      "Train Epoch: 4 [43008/60000 (72%)]\tLoss: 1.411299\n",
      "Train Epoch: 4 [43136/60000 (72%)]\tLoss: 1.066184\n",
      "Train Epoch: 4 [43264/60000 (72%)]\tLoss: 0.989292\n",
      "Train Epoch: 4 [43392/60000 (72%)]\tLoss: 1.013294\n",
      "Train Epoch: 4 [43520/60000 (73%)]\tLoss: 0.900794\n",
      "Train Epoch: 4 [43648/60000 (73%)]\tLoss: 1.214839\n",
      "Train Epoch: 4 [43776/60000 (73%)]\tLoss: 1.243968\n",
      "Train Epoch: 4 [43904/60000 (73%)]\tLoss: 1.087992\n",
      "Train Epoch: 4 [44032/60000 (74%)]\tLoss: 1.188702\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 1.252690\n",
      "Train Epoch: 4 [44288/60000 (74%)]\tLoss: 1.115112\n",
      "Train Epoch: 4 [44416/60000 (74%)]\tLoss: 1.015817\n",
      "Train Epoch: 4 [44544/60000 (74%)]\tLoss: 0.996958\n",
      "Train Epoch: 4 [44672/60000 (75%)]\tLoss: 1.136829\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 1.358989\n",
      "Train Epoch: 4 [44928/60000 (75%)]\tLoss: 1.212908\n",
      "Train Epoch: 4 [45056/60000 (75%)]\tLoss: 1.226998\n",
      "Train Epoch: 4 [45184/60000 (75%)]\tLoss: 1.129122\n",
      "Train Epoch: 4 [45312/60000 (76%)]\tLoss: 0.978025\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 1.231317\n",
      "Train Epoch: 4 [45568/60000 (76%)]\tLoss: 1.195507\n",
      "Train Epoch: 4 [45696/60000 (76%)]\tLoss: 1.263585\n",
      "Train Epoch: 4 [45824/60000 (76%)]\tLoss: 1.199382\n",
      "Train Epoch: 4 [45952/60000 (77%)]\tLoss: 1.102126\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 1.132703\n",
      "Train Epoch: 4 [46208/60000 (77%)]\tLoss: 1.161225\n",
      "Train Epoch: 4 [46336/60000 (77%)]\tLoss: 1.373175\n",
      "Train Epoch: 4 [46464/60000 (78%)]\tLoss: 1.052245\n",
      "Train Epoch: 4 [46592/60000 (78%)]\tLoss: 1.078357\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 1.138428\n",
      "Train Epoch: 4 [46848/60000 (78%)]\tLoss: 1.003648\n",
      "Train Epoch: 4 [46976/60000 (78%)]\tLoss: 1.136502\n",
      "Train Epoch: 4 [47104/60000 (79%)]\tLoss: 1.094610\n",
      "Train Epoch: 4 [47232/60000 (79%)]\tLoss: 1.241427\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 1.347567\n",
      "Train Epoch: 4 [47488/60000 (79%)]\tLoss: 1.200917\n",
      "Train Epoch: 4 [47616/60000 (79%)]\tLoss: 1.026882\n",
      "Train Epoch: 4 [47744/60000 (80%)]\tLoss: 1.075462\n",
      "Train Epoch: 4 [47872/60000 (80%)]\tLoss: 1.316862\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.024550\n",
      "Train Epoch: 4 [48128/60000 (80%)]\tLoss: 0.983213\n",
      "Train Epoch: 4 [48256/60000 (81%)]\tLoss: 1.250860\n",
      "Train Epoch: 4 [48384/60000 (81%)]\tLoss: 1.029389\n",
      "Train Epoch: 4 [48512/60000 (81%)]\tLoss: 1.054447\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.995413\n",
      "Train Epoch: 4 [48768/60000 (81%)]\tLoss: 1.126792\n",
      "Train Epoch: 4 [48896/60000 (82%)]\tLoss: 1.279909\n",
      "Train Epoch: 4 [49024/60000 (82%)]\tLoss: 1.236522\n",
      "Train Epoch: 4 [49152/60000 (82%)]\tLoss: 1.223936\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 1.045231\n",
      "Train Epoch: 4 [49408/60000 (82%)]\tLoss: 1.273549\n",
      "Train Epoch: 4 [49536/60000 (83%)]\tLoss: 1.366998\n",
      "Train Epoch: 4 [49664/60000 (83%)]\tLoss: 1.109557\n",
      "Train Epoch: 4 [49792/60000 (83%)]\tLoss: 1.270278\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 1.249238\n",
      "Train Epoch: 4 [50048/60000 (84%)]\tLoss: 1.076978\n",
      "Train Epoch: 4 [50176/60000 (84%)]\tLoss: 1.315584\n",
      "Train Epoch: 4 [50304/60000 (84%)]\tLoss: 1.366943\n",
      "Train Epoch: 4 [50432/60000 (84%)]\tLoss: 1.136621\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 1.077105\n",
      "Train Epoch: 4 [50688/60000 (85%)]\tLoss: 1.229809\n",
      "Train Epoch: 4 [50816/60000 (85%)]\tLoss: 1.044029\n",
      "Train Epoch: 4 [50944/60000 (85%)]\tLoss: 0.991624\n",
      "Train Epoch: 4 [51072/60000 (85%)]\tLoss: 1.185239\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.213941\n",
      "Train Epoch: 4 [51328/60000 (86%)]\tLoss: 1.074436\n",
      "Train Epoch: 4 [51456/60000 (86%)]\tLoss: 1.059320\n",
      "Train Epoch: 4 [51584/60000 (86%)]\tLoss: 1.128037\n",
      "Train Epoch: 4 [51712/60000 (86%)]\tLoss: 1.035916\n",
      "Train Epoch: 4 [51840/60000 (87%)]\tLoss: 1.216388\n",
      "Train Epoch: 4 [51968/60000 (87%)]\tLoss: 1.177607\n",
      "Train Epoch: 4 [52096/60000 (87%)]\tLoss: 1.348671\n",
      "Train Epoch: 4 [52224/60000 (87%)]\tLoss: 1.087868\n",
      "Train Epoch: 4 [52352/60000 (87%)]\tLoss: 1.060826\n",
      "Train Epoch: 4 [52480/60000 (88%)]\tLoss: 0.928480\n",
      "Train Epoch: 4 [52608/60000 (88%)]\tLoss: 1.187091\n",
      "Train Epoch: 4 [52736/60000 (88%)]\tLoss: 1.237798\n",
      "Train Epoch: 4 [52864/60000 (88%)]\tLoss: 1.519976\n",
      "Train Epoch: 4 [52992/60000 (88%)]\tLoss: 1.138829\n",
      "Train Epoch: 4 [53120/60000 (89%)]\tLoss: 1.214572\n",
      "Train Epoch: 4 [53248/60000 (89%)]\tLoss: 1.033458\n",
      "Train Epoch: 4 [53376/60000 (89%)]\tLoss: 1.171780\n",
      "Train Epoch: 4 [53504/60000 (89%)]\tLoss: 1.123101\n",
      "Train Epoch: 4 [53632/60000 (90%)]\tLoss: 1.151117\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 1.043209\n",
      "Train Epoch: 4 [53888/60000 (90%)]\tLoss: 1.143513\n",
      "Train Epoch: 4 [54016/60000 (90%)]\tLoss: 1.218853\n",
      "Train Epoch: 4 [54144/60000 (90%)]\tLoss: 1.082758\n",
      "Train Epoch: 4 [54272/60000 (91%)]\tLoss: 1.031704\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 1.016352\n",
      "Train Epoch: 4 [54528/60000 (91%)]\tLoss: 1.076935\n",
      "Train Epoch: 4 [54656/60000 (91%)]\tLoss: 0.980847\n",
      "Train Epoch: 4 [54784/60000 (91%)]\tLoss: 1.229445\n",
      "Train Epoch: 4 [54912/60000 (92%)]\tLoss: 1.235296\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 1.011366\n",
      "Train Epoch: 4 [55168/60000 (92%)]\tLoss: 0.975396\n",
      "Train Epoch: 4 [55296/60000 (92%)]\tLoss: 1.142704\n",
      "Train Epoch: 4 [55424/60000 (93%)]\tLoss: 1.083732\n",
      "Train Epoch: 4 [55552/60000 (93%)]\tLoss: 1.046307\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 1.042765\n",
      "Train Epoch: 4 [55808/60000 (93%)]\tLoss: 1.056434\n",
      "Train Epoch: 4 [55936/60000 (93%)]\tLoss: 1.073031\n",
      "Train Epoch: 4 [56064/60000 (94%)]\tLoss: 1.128220\n",
      "Train Epoch: 4 [56192/60000 (94%)]\tLoss: 1.133696\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 1.061033\n",
      "Train Epoch: 4 [56448/60000 (94%)]\tLoss: 1.127726\n",
      "Train Epoch: 4 [56576/60000 (94%)]\tLoss: 1.129181\n",
      "Train Epoch: 4 [56704/60000 (95%)]\tLoss: 0.884576\n",
      "Train Epoch: 4 [56832/60000 (95%)]\tLoss: 1.071867\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 1.129718\n",
      "Train Epoch: 4 [57088/60000 (95%)]\tLoss: 1.099055\n",
      "Train Epoch: 4 [57216/60000 (96%)]\tLoss: 1.358887\n",
      "Train Epoch: 4 [57344/60000 (96%)]\tLoss: 1.204568\n",
      "Train Epoch: 4 [57472/60000 (96%)]\tLoss: 1.221826\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 1.178385\n",
      "Train Epoch: 4 [57728/60000 (96%)]\tLoss: 1.150914\n",
      "Train Epoch: 4 [57856/60000 (97%)]\tLoss: 1.008725\n",
      "Train Epoch: 4 [57984/60000 (97%)]\tLoss: 1.016693\n",
      "Train Epoch: 4 [58112/60000 (97%)]\tLoss: 0.925109\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 1.046519\n",
      "Train Epoch: 4 [58368/60000 (97%)]\tLoss: 1.061142\n",
      "Train Epoch: 4 [58496/60000 (98%)]\tLoss: 1.022540\n",
      "Train Epoch: 4 [58624/60000 (98%)]\tLoss: 0.974734\n",
      "Train Epoch: 4 [58752/60000 (98%)]\tLoss: 1.088934\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.823480\n",
      "Train Epoch: 4 [59008/60000 (99%)]\tLoss: 0.904685\n",
      "Train Epoch: 4 [59136/60000 (99%)]\tLoss: 0.907175\n",
      "Train Epoch: 4 [59264/60000 (99%)]\tLoss: 1.256556\n",
      "Train Epoch: 4 [59392/60000 (99%)]\tLoss: 0.998611\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 1.016833\n",
      "Train Epoch: 4 [59648/60000 (100%)]\tLoss: 1.332367\n",
      "Train Epoch: 4 [59776/60000 (100%)]\tLoss: 0.928516\n",
      "================================================================\n",
      "Training: Average loss: 0.4977, Accuracy: 53177/60000 (89%)\n",
      "Test: Average loss: 0.4784, Accuracy: 8913/10000 (89%)\n",
      "================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.155546\n",
      "Train Epoch: 5 [128/60000 (0%)]\tLoss: 1.162005\n",
      "Train Epoch: 5 [256/60000 (0%)]\tLoss: 1.050108\n",
      "Train Epoch: 5 [384/60000 (1%)]\tLoss: 1.094493\n",
      "Train Epoch: 5 [512/60000 (1%)]\tLoss: 1.209744\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.950250\n",
      "Train Epoch: 5 [768/60000 (1%)]\tLoss: 1.294509\n",
      "Train Epoch: 5 [896/60000 (1%)]\tLoss: 1.182575\n",
      "Train Epoch: 5 [1024/60000 (2%)]\tLoss: 1.350753\n",
      "Train Epoch: 5 [1152/60000 (2%)]\tLoss: 1.092785\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 1.167883\n",
      "Train Epoch: 5 [1408/60000 (2%)]\tLoss: 1.158268\n",
      "Train Epoch: 5 [1536/60000 (3%)]\tLoss: 1.122755\n",
      "Train Epoch: 5 [1664/60000 (3%)]\tLoss: 1.130487\n",
      "Train Epoch: 5 [1792/60000 (3%)]\tLoss: 0.968398\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 1.131233\n",
      "Train Epoch: 5 [2048/60000 (3%)]\tLoss: 0.981224\n",
      "Train Epoch: 5 [2176/60000 (4%)]\tLoss: 0.985499\n",
      "Train Epoch: 5 [2304/60000 (4%)]\tLoss: 1.046505\n",
      "Train Epoch: 5 [2432/60000 (4%)]\tLoss: 1.098275\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 1.080137\n",
      "Train Epoch: 5 [2688/60000 (4%)]\tLoss: 0.952380\n",
      "Train Epoch: 5 [2816/60000 (5%)]\tLoss: 1.037605\n",
      "Train Epoch: 5 [2944/60000 (5%)]\tLoss: 1.205501\n",
      "Train Epoch: 5 [3072/60000 (5%)]\tLoss: 1.083070\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 1.121261\n",
      "Train Epoch: 5 [3328/60000 (6%)]\tLoss: 1.197649\n",
      "Train Epoch: 5 [3456/60000 (6%)]\tLoss: 1.194021\n",
      "Train Epoch: 5 [3584/60000 (6%)]\tLoss: 1.067181\n",
      "Train Epoch: 5 [3712/60000 (6%)]\tLoss: 1.183310\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.939489\n",
      "Train Epoch: 5 [3968/60000 (7%)]\tLoss: 1.095169\n",
      "Train Epoch: 5 [4096/60000 (7%)]\tLoss: 1.147597\n",
      "Train Epoch: 5 [4224/60000 (7%)]\tLoss: 1.182928\n",
      "Train Epoch: 5 [4352/60000 (7%)]\tLoss: 1.071024\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.991593\n",
      "Train Epoch: 5 [4608/60000 (8%)]\tLoss: 1.155877\n",
      "Train Epoch: 5 [4736/60000 (8%)]\tLoss: 1.286282\n",
      "Train Epoch: 5 [4864/60000 (8%)]\tLoss: 1.142569\n",
      "Train Epoch: 5 [4992/60000 (8%)]\tLoss: 1.153526\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 1.269769\n",
      "Train Epoch: 5 [5248/60000 (9%)]\tLoss: 1.187096\n",
      "Train Epoch: 5 [5376/60000 (9%)]\tLoss: 1.141713\n",
      "Train Epoch: 5 [5504/60000 (9%)]\tLoss: 1.127065\n",
      "Train Epoch: 5 [5632/60000 (9%)]\tLoss: 1.053948\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 1.148778\n",
      "Train Epoch: 5 [5888/60000 (10%)]\tLoss: 1.136536\n",
      "Train Epoch: 5 [6016/60000 (10%)]\tLoss: 0.945864\n",
      "Train Epoch: 5 [6144/60000 (10%)]\tLoss: 1.076322\n",
      "Train Epoch: 5 [6272/60000 (10%)]\tLoss: 1.085616\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 1.124427\n",
      "Train Epoch: 5 [6528/60000 (11%)]\tLoss: 0.928206\n",
      "Train Epoch: 5 [6656/60000 (11%)]\tLoss: 1.053650\n",
      "Train Epoch: 5 [6784/60000 (11%)]\tLoss: 1.383042\n",
      "Train Epoch: 5 [6912/60000 (12%)]\tLoss: 1.263214\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 1.083045\n",
      "Train Epoch: 5 [7168/60000 (12%)]\tLoss: 1.321269\n",
      "Train Epoch: 5 [7296/60000 (12%)]\tLoss: 1.241267\n",
      "Train Epoch: 5 [7424/60000 (12%)]\tLoss: 1.112622\n",
      "Train Epoch: 5 [7552/60000 (13%)]\tLoss: 1.119181\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 1.157748\n",
      "Train Epoch: 5 [7808/60000 (13%)]\tLoss: 1.247203\n",
      "Train Epoch: 5 [7936/60000 (13%)]\tLoss: 1.025299\n",
      "Train Epoch: 5 [8064/60000 (13%)]\tLoss: 1.105243\n",
      "Train Epoch: 5 [8192/60000 (14%)]\tLoss: 1.340785\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 1.112771\n",
      "Train Epoch: 5 [8448/60000 (14%)]\tLoss: 1.069561\n",
      "Train Epoch: 5 [8576/60000 (14%)]\tLoss: 1.121343\n",
      "Train Epoch: 5 [8704/60000 (15%)]\tLoss: 1.291608\n",
      "Train Epoch: 5 [8832/60000 (15%)]\tLoss: 1.355101\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.954256\n",
      "Train Epoch: 5 [9088/60000 (15%)]\tLoss: 1.018225\n",
      "Train Epoch: 5 [9216/60000 (15%)]\tLoss: 1.101918\n",
      "Train Epoch: 5 [9344/60000 (16%)]\tLoss: 1.179622\n",
      "Train Epoch: 5 [9472/60000 (16%)]\tLoss: 1.066353\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.998732\n",
      "Train Epoch: 5 [9728/60000 (16%)]\tLoss: 1.063566\n",
      "Train Epoch: 5 [9856/60000 (16%)]\tLoss: 1.008431\n",
      "Train Epoch: 5 [9984/60000 (17%)]\tLoss: 1.061756\n",
      "Train Epoch: 5 [10112/60000 (17%)]\tLoss: 1.153405\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 1.063264\n",
      "Train Epoch: 5 [10368/60000 (17%)]\tLoss: 1.063803\n",
      "Train Epoch: 5 [10496/60000 (18%)]\tLoss: 1.022175\n",
      "Train Epoch: 5 [10624/60000 (18%)]\tLoss: 1.138438\n",
      "Train Epoch: 5 [10752/60000 (18%)]\tLoss: 1.143411\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 1.146243\n",
      "Train Epoch: 5 [11008/60000 (18%)]\tLoss: 1.126109\n",
      "Train Epoch: 5 [11136/60000 (19%)]\tLoss: 1.075243\n",
      "Train Epoch: 5 [11264/60000 (19%)]\tLoss: 1.024976\n",
      "Train Epoch: 5 [11392/60000 (19%)]\tLoss: 0.963752\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 1.230695\n",
      "Train Epoch: 5 [11648/60000 (19%)]\tLoss: 1.374408\n",
      "Train Epoch: 5 [11776/60000 (20%)]\tLoss: 1.132026\n",
      "Train Epoch: 5 [11904/60000 (20%)]\tLoss: 1.082715\n",
      "Train Epoch: 5 [12032/60000 (20%)]\tLoss: 1.148003\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 1.116305\n",
      "Train Epoch: 5 [12288/60000 (21%)]\tLoss: 1.256178\n",
      "Train Epoch: 5 [12416/60000 (21%)]\tLoss: 1.171483\n",
      "Train Epoch: 5 [12544/60000 (21%)]\tLoss: 1.226716\n",
      "Train Epoch: 5 [12672/60000 (21%)]\tLoss: 1.124887\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.038373\n",
      "Train Epoch: 5 [12928/60000 (22%)]\tLoss: 1.406256\n",
      "Train Epoch: 5 [13056/60000 (22%)]\tLoss: 1.261941\n",
      "Train Epoch: 5 [13184/60000 (22%)]\tLoss: 0.999832\n",
      "Train Epoch: 5 [13312/60000 (22%)]\tLoss: 1.109156\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 1.038839\n",
      "Train Epoch: 5 [13568/60000 (23%)]\tLoss: 1.193011\n",
      "Train Epoch: 5 [13696/60000 (23%)]\tLoss: 1.155576\n",
      "Train Epoch: 5 [13824/60000 (23%)]\tLoss: 1.072175\n",
      "Train Epoch: 5 [13952/60000 (23%)]\tLoss: 1.318273\n",
      "Train Epoch: 5 [14080/60000 (24%)]\tLoss: 1.195673\n",
      "Train Epoch: 5 [14208/60000 (24%)]\tLoss: 1.362959\n",
      "Train Epoch: 5 [14336/60000 (24%)]\tLoss: 1.246162\n",
      "Train Epoch: 5 [14464/60000 (24%)]\tLoss: 1.238515\n",
      "Train Epoch: 5 [14592/60000 (24%)]\tLoss: 1.215262\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 1.344382\n",
      "Train Epoch: 5 [14848/60000 (25%)]\tLoss: 1.057054\n",
      "Train Epoch: 5 [14976/60000 (25%)]\tLoss: 1.096047\n",
      "Train Epoch: 5 [15104/60000 (25%)]\tLoss: 1.123960\n",
      "Train Epoch: 5 [15232/60000 (25%)]\tLoss: 1.119278\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 1.099695\n",
      "Train Epoch: 5 [15488/60000 (26%)]\tLoss: 1.039876\n",
      "Train Epoch: 5 [15616/60000 (26%)]\tLoss: 1.165149\n",
      "Train Epoch: 5 [15744/60000 (26%)]\tLoss: 1.209703\n",
      "Train Epoch: 5 [15872/60000 (26%)]\tLoss: 1.173319\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.293769\n",
      "Train Epoch: 5 [16128/60000 (27%)]\tLoss: 1.042120\n",
      "Train Epoch: 5 [16256/60000 (27%)]\tLoss: 1.047116\n",
      "Train Epoch: 5 [16384/60000 (27%)]\tLoss: 0.931584\n",
      "Train Epoch: 5 [16512/60000 (28%)]\tLoss: 1.063110\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 1.156936\n",
      "Train Epoch: 5 [16768/60000 (28%)]\tLoss: 1.206115\n",
      "Train Epoch: 5 [16896/60000 (28%)]\tLoss: 1.224823\n",
      "Train Epoch: 5 [17024/60000 (28%)]\tLoss: 1.111203\n",
      "Train Epoch: 5 [17152/60000 (29%)]\tLoss: 1.097913\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 1.046244\n",
      "Train Epoch: 5 [17408/60000 (29%)]\tLoss: 1.087407\n",
      "Train Epoch: 5 [17536/60000 (29%)]\tLoss: 1.311999\n",
      "Train Epoch: 5 [17664/60000 (29%)]\tLoss: 1.092430\n",
      "Train Epoch: 5 [17792/60000 (30%)]\tLoss: 1.132251\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 1.055946\n",
      "Train Epoch: 5 [18048/60000 (30%)]\tLoss: 1.044732\n",
      "Train Epoch: 5 [18176/60000 (30%)]\tLoss: 0.867122\n",
      "Train Epoch: 5 [18304/60000 (31%)]\tLoss: 1.109362\n",
      "Train Epoch: 5 [18432/60000 (31%)]\tLoss: 1.098933\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 1.202401\n",
      "Train Epoch: 5 [18688/60000 (31%)]\tLoss: 1.071222\n",
      "Train Epoch: 5 [18816/60000 (31%)]\tLoss: 1.063759\n",
      "Train Epoch: 5 [18944/60000 (32%)]\tLoss: 1.207656\n",
      "Train Epoch: 5 [19072/60000 (32%)]\tLoss: 1.166056\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.937777\n",
      "Train Epoch: 5 [19328/60000 (32%)]\tLoss: 1.230300\n",
      "Train Epoch: 5 [19456/60000 (32%)]\tLoss: 1.110538\n",
      "Train Epoch: 5 [19584/60000 (33%)]\tLoss: 0.960579\n",
      "Train Epoch: 5 [19712/60000 (33%)]\tLoss: 0.936505\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 1.048689\n",
      "Train Epoch: 5 [19968/60000 (33%)]\tLoss: 1.174615\n",
      "Train Epoch: 5 [20096/60000 (34%)]\tLoss: 1.153572\n",
      "Train Epoch: 5 [20224/60000 (34%)]\tLoss: 1.139548\n",
      "Train Epoch: 5 [20352/60000 (34%)]\tLoss: 0.962629\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 1.069623\n",
      "Train Epoch: 5 [20608/60000 (34%)]\tLoss: 1.057546\n",
      "Train Epoch: 5 [20736/60000 (35%)]\tLoss: 1.205884\n",
      "Train Epoch: 5 [20864/60000 (35%)]\tLoss: 1.285836\n",
      "Train Epoch: 5 [20992/60000 (35%)]\tLoss: 1.098945\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.963482\n",
      "Train Epoch: 5 [21248/60000 (35%)]\tLoss: 1.102094\n",
      "Train Epoch: 5 [21376/60000 (36%)]\tLoss: 1.198673\n",
      "Train Epoch: 5 [21504/60000 (36%)]\tLoss: 1.158541\n",
      "Train Epoch: 5 [21632/60000 (36%)]\tLoss: 1.074936\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.921221\n",
      "Train Epoch: 5 [21888/60000 (37%)]\tLoss: 0.944792\n",
      "Train Epoch: 5 [22016/60000 (37%)]\tLoss: 1.142874\n",
      "Train Epoch: 5 [22144/60000 (37%)]\tLoss: 1.191085\n",
      "Train Epoch: 5 [22272/60000 (37%)]\tLoss: 1.032893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 1.278522\n",
      "Train Epoch: 5 [22528/60000 (38%)]\tLoss: 1.278320\n",
      "Train Epoch: 5 [22656/60000 (38%)]\tLoss: 1.064486\n",
      "Train Epoch: 5 [22784/60000 (38%)]\tLoss: 1.014677\n",
      "Train Epoch: 5 [22912/60000 (38%)]\tLoss: 1.058283\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 1.075641\n",
      "Train Epoch: 5 [23168/60000 (39%)]\tLoss: 1.033353\n",
      "Train Epoch: 5 [23296/60000 (39%)]\tLoss: 0.951113\n",
      "Train Epoch: 5 [23424/60000 (39%)]\tLoss: 1.169116\n",
      "Train Epoch: 5 [23552/60000 (39%)]\tLoss: 1.114299\n",
      "Train Epoch: 5 [23680/60000 (40%)]\tLoss: 1.220328\n",
      "Train Epoch: 5 [23808/60000 (40%)]\tLoss: 1.090182\n",
      "Train Epoch: 5 [23936/60000 (40%)]\tLoss: 1.120238\n",
      "Train Epoch: 5 [24064/60000 (40%)]\tLoss: 1.085670\n",
      "Train Epoch: 5 [24192/60000 (40%)]\tLoss: 1.257832\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.980685\n",
      "Train Epoch: 5 [24448/60000 (41%)]\tLoss: 1.035411\n",
      "Train Epoch: 5 [24576/60000 (41%)]\tLoss: 1.175304\n",
      "Train Epoch: 5 [24704/60000 (41%)]\tLoss: 1.388878\n",
      "Train Epoch: 5 [24832/60000 (41%)]\tLoss: 1.105511\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 1.106003\n",
      "Train Epoch: 5 [25088/60000 (42%)]\tLoss: 1.056274\n",
      "Train Epoch: 5 [25216/60000 (42%)]\tLoss: 1.096092\n",
      "Train Epoch: 5 [25344/60000 (42%)]\tLoss: 0.928388\n",
      "Train Epoch: 5 [25472/60000 (43%)]\tLoss: 0.997001\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.988521\n",
      "Train Epoch: 5 [25728/60000 (43%)]\tLoss: 1.105527\n",
      "Train Epoch: 5 [25856/60000 (43%)]\tLoss: 1.006501\n",
      "Train Epoch: 5 [25984/60000 (43%)]\tLoss: 0.864668\n",
      "Train Epoch: 5 [26112/60000 (44%)]\tLoss: 1.105507\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 1.087520\n",
      "Train Epoch: 5 [26368/60000 (44%)]\tLoss: 1.286492\n",
      "Train Epoch: 5 [26496/60000 (44%)]\tLoss: 1.279732\n",
      "Train Epoch: 5 [26624/60000 (44%)]\tLoss: 1.348514\n",
      "Train Epoch: 5 [26752/60000 (45%)]\tLoss: 1.060636\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 1.086339\n",
      "Train Epoch: 5 [27008/60000 (45%)]\tLoss: 1.025348\n",
      "Train Epoch: 5 [27136/60000 (45%)]\tLoss: 1.302054\n",
      "Train Epoch: 5 [27264/60000 (46%)]\tLoss: 1.217382\n",
      "Train Epoch: 5 [27392/60000 (46%)]\tLoss: 1.125322\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 1.050621\n",
      "Train Epoch: 5 [27648/60000 (46%)]\tLoss: 1.092003\n",
      "Train Epoch: 5 [27776/60000 (46%)]\tLoss: 1.063345\n",
      "Train Epoch: 5 [27904/60000 (47%)]\tLoss: 0.926985\n",
      "Train Epoch: 5 [28032/60000 (47%)]\tLoss: 0.859082\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 1.163640\n",
      "Train Epoch: 5 [28288/60000 (47%)]\tLoss: 1.196619\n",
      "Train Epoch: 5 [28416/60000 (47%)]\tLoss: 1.135782\n",
      "Train Epoch: 5 [28544/60000 (48%)]\tLoss: 1.193239\n",
      "Train Epoch: 5 [28672/60000 (48%)]\tLoss: 1.128100\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 1.033536\n",
      "Train Epoch: 5 [28928/60000 (48%)]\tLoss: 1.058665\n",
      "Train Epoch: 5 [29056/60000 (49%)]\tLoss: 1.252687\n",
      "Train Epoch: 5 [29184/60000 (49%)]\tLoss: 1.087650\n",
      "Train Epoch: 5 [29312/60000 (49%)]\tLoss: 1.158973\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.884116\n",
      "Train Epoch: 5 [29568/60000 (49%)]\tLoss: 1.075530\n",
      "Train Epoch: 5 [29696/60000 (50%)]\tLoss: 1.187165\n",
      "Train Epoch: 5 [29824/60000 (50%)]\tLoss: 1.260720\n",
      "Train Epoch: 5 [29952/60000 (50%)]\tLoss: 1.116977\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 1.324295\n",
      "Train Epoch: 5 [30208/60000 (50%)]\tLoss: 0.985398\n",
      "Train Epoch: 5 [30336/60000 (51%)]\tLoss: 1.095982\n",
      "Train Epoch: 5 [30464/60000 (51%)]\tLoss: 1.291622\n",
      "Train Epoch: 5 [30592/60000 (51%)]\tLoss: 1.228760\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.985762\n",
      "Train Epoch: 5 [30848/60000 (51%)]\tLoss: 1.216044\n",
      "Train Epoch: 5 [30976/60000 (52%)]\tLoss: 1.006597\n",
      "Train Epoch: 5 [31104/60000 (52%)]\tLoss: 1.209723\n",
      "Train Epoch: 5 [31232/60000 (52%)]\tLoss: 1.309431\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 1.191094\n",
      "Train Epoch: 5 [31488/60000 (53%)]\tLoss: 1.077584\n",
      "Train Epoch: 5 [31616/60000 (53%)]\tLoss: 1.338684\n",
      "Train Epoch: 5 [31744/60000 (53%)]\tLoss: 1.061856\n",
      "Train Epoch: 5 [31872/60000 (53%)]\tLoss: 1.062064\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.083549\n",
      "Train Epoch: 5 [32128/60000 (54%)]\tLoss: 1.343383\n",
      "Train Epoch: 5 [32256/60000 (54%)]\tLoss: 1.231154\n",
      "Train Epoch: 5 [32384/60000 (54%)]\tLoss: 1.303555\n",
      "Train Epoch: 5 [32512/60000 (54%)]\tLoss: 0.908850\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 1.003375\n",
      "Train Epoch: 5 [32768/60000 (55%)]\tLoss: 1.144110\n",
      "Train Epoch: 5 [32896/60000 (55%)]\tLoss: 1.035680\n",
      "Train Epoch: 5 [33024/60000 (55%)]\tLoss: 1.214486\n",
      "Train Epoch: 5 [33152/60000 (55%)]\tLoss: 1.055229\n",
      "Train Epoch: 5 [33280/60000 (56%)]\tLoss: 1.061023\n",
      "Train Epoch: 5 [33408/60000 (56%)]\tLoss: 1.065109\n",
      "Train Epoch: 5 [33536/60000 (56%)]\tLoss: 1.020760\n",
      "Train Epoch: 5 [33664/60000 (56%)]\tLoss: 1.062070\n",
      "Train Epoch: 5 [33792/60000 (56%)]\tLoss: 1.062370\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 1.024509\n",
      "Train Epoch: 5 [34048/60000 (57%)]\tLoss: 1.106792\n",
      "Train Epoch: 5 [34176/60000 (57%)]\tLoss: 0.960108\n",
      "Train Epoch: 5 [34304/60000 (57%)]\tLoss: 1.134238\n",
      "Train Epoch: 5 [34432/60000 (57%)]\tLoss: 0.966017\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 1.191800\n",
      "Train Epoch: 5 [34688/60000 (58%)]\tLoss: 1.287390\n",
      "Train Epoch: 5 [34816/60000 (58%)]\tLoss: 1.218431\n",
      "Train Epoch: 5 [34944/60000 (58%)]\tLoss: 1.006669\n",
      "Train Epoch: 5 [35072/60000 (59%)]\tLoss: 1.062791\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 1.068618\n",
      "Train Epoch: 5 [35328/60000 (59%)]\tLoss: 1.038639\n",
      "Train Epoch: 5 [35456/60000 (59%)]\tLoss: 1.038575\n",
      "Train Epoch: 5 [35584/60000 (59%)]\tLoss: 1.272462\n",
      "Train Epoch: 5 [35712/60000 (60%)]\tLoss: 0.977933\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.988129\n",
      "Train Epoch: 5 [35968/60000 (60%)]\tLoss: 1.046953\n",
      "Train Epoch: 5 [36096/60000 (60%)]\tLoss: 1.029375\n",
      "Train Epoch: 5 [36224/60000 (60%)]\tLoss: 1.040379\n",
      "Train Epoch: 5 [36352/60000 (61%)]\tLoss: 1.122608\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 1.144827\n",
      "Train Epoch: 5 [36608/60000 (61%)]\tLoss: 1.044872\n",
      "Train Epoch: 5 [36736/60000 (61%)]\tLoss: 1.127940\n",
      "Train Epoch: 5 [36864/60000 (62%)]\tLoss: 1.037018\n",
      "Train Epoch: 5 [36992/60000 (62%)]\tLoss: 1.211582\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 1.162258\n",
      "Train Epoch: 5 [37248/60000 (62%)]\tLoss: 1.308857\n",
      "Train Epoch: 5 [37376/60000 (62%)]\tLoss: 1.416620\n",
      "Train Epoch: 5 [37504/60000 (63%)]\tLoss: 1.079403\n",
      "Train Epoch: 5 [37632/60000 (63%)]\tLoss: 1.012329\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 1.084552\n",
      "Train Epoch: 5 [37888/60000 (63%)]\tLoss: 0.961175\n",
      "Train Epoch: 5 [38016/60000 (63%)]\tLoss: 1.130294\n",
      "Train Epoch: 5 [38144/60000 (64%)]\tLoss: 1.098305\n",
      "Train Epoch: 5 [38272/60000 (64%)]\tLoss: 1.290817\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.961649\n",
      "Train Epoch: 5 [38528/60000 (64%)]\tLoss: 1.164887\n",
      "Train Epoch: 5 [38656/60000 (65%)]\tLoss: 1.095091\n",
      "Train Epoch: 5 [38784/60000 (65%)]\tLoss: 1.034771\n",
      "Train Epoch: 5 [38912/60000 (65%)]\tLoss: 1.070824\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.857304\n",
      "Train Epoch: 5 [39168/60000 (65%)]\tLoss: 1.052606\n",
      "Train Epoch: 5 [39296/60000 (66%)]\tLoss: 1.324088\n",
      "Train Epoch: 5 [39424/60000 (66%)]\tLoss: 1.215584\n",
      "Train Epoch: 5 [39552/60000 (66%)]\tLoss: 1.078606\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.993804\n",
      "Train Epoch: 5 [39808/60000 (66%)]\tLoss: 1.263713\n",
      "Train Epoch: 5 [39936/60000 (67%)]\tLoss: 1.076725\n",
      "Train Epoch: 5 [40064/60000 (67%)]\tLoss: 0.998426\n",
      "Train Epoch: 5 [40192/60000 (67%)]\tLoss: 1.048945\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.854840\n",
      "Train Epoch: 5 [40448/60000 (68%)]\tLoss: 1.159140\n",
      "Train Epoch: 5 [40576/60000 (68%)]\tLoss: 1.139181\n",
      "Train Epoch: 5 [40704/60000 (68%)]\tLoss: 1.087908\n",
      "Train Epoch: 5 [40832/60000 (68%)]\tLoss: 0.917035\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.955794\n",
      "Train Epoch: 5 [41088/60000 (69%)]\tLoss: 1.091249\n",
      "Train Epoch: 5 [41216/60000 (69%)]\tLoss: 1.191725\n",
      "Train Epoch: 5 [41344/60000 (69%)]\tLoss: 1.256195\n",
      "Train Epoch: 5 [41472/60000 (69%)]\tLoss: 1.270666\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 1.125814\n",
      "Train Epoch: 5 [41728/60000 (70%)]\tLoss: 1.181298\n",
      "Train Epoch: 5 [41856/60000 (70%)]\tLoss: 1.091055\n",
      "Train Epoch: 5 [41984/60000 (70%)]\tLoss: 1.065962\n",
      "Train Epoch: 5 [42112/60000 (70%)]\tLoss: 1.162359\n",
      "Train Epoch: 5 [42240/60000 (71%)]\tLoss: 1.217924\n",
      "Train Epoch: 5 [42368/60000 (71%)]\tLoss: 1.118979\n",
      "Train Epoch: 5 [42496/60000 (71%)]\tLoss: 1.111893\n",
      "Train Epoch: 5 [42624/60000 (71%)]\tLoss: 1.041763\n",
      "Train Epoch: 5 [42752/60000 (71%)]\tLoss: 1.023175\n",
      "Train Epoch: 5 [42880/60000 (72%)]\tLoss: 1.189000\n",
      "Train Epoch: 5 [43008/60000 (72%)]\tLoss: 1.163566\n",
      "Train Epoch: 5 [43136/60000 (72%)]\tLoss: 0.946941\n",
      "Train Epoch: 5 [43264/60000 (72%)]\tLoss: 0.972517\n",
      "Train Epoch: 5 [43392/60000 (72%)]\tLoss: 0.890552\n",
      "Train Epoch: 5 [43520/60000 (73%)]\tLoss: 1.025594\n",
      "Train Epoch: 5 [43648/60000 (73%)]\tLoss: 1.060250\n",
      "Train Epoch: 5 [43776/60000 (73%)]\tLoss: 1.222755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [43904/60000 (73%)]\tLoss: 1.072506\n",
      "Train Epoch: 5 [44032/60000 (74%)]\tLoss: 1.055745\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 1.154040\n",
      "Train Epoch: 5 [44288/60000 (74%)]\tLoss: 0.976083\n",
      "Train Epoch: 5 [44416/60000 (74%)]\tLoss: 0.984970\n",
      "Train Epoch: 5 [44544/60000 (74%)]\tLoss: 0.848503\n",
      "Train Epoch: 5 [44672/60000 (75%)]\tLoss: 1.083702\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 1.236695\n",
      "Train Epoch: 5 [44928/60000 (75%)]\tLoss: 1.340373\n",
      "Train Epoch: 5 [45056/60000 (75%)]\tLoss: 1.195528\n",
      "Train Epoch: 5 [45184/60000 (75%)]\tLoss: 0.997245\n",
      "Train Epoch: 5 [45312/60000 (76%)]\tLoss: 0.928168\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 1.094852\n",
      "Train Epoch: 5 [45568/60000 (76%)]\tLoss: 1.078899\n",
      "Train Epoch: 5 [45696/60000 (76%)]\tLoss: 1.050313\n",
      "Train Epoch: 5 [45824/60000 (76%)]\tLoss: 1.163037\n",
      "Train Epoch: 5 [45952/60000 (77%)]\tLoss: 1.092577\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 1.070331\n",
      "Train Epoch: 5 [46208/60000 (77%)]\tLoss: 1.203439\n",
      "Train Epoch: 5 [46336/60000 (77%)]\tLoss: 1.168298\n",
      "Train Epoch: 5 [46464/60000 (78%)]\tLoss: 0.956103\n",
      "Train Epoch: 5 [46592/60000 (78%)]\tLoss: 0.990431\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.946406\n",
      "Train Epoch: 5 [46848/60000 (78%)]\tLoss: 0.895709\n",
      "Train Epoch: 5 [46976/60000 (78%)]\tLoss: 0.964610\n",
      "Train Epoch: 5 [47104/60000 (79%)]\tLoss: 0.955590\n",
      "Train Epoch: 5 [47232/60000 (79%)]\tLoss: 1.209882\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 1.094056\n",
      "Train Epoch: 5 [47488/60000 (79%)]\tLoss: 1.103013\n",
      "Train Epoch: 5 [47616/60000 (79%)]\tLoss: 1.081194\n",
      "Train Epoch: 5 [47744/60000 (80%)]\tLoss: 0.965395\n",
      "Train Epoch: 5 [47872/60000 (80%)]\tLoss: 1.157126\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 1.013001\n",
      "Train Epoch: 5 [48128/60000 (80%)]\tLoss: 0.767152\n",
      "Train Epoch: 5 [48256/60000 (81%)]\tLoss: 1.025311\n",
      "Train Epoch: 5 [48384/60000 (81%)]\tLoss: 0.931825\n",
      "Train Epoch: 5 [48512/60000 (81%)]\tLoss: 1.041233\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.999643\n",
      "Train Epoch: 5 [48768/60000 (81%)]\tLoss: 0.901754\n",
      "Train Epoch: 5 [48896/60000 (82%)]\tLoss: 1.277790\n",
      "Train Epoch: 5 [49024/60000 (82%)]\tLoss: 1.113611\n",
      "Train Epoch: 5 [49152/60000 (82%)]\tLoss: 1.222819\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.833734\n",
      "Train Epoch: 5 [49408/60000 (82%)]\tLoss: 1.280340\n",
      "Train Epoch: 5 [49536/60000 (83%)]\tLoss: 1.320748\n",
      "Train Epoch: 5 [49664/60000 (83%)]\tLoss: 1.006868\n",
      "Train Epoch: 5 [49792/60000 (83%)]\tLoss: 1.283912\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 1.032589\n",
      "Train Epoch: 5 [50048/60000 (84%)]\tLoss: 1.038743\n",
      "Train Epoch: 5 [50176/60000 (84%)]\tLoss: 0.989453\n",
      "Train Epoch: 5 [50304/60000 (84%)]\tLoss: 1.485005\n",
      "Train Epoch: 5 [50432/60000 (84%)]\tLoss: 0.929825\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 1.069602\n",
      "Train Epoch: 5 [50688/60000 (85%)]\tLoss: 1.098014\n",
      "Train Epoch: 5 [50816/60000 (85%)]\tLoss: 1.065750\n",
      "Train Epoch: 5 [50944/60000 (85%)]\tLoss: 0.849069\n",
      "Train Epoch: 5 [51072/60000 (85%)]\tLoss: 1.062336\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.071014\n",
      "Train Epoch: 5 [51328/60000 (86%)]\tLoss: 0.941309\n",
      "Train Epoch: 5 [51456/60000 (86%)]\tLoss: 0.950522\n",
      "Train Epoch: 5 [51584/60000 (86%)]\tLoss: 0.950978\n",
      "Train Epoch: 5 [51712/60000 (86%)]\tLoss: 0.911967\n",
      "Train Epoch: 5 [51840/60000 (87%)]\tLoss: 0.948699\n",
      "Train Epoch: 5 [51968/60000 (87%)]\tLoss: 1.263668\n",
      "Train Epoch: 5 [52096/60000 (87%)]\tLoss: 1.237539\n",
      "Train Epoch: 5 [52224/60000 (87%)]\tLoss: 1.053506\n",
      "Train Epoch: 5 [52352/60000 (87%)]\tLoss: 0.904632\n",
      "Train Epoch: 5 [52480/60000 (88%)]\tLoss: 0.797782\n",
      "Train Epoch: 5 [52608/60000 (88%)]\tLoss: 1.054524\n",
      "Train Epoch: 5 [52736/60000 (88%)]\tLoss: 1.192141\n",
      "Train Epoch: 5 [52864/60000 (88%)]\tLoss: 1.390653\n",
      "Train Epoch: 5 [52992/60000 (88%)]\tLoss: 1.100996\n",
      "Train Epoch: 5 [53120/60000 (89%)]\tLoss: 1.182482\n",
      "Train Epoch: 5 [53248/60000 (89%)]\tLoss: 0.839182\n",
      "Train Epoch: 5 [53376/60000 (89%)]\tLoss: 1.044431\n",
      "Train Epoch: 5 [53504/60000 (89%)]\tLoss: 1.162570\n",
      "Train Epoch: 5 [53632/60000 (90%)]\tLoss: 1.039104\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 1.070929\n",
      "Train Epoch: 5 [53888/60000 (90%)]\tLoss: 1.158709\n",
      "Train Epoch: 5 [54016/60000 (90%)]\tLoss: 1.098950\n",
      "Train Epoch: 5 [54144/60000 (90%)]\tLoss: 0.990025\n",
      "Train Epoch: 5 [54272/60000 (91%)]\tLoss: 0.961781\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.895380\n",
      "Train Epoch: 5 [54528/60000 (91%)]\tLoss: 0.880877\n",
      "Train Epoch: 5 [54656/60000 (91%)]\tLoss: 0.960048\n",
      "Train Epoch: 5 [54784/60000 (91%)]\tLoss: 1.104861\n",
      "Train Epoch: 5 [54912/60000 (92%)]\tLoss: 1.183660\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.849475\n",
      "Train Epoch: 5 [55168/60000 (92%)]\tLoss: 1.019791\n",
      "Train Epoch: 5 [55296/60000 (92%)]\tLoss: 0.902386\n",
      "Train Epoch: 5 [55424/60000 (93%)]\tLoss: 1.002554\n",
      "Train Epoch: 5 [55552/60000 (93%)]\tLoss: 0.846146\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 1.034772\n",
      "Train Epoch: 5 [55808/60000 (93%)]\tLoss: 0.976120\n",
      "Train Epoch: 5 [55936/60000 (93%)]\tLoss: 0.966535\n",
      "Train Epoch: 5 [56064/60000 (94%)]\tLoss: 0.943675\n",
      "Train Epoch: 5 [56192/60000 (94%)]\tLoss: 1.176341\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 1.006880\n",
      "Train Epoch: 5 [56448/60000 (94%)]\tLoss: 1.099727\n",
      "Train Epoch: 5 [56576/60000 (94%)]\tLoss: 1.090453\n",
      "Train Epoch: 5 [56704/60000 (95%)]\tLoss: 0.780290\n",
      "Train Epoch: 5 [56832/60000 (95%)]\tLoss: 0.858376\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 1.065808\n",
      "Train Epoch: 5 [57088/60000 (95%)]\tLoss: 0.881410\n",
      "Train Epoch: 5 [57216/60000 (96%)]\tLoss: 1.212168\n",
      "Train Epoch: 5 [57344/60000 (96%)]\tLoss: 1.051653\n",
      "Train Epoch: 5 [57472/60000 (96%)]\tLoss: 1.030620\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 1.064705\n",
      "Train Epoch: 5 [57728/60000 (96%)]\tLoss: 1.051187\n",
      "Train Epoch: 5 [57856/60000 (97%)]\tLoss: 0.878733\n",
      "Train Epoch: 5 [57984/60000 (97%)]\tLoss: 0.993441\n",
      "Train Epoch: 5 [58112/60000 (97%)]\tLoss: 0.831344\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.852346\n",
      "Train Epoch: 5 [58368/60000 (97%)]\tLoss: 0.841335\n",
      "Train Epoch: 5 [58496/60000 (98%)]\tLoss: 0.972828\n",
      "Train Epoch: 5 [58624/60000 (98%)]\tLoss: 0.835608\n",
      "Train Epoch: 5 [58752/60000 (98%)]\tLoss: 1.123911\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.768605\n",
      "Train Epoch: 5 [59008/60000 (99%)]\tLoss: 0.886431\n",
      "Train Epoch: 5 [59136/60000 (99%)]\tLoss: 0.913913\n",
      "Train Epoch: 5 [59264/60000 (99%)]\tLoss: 1.115697\n",
      "Train Epoch: 5 [59392/60000 (99%)]\tLoss: 0.824377\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.873733\n",
      "Train Epoch: 5 [59648/60000 (100%)]\tLoss: 1.222244\n",
      "Train Epoch: 5 [59776/60000 (100%)]\tLoss: 0.837197\n",
      "================================================================\n",
      "Training: Average loss: 0.4139, Accuracy: 53796/60000 (90%)\n",
      "Test: Average loss: 0.3961, Accuracy: 8995/10000 (90%)\n",
      "================================================================\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.034526\n",
      "Train Epoch: 6 [128/60000 (0%)]\tLoss: 1.088889\n",
      "Train Epoch: 6 [256/60000 (0%)]\tLoss: 0.889319\n",
      "Train Epoch: 6 [384/60000 (1%)]\tLoss: 1.020967\n",
      "Train Epoch: 6 [512/60000 (1%)]\tLoss: 0.986897\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.960048\n",
      "Train Epoch: 6 [768/60000 (1%)]\tLoss: 1.166026\n",
      "Train Epoch: 6 [896/60000 (1%)]\tLoss: 1.191154\n",
      "Train Epoch: 6 [1024/60000 (2%)]\tLoss: 1.261745\n",
      "Train Epoch: 6 [1152/60000 (2%)]\tLoss: 0.971596\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 1.024533\n",
      "Train Epoch: 6 [1408/60000 (2%)]\tLoss: 1.034922\n",
      "Train Epoch: 6 [1536/60000 (3%)]\tLoss: 1.050035\n",
      "Train Epoch: 6 [1664/60000 (3%)]\tLoss: 0.926686\n",
      "Train Epoch: 6 [1792/60000 (3%)]\tLoss: 1.037295\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 1.005253\n",
      "Train Epoch: 6 [2048/60000 (3%)]\tLoss: 0.971210\n",
      "Train Epoch: 6 [2176/60000 (4%)]\tLoss: 0.886630\n",
      "Train Epoch: 6 [2304/60000 (4%)]\tLoss: 0.964362\n",
      "Train Epoch: 6 [2432/60000 (4%)]\tLoss: 0.966641\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.925981\n",
      "Train Epoch: 6 [2688/60000 (4%)]\tLoss: 0.966385\n",
      "Train Epoch: 6 [2816/60000 (5%)]\tLoss: 0.994440\n",
      "Train Epoch: 6 [2944/60000 (5%)]\tLoss: 1.227557\n",
      "Train Epoch: 6 [3072/60000 (5%)]\tLoss: 0.995194\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 1.043189\n",
      "Train Epoch: 6 [3328/60000 (6%)]\tLoss: 1.085294\n",
      "Train Epoch: 6 [3456/60000 (6%)]\tLoss: 1.160408\n",
      "Train Epoch: 6 [3584/60000 (6%)]\tLoss: 1.070517\n",
      "Train Epoch: 6 [3712/60000 (6%)]\tLoss: 1.011902\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.859489\n",
      "Train Epoch: 6 [3968/60000 (7%)]\tLoss: 0.872212\n",
      "Train Epoch: 6 [4096/60000 (7%)]\tLoss: 1.109244\n",
      "Train Epoch: 6 [4224/60000 (7%)]\tLoss: 1.041474\n",
      "Train Epoch: 6 [4352/60000 (7%)]\tLoss: 1.011105\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.971621\n",
      "Train Epoch: 6 [4608/60000 (8%)]\tLoss: 0.978294\n",
      "Train Epoch: 6 [4736/60000 (8%)]\tLoss: 1.243362\n",
      "Train Epoch: 6 [4864/60000 (8%)]\tLoss: 1.033065\n",
      "Train Epoch: 6 [4992/60000 (8%)]\tLoss: 1.010676\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 1.204983\n",
      "Train Epoch: 6 [5248/60000 (9%)]\tLoss: 1.153621\n",
      "Train Epoch: 6 [5376/60000 (9%)]\tLoss: 0.865053\n",
      "Train Epoch: 6 [5504/60000 (9%)]\tLoss: 1.035933\n",
      "Train Epoch: 6 [5632/60000 (9%)]\tLoss: 0.998295\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 1.072269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [5888/60000 (10%)]\tLoss: 0.972645\n",
      "Train Epoch: 6 [6016/60000 (10%)]\tLoss: 0.708781\n",
      "Train Epoch: 6 [6144/60000 (10%)]\tLoss: 1.200084\n",
      "Train Epoch: 6 [6272/60000 (10%)]\tLoss: 1.017487\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 1.037846\n",
      "Train Epoch: 6 [6528/60000 (11%)]\tLoss: 0.931494\n",
      "Train Epoch: 6 [6656/60000 (11%)]\tLoss: 1.003819\n",
      "Train Epoch: 6 [6784/60000 (11%)]\tLoss: 1.101857\n",
      "Train Epoch: 6 [6912/60000 (12%)]\tLoss: 1.136886\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 1.079861\n",
      "Train Epoch: 6 [7168/60000 (12%)]\tLoss: 1.218195\n",
      "Train Epoch: 6 [7296/60000 (12%)]\tLoss: 1.226914\n",
      "Train Epoch: 6 [7424/60000 (12%)]\tLoss: 0.998770\n",
      "Train Epoch: 6 [7552/60000 (13%)]\tLoss: 1.135073\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 1.013658\n",
      "Train Epoch: 6 [7808/60000 (13%)]\tLoss: 1.143670\n",
      "Train Epoch: 6 [7936/60000 (13%)]\tLoss: 0.993368\n",
      "Train Epoch: 6 [8064/60000 (13%)]\tLoss: 1.096491\n",
      "Train Epoch: 6 [8192/60000 (14%)]\tLoss: 1.140323\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 1.042244\n",
      "Train Epoch: 6 [8448/60000 (14%)]\tLoss: 1.029926\n",
      "Train Epoch: 6 [8576/60000 (14%)]\tLoss: 1.188011\n",
      "Train Epoch: 6 [8704/60000 (15%)]\tLoss: 1.324336\n",
      "Train Epoch: 6 [8832/60000 (15%)]\tLoss: 1.191778\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.822866\n",
      "Train Epoch: 6 [9088/60000 (15%)]\tLoss: 1.018857\n",
      "Train Epoch: 6 [9216/60000 (15%)]\tLoss: 1.062029\n",
      "Train Epoch: 6 [9344/60000 (16%)]\tLoss: 1.034487\n",
      "Train Epoch: 6 [9472/60000 (16%)]\tLoss: 1.027802\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 1.014842\n",
      "Train Epoch: 6 [9728/60000 (16%)]\tLoss: 0.996976\n",
      "Train Epoch: 6 [9856/60000 (16%)]\tLoss: 0.999094\n",
      "Train Epoch: 6 [9984/60000 (17%)]\tLoss: 0.979734\n",
      "Train Epoch: 6 [10112/60000 (17%)]\tLoss: 0.987723\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.946127\n",
      "Train Epoch: 6 [10368/60000 (17%)]\tLoss: 0.755920\n",
      "Train Epoch: 6 [10496/60000 (18%)]\tLoss: 0.983248\n",
      "Train Epoch: 6 [10624/60000 (18%)]\tLoss: 0.915648\n",
      "Train Epoch: 6 [10752/60000 (18%)]\tLoss: 1.002420\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 1.001012\n",
      "Train Epoch: 6 [11008/60000 (18%)]\tLoss: 1.041193\n",
      "Train Epoch: 6 [11136/60000 (19%)]\tLoss: 1.112937\n",
      "Train Epoch: 6 [11264/60000 (19%)]\tLoss: 0.998087\n",
      "Train Epoch: 6 [11392/60000 (19%)]\tLoss: 0.963682\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 1.279490\n",
      "Train Epoch: 6 [11648/60000 (19%)]\tLoss: 1.252548\n",
      "Train Epoch: 6 [11776/60000 (20%)]\tLoss: 1.028804\n",
      "Train Epoch: 6 [11904/60000 (20%)]\tLoss: 1.017182\n",
      "Train Epoch: 6 [12032/60000 (20%)]\tLoss: 1.118139\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 1.027215\n",
      "Train Epoch: 6 [12288/60000 (21%)]\tLoss: 1.153598\n",
      "Train Epoch: 6 [12416/60000 (21%)]\tLoss: 1.138583\n",
      "Train Epoch: 6 [12544/60000 (21%)]\tLoss: 1.131323\n",
      "Train Epoch: 6 [12672/60000 (21%)]\tLoss: 1.076953\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.990827\n",
      "Train Epoch: 6 [12928/60000 (22%)]\tLoss: 1.310923\n",
      "Train Epoch: 6 [13056/60000 (22%)]\tLoss: 1.188515\n",
      "Train Epoch: 6 [13184/60000 (22%)]\tLoss: 0.940631\n",
      "Train Epoch: 6 [13312/60000 (22%)]\tLoss: 0.963715\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.887486\n",
      "Train Epoch: 6 [13568/60000 (23%)]\tLoss: 1.002995\n",
      "Train Epoch: 6 [13696/60000 (23%)]\tLoss: 1.027624\n",
      "Train Epoch: 6 [13824/60000 (23%)]\tLoss: 1.013597\n",
      "Train Epoch: 6 [13952/60000 (23%)]\tLoss: 1.180338\n",
      "Train Epoch: 6 [14080/60000 (24%)]\tLoss: 0.967805\n",
      "Train Epoch: 6 [14208/60000 (24%)]\tLoss: 1.196660\n",
      "Train Epoch: 6 [14336/60000 (24%)]\tLoss: 1.219217\n",
      "Train Epoch: 6 [14464/60000 (24%)]\tLoss: 1.092039\n",
      "Train Epoch: 6 [14592/60000 (24%)]\tLoss: 1.204296\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 1.336667\n",
      "Train Epoch: 6 [14848/60000 (25%)]\tLoss: 1.020802\n",
      "Train Epoch: 6 [14976/60000 (25%)]\tLoss: 0.975879\n",
      "Train Epoch: 6 [15104/60000 (25%)]\tLoss: 1.003477\n",
      "Train Epoch: 6 [15232/60000 (25%)]\tLoss: 0.986594\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 1.063579\n",
      "Train Epoch: 6 [15488/60000 (26%)]\tLoss: 0.944126\n",
      "Train Epoch: 6 [15616/60000 (26%)]\tLoss: 1.014995\n",
      "Train Epoch: 6 [15744/60000 (26%)]\tLoss: 1.174895\n",
      "Train Epoch: 6 [15872/60000 (26%)]\tLoss: 1.198855\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 1.146658\n",
      "Train Epoch: 6 [16128/60000 (27%)]\tLoss: 0.960172\n",
      "Train Epoch: 6 [16256/60000 (27%)]\tLoss: 0.875978\n",
      "Train Epoch: 6 [16384/60000 (27%)]\tLoss: 1.011010\n",
      "Train Epoch: 6 [16512/60000 (28%)]\tLoss: 0.931110\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 1.245107\n",
      "Train Epoch: 6 [16768/60000 (28%)]\tLoss: 1.061851\n",
      "Train Epoch: 6 [16896/60000 (28%)]\tLoss: 1.153667\n",
      "Train Epoch: 6 [17024/60000 (28%)]\tLoss: 1.045235\n",
      "Train Epoch: 6 [17152/60000 (29%)]\tLoss: 1.196580\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.969005\n",
      "Train Epoch: 6 [17408/60000 (29%)]\tLoss: 1.147920\n",
      "Train Epoch: 6 [17536/60000 (29%)]\tLoss: 1.255055\n",
      "Train Epoch: 6 [17664/60000 (29%)]\tLoss: 1.087629\n",
      "Train Epoch: 6 [17792/60000 (30%)]\tLoss: 1.066847\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 1.023646\n",
      "Train Epoch: 6 [18048/60000 (30%)]\tLoss: 0.817626\n",
      "Train Epoch: 6 [18176/60000 (30%)]\tLoss: 0.837244\n",
      "Train Epoch: 6 [18304/60000 (31%)]\tLoss: 1.192219\n",
      "Train Epoch: 6 [18432/60000 (31%)]\tLoss: 0.980852\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 1.034847\n",
      "Train Epoch: 6 [18688/60000 (31%)]\tLoss: 1.012373\n",
      "Train Epoch: 6 [18816/60000 (31%)]\tLoss: 1.024730\n",
      "Train Epoch: 6 [18944/60000 (32%)]\tLoss: 1.029011\n",
      "Train Epoch: 6 [19072/60000 (32%)]\tLoss: 1.204599\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 1.025142\n",
      "Train Epoch: 6 [19328/60000 (32%)]\tLoss: 1.110567\n",
      "Train Epoch: 6 [19456/60000 (32%)]\tLoss: 0.828652\n",
      "Train Epoch: 6 [19584/60000 (33%)]\tLoss: 0.993601\n",
      "Train Epoch: 6 [19712/60000 (33%)]\tLoss: 0.763469\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.998305\n",
      "Train Epoch: 6 [19968/60000 (33%)]\tLoss: 1.104330\n",
      "Train Epoch: 6 [20096/60000 (34%)]\tLoss: 1.168261\n",
      "Train Epoch: 6 [20224/60000 (34%)]\tLoss: 0.978245\n",
      "Train Epoch: 6 [20352/60000 (34%)]\tLoss: 0.839785\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 1.031513\n",
      "Train Epoch: 6 [20608/60000 (34%)]\tLoss: 1.149009\n",
      "Train Epoch: 6 [20736/60000 (35%)]\tLoss: 1.224273\n",
      "Train Epoch: 6 [20864/60000 (35%)]\tLoss: 1.200493\n",
      "Train Epoch: 6 [20992/60000 (35%)]\tLoss: 0.958081\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.917133\n",
      "Train Epoch: 6 [21248/60000 (35%)]\tLoss: 0.851456\n",
      "Train Epoch: 6 [21376/60000 (36%)]\tLoss: 0.992060\n",
      "Train Epoch: 6 [21504/60000 (36%)]\tLoss: 1.028336\n",
      "Train Epoch: 6 [21632/60000 (36%)]\tLoss: 1.067138\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.687595\n",
      "Train Epoch: 6 [21888/60000 (37%)]\tLoss: 0.977078\n",
      "Train Epoch: 6 [22016/60000 (37%)]\tLoss: 1.086793\n",
      "Train Epoch: 6 [22144/60000 (37%)]\tLoss: 1.044931\n",
      "Train Epoch: 6 [22272/60000 (37%)]\tLoss: 0.922978\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 1.080418\n",
      "Train Epoch: 6 [22528/60000 (38%)]\tLoss: 1.181204\n",
      "Train Epoch: 6 [22656/60000 (38%)]\tLoss: 1.028868\n",
      "Train Epoch: 6 [22784/60000 (38%)]\tLoss: 0.871471\n",
      "Train Epoch: 6 [22912/60000 (38%)]\tLoss: 0.890637\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 1.150791\n",
      "Train Epoch: 6 [23168/60000 (39%)]\tLoss: 0.845027\n",
      "Train Epoch: 6 [23296/60000 (39%)]\tLoss: 0.901761\n",
      "Train Epoch: 6 [23424/60000 (39%)]\tLoss: 0.939464\n",
      "Train Epoch: 6 [23552/60000 (39%)]\tLoss: 1.041088\n",
      "Train Epoch: 6 [23680/60000 (40%)]\tLoss: 1.103465\n",
      "Train Epoch: 6 [23808/60000 (40%)]\tLoss: 0.902564\n",
      "Train Epoch: 6 [23936/60000 (40%)]\tLoss: 1.126641\n",
      "Train Epoch: 6 [24064/60000 (40%)]\tLoss: 0.924702\n",
      "Train Epoch: 6 [24192/60000 (40%)]\tLoss: 1.154333\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.798858\n",
      "Train Epoch: 6 [24448/60000 (41%)]\tLoss: 1.157239\n",
      "Train Epoch: 6 [24576/60000 (41%)]\tLoss: 1.133916\n",
      "Train Epoch: 6 [24704/60000 (41%)]\tLoss: 1.210935\n",
      "Train Epoch: 6 [24832/60000 (41%)]\tLoss: 1.147022\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 1.045973\n",
      "Train Epoch: 6 [25088/60000 (42%)]\tLoss: 1.043892\n",
      "Train Epoch: 6 [25216/60000 (42%)]\tLoss: 1.098453\n",
      "Train Epoch: 6 [25344/60000 (42%)]\tLoss: 0.813452\n",
      "Train Epoch: 6 [25472/60000 (43%)]\tLoss: 0.899188\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.050687\n",
      "Train Epoch: 6 [25728/60000 (43%)]\tLoss: 0.950619\n",
      "Train Epoch: 6 [25856/60000 (43%)]\tLoss: 0.928684\n",
      "Train Epoch: 6 [25984/60000 (43%)]\tLoss: 0.807263\n",
      "Train Epoch: 6 [26112/60000 (44%)]\tLoss: 1.089074\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.855518\n",
      "Train Epoch: 6 [26368/60000 (44%)]\tLoss: 1.218809\n",
      "Train Epoch: 6 [26496/60000 (44%)]\tLoss: 1.107062\n",
      "Train Epoch: 6 [26624/60000 (44%)]\tLoss: 1.327919\n",
      "Train Epoch: 6 [26752/60000 (45%)]\tLoss: 1.017424\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 1.024935\n",
      "Train Epoch: 6 [27008/60000 (45%)]\tLoss: 1.032082\n",
      "Train Epoch: 6 [27136/60000 (45%)]\tLoss: 1.402147\n",
      "Train Epoch: 6 [27264/60000 (46%)]\tLoss: 1.099858\n",
      "Train Epoch: 6 [27392/60000 (46%)]\tLoss: 1.029625\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.994374\n",
      "Train Epoch: 6 [27648/60000 (46%)]\tLoss: 1.007388\n",
      "Train Epoch: 6 [27776/60000 (46%)]\tLoss: 0.984887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [27904/60000 (47%)]\tLoss: 0.728790\n",
      "Train Epoch: 6 [28032/60000 (47%)]\tLoss: 0.774599\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.889719\n",
      "Train Epoch: 6 [28288/60000 (47%)]\tLoss: 1.138283\n",
      "Train Epoch: 6 [28416/60000 (47%)]\tLoss: 1.085405\n",
      "Train Epoch: 6 [28544/60000 (48%)]\tLoss: 1.047590\n",
      "Train Epoch: 6 [28672/60000 (48%)]\tLoss: 1.077568\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 1.112333\n",
      "Train Epoch: 6 [28928/60000 (48%)]\tLoss: 1.139118\n",
      "Train Epoch: 6 [29056/60000 (49%)]\tLoss: 1.212244\n",
      "Train Epoch: 6 [29184/60000 (49%)]\tLoss: 1.018209\n",
      "Train Epoch: 6 [29312/60000 (49%)]\tLoss: 0.990133\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.953828\n",
      "Train Epoch: 6 [29568/60000 (49%)]\tLoss: 1.116565\n",
      "Train Epoch: 6 [29696/60000 (50%)]\tLoss: 1.114839\n",
      "Train Epoch: 6 [29824/60000 (50%)]\tLoss: 1.183293\n",
      "Train Epoch: 6 [29952/60000 (50%)]\tLoss: 1.014659\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 1.085425\n",
      "Train Epoch: 6 [30208/60000 (50%)]\tLoss: 1.050519\n",
      "Train Epoch: 6 [30336/60000 (51%)]\tLoss: 0.996686\n",
      "Train Epoch: 6 [30464/60000 (51%)]\tLoss: 0.979700\n",
      "Train Epoch: 6 [30592/60000 (51%)]\tLoss: 1.257883\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.972713\n",
      "Train Epoch: 6 [30848/60000 (51%)]\tLoss: 1.117760\n",
      "Train Epoch: 6 [30976/60000 (52%)]\tLoss: 0.975197\n",
      "Train Epoch: 6 [31104/60000 (52%)]\tLoss: 0.951404\n",
      "Train Epoch: 6 [31232/60000 (52%)]\tLoss: 1.242659\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 1.109632\n",
      "Train Epoch: 6 [31488/60000 (53%)]\tLoss: 1.012249\n",
      "Train Epoch: 6 [31616/60000 (53%)]\tLoss: 1.244506\n",
      "Train Epoch: 6 [31744/60000 (53%)]\tLoss: 0.903129\n",
      "Train Epoch: 6 [31872/60000 (53%)]\tLoss: 0.899647\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.039588\n",
      "Train Epoch: 6 [32128/60000 (54%)]\tLoss: 1.184881\n",
      "Train Epoch: 6 [32256/60000 (54%)]\tLoss: 1.254372\n",
      "Train Epoch: 6 [32384/60000 (54%)]\tLoss: 1.254130\n",
      "Train Epoch: 6 [32512/60000 (54%)]\tLoss: 0.875191\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.860102\n",
      "Train Epoch: 6 [32768/60000 (55%)]\tLoss: 1.110765\n",
      "Train Epoch: 6 [32896/60000 (55%)]\tLoss: 0.952087\n",
      "Train Epoch: 6 [33024/60000 (55%)]\tLoss: 1.122115\n",
      "Train Epoch: 6 [33152/60000 (55%)]\tLoss: 1.016933\n",
      "Train Epoch: 6 [33280/60000 (56%)]\tLoss: 1.049305\n",
      "Train Epoch: 6 [33408/60000 (56%)]\tLoss: 0.916148\n",
      "Train Epoch: 6 [33536/60000 (56%)]\tLoss: 0.861181\n",
      "Train Epoch: 6 [33664/60000 (56%)]\tLoss: 0.945174\n",
      "Train Epoch: 6 [33792/60000 (56%)]\tLoss: 0.807278\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.890820\n",
      "Train Epoch: 6 [34048/60000 (57%)]\tLoss: 0.982874\n",
      "Train Epoch: 6 [34176/60000 (57%)]\tLoss: 0.788431\n",
      "Train Epoch: 6 [34304/60000 (57%)]\tLoss: 0.936259\n",
      "Train Epoch: 6 [34432/60000 (57%)]\tLoss: 0.894703\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.977640\n",
      "Train Epoch: 6 [34688/60000 (58%)]\tLoss: 1.192295\n",
      "Train Epoch: 6 [34816/60000 (58%)]\tLoss: 1.128676\n",
      "Train Epoch: 6 [34944/60000 (58%)]\tLoss: 0.915117\n",
      "Train Epoch: 6 [35072/60000 (59%)]\tLoss: 0.984634\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.903890\n",
      "Train Epoch: 6 [35328/60000 (59%)]\tLoss: 0.899231\n",
      "Train Epoch: 6 [35456/60000 (59%)]\tLoss: 0.860239\n",
      "Train Epoch: 6 [35584/60000 (59%)]\tLoss: 1.074338\n",
      "Train Epoch: 6 [35712/60000 (60%)]\tLoss: 0.945647\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.889321\n",
      "Train Epoch: 6 [35968/60000 (60%)]\tLoss: 0.968361\n",
      "Train Epoch: 6 [36096/60000 (60%)]\tLoss: 1.045155\n",
      "Train Epoch: 6 [36224/60000 (60%)]\tLoss: 0.863000\n",
      "Train Epoch: 6 [36352/60000 (61%)]\tLoss: 1.024811\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 1.080799\n",
      "Train Epoch: 6 [36608/60000 (61%)]\tLoss: 0.765880\n",
      "Train Epoch: 6 [36736/60000 (61%)]\tLoss: 1.086115\n",
      "Train Epoch: 6 [36864/60000 (62%)]\tLoss: 1.016172\n",
      "Train Epoch: 6 [36992/60000 (62%)]\tLoss: 1.014451\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.996785\n",
      "Train Epoch: 6 [37248/60000 (62%)]\tLoss: 1.262830\n",
      "Train Epoch: 6 [37376/60000 (62%)]\tLoss: 1.262631\n",
      "Train Epoch: 6 [37504/60000 (63%)]\tLoss: 1.078420\n",
      "Train Epoch: 6 [37632/60000 (63%)]\tLoss: 0.997617\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 1.052165\n",
      "Train Epoch: 6 [37888/60000 (63%)]\tLoss: 0.868114\n",
      "Train Epoch: 6 [38016/60000 (63%)]\tLoss: 1.005055\n",
      "Train Epoch: 6 [38144/60000 (64%)]\tLoss: 1.039222\n",
      "Train Epoch: 6 [38272/60000 (64%)]\tLoss: 0.924442\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.897789\n",
      "Train Epoch: 6 [38528/60000 (64%)]\tLoss: 1.031489\n",
      "Train Epoch: 6 [38656/60000 (65%)]\tLoss: 1.046235\n",
      "Train Epoch: 6 [38784/60000 (65%)]\tLoss: 0.926295\n",
      "Train Epoch: 6 [38912/60000 (65%)]\tLoss: 1.024241\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.749484\n",
      "Train Epoch: 6 [39168/60000 (65%)]\tLoss: 0.975427\n",
      "Train Epoch: 6 [39296/60000 (66%)]\tLoss: 1.280270\n",
      "Train Epoch: 6 [39424/60000 (66%)]\tLoss: 1.029558\n",
      "Train Epoch: 6 [39552/60000 (66%)]\tLoss: 1.216794\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 1.109821\n",
      "Train Epoch: 6 [39808/60000 (66%)]\tLoss: 1.053915\n",
      "Train Epoch: 6 [39936/60000 (67%)]\tLoss: 0.962537\n",
      "Train Epoch: 6 [40064/60000 (67%)]\tLoss: 0.895157\n",
      "Train Epoch: 6 [40192/60000 (67%)]\tLoss: 1.016948\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.812642\n",
      "Train Epoch: 6 [40448/60000 (68%)]\tLoss: 1.143354\n",
      "Train Epoch: 6 [40576/60000 (68%)]\tLoss: 1.060644\n",
      "Train Epoch: 6 [40704/60000 (68%)]\tLoss: 0.908685\n",
      "Train Epoch: 6 [40832/60000 (68%)]\tLoss: 0.786973\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.995513\n",
      "Train Epoch: 6 [41088/60000 (69%)]\tLoss: 0.910653\n",
      "Train Epoch: 6 [41216/60000 (69%)]\tLoss: 1.141252\n",
      "Train Epoch: 6 [41344/60000 (69%)]\tLoss: 1.188230\n",
      "Train Epoch: 6 [41472/60000 (69%)]\tLoss: 1.064155\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 1.033391\n",
      "Train Epoch: 6 [41728/60000 (70%)]\tLoss: 0.992819\n",
      "Train Epoch: 6 [41856/60000 (70%)]\tLoss: 1.131791\n",
      "Train Epoch: 6 [41984/60000 (70%)]\tLoss: 0.932123\n",
      "Train Epoch: 6 [42112/60000 (70%)]\tLoss: 1.140462\n",
      "Train Epoch: 6 [42240/60000 (71%)]\tLoss: 1.160997\n",
      "Train Epoch: 6 [42368/60000 (71%)]\tLoss: 1.167083\n",
      "Train Epoch: 6 [42496/60000 (71%)]\tLoss: 1.063210\n",
      "Train Epoch: 6 [42624/60000 (71%)]\tLoss: 1.058725\n",
      "Train Epoch: 6 [42752/60000 (71%)]\tLoss: 0.994070\n",
      "Train Epoch: 6 [42880/60000 (72%)]\tLoss: 1.258180\n",
      "Train Epoch: 6 [43008/60000 (72%)]\tLoss: 1.230015\n",
      "Train Epoch: 6 [43136/60000 (72%)]\tLoss: 1.077360\n",
      "Train Epoch: 6 [43264/60000 (72%)]\tLoss: 0.966597\n",
      "Train Epoch: 6 [43392/60000 (72%)]\tLoss: 0.867650\n",
      "Train Epoch: 6 [43520/60000 (73%)]\tLoss: 0.883502\n",
      "Train Epoch: 6 [43648/60000 (73%)]\tLoss: 0.898842\n",
      "Train Epoch: 6 [43776/60000 (73%)]\tLoss: 1.154760\n",
      "Train Epoch: 6 [43904/60000 (73%)]\tLoss: 0.995959\n",
      "Train Epoch: 6 [44032/60000 (74%)]\tLoss: 1.090206\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 1.008197\n",
      "Train Epoch: 6 [44288/60000 (74%)]\tLoss: 1.004191\n",
      "Train Epoch: 6 [44416/60000 (74%)]\tLoss: 0.957112\n",
      "Train Epoch: 6 [44544/60000 (74%)]\tLoss: 0.810964\n",
      "Train Epoch: 6 [44672/60000 (75%)]\tLoss: 0.969476\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 1.165903\n",
      "Train Epoch: 6 [44928/60000 (75%)]\tLoss: 1.164185\n",
      "Train Epoch: 6 [45056/60000 (75%)]\tLoss: 1.099679\n",
      "Train Epoch: 6 [45184/60000 (75%)]\tLoss: 1.064655\n",
      "Train Epoch: 6 [45312/60000 (76%)]\tLoss: 0.939398\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 1.041170\n",
      "Train Epoch: 6 [45568/60000 (76%)]\tLoss: 0.939219\n",
      "Train Epoch: 6 [45696/60000 (76%)]\tLoss: 1.021233\n",
      "Train Epoch: 6 [45824/60000 (76%)]\tLoss: 1.133162\n",
      "Train Epoch: 6 [45952/60000 (77%)]\tLoss: 1.103888\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 1.020165\n",
      "Train Epoch: 6 [46208/60000 (77%)]\tLoss: 1.197769\n",
      "Train Epoch: 6 [46336/60000 (77%)]\tLoss: 1.148131\n",
      "Train Epoch: 6 [46464/60000 (78%)]\tLoss: 0.921640\n",
      "Train Epoch: 6 [46592/60000 (78%)]\tLoss: 0.941936\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 1.059690\n",
      "Train Epoch: 6 [46848/60000 (78%)]\tLoss: 0.835977\n",
      "Train Epoch: 6 [46976/60000 (78%)]\tLoss: 1.040464\n",
      "Train Epoch: 6 [47104/60000 (79%)]\tLoss: 1.008824\n",
      "Train Epoch: 6 [47232/60000 (79%)]\tLoss: 1.226583\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 1.101524\n",
      "Train Epoch: 6 [47488/60000 (79%)]\tLoss: 1.242700\n",
      "Train Epoch: 6 [47616/60000 (79%)]\tLoss: 0.962712\n",
      "Train Epoch: 6 [47744/60000 (80%)]\tLoss: 0.883560\n",
      "Train Epoch: 6 [47872/60000 (80%)]\tLoss: 1.142943\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.850232\n",
      "Train Epoch: 6 [48128/60000 (80%)]\tLoss: 0.765195\n",
      "Train Epoch: 6 [48256/60000 (81%)]\tLoss: 0.952480\n",
      "Train Epoch: 6 [48384/60000 (81%)]\tLoss: 0.836117\n",
      "Train Epoch: 6 [48512/60000 (81%)]\tLoss: 0.837866\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 1.034155\n",
      "Train Epoch: 6 [48768/60000 (81%)]\tLoss: 0.888344\n",
      "Train Epoch: 6 [48896/60000 (82%)]\tLoss: 1.202987\n",
      "Train Epoch: 6 [49024/60000 (82%)]\tLoss: 1.239362\n",
      "Train Epoch: 6 [49152/60000 (82%)]\tLoss: 1.223604\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.964753\n",
      "Train Epoch: 6 [49408/60000 (82%)]\tLoss: 1.135926\n",
      "Train Epoch: 6 [49536/60000 (83%)]\tLoss: 1.234365\n",
      "Train Epoch: 6 [49664/60000 (83%)]\tLoss: 0.871499\n",
      "Train Epoch: 6 [49792/60000 (83%)]\tLoss: 1.027797\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.934383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [50048/60000 (84%)]\tLoss: 0.983054\n",
      "Train Epoch: 6 [50176/60000 (84%)]\tLoss: 1.095457\n",
      "Train Epoch: 6 [50304/60000 (84%)]\tLoss: 1.314433\n",
      "Train Epoch: 6 [50432/60000 (84%)]\tLoss: 0.886040\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.930886\n",
      "Train Epoch: 6 [50688/60000 (85%)]\tLoss: 1.105791\n",
      "Train Epoch: 6 [50816/60000 (85%)]\tLoss: 0.986536\n",
      "Train Epoch: 6 [50944/60000 (85%)]\tLoss: 0.784054\n",
      "Train Epoch: 6 [51072/60000 (85%)]\tLoss: 1.000374\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.966970\n",
      "Train Epoch: 6 [51328/60000 (86%)]\tLoss: 0.865810\n",
      "Train Epoch: 6 [51456/60000 (86%)]\tLoss: 0.820168\n",
      "Train Epoch: 6 [51584/60000 (86%)]\tLoss: 0.828324\n",
      "Train Epoch: 6 [51712/60000 (86%)]\tLoss: 0.976310\n",
      "Train Epoch: 6 [51840/60000 (87%)]\tLoss: 1.023046\n",
      "Train Epoch: 6 [51968/60000 (87%)]\tLoss: 1.014522\n",
      "Train Epoch: 6 [52096/60000 (87%)]\tLoss: 1.170366\n",
      "Train Epoch: 6 [52224/60000 (87%)]\tLoss: 1.030451\n",
      "Train Epoch: 6 [52352/60000 (87%)]\tLoss: 0.836690\n",
      "Train Epoch: 6 [52480/60000 (88%)]\tLoss: 0.840179\n",
      "Train Epoch: 6 [52608/60000 (88%)]\tLoss: 1.127715\n",
      "Train Epoch: 6 [52736/60000 (88%)]\tLoss: 1.096716\n",
      "Train Epoch: 6 [52864/60000 (88%)]\tLoss: 1.369755\n",
      "Train Epoch: 6 [52992/60000 (88%)]\tLoss: 0.996619\n",
      "Train Epoch: 6 [53120/60000 (89%)]\tLoss: 1.169628\n",
      "Train Epoch: 6 [53248/60000 (89%)]\tLoss: 0.709387\n",
      "Train Epoch: 6 [53376/60000 (89%)]\tLoss: 0.947308\n",
      "Train Epoch: 6 [53504/60000 (89%)]\tLoss: 1.073163\n",
      "Train Epoch: 6 [53632/60000 (90%)]\tLoss: 0.908983\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.978208\n",
      "Train Epoch: 6 [53888/60000 (90%)]\tLoss: 1.193748\n",
      "Train Epoch: 6 [54016/60000 (90%)]\tLoss: 1.004493\n",
      "Train Epoch: 6 [54144/60000 (90%)]\tLoss: 0.848612\n",
      "Train Epoch: 6 [54272/60000 (91%)]\tLoss: 0.830752\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.879084\n",
      "Train Epoch: 6 [54528/60000 (91%)]\tLoss: 0.951693\n",
      "Train Epoch: 6 [54656/60000 (91%)]\tLoss: 0.917708\n",
      "Train Epoch: 6 [54784/60000 (91%)]\tLoss: 1.040107\n",
      "Train Epoch: 6 [54912/60000 (92%)]\tLoss: 1.247379\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.970135\n",
      "Train Epoch: 6 [55168/60000 (92%)]\tLoss: 0.865335\n",
      "Train Epoch: 6 [55296/60000 (92%)]\tLoss: 0.761547\n",
      "Train Epoch: 6 [55424/60000 (93%)]\tLoss: 1.058787\n",
      "Train Epoch: 6 [55552/60000 (93%)]\tLoss: 0.840148\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.954252\n",
      "Train Epoch: 6 [55808/60000 (93%)]\tLoss: 0.843467\n",
      "Train Epoch: 6 [55936/60000 (93%)]\tLoss: 0.851870\n",
      "Train Epoch: 6 [56064/60000 (94%)]\tLoss: 1.002393\n",
      "Train Epoch: 6 [56192/60000 (94%)]\tLoss: 0.984445\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.978768\n",
      "Train Epoch: 6 [56448/60000 (94%)]\tLoss: 0.981739\n",
      "Train Epoch: 6 [56576/60000 (94%)]\tLoss: 1.003989\n",
      "Train Epoch: 6 [56704/60000 (95%)]\tLoss: 0.742477\n",
      "Train Epoch: 6 [56832/60000 (95%)]\tLoss: 0.895861\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 1.025313\n",
      "Train Epoch: 6 [57088/60000 (95%)]\tLoss: 0.849026\n",
      "Train Epoch: 6 [57216/60000 (96%)]\tLoss: 1.143026\n",
      "Train Epoch: 6 [57344/60000 (96%)]\tLoss: 0.968628\n",
      "Train Epoch: 6 [57472/60000 (96%)]\tLoss: 0.964251\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.987524\n",
      "Train Epoch: 6 [57728/60000 (96%)]\tLoss: 0.946165\n",
      "Train Epoch: 6 [57856/60000 (97%)]\tLoss: 1.024746\n",
      "Train Epoch: 6 [57984/60000 (97%)]\tLoss: 0.932780\n",
      "Train Epoch: 6 [58112/60000 (97%)]\tLoss: 0.847936\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.756498\n",
      "Train Epoch: 6 [58368/60000 (97%)]\tLoss: 0.874324\n",
      "Train Epoch: 6 [58496/60000 (98%)]\tLoss: 0.797231\n",
      "Train Epoch: 6 [58624/60000 (98%)]\tLoss: 0.757748\n",
      "Train Epoch: 6 [58752/60000 (98%)]\tLoss: 0.886721\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.702406\n",
      "Train Epoch: 6 [59008/60000 (99%)]\tLoss: 0.637884\n",
      "Train Epoch: 6 [59136/60000 (99%)]\tLoss: 0.773062\n",
      "Train Epoch: 6 [59264/60000 (99%)]\tLoss: 1.074669\n",
      "Train Epoch: 6 [59392/60000 (99%)]\tLoss: 0.943660\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.877359\n",
      "Train Epoch: 6 [59648/60000 (100%)]\tLoss: 1.073951\n",
      "Train Epoch: 6 [59776/60000 (100%)]\tLoss: 0.746262\n",
      "================================================================\n",
      "Training: Average loss: 0.3675, Accuracy: 54388/60000 (91%)\n",
      "Test: Average loss: 0.3515, Accuracy: 9106/10000 (91%)\n",
      "================================================================\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.921980\n",
      "Train Epoch: 7 [128/60000 (0%)]\tLoss: 0.960755\n",
      "Train Epoch: 7 [256/60000 (0%)]\tLoss: 0.903713\n",
      "Train Epoch: 7 [384/60000 (1%)]\tLoss: 0.924514\n",
      "Train Epoch: 7 [512/60000 (1%)]\tLoss: 1.141376\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.904348\n",
      "Train Epoch: 7 [768/60000 (1%)]\tLoss: 1.137380\n",
      "Train Epoch: 7 [896/60000 (1%)]\tLoss: 1.058751\n",
      "Train Epoch: 7 [1024/60000 (2%)]\tLoss: 1.078819\n",
      "Train Epoch: 7 [1152/60000 (2%)]\tLoss: 1.056316\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 1.042025\n",
      "Train Epoch: 7 [1408/60000 (2%)]\tLoss: 1.023953\n",
      "Train Epoch: 7 [1536/60000 (3%)]\tLoss: 1.196740\n",
      "Train Epoch: 7 [1664/60000 (3%)]\tLoss: 0.869879\n",
      "Train Epoch: 7 [1792/60000 (3%)]\tLoss: 0.811021\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.919432\n",
      "Train Epoch: 7 [2048/60000 (3%)]\tLoss: 1.037651\n",
      "Train Epoch: 7 [2176/60000 (4%)]\tLoss: 0.901719\n",
      "Train Epoch: 7 [2304/60000 (4%)]\tLoss: 1.042145\n",
      "Train Epoch: 7 [2432/60000 (4%)]\tLoss: 0.820715\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.835380\n",
      "Train Epoch: 7 [2688/60000 (4%)]\tLoss: 0.887329\n",
      "Train Epoch: 7 [2816/60000 (5%)]\tLoss: 0.853863\n",
      "Train Epoch: 7 [2944/60000 (5%)]\tLoss: 1.076568\n",
      "Train Epoch: 7 [3072/60000 (5%)]\tLoss: 1.009976\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.947941\n",
      "Train Epoch: 7 [3328/60000 (6%)]\tLoss: 0.889188\n",
      "Train Epoch: 7 [3456/60000 (6%)]\tLoss: 0.882045\n",
      "Train Epoch: 7 [3584/60000 (6%)]\tLoss: 0.898155\n",
      "Train Epoch: 7 [3712/60000 (6%)]\tLoss: 1.026648\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.733131\n",
      "Train Epoch: 7 [3968/60000 (7%)]\tLoss: 1.027195\n",
      "Train Epoch: 7 [4096/60000 (7%)]\tLoss: 0.996753\n",
      "Train Epoch: 7 [4224/60000 (7%)]\tLoss: 0.937759\n",
      "Train Epoch: 7 [4352/60000 (7%)]\tLoss: 0.922628\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.789840\n",
      "Train Epoch: 7 [4608/60000 (8%)]\tLoss: 0.931512\n",
      "Train Epoch: 7 [4736/60000 (8%)]\tLoss: 1.035416\n",
      "Train Epoch: 7 [4864/60000 (8%)]\tLoss: 1.055680\n",
      "Train Epoch: 7 [4992/60000 (8%)]\tLoss: 1.046222\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 1.073120\n",
      "Train Epoch: 7 [5248/60000 (9%)]\tLoss: 1.059667\n",
      "Train Epoch: 7 [5376/60000 (9%)]\tLoss: 0.688458\n",
      "Train Epoch: 7 [5504/60000 (9%)]\tLoss: 0.961236\n",
      "Train Epoch: 7 [5632/60000 (9%)]\tLoss: 0.992157\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.959847\n",
      "Train Epoch: 7 [5888/60000 (10%)]\tLoss: 0.830497\n",
      "Train Epoch: 7 [6016/60000 (10%)]\tLoss: 0.687819\n",
      "Train Epoch: 7 [6144/60000 (10%)]\tLoss: 0.871156\n",
      "Train Epoch: 7 [6272/60000 (10%)]\tLoss: 0.886459\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 1.098032\n",
      "Train Epoch: 7 [6528/60000 (11%)]\tLoss: 0.917437\n",
      "Train Epoch: 7 [6656/60000 (11%)]\tLoss: 0.930996\n",
      "Train Epoch: 7 [6784/60000 (11%)]\tLoss: 1.000544\n",
      "Train Epoch: 7 [6912/60000 (12%)]\tLoss: 1.216340\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.988174\n",
      "Train Epoch: 7 [7168/60000 (12%)]\tLoss: 1.202736\n",
      "Train Epoch: 7 [7296/60000 (12%)]\tLoss: 0.913050\n",
      "Train Epoch: 7 [7424/60000 (12%)]\tLoss: 0.879784\n",
      "Train Epoch: 7 [7552/60000 (13%)]\tLoss: 0.953853\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 1.013412\n",
      "Train Epoch: 7 [7808/60000 (13%)]\tLoss: 1.187174\n",
      "Train Epoch: 7 [7936/60000 (13%)]\tLoss: 0.845568\n",
      "Train Epoch: 7 [8064/60000 (13%)]\tLoss: 0.940654\n",
      "Train Epoch: 7 [8192/60000 (14%)]\tLoss: 0.993803\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 1.043049\n",
      "Train Epoch: 7 [8448/60000 (14%)]\tLoss: 0.885330\n",
      "Train Epoch: 7 [8576/60000 (14%)]\tLoss: 1.124426\n",
      "Train Epoch: 7 [8704/60000 (15%)]\tLoss: 1.222431\n",
      "Train Epoch: 7 [8832/60000 (15%)]\tLoss: 1.150977\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.844700\n",
      "Train Epoch: 7 [9088/60000 (15%)]\tLoss: 0.919349\n",
      "Train Epoch: 7 [9216/60000 (15%)]\tLoss: 0.909548\n",
      "Train Epoch: 7 [9344/60000 (16%)]\tLoss: 0.915529\n",
      "Train Epoch: 7 [9472/60000 (16%)]\tLoss: 0.943758\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 1.007328\n",
      "Train Epoch: 7 [9728/60000 (16%)]\tLoss: 0.998465\n",
      "Train Epoch: 7 [9856/60000 (16%)]\tLoss: 0.807167\n",
      "Train Epoch: 7 [9984/60000 (17%)]\tLoss: 1.030530\n",
      "Train Epoch: 7 [10112/60000 (17%)]\tLoss: 0.944258\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.966598\n",
      "Train Epoch: 7 [10368/60000 (17%)]\tLoss: 0.710347\n",
      "Train Epoch: 7 [10496/60000 (18%)]\tLoss: 0.802277\n",
      "Train Epoch: 7 [10624/60000 (18%)]\tLoss: 1.002629\n",
      "Train Epoch: 7 [10752/60000 (18%)]\tLoss: 0.943673\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.861138\n",
      "Train Epoch: 7 [11008/60000 (18%)]\tLoss: 0.863027\n",
      "Train Epoch: 7 [11136/60000 (19%)]\tLoss: 1.046847\n",
      "Train Epoch: 7 [11264/60000 (19%)]\tLoss: 0.965149\n",
      "Train Epoch: 7 [11392/60000 (19%)]\tLoss: 0.987093\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 1.208864\n",
      "Train Epoch: 7 [11648/60000 (19%)]\tLoss: 1.165184\n",
      "Train Epoch: 7 [11776/60000 (20%)]\tLoss: 0.927249\n",
      "Train Epoch: 7 [11904/60000 (20%)]\tLoss: 0.957797\n",
      "Train Epoch: 7 [12032/60000 (20%)]\tLoss: 1.033560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 1.056501\n",
      "Train Epoch: 7 [12288/60000 (21%)]\tLoss: 0.935750\n",
      "Train Epoch: 7 [12416/60000 (21%)]\tLoss: 1.026054\n",
      "Train Epoch: 7 [12544/60000 (21%)]\tLoss: 1.049823\n",
      "Train Epoch: 7 [12672/60000 (21%)]\tLoss: 1.035064\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.954225\n",
      "Train Epoch: 7 [12928/60000 (22%)]\tLoss: 1.285213\n",
      "Train Epoch: 7 [13056/60000 (22%)]\tLoss: 1.251214\n",
      "Train Epoch: 7 [13184/60000 (22%)]\tLoss: 0.831344\n",
      "Train Epoch: 7 [13312/60000 (22%)]\tLoss: 0.942763\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.877714\n",
      "Train Epoch: 7 [13568/60000 (23%)]\tLoss: 0.963017\n",
      "Train Epoch: 7 [13696/60000 (23%)]\tLoss: 1.058520\n",
      "Train Epoch: 7 [13824/60000 (23%)]\tLoss: 0.973518\n",
      "Train Epoch: 7 [13952/60000 (23%)]\tLoss: 1.149018\n",
      "Train Epoch: 7 [14080/60000 (24%)]\tLoss: 0.995420\n",
      "Train Epoch: 7 [14208/60000 (24%)]\tLoss: 1.222093\n",
      "Train Epoch: 7 [14336/60000 (24%)]\tLoss: 1.103558\n",
      "Train Epoch: 7 [14464/60000 (24%)]\tLoss: 0.958845\n",
      "Train Epoch: 7 [14592/60000 (24%)]\tLoss: 1.237271\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 1.206753\n",
      "Train Epoch: 7 [14848/60000 (25%)]\tLoss: 1.014320\n",
      "Train Epoch: 7 [14976/60000 (25%)]\tLoss: 0.804867\n",
      "Train Epoch: 7 [15104/60000 (25%)]\tLoss: 0.901524\n",
      "Train Epoch: 7 [15232/60000 (25%)]\tLoss: 0.894434\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.908225\n",
      "Train Epoch: 7 [15488/60000 (26%)]\tLoss: 0.888981\n",
      "Train Epoch: 7 [15616/60000 (26%)]\tLoss: 0.989008\n",
      "Train Epoch: 7 [15744/60000 (26%)]\tLoss: 1.281177\n",
      "Train Epoch: 7 [15872/60000 (26%)]\tLoss: 1.130983\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 1.103312\n",
      "Train Epoch: 7 [16128/60000 (27%)]\tLoss: 0.985270\n",
      "Train Epoch: 7 [16256/60000 (27%)]\tLoss: 0.866080\n",
      "Train Epoch: 7 [16384/60000 (27%)]\tLoss: 0.813396\n",
      "Train Epoch: 7 [16512/60000 (28%)]\tLoss: 0.864126\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 1.155083\n",
      "Train Epoch: 7 [16768/60000 (28%)]\tLoss: 1.113117\n",
      "Train Epoch: 7 [16896/60000 (28%)]\tLoss: 1.164649\n",
      "Train Epoch: 7 [17024/60000 (28%)]\tLoss: 0.989146\n",
      "Train Epoch: 7 [17152/60000 (29%)]\tLoss: 0.992423\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.937885\n",
      "Train Epoch: 7 [17408/60000 (29%)]\tLoss: 0.979570\n",
      "Train Epoch: 7 [17536/60000 (29%)]\tLoss: 1.036290\n",
      "Train Epoch: 7 [17664/60000 (29%)]\tLoss: 1.017180\n",
      "Train Epoch: 7 [17792/60000 (30%)]\tLoss: 1.063714\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.891597\n",
      "Train Epoch: 7 [18048/60000 (30%)]\tLoss: 0.853585\n",
      "Train Epoch: 7 [18176/60000 (30%)]\tLoss: 0.763163\n",
      "Train Epoch: 7 [18304/60000 (31%)]\tLoss: 0.860114\n",
      "Train Epoch: 7 [18432/60000 (31%)]\tLoss: 1.028687\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 1.017416\n",
      "Train Epoch: 7 [18688/60000 (31%)]\tLoss: 0.992692\n",
      "Train Epoch: 7 [18816/60000 (31%)]\tLoss: 0.838726\n",
      "Train Epoch: 7 [18944/60000 (32%)]\tLoss: 1.095593\n",
      "Train Epoch: 7 [19072/60000 (32%)]\tLoss: 1.186246\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.944100\n",
      "Train Epoch: 7 [19328/60000 (32%)]\tLoss: 1.004177\n",
      "Train Epoch: 7 [19456/60000 (32%)]\tLoss: 0.877158\n",
      "Train Epoch: 7 [19584/60000 (33%)]\tLoss: 0.865915\n",
      "Train Epoch: 7 [19712/60000 (33%)]\tLoss: 0.814770\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.920538\n",
      "Train Epoch: 7 [19968/60000 (33%)]\tLoss: 1.072144\n",
      "Train Epoch: 7 [20096/60000 (34%)]\tLoss: 0.992792\n",
      "Train Epoch: 7 [20224/60000 (34%)]\tLoss: 0.926880\n",
      "Train Epoch: 7 [20352/60000 (34%)]\tLoss: 0.822535\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.946916\n",
      "Train Epoch: 7 [20608/60000 (34%)]\tLoss: 0.962376\n",
      "Train Epoch: 7 [20736/60000 (35%)]\tLoss: 1.045232\n",
      "Train Epoch: 7 [20864/60000 (35%)]\tLoss: 1.204941\n",
      "Train Epoch: 7 [20992/60000 (35%)]\tLoss: 0.918801\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.877576\n",
      "Train Epoch: 7 [21248/60000 (35%)]\tLoss: 0.800216\n",
      "Train Epoch: 7 [21376/60000 (36%)]\tLoss: 0.862482\n",
      "Train Epoch: 7 [21504/60000 (36%)]\tLoss: 1.007920\n",
      "Train Epoch: 7 [21632/60000 (36%)]\tLoss: 0.846390\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.693374\n",
      "Train Epoch: 7 [21888/60000 (37%)]\tLoss: 0.836015\n",
      "Train Epoch: 7 [22016/60000 (37%)]\tLoss: 0.985575\n",
      "Train Epoch: 7 [22144/60000 (37%)]\tLoss: 1.098167\n",
      "Train Epoch: 7 [22272/60000 (37%)]\tLoss: 0.871332\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 1.066318\n",
      "Train Epoch: 7 [22528/60000 (38%)]\tLoss: 1.173332\n",
      "Train Epoch: 7 [22656/60000 (38%)]\tLoss: 0.915963\n",
      "Train Epoch: 7 [22784/60000 (38%)]\tLoss: 0.940310\n",
      "Train Epoch: 7 [22912/60000 (38%)]\tLoss: 0.900714\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.993414\n",
      "Train Epoch: 7 [23168/60000 (39%)]\tLoss: 0.900100\n",
      "Train Epoch: 7 [23296/60000 (39%)]\tLoss: 0.801931\n",
      "Train Epoch: 7 [23424/60000 (39%)]\tLoss: 0.786481\n",
      "Train Epoch: 7 [23552/60000 (39%)]\tLoss: 0.969652\n",
      "Train Epoch: 7 [23680/60000 (40%)]\tLoss: 0.989978\n",
      "Train Epoch: 7 [23808/60000 (40%)]\tLoss: 1.049358\n",
      "Train Epoch: 7 [23936/60000 (40%)]\tLoss: 1.010543\n",
      "Train Epoch: 7 [24064/60000 (40%)]\tLoss: 0.861567\n",
      "Train Epoch: 7 [24192/60000 (40%)]\tLoss: 1.107427\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.852704\n",
      "Train Epoch: 7 [24448/60000 (41%)]\tLoss: 1.087890\n",
      "Train Epoch: 7 [24576/60000 (41%)]\tLoss: 1.006818\n",
      "Train Epoch: 7 [24704/60000 (41%)]\tLoss: 1.214661\n",
      "Train Epoch: 7 [24832/60000 (41%)]\tLoss: 1.045157\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.828763\n",
      "Train Epoch: 7 [25088/60000 (42%)]\tLoss: 0.940055\n",
      "Train Epoch: 7 [25216/60000 (42%)]\tLoss: 0.855016\n",
      "Train Epoch: 7 [25344/60000 (42%)]\tLoss: 0.653442\n",
      "Train Epoch: 7 [25472/60000 (43%)]\tLoss: 0.907031\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.010386\n",
      "Train Epoch: 7 [25728/60000 (43%)]\tLoss: 0.927486\n",
      "Train Epoch: 7 [25856/60000 (43%)]\tLoss: 0.894475\n",
      "Train Epoch: 7 [25984/60000 (43%)]\tLoss: 0.794217\n",
      "Train Epoch: 7 [26112/60000 (44%)]\tLoss: 0.866086\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.917516\n",
      "Train Epoch: 7 [26368/60000 (44%)]\tLoss: 1.107499\n",
      "Train Epoch: 7 [26496/60000 (44%)]\tLoss: 0.943126\n",
      "Train Epoch: 7 [26624/60000 (44%)]\tLoss: 1.124574\n",
      "Train Epoch: 7 [26752/60000 (45%)]\tLoss: 0.910066\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.841725\n",
      "Train Epoch: 7 [27008/60000 (45%)]\tLoss: 0.958641\n",
      "Train Epoch: 7 [27136/60000 (45%)]\tLoss: 1.194939\n",
      "Train Epoch: 7 [27264/60000 (46%)]\tLoss: 0.953442\n",
      "Train Epoch: 7 [27392/60000 (46%)]\tLoss: 0.951890\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.802998\n",
      "Train Epoch: 7 [27648/60000 (46%)]\tLoss: 0.991184\n",
      "Train Epoch: 7 [27776/60000 (46%)]\tLoss: 0.927739\n",
      "Train Epoch: 7 [27904/60000 (47%)]\tLoss: 0.744852\n",
      "Train Epoch: 7 [28032/60000 (47%)]\tLoss: 0.802777\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.816186\n",
      "Train Epoch: 7 [28288/60000 (47%)]\tLoss: 1.082414\n",
      "Train Epoch: 7 [28416/60000 (47%)]\tLoss: 1.042095\n",
      "Train Epoch: 7 [28544/60000 (48%)]\tLoss: 1.063025\n",
      "Train Epoch: 7 [28672/60000 (48%)]\tLoss: 1.024850\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.728630\n",
      "Train Epoch: 7 [28928/60000 (48%)]\tLoss: 0.929723\n",
      "Train Epoch: 7 [29056/60000 (49%)]\tLoss: 1.282247\n",
      "Train Epoch: 7 [29184/60000 (49%)]\tLoss: 0.953920\n",
      "Train Epoch: 7 [29312/60000 (49%)]\tLoss: 1.028679\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.910562\n",
      "Train Epoch: 7 [29568/60000 (49%)]\tLoss: 0.946599\n",
      "Train Epoch: 7 [29696/60000 (50%)]\tLoss: 1.136912\n",
      "Train Epoch: 7 [29824/60000 (50%)]\tLoss: 1.306603\n",
      "Train Epoch: 7 [29952/60000 (50%)]\tLoss: 1.114249\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 1.104185\n",
      "Train Epoch: 7 [30208/60000 (50%)]\tLoss: 0.920057\n",
      "Train Epoch: 7 [30336/60000 (51%)]\tLoss: 0.977247\n",
      "Train Epoch: 7 [30464/60000 (51%)]\tLoss: 1.011721\n",
      "Train Epoch: 7 [30592/60000 (51%)]\tLoss: 1.154374\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.921866\n",
      "Train Epoch: 7 [30848/60000 (51%)]\tLoss: 1.073782\n",
      "Train Epoch: 7 [30976/60000 (52%)]\tLoss: 0.900189\n",
      "Train Epoch: 7 [31104/60000 (52%)]\tLoss: 0.928843\n",
      "Train Epoch: 7 [31232/60000 (52%)]\tLoss: 1.085180\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.992825\n",
      "Train Epoch: 7 [31488/60000 (53%)]\tLoss: 1.066327\n",
      "Train Epoch: 7 [31616/60000 (53%)]\tLoss: 1.181426\n",
      "Train Epoch: 7 [31744/60000 (53%)]\tLoss: 0.947055\n",
      "Train Epoch: 7 [31872/60000 (53%)]\tLoss: 0.808509\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.007682\n",
      "Train Epoch: 7 [32128/60000 (54%)]\tLoss: 1.119666\n",
      "Train Epoch: 7 [32256/60000 (54%)]\tLoss: 1.042862\n",
      "Train Epoch: 7 [32384/60000 (54%)]\tLoss: 1.246003\n",
      "Train Epoch: 7 [32512/60000 (54%)]\tLoss: 1.023354\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.924199\n",
      "Train Epoch: 7 [32768/60000 (55%)]\tLoss: 1.060937\n",
      "Train Epoch: 7 [32896/60000 (55%)]\tLoss: 0.900087\n",
      "Train Epoch: 7 [33024/60000 (55%)]\tLoss: 0.942932\n",
      "Train Epoch: 7 [33152/60000 (55%)]\tLoss: 0.873568\n",
      "Train Epoch: 7 [33280/60000 (56%)]\tLoss: 0.946082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [33408/60000 (56%)]\tLoss: 0.881964\n",
      "Train Epoch: 7 [33536/60000 (56%)]\tLoss: 0.979513\n",
      "Train Epoch: 7 [33664/60000 (56%)]\tLoss: 0.907996\n",
      "Train Epoch: 7 [33792/60000 (56%)]\tLoss: 0.814556\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.856154\n",
      "Train Epoch: 7 [34048/60000 (57%)]\tLoss: 0.928254\n",
      "Train Epoch: 7 [34176/60000 (57%)]\tLoss: 0.895606\n",
      "Train Epoch: 7 [34304/60000 (57%)]\tLoss: 0.966213\n",
      "Train Epoch: 7 [34432/60000 (57%)]\tLoss: 0.973540\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.945185\n",
      "Train Epoch: 7 [34688/60000 (58%)]\tLoss: 1.186849\n",
      "Train Epoch: 7 [34816/60000 (58%)]\tLoss: 1.124424\n",
      "Train Epoch: 7 [34944/60000 (58%)]\tLoss: 0.847198\n",
      "Train Epoch: 7 [35072/60000 (59%)]\tLoss: 0.963100\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.919775\n",
      "Train Epoch: 7 [35328/60000 (59%)]\tLoss: 0.746177\n",
      "Train Epoch: 7 [35456/60000 (59%)]\tLoss: 0.920852\n",
      "Train Epoch: 7 [35584/60000 (59%)]\tLoss: 1.063922\n",
      "Train Epoch: 7 [35712/60000 (60%)]\tLoss: 0.730636\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 1.025966\n",
      "Train Epoch: 7 [35968/60000 (60%)]\tLoss: 0.999760\n",
      "Train Epoch: 7 [36096/60000 (60%)]\tLoss: 0.995362\n",
      "Train Epoch: 7 [36224/60000 (60%)]\tLoss: 0.944947\n",
      "Train Epoch: 7 [36352/60000 (61%)]\tLoss: 0.926147\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.881604\n",
      "Train Epoch: 7 [36608/60000 (61%)]\tLoss: 0.809064\n",
      "Train Epoch: 7 [36736/60000 (61%)]\tLoss: 1.008262\n",
      "Train Epoch: 7 [36864/60000 (62%)]\tLoss: 0.806374\n",
      "Train Epoch: 7 [36992/60000 (62%)]\tLoss: 1.107593\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.949055\n",
      "Train Epoch: 7 [37248/60000 (62%)]\tLoss: 1.108074\n",
      "Train Epoch: 7 [37376/60000 (62%)]\tLoss: 1.225932\n",
      "Train Epoch: 7 [37504/60000 (63%)]\tLoss: 1.037582\n",
      "Train Epoch: 7 [37632/60000 (63%)]\tLoss: 0.900252\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.853058\n",
      "Train Epoch: 7 [37888/60000 (63%)]\tLoss: 0.898975\n",
      "Train Epoch: 7 [38016/60000 (63%)]\tLoss: 0.878077\n",
      "Train Epoch: 7 [38144/60000 (64%)]\tLoss: 0.973345\n",
      "Train Epoch: 7 [38272/60000 (64%)]\tLoss: 1.038998\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.761435\n",
      "Train Epoch: 7 [38528/60000 (64%)]\tLoss: 0.948992\n",
      "Train Epoch: 7 [38656/60000 (65%)]\tLoss: 0.905038\n",
      "Train Epoch: 7 [38784/60000 (65%)]\tLoss: 0.840354\n",
      "Train Epoch: 7 [38912/60000 (65%)]\tLoss: 0.794670\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.781456\n",
      "Train Epoch: 7 [39168/60000 (65%)]\tLoss: 0.935726\n",
      "Train Epoch: 7 [39296/60000 (66%)]\tLoss: 1.116460\n",
      "Train Epoch: 7 [39424/60000 (66%)]\tLoss: 1.100562\n",
      "Train Epoch: 7 [39552/60000 (66%)]\tLoss: 0.938717\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.984732\n",
      "Train Epoch: 7 [39808/60000 (66%)]\tLoss: 1.042995\n",
      "Train Epoch: 7 [39936/60000 (67%)]\tLoss: 0.942338\n",
      "Train Epoch: 7 [40064/60000 (67%)]\tLoss: 0.847255\n",
      "Train Epoch: 7 [40192/60000 (67%)]\tLoss: 1.096035\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.861295\n",
      "Train Epoch: 7 [40448/60000 (68%)]\tLoss: 1.086549\n",
      "Train Epoch: 7 [40576/60000 (68%)]\tLoss: 1.095790\n",
      "Train Epoch: 7 [40704/60000 (68%)]\tLoss: 0.915434\n",
      "Train Epoch: 7 [40832/60000 (68%)]\tLoss: 0.778354\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 1.051608\n",
      "Train Epoch: 7 [41088/60000 (69%)]\tLoss: 0.904004\n",
      "Train Epoch: 7 [41216/60000 (69%)]\tLoss: 1.006706\n",
      "Train Epoch: 7 [41344/60000 (69%)]\tLoss: 1.047650\n",
      "Train Epoch: 7 [41472/60000 (69%)]\tLoss: 1.085628\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.878123\n",
      "Train Epoch: 7 [41728/60000 (70%)]\tLoss: 0.902829\n",
      "Train Epoch: 7 [41856/60000 (70%)]\tLoss: 1.014476\n",
      "Train Epoch: 7 [41984/60000 (70%)]\tLoss: 0.834155\n",
      "Train Epoch: 7 [42112/60000 (70%)]\tLoss: 1.055998\n",
      "Train Epoch: 7 [42240/60000 (71%)]\tLoss: 1.096023\n",
      "Train Epoch: 7 [42368/60000 (71%)]\tLoss: 1.053486\n",
      "Train Epoch: 7 [42496/60000 (71%)]\tLoss: 0.924913\n",
      "Train Epoch: 7 [42624/60000 (71%)]\tLoss: 0.922086\n",
      "Train Epoch: 7 [42752/60000 (71%)]\tLoss: 0.897045\n",
      "Train Epoch: 7 [42880/60000 (72%)]\tLoss: 1.092618\n",
      "Train Epoch: 7 [43008/60000 (72%)]\tLoss: 1.140830\n",
      "Train Epoch: 7 [43136/60000 (72%)]\tLoss: 0.853133\n",
      "Train Epoch: 7 [43264/60000 (72%)]\tLoss: 0.669440\n",
      "Train Epoch: 7 [43392/60000 (72%)]\tLoss: 0.797519\n",
      "Train Epoch: 7 [43520/60000 (73%)]\tLoss: 0.774779\n",
      "Train Epoch: 7 [43648/60000 (73%)]\tLoss: 0.855460\n",
      "Train Epoch: 7 [43776/60000 (73%)]\tLoss: 1.180072\n",
      "Train Epoch: 7 [43904/60000 (73%)]\tLoss: 1.046652\n",
      "Train Epoch: 7 [44032/60000 (74%)]\tLoss: 1.026745\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 1.069247\n",
      "Train Epoch: 7 [44288/60000 (74%)]\tLoss: 0.977688\n",
      "Train Epoch: 7 [44416/60000 (74%)]\tLoss: 0.874555\n",
      "Train Epoch: 7 [44544/60000 (74%)]\tLoss: 0.760169\n",
      "Train Epoch: 7 [44672/60000 (75%)]\tLoss: 0.795715\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 1.122293\n",
      "Train Epoch: 7 [44928/60000 (75%)]\tLoss: 1.111295\n",
      "Train Epoch: 7 [45056/60000 (75%)]\tLoss: 0.967084\n",
      "Train Epoch: 7 [45184/60000 (75%)]\tLoss: 0.849958\n",
      "Train Epoch: 7 [45312/60000 (76%)]\tLoss: 0.729427\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 1.080474\n",
      "Train Epoch: 7 [45568/60000 (76%)]\tLoss: 0.928369\n",
      "Train Epoch: 7 [45696/60000 (76%)]\tLoss: 1.019439\n",
      "Train Epoch: 7 [45824/60000 (76%)]\tLoss: 0.956119\n",
      "Train Epoch: 7 [45952/60000 (77%)]\tLoss: 0.973883\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.991613\n",
      "Train Epoch: 7 [46208/60000 (77%)]\tLoss: 0.997131\n",
      "Train Epoch: 7 [46336/60000 (77%)]\tLoss: 1.121359\n",
      "Train Epoch: 7 [46464/60000 (78%)]\tLoss: 0.778026\n",
      "Train Epoch: 7 [46592/60000 (78%)]\tLoss: 0.878507\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.826797\n",
      "Train Epoch: 7 [46848/60000 (78%)]\tLoss: 0.815950\n",
      "Train Epoch: 7 [46976/60000 (78%)]\tLoss: 0.913899\n",
      "Train Epoch: 7 [47104/60000 (79%)]\tLoss: 0.791919\n",
      "Train Epoch: 7 [47232/60000 (79%)]\tLoss: 1.092698\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 1.077237\n",
      "Train Epoch: 7 [47488/60000 (79%)]\tLoss: 0.955795\n",
      "Train Epoch: 7 [47616/60000 (79%)]\tLoss: 1.001164\n",
      "Train Epoch: 7 [47744/60000 (80%)]\tLoss: 0.981065\n",
      "Train Epoch: 7 [47872/60000 (80%)]\tLoss: 1.088556\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.803017\n",
      "Train Epoch: 7 [48128/60000 (80%)]\tLoss: 0.712451\n",
      "Train Epoch: 7 [48256/60000 (81%)]\tLoss: 0.846394\n",
      "Train Epoch: 7 [48384/60000 (81%)]\tLoss: 0.787090\n",
      "Train Epoch: 7 [48512/60000 (81%)]\tLoss: 0.994479\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.815477\n",
      "Train Epoch: 7 [48768/60000 (81%)]\tLoss: 0.910503\n",
      "Train Epoch: 7 [48896/60000 (82%)]\tLoss: 1.282704\n",
      "Train Epoch: 7 [49024/60000 (82%)]\tLoss: 1.090586\n",
      "Train Epoch: 7 [49152/60000 (82%)]\tLoss: 1.062827\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.723087\n",
      "Train Epoch: 7 [49408/60000 (82%)]\tLoss: 1.142494\n",
      "Train Epoch: 7 [49536/60000 (83%)]\tLoss: 1.161418\n",
      "Train Epoch: 7 [49664/60000 (83%)]\tLoss: 0.997209\n",
      "Train Epoch: 7 [49792/60000 (83%)]\tLoss: 1.143395\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.998379\n",
      "Train Epoch: 7 [50048/60000 (84%)]\tLoss: 0.902608\n",
      "Train Epoch: 7 [50176/60000 (84%)]\tLoss: 1.012010\n",
      "Train Epoch: 7 [50304/60000 (84%)]\tLoss: 1.323143\n",
      "Train Epoch: 7 [50432/60000 (84%)]\tLoss: 0.898240\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 1.061693\n",
      "Train Epoch: 7 [50688/60000 (85%)]\tLoss: 0.998984\n",
      "Train Epoch: 7 [50816/60000 (85%)]\tLoss: 0.997358\n",
      "Train Epoch: 7 [50944/60000 (85%)]\tLoss: 0.767483\n",
      "Train Epoch: 7 [51072/60000 (85%)]\tLoss: 0.885424\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 1.042717\n",
      "Train Epoch: 7 [51328/60000 (86%)]\tLoss: 0.865943\n",
      "Train Epoch: 7 [51456/60000 (86%)]\tLoss: 0.849750\n",
      "Train Epoch: 7 [51584/60000 (86%)]\tLoss: 0.722475\n",
      "Train Epoch: 7 [51712/60000 (86%)]\tLoss: 0.846438\n",
      "Train Epoch: 7 [51840/60000 (87%)]\tLoss: 0.888525\n",
      "Train Epoch: 7 [51968/60000 (87%)]\tLoss: 1.127648\n",
      "Train Epoch: 7 [52096/60000 (87%)]\tLoss: 1.114838\n",
      "Train Epoch: 7 [52224/60000 (87%)]\tLoss: 0.943710\n",
      "Train Epoch: 7 [52352/60000 (87%)]\tLoss: 0.786956\n",
      "Train Epoch: 7 [52480/60000 (88%)]\tLoss: 0.605879\n",
      "Train Epoch: 7 [52608/60000 (88%)]\tLoss: 0.995631\n",
      "Train Epoch: 7 [52736/60000 (88%)]\tLoss: 1.079890\n",
      "Train Epoch: 7 [52864/60000 (88%)]\tLoss: 1.286534\n",
      "Train Epoch: 7 [52992/60000 (88%)]\tLoss: 0.931733\n",
      "Train Epoch: 7 [53120/60000 (89%)]\tLoss: 0.899984\n",
      "Train Epoch: 7 [53248/60000 (89%)]\tLoss: 0.709960\n",
      "Train Epoch: 7 [53376/60000 (89%)]\tLoss: 0.840760\n",
      "Train Epoch: 7 [53504/60000 (89%)]\tLoss: 1.017825\n",
      "Train Epoch: 7 [53632/60000 (90%)]\tLoss: 0.963825\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.815687\n",
      "Train Epoch: 7 [53888/60000 (90%)]\tLoss: 1.062171\n",
      "Train Epoch: 7 [54016/60000 (90%)]\tLoss: 0.889929\n",
      "Train Epoch: 7 [54144/60000 (90%)]\tLoss: 0.800088\n",
      "Train Epoch: 7 [54272/60000 (91%)]\tLoss: 0.823292\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.745844\n",
      "Train Epoch: 7 [54528/60000 (91%)]\tLoss: 1.069304\n",
      "Train Epoch: 7 [54656/60000 (91%)]\tLoss: 0.818927\n",
      "Train Epoch: 7 [54784/60000 (91%)]\tLoss: 0.912919\n",
      "Train Epoch: 7 [54912/60000 (92%)]\tLoss: 0.998713\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.817362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [55168/60000 (92%)]\tLoss: 0.889496\n",
      "Train Epoch: 7 [55296/60000 (92%)]\tLoss: 0.736112\n",
      "Train Epoch: 7 [55424/60000 (93%)]\tLoss: 0.807903\n",
      "Train Epoch: 7 [55552/60000 (93%)]\tLoss: 0.765822\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.910263\n",
      "Train Epoch: 7 [55808/60000 (93%)]\tLoss: 0.809923\n",
      "Train Epoch: 7 [55936/60000 (93%)]\tLoss: 0.767853\n",
      "Train Epoch: 7 [56064/60000 (94%)]\tLoss: 0.789289\n",
      "Train Epoch: 7 [56192/60000 (94%)]\tLoss: 1.009079\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.838690\n",
      "Train Epoch: 7 [56448/60000 (94%)]\tLoss: 0.899032\n",
      "Train Epoch: 7 [56576/60000 (94%)]\tLoss: 0.871050\n",
      "Train Epoch: 7 [56704/60000 (95%)]\tLoss: 0.713182\n",
      "Train Epoch: 7 [56832/60000 (95%)]\tLoss: 0.866816\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.919812\n",
      "Train Epoch: 7 [57088/60000 (95%)]\tLoss: 0.801498\n",
      "Train Epoch: 7 [57216/60000 (96%)]\tLoss: 1.078270\n",
      "Train Epoch: 7 [57344/60000 (96%)]\tLoss: 0.890282\n",
      "Train Epoch: 7 [57472/60000 (96%)]\tLoss: 1.000520\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 1.033701\n",
      "Train Epoch: 7 [57728/60000 (96%)]\tLoss: 1.006590\n",
      "Train Epoch: 7 [57856/60000 (97%)]\tLoss: 0.813463\n",
      "Train Epoch: 7 [57984/60000 (97%)]\tLoss: 0.799048\n",
      "Train Epoch: 7 [58112/60000 (97%)]\tLoss: 0.722614\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.783519\n",
      "Train Epoch: 7 [58368/60000 (97%)]\tLoss: 0.819982\n",
      "Train Epoch: 7 [58496/60000 (98%)]\tLoss: 0.760161\n",
      "Train Epoch: 7 [58624/60000 (98%)]\tLoss: 0.739145\n",
      "Train Epoch: 7 [58752/60000 (98%)]\tLoss: 0.805159\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.691560\n",
      "Train Epoch: 7 [59008/60000 (99%)]\tLoss: 0.793279\n",
      "Train Epoch: 7 [59136/60000 (99%)]\tLoss: 0.795111\n",
      "Train Epoch: 7 [59264/60000 (99%)]\tLoss: 0.970099\n",
      "Train Epoch: 7 [59392/60000 (99%)]\tLoss: 0.848509\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.686957\n",
      "Train Epoch: 7 [59648/60000 (100%)]\tLoss: 1.160024\n",
      "Train Epoch: 7 [59776/60000 (100%)]\tLoss: 0.619924\n",
      "================================================================\n",
      "Training: Average loss: 0.3297, Accuracy: 54900/60000 (92%)\n",
      "Test: Average loss: 0.3131, Accuracy: 9195/10000 (92%)\n",
      "================================================================\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.897164\n",
      "Train Epoch: 8 [128/60000 (0%)]\tLoss: 1.027020\n",
      "Train Epoch: 8 [256/60000 (0%)]\tLoss: 0.787344\n",
      "Train Epoch: 8 [384/60000 (1%)]\tLoss: 0.966637\n",
      "Train Epoch: 8 [512/60000 (1%)]\tLoss: 1.150755\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.824119\n",
      "Train Epoch: 8 [768/60000 (1%)]\tLoss: 1.108821\n",
      "Train Epoch: 8 [896/60000 (1%)]\tLoss: 1.117004\n",
      "Train Epoch: 8 [1024/60000 (2%)]\tLoss: 1.183196\n",
      "Train Epoch: 8 [1152/60000 (2%)]\tLoss: 0.959345\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 1.026817\n",
      "Train Epoch: 8 [1408/60000 (2%)]\tLoss: 0.874166\n",
      "Train Epoch: 8 [1536/60000 (3%)]\tLoss: 0.939213\n",
      "Train Epoch: 8 [1664/60000 (3%)]\tLoss: 0.708260\n",
      "Train Epoch: 8 [1792/60000 (3%)]\tLoss: 0.734570\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.800336\n",
      "Train Epoch: 8 [2048/60000 (3%)]\tLoss: 0.787561\n",
      "Train Epoch: 8 [2176/60000 (4%)]\tLoss: 0.807790\n",
      "Train Epoch: 8 [2304/60000 (4%)]\tLoss: 1.095837\n",
      "Train Epoch: 8 [2432/60000 (4%)]\tLoss: 0.782777\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.782488\n",
      "Train Epoch: 8 [2688/60000 (4%)]\tLoss: 0.950895\n",
      "Train Epoch: 8 [2816/60000 (5%)]\tLoss: 0.894549\n",
      "Train Epoch: 8 [2944/60000 (5%)]\tLoss: 0.946159\n",
      "Train Epoch: 8 [3072/60000 (5%)]\tLoss: 0.866724\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.662699\n",
      "Train Epoch: 8 [3328/60000 (6%)]\tLoss: 0.948352\n",
      "Train Epoch: 8 [3456/60000 (6%)]\tLoss: 0.860530\n",
      "Train Epoch: 8 [3584/60000 (6%)]\tLoss: 0.983708\n",
      "Train Epoch: 8 [3712/60000 (6%)]\tLoss: 1.013538\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.835953\n",
      "Train Epoch: 8 [3968/60000 (7%)]\tLoss: 0.904684\n",
      "Train Epoch: 8 [4096/60000 (7%)]\tLoss: 0.912735\n",
      "Train Epoch: 8 [4224/60000 (7%)]\tLoss: 0.772667\n",
      "Train Epoch: 8 [4352/60000 (7%)]\tLoss: 0.958066\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.825886\n",
      "Train Epoch: 8 [4608/60000 (8%)]\tLoss: 0.813382\n",
      "Train Epoch: 8 [4736/60000 (8%)]\tLoss: 0.935352\n",
      "Train Epoch: 8 [4864/60000 (8%)]\tLoss: 0.920541\n",
      "Train Epoch: 8 [4992/60000 (8%)]\tLoss: 0.976627\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 1.039753\n",
      "Train Epoch: 8 [5248/60000 (9%)]\tLoss: 0.921728\n",
      "Train Epoch: 8 [5376/60000 (9%)]\tLoss: 0.743083\n",
      "Train Epoch: 8 [5504/60000 (9%)]\tLoss: 0.916443\n",
      "Train Epoch: 8 [5632/60000 (9%)]\tLoss: 0.886562\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.999841\n",
      "Train Epoch: 8 [5888/60000 (10%)]\tLoss: 0.952271\n",
      "Train Epoch: 8 [6016/60000 (10%)]\tLoss: 0.678183\n",
      "Train Epoch: 8 [6144/60000 (10%)]\tLoss: 0.981638\n",
      "Train Epoch: 8 [6272/60000 (10%)]\tLoss: 0.850032\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.921181\n",
      "Train Epoch: 8 [6528/60000 (11%)]\tLoss: 0.737280\n",
      "Train Epoch: 8 [6656/60000 (11%)]\tLoss: 0.902899\n",
      "Train Epoch: 8 [6784/60000 (11%)]\tLoss: 1.035427\n",
      "Train Epoch: 8 [6912/60000 (12%)]\tLoss: 1.002280\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.913336\n",
      "Train Epoch: 8 [7168/60000 (12%)]\tLoss: 0.977281\n",
      "Train Epoch: 8 [7296/60000 (12%)]\tLoss: 0.882745\n",
      "Train Epoch: 8 [7424/60000 (12%)]\tLoss: 0.865411\n",
      "Train Epoch: 8 [7552/60000 (13%)]\tLoss: 0.887116\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.967628\n",
      "Train Epoch: 8 [7808/60000 (13%)]\tLoss: 0.951866\n",
      "Train Epoch: 8 [7936/60000 (13%)]\tLoss: 0.850397\n",
      "Train Epoch: 8 [8064/60000 (13%)]\tLoss: 0.905268\n",
      "Train Epoch: 8 [8192/60000 (14%)]\tLoss: 1.101376\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.922952\n",
      "Train Epoch: 8 [8448/60000 (14%)]\tLoss: 0.855262\n",
      "Train Epoch: 8 [8576/60000 (14%)]\tLoss: 0.917424\n",
      "Train Epoch: 8 [8704/60000 (15%)]\tLoss: 1.003082\n",
      "Train Epoch: 8 [8832/60000 (15%)]\tLoss: 1.290458\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.747525\n",
      "Train Epoch: 8 [9088/60000 (15%)]\tLoss: 0.949880\n",
      "Train Epoch: 8 [9216/60000 (15%)]\tLoss: 0.807750\n",
      "Train Epoch: 8 [9344/60000 (16%)]\tLoss: 0.912022\n",
      "Train Epoch: 8 [9472/60000 (16%)]\tLoss: 0.974317\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.844548\n",
      "Train Epoch: 8 [9728/60000 (16%)]\tLoss: 0.915029\n",
      "Train Epoch: 8 [9856/60000 (16%)]\tLoss: 0.868922\n",
      "Train Epoch: 8 [9984/60000 (17%)]\tLoss: 0.903376\n",
      "Train Epoch: 8 [10112/60000 (17%)]\tLoss: 0.916607\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.922331\n",
      "Train Epoch: 8 [10368/60000 (17%)]\tLoss: 0.698027\n",
      "Train Epoch: 8 [10496/60000 (18%)]\tLoss: 0.799590\n",
      "Train Epoch: 8 [10624/60000 (18%)]\tLoss: 0.766714\n",
      "Train Epoch: 8 [10752/60000 (18%)]\tLoss: 0.952492\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.959657\n",
      "Train Epoch: 8 [11008/60000 (18%)]\tLoss: 0.844185\n",
      "Train Epoch: 8 [11136/60000 (19%)]\tLoss: 0.984972\n",
      "Train Epoch: 8 [11264/60000 (19%)]\tLoss: 0.898736\n",
      "Train Epoch: 8 [11392/60000 (19%)]\tLoss: 0.730410\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 1.247784\n",
      "Train Epoch: 8 [11648/60000 (19%)]\tLoss: 1.130390\n",
      "Train Epoch: 8 [11776/60000 (20%)]\tLoss: 0.968048\n",
      "Train Epoch: 8 [11904/60000 (20%)]\tLoss: 0.915837\n",
      "Train Epoch: 8 [12032/60000 (20%)]\tLoss: 1.010138\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.939122\n",
      "Train Epoch: 8 [12288/60000 (21%)]\tLoss: 0.946659\n",
      "Train Epoch: 8 [12416/60000 (21%)]\tLoss: 0.947237\n",
      "Train Epoch: 8 [12544/60000 (21%)]\tLoss: 1.167821\n",
      "Train Epoch: 8 [12672/60000 (21%)]\tLoss: 1.021838\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.922012\n",
      "Train Epoch: 8 [12928/60000 (22%)]\tLoss: 1.329195\n",
      "Train Epoch: 8 [13056/60000 (22%)]\tLoss: 1.102259\n",
      "Train Epoch: 8 [13184/60000 (22%)]\tLoss: 0.879968\n",
      "Train Epoch: 8 [13312/60000 (22%)]\tLoss: 0.959282\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.806300\n",
      "Train Epoch: 8 [13568/60000 (23%)]\tLoss: 0.972202\n",
      "Train Epoch: 8 [13696/60000 (23%)]\tLoss: 1.008830\n",
      "Train Epoch: 8 [13824/60000 (23%)]\tLoss: 0.876124\n",
      "Train Epoch: 8 [13952/60000 (23%)]\tLoss: 1.005293\n",
      "Train Epoch: 8 [14080/60000 (24%)]\tLoss: 0.810848\n",
      "Train Epoch: 8 [14208/60000 (24%)]\tLoss: 1.110819\n",
      "Train Epoch: 8 [14336/60000 (24%)]\tLoss: 1.030107\n",
      "Train Epoch: 8 [14464/60000 (24%)]\tLoss: 0.873930\n",
      "Train Epoch: 8 [14592/60000 (24%)]\tLoss: 1.214015\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 1.170250\n",
      "Train Epoch: 8 [14848/60000 (25%)]\tLoss: 0.964501\n",
      "Train Epoch: 8 [14976/60000 (25%)]\tLoss: 0.795248\n",
      "Train Epoch: 8 [15104/60000 (25%)]\tLoss: 0.943810\n",
      "Train Epoch: 8 [15232/60000 (25%)]\tLoss: 0.850704\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.779658\n",
      "Train Epoch: 8 [15488/60000 (26%)]\tLoss: 0.806428\n",
      "Train Epoch: 8 [15616/60000 (26%)]\tLoss: 0.991709\n",
      "Train Epoch: 8 [15744/60000 (26%)]\tLoss: 1.069065\n",
      "Train Epoch: 8 [15872/60000 (26%)]\tLoss: 0.892671\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 1.229608\n",
      "Train Epoch: 8 [16128/60000 (27%)]\tLoss: 0.877110\n",
      "Train Epoch: 8 [16256/60000 (27%)]\tLoss: 0.843295\n",
      "Train Epoch: 8 [16384/60000 (27%)]\tLoss: 0.837837\n",
      "Train Epoch: 8 [16512/60000 (28%)]\tLoss: 0.853731\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.935295\n",
      "Train Epoch: 8 [16768/60000 (28%)]\tLoss: 1.046692\n",
      "Train Epoch: 8 [16896/60000 (28%)]\tLoss: 1.142894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [17024/60000 (28%)]\tLoss: 0.931447\n",
      "Train Epoch: 8 [17152/60000 (29%)]\tLoss: 0.994390\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.877683\n",
      "Train Epoch: 8 [17408/60000 (29%)]\tLoss: 1.000554\n",
      "Train Epoch: 8 [17536/60000 (29%)]\tLoss: 1.129006\n",
      "Train Epoch: 8 [17664/60000 (29%)]\tLoss: 1.032172\n",
      "Train Epoch: 8 [17792/60000 (30%)]\tLoss: 0.987174\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.853489\n",
      "Train Epoch: 8 [18048/60000 (30%)]\tLoss: 0.794788\n",
      "Train Epoch: 8 [18176/60000 (30%)]\tLoss: 0.689941\n",
      "Train Epoch: 8 [18304/60000 (31%)]\tLoss: 0.984936\n",
      "Train Epoch: 8 [18432/60000 (31%)]\tLoss: 0.839432\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.795601\n",
      "Train Epoch: 8 [18688/60000 (31%)]\tLoss: 0.900524\n",
      "Train Epoch: 8 [18816/60000 (31%)]\tLoss: 0.744756\n",
      "Train Epoch: 8 [18944/60000 (32%)]\tLoss: 0.795911\n",
      "Train Epoch: 8 [19072/60000 (32%)]\tLoss: 1.092815\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.881015\n",
      "Train Epoch: 8 [19328/60000 (32%)]\tLoss: 0.915281\n",
      "Train Epoch: 8 [19456/60000 (32%)]\tLoss: 0.714498\n",
      "Train Epoch: 8 [19584/60000 (33%)]\tLoss: 0.711861\n",
      "Train Epoch: 8 [19712/60000 (33%)]\tLoss: 0.890156\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.927143\n",
      "Train Epoch: 8 [19968/60000 (33%)]\tLoss: 0.983968\n",
      "Train Epoch: 8 [20096/60000 (34%)]\tLoss: 1.122572\n",
      "Train Epoch: 8 [20224/60000 (34%)]\tLoss: 1.003767\n",
      "Train Epoch: 8 [20352/60000 (34%)]\tLoss: 0.589623\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 1.044293\n",
      "Train Epoch: 8 [20608/60000 (34%)]\tLoss: 0.964612\n",
      "Train Epoch: 8 [20736/60000 (35%)]\tLoss: 0.942319\n",
      "Train Epoch: 8 [20864/60000 (35%)]\tLoss: 1.132116\n",
      "Train Epoch: 8 [20992/60000 (35%)]\tLoss: 0.949468\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.903307\n",
      "Train Epoch: 8 [21248/60000 (35%)]\tLoss: 0.788572\n",
      "Train Epoch: 8 [21376/60000 (36%)]\tLoss: 0.977997\n",
      "Train Epoch: 8 [21504/60000 (36%)]\tLoss: 0.928028\n",
      "Train Epoch: 8 [21632/60000 (36%)]\tLoss: 0.856412\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.658395\n",
      "Train Epoch: 8 [21888/60000 (37%)]\tLoss: 0.843718\n",
      "Train Epoch: 8 [22016/60000 (37%)]\tLoss: 0.802592\n",
      "Train Epoch: 8 [22144/60000 (37%)]\tLoss: 0.973455\n",
      "Train Epoch: 8 [22272/60000 (37%)]\tLoss: 0.780329\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.998803\n",
      "Train Epoch: 8 [22528/60000 (38%)]\tLoss: 1.266078\n",
      "Train Epoch: 8 [22656/60000 (38%)]\tLoss: 1.064634\n",
      "Train Epoch: 8 [22784/60000 (38%)]\tLoss: 0.767485\n",
      "Train Epoch: 8 [22912/60000 (38%)]\tLoss: 0.744366\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.867151\n",
      "Train Epoch: 8 [23168/60000 (39%)]\tLoss: 0.857019\n",
      "Train Epoch: 8 [23296/60000 (39%)]\tLoss: 0.697547\n",
      "Train Epoch: 8 [23424/60000 (39%)]\tLoss: 0.878219\n",
      "Train Epoch: 8 [23552/60000 (39%)]\tLoss: 0.889602\n",
      "Train Epoch: 8 [23680/60000 (40%)]\tLoss: 0.953251\n",
      "Train Epoch: 8 [23808/60000 (40%)]\tLoss: 0.936236\n",
      "Train Epoch: 8 [23936/60000 (40%)]\tLoss: 0.918808\n",
      "Train Epoch: 8 [24064/60000 (40%)]\tLoss: 0.856063\n",
      "Train Epoch: 8 [24192/60000 (40%)]\tLoss: 0.990138\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.722124\n",
      "Train Epoch: 8 [24448/60000 (41%)]\tLoss: 0.968232\n",
      "Train Epoch: 8 [24576/60000 (41%)]\tLoss: 0.991858\n",
      "Train Epoch: 8 [24704/60000 (41%)]\tLoss: 0.992344\n",
      "Train Epoch: 8 [24832/60000 (41%)]\tLoss: 1.006338\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.847026\n",
      "Train Epoch: 8 [25088/60000 (42%)]\tLoss: 0.879401\n",
      "Train Epoch: 8 [25216/60000 (42%)]\tLoss: 0.948511\n",
      "Train Epoch: 8 [25344/60000 (42%)]\tLoss: 0.722325\n",
      "Train Epoch: 8 [25472/60000 (43%)]\tLoss: 0.750513\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.849241\n",
      "Train Epoch: 8 [25728/60000 (43%)]\tLoss: 0.914341\n",
      "Train Epoch: 8 [25856/60000 (43%)]\tLoss: 0.811252\n",
      "Train Epoch: 8 [25984/60000 (43%)]\tLoss: 0.825985\n",
      "Train Epoch: 8 [26112/60000 (44%)]\tLoss: 0.920628\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.821948\n",
      "Train Epoch: 8 [26368/60000 (44%)]\tLoss: 0.967415\n",
      "Train Epoch: 8 [26496/60000 (44%)]\tLoss: 1.047624\n",
      "Train Epoch: 8 [26624/60000 (44%)]\tLoss: 1.202513\n",
      "Train Epoch: 8 [26752/60000 (45%)]\tLoss: 0.893699\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.854242\n",
      "Train Epoch: 8 [27008/60000 (45%)]\tLoss: 0.935672\n",
      "Train Epoch: 8 [27136/60000 (45%)]\tLoss: 1.235355\n",
      "Train Epoch: 8 [27264/60000 (46%)]\tLoss: 0.866590\n",
      "Train Epoch: 8 [27392/60000 (46%)]\tLoss: 0.941671\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.769842\n",
      "Train Epoch: 8 [27648/60000 (46%)]\tLoss: 0.819520\n",
      "Train Epoch: 8 [27776/60000 (46%)]\tLoss: 0.919168\n",
      "Train Epoch: 8 [27904/60000 (47%)]\tLoss: 0.769274\n",
      "Train Epoch: 8 [28032/60000 (47%)]\tLoss: 0.782627\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.882383\n",
      "Train Epoch: 8 [28288/60000 (47%)]\tLoss: 0.903027\n",
      "Train Epoch: 8 [28416/60000 (47%)]\tLoss: 0.977251\n",
      "Train Epoch: 8 [28544/60000 (48%)]\tLoss: 1.015664\n",
      "Train Epoch: 8 [28672/60000 (48%)]\tLoss: 0.881224\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.896528\n",
      "Train Epoch: 8 [28928/60000 (48%)]\tLoss: 0.896650\n",
      "Train Epoch: 8 [29056/60000 (49%)]\tLoss: 1.033878\n",
      "Train Epoch: 8 [29184/60000 (49%)]\tLoss: 0.953161\n",
      "Train Epoch: 8 [29312/60000 (49%)]\tLoss: 1.020026\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.847535\n",
      "Train Epoch: 8 [29568/60000 (49%)]\tLoss: 0.775920\n",
      "Train Epoch: 8 [29696/60000 (50%)]\tLoss: 1.079972\n",
      "Train Epoch: 8 [29824/60000 (50%)]\tLoss: 1.084601\n",
      "Train Epoch: 8 [29952/60000 (50%)]\tLoss: 1.051670\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 1.072264\n",
      "Train Epoch: 8 [30208/60000 (50%)]\tLoss: 0.892928\n",
      "Train Epoch: 8 [30336/60000 (51%)]\tLoss: 0.855156\n",
      "Train Epoch: 8 [30464/60000 (51%)]\tLoss: 0.959890\n",
      "Train Epoch: 8 [30592/60000 (51%)]\tLoss: 1.039516\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.799859\n",
      "Train Epoch: 8 [30848/60000 (51%)]\tLoss: 1.028738\n",
      "Train Epoch: 8 [30976/60000 (52%)]\tLoss: 0.860708\n",
      "Train Epoch: 8 [31104/60000 (52%)]\tLoss: 0.970568\n",
      "Train Epoch: 8 [31232/60000 (52%)]\tLoss: 1.050433\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.925633\n",
      "Train Epoch: 8 [31488/60000 (53%)]\tLoss: 0.901811\n",
      "Train Epoch: 8 [31616/60000 (53%)]\tLoss: 1.090827\n",
      "Train Epoch: 8 [31744/60000 (53%)]\tLoss: 0.870549\n",
      "Train Epoch: 8 [31872/60000 (53%)]\tLoss: 0.883984\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.048300\n",
      "Train Epoch: 8 [32128/60000 (54%)]\tLoss: 0.961321\n",
      "Train Epoch: 8 [32256/60000 (54%)]\tLoss: 1.127537\n",
      "Train Epoch: 8 [32384/60000 (54%)]\tLoss: 1.163680\n",
      "Train Epoch: 8 [32512/60000 (54%)]\tLoss: 0.850024\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.805570\n",
      "Train Epoch: 8 [32768/60000 (55%)]\tLoss: 0.922521\n",
      "Train Epoch: 8 [32896/60000 (55%)]\tLoss: 0.821030\n",
      "Train Epoch: 8 [33024/60000 (55%)]\tLoss: 0.920546\n",
      "Train Epoch: 8 [33152/60000 (55%)]\tLoss: 0.910298\n",
      "Train Epoch: 8 [33280/60000 (56%)]\tLoss: 0.973016\n",
      "Train Epoch: 8 [33408/60000 (56%)]\tLoss: 0.883020\n",
      "Train Epoch: 8 [33536/60000 (56%)]\tLoss: 0.887379\n",
      "Train Epoch: 8 [33664/60000 (56%)]\tLoss: 0.946243\n",
      "Train Epoch: 8 [33792/60000 (56%)]\tLoss: 0.678319\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.809097\n",
      "Train Epoch: 8 [34048/60000 (57%)]\tLoss: 0.975269\n",
      "Train Epoch: 8 [34176/60000 (57%)]\tLoss: 0.751299\n",
      "Train Epoch: 8 [34304/60000 (57%)]\tLoss: 0.897762\n",
      "Train Epoch: 8 [34432/60000 (57%)]\tLoss: 0.943135\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.910592\n",
      "Train Epoch: 8 [34688/60000 (58%)]\tLoss: 1.094383\n",
      "Train Epoch: 8 [34816/60000 (58%)]\tLoss: 1.093102\n",
      "Train Epoch: 8 [34944/60000 (58%)]\tLoss: 0.908396\n",
      "Train Epoch: 8 [35072/60000 (59%)]\tLoss: 0.892683\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.848277\n",
      "Train Epoch: 8 [35328/60000 (59%)]\tLoss: 0.856020\n",
      "Train Epoch: 8 [35456/60000 (59%)]\tLoss: 0.798901\n",
      "Train Epoch: 8 [35584/60000 (59%)]\tLoss: 0.957857\n",
      "Train Epoch: 8 [35712/60000 (60%)]\tLoss: 0.767336\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.919153\n",
      "Train Epoch: 8 [35968/60000 (60%)]\tLoss: 0.907621\n",
      "Train Epoch: 8 [36096/60000 (60%)]\tLoss: 0.880827\n",
      "Train Epoch: 8 [36224/60000 (60%)]\tLoss: 0.670171\n",
      "Train Epoch: 8 [36352/60000 (61%)]\tLoss: 0.887218\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.824833\n",
      "Train Epoch: 8 [36608/60000 (61%)]\tLoss: 0.668990\n",
      "Train Epoch: 8 [36736/60000 (61%)]\tLoss: 0.979220\n",
      "Train Epoch: 8 [36864/60000 (62%)]\tLoss: 0.694817\n",
      "Train Epoch: 8 [36992/60000 (62%)]\tLoss: 1.016174\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.908358\n",
      "Train Epoch: 8 [37248/60000 (62%)]\tLoss: 1.042533\n",
      "Train Epoch: 8 [37376/60000 (62%)]\tLoss: 1.279361\n",
      "Train Epoch: 8 [37504/60000 (63%)]\tLoss: 0.980431\n",
      "Train Epoch: 8 [37632/60000 (63%)]\tLoss: 0.909003\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.844878\n",
      "Train Epoch: 8 [37888/60000 (63%)]\tLoss: 0.903796\n",
      "Train Epoch: 8 [38016/60000 (63%)]\tLoss: 0.807601\n",
      "Train Epoch: 8 [38144/60000 (64%)]\tLoss: 0.963311\n",
      "Train Epoch: 8 [38272/60000 (64%)]\tLoss: 1.001199\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.787196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [38528/60000 (64%)]\tLoss: 1.078774\n",
      "Train Epoch: 8 [38656/60000 (65%)]\tLoss: 0.861306\n",
      "Train Epoch: 8 [38784/60000 (65%)]\tLoss: 0.765641\n",
      "Train Epoch: 8 [38912/60000 (65%)]\tLoss: 0.721364\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.697387\n",
      "Train Epoch: 8 [39168/60000 (65%)]\tLoss: 0.812777\n",
      "Train Epoch: 8 [39296/60000 (66%)]\tLoss: 1.247250\n",
      "Train Epoch: 8 [39424/60000 (66%)]\tLoss: 0.922936\n",
      "Train Epoch: 8 [39552/60000 (66%)]\tLoss: 0.838281\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 1.022069\n",
      "Train Epoch: 8 [39808/60000 (66%)]\tLoss: 1.046807\n",
      "Train Epoch: 8 [39936/60000 (67%)]\tLoss: 0.870454\n",
      "Train Epoch: 8 [40064/60000 (67%)]\tLoss: 0.869337\n",
      "Train Epoch: 8 [40192/60000 (67%)]\tLoss: 0.968542\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.797562\n",
      "Train Epoch: 8 [40448/60000 (68%)]\tLoss: 0.847736\n",
      "Train Epoch: 8 [40576/60000 (68%)]\tLoss: 0.932397\n",
      "Train Epoch: 8 [40704/60000 (68%)]\tLoss: 0.900447\n",
      "Train Epoch: 8 [40832/60000 (68%)]\tLoss: 0.761478\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.954401\n",
      "Train Epoch: 8 [41088/60000 (69%)]\tLoss: 0.948646\n",
      "Train Epoch: 8 [41216/60000 (69%)]\tLoss: 1.366101\n",
      "Train Epoch: 8 [41344/60000 (69%)]\tLoss: 1.056859\n",
      "Train Epoch: 8 [41472/60000 (69%)]\tLoss: 0.953804\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.781500\n",
      "Train Epoch: 8 [41728/60000 (70%)]\tLoss: 0.743301\n",
      "Train Epoch: 8 [41856/60000 (70%)]\tLoss: 0.862330\n",
      "Train Epoch: 8 [41984/60000 (70%)]\tLoss: 1.038372\n",
      "Train Epoch: 8 [42112/60000 (70%)]\tLoss: 1.017706\n",
      "Train Epoch: 8 [42240/60000 (71%)]\tLoss: 1.130896\n",
      "Train Epoch: 8 [42368/60000 (71%)]\tLoss: 0.963582\n",
      "Train Epoch: 8 [42496/60000 (71%)]\tLoss: 0.872150\n",
      "Train Epoch: 8 [42624/60000 (71%)]\tLoss: 1.015527\n",
      "Train Epoch: 8 [42752/60000 (71%)]\tLoss: 0.964686\n",
      "Train Epoch: 8 [42880/60000 (72%)]\tLoss: 1.113796\n",
      "Train Epoch: 8 [43008/60000 (72%)]\tLoss: 1.025405\n",
      "Train Epoch: 8 [43136/60000 (72%)]\tLoss: 0.818419\n",
      "Train Epoch: 8 [43264/60000 (72%)]\tLoss: 0.606043\n",
      "Train Epoch: 8 [43392/60000 (72%)]\tLoss: 0.700768\n",
      "Train Epoch: 8 [43520/60000 (73%)]\tLoss: 0.676850\n",
      "Train Epoch: 8 [43648/60000 (73%)]\tLoss: 0.844405\n",
      "Train Epoch: 8 [43776/60000 (73%)]\tLoss: 0.855006\n",
      "Train Epoch: 8 [43904/60000 (73%)]\tLoss: 0.928826\n",
      "Train Epoch: 8 [44032/60000 (74%)]\tLoss: 0.987571\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 1.013075\n",
      "Train Epoch: 8 [44288/60000 (74%)]\tLoss: 1.029134\n",
      "Train Epoch: 8 [44416/60000 (74%)]\tLoss: 0.930942\n",
      "Train Epoch: 8 [44544/60000 (74%)]\tLoss: 0.722873\n",
      "Train Epoch: 8 [44672/60000 (75%)]\tLoss: 0.744447\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.942810\n",
      "Train Epoch: 8 [44928/60000 (75%)]\tLoss: 0.927799\n",
      "Train Epoch: 8 [45056/60000 (75%)]\tLoss: 0.883215\n",
      "Train Epoch: 8 [45184/60000 (75%)]\tLoss: 0.834290\n",
      "Train Epoch: 8 [45312/60000 (76%)]\tLoss: 0.757149\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 1.045830\n",
      "Train Epoch: 8 [45568/60000 (76%)]\tLoss: 0.813089\n",
      "Train Epoch: 8 [45696/60000 (76%)]\tLoss: 0.961493\n",
      "Train Epoch: 8 [45824/60000 (76%)]\tLoss: 0.985161\n",
      "Train Epoch: 8 [45952/60000 (77%)]\tLoss: 0.924417\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.882909\n",
      "Train Epoch: 8 [46208/60000 (77%)]\tLoss: 0.935749\n",
      "Train Epoch: 8 [46336/60000 (77%)]\tLoss: 1.043768\n",
      "Train Epoch: 8 [46464/60000 (78%)]\tLoss: 0.764985\n",
      "Train Epoch: 8 [46592/60000 (78%)]\tLoss: 0.842941\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.873846\n",
      "Train Epoch: 8 [46848/60000 (78%)]\tLoss: 0.748867\n",
      "Train Epoch: 8 [46976/60000 (78%)]\tLoss: 0.816853\n",
      "Train Epoch: 8 [47104/60000 (79%)]\tLoss: 0.851761\n",
      "Train Epoch: 8 [47232/60000 (79%)]\tLoss: 1.062306\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 1.072317\n",
      "Train Epoch: 8 [47488/60000 (79%)]\tLoss: 1.029560\n",
      "Train Epoch: 8 [47616/60000 (79%)]\tLoss: 0.897858\n",
      "Train Epoch: 8 [47744/60000 (80%)]\tLoss: 0.749536\n",
      "Train Epoch: 8 [47872/60000 (80%)]\tLoss: 0.995512\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.758542\n",
      "Train Epoch: 8 [48128/60000 (80%)]\tLoss: 0.797464\n",
      "Train Epoch: 8 [48256/60000 (81%)]\tLoss: 0.852570\n",
      "Train Epoch: 8 [48384/60000 (81%)]\tLoss: 0.768950\n",
      "Train Epoch: 8 [48512/60000 (81%)]\tLoss: 0.742994\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.753365\n",
      "Train Epoch: 8 [48768/60000 (81%)]\tLoss: 0.755339\n",
      "Train Epoch: 8 [48896/60000 (82%)]\tLoss: 1.199388\n",
      "Train Epoch: 8 [49024/60000 (82%)]\tLoss: 1.044745\n",
      "Train Epoch: 8 [49152/60000 (82%)]\tLoss: 0.957447\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.661071\n",
      "Train Epoch: 8 [49408/60000 (82%)]\tLoss: 1.043265\n",
      "Train Epoch: 8 [49536/60000 (83%)]\tLoss: 1.220430\n",
      "Train Epoch: 8 [49664/60000 (83%)]\tLoss: 0.869619\n",
      "Train Epoch: 8 [49792/60000 (83%)]\tLoss: 0.935399\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.854553\n",
      "Train Epoch: 8 [50048/60000 (84%)]\tLoss: 0.853001\n",
      "Train Epoch: 8 [50176/60000 (84%)]\tLoss: 0.940537\n",
      "Train Epoch: 8 [50304/60000 (84%)]\tLoss: 1.498196\n",
      "Train Epoch: 8 [50432/60000 (84%)]\tLoss: 0.976124\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.901988\n",
      "Train Epoch: 8 [50688/60000 (85%)]\tLoss: 0.933465\n",
      "Train Epoch: 8 [50816/60000 (85%)]\tLoss: 0.860266\n",
      "Train Epoch: 8 [50944/60000 (85%)]\tLoss: 0.745290\n",
      "Train Epoch: 8 [51072/60000 (85%)]\tLoss: 0.898730\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.854094\n",
      "Train Epoch: 8 [51328/60000 (86%)]\tLoss: 0.886975\n",
      "Train Epoch: 8 [51456/60000 (86%)]\tLoss: 0.809600\n",
      "Train Epoch: 8 [51584/60000 (86%)]\tLoss: 0.747128\n",
      "Train Epoch: 8 [51712/60000 (86%)]\tLoss: 1.004051\n",
      "Train Epoch: 8 [51840/60000 (87%)]\tLoss: 0.834423\n",
      "Train Epoch: 8 [51968/60000 (87%)]\tLoss: 1.096883\n",
      "Train Epoch: 8 [52096/60000 (87%)]\tLoss: 1.046409\n",
      "Train Epoch: 8 [52224/60000 (87%)]\tLoss: 1.036977\n",
      "Train Epoch: 8 [52352/60000 (87%)]\tLoss: 0.781468\n",
      "Train Epoch: 8 [52480/60000 (88%)]\tLoss: 0.581330\n",
      "Train Epoch: 8 [52608/60000 (88%)]\tLoss: 0.818989\n",
      "Train Epoch: 8 [52736/60000 (88%)]\tLoss: 1.087838\n",
      "Train Epoch: 8 [52864/60000 (88%)]\tLoss: 1.200901\n",
      "Train Epoch: 8 [52992/60000 (88%)]\tLoss: 0.989802\n",
      "Train Epoch: 8 [53120/60000 (89%)]\tLoss: 0.955170\n",
      "Train Epoch: 8 [53248/60000 (89%)]\tLoss: 0.814959\n",
      "Train Epoch: 8 [53376/60000 (89%)]\tLoss: 0.710242\n",
      "Train Epoch: 8 [53504/60000 (89%)]\tLoss: 0.903947\n",
      "Train Epoch: 8 [53632/60000 (90%)]\tLoss: 0.822998\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.753897\n",
      "Train Epoch: 8 [53888/60000 (90%)]\tLoss: 0.870643\n",
      "Train Epoch: 8 [54016/60000 (90%)]\tLoss: 1.002185\n",
      "Train Epoch: 8 [54144/60000 (90%)]\tLoss: 0.721488\n",
      "Train Epoch: 8 [54272/60000 (91%)]\tLoss: 0.918153\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.637054\n",
      "Train Epoch: 8 [54528/60000 (91%)]\tLoss: 0.832836\n",
      "Train Epoch: 8 [54656/60000 (91%)]\tLoss: 0.732960\n",
      "Train Epoch: 8 [54784/60000 (91%)]\tLoss: 0.915502\n",
      "Train Epoch: 8 [54912/60000 (92%)]\tLoss: 1.121471\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.713128\n",
      "Train Epoch: 8 [55168/60000 (92%)]\tLoss: 0.814973\n",
      "Train Epoch: 8 [55296/60000 (92%)]\tLoss: 0.744567\n",
      "Train Epoch: 8 [55424/60000 (93%)]\tLoss: 0.791840\n",
      "Train Epoch: 8 [55552/60000 (93%)]\tLoss: 0.779091\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.859777\n",
      "Train Epoch: 8 [55808/60000 (93%)]\tLoss: 0.808232\n",
      "Train Epoch: 8 [55936/60000 (93%)]\tLoss: 0.711274\n",
      "Train Epoch: 8 [56064/60000 (94%)]\tLoss: 0.741437\n",
      "Train Epoch: 8 [56192/60000 (94%)]\tLoss: 0.983153\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.832507\n",
      "Train Epoch: 8 [56448/60000 (94%)]\tLoss: 0.753948\n",
      "Train Epoch: 8 [56576/60000 (94%)]\tLoss: 0.943750\n",
      "Train Epoch: 8 [56704/60000 (95%)]\tLoss: 0.635766\n",
      "Train Epoch: 8 [56832/60000 (95%)]\tLoss: 0.810555\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.856404\n",
      "Train Epoch: 8 [57088/60000 (95%)]\tLoss: 0.757301\n",
      "Train Epoch: 8 [57216/60000 (96%)]\tLoss: 0.960665\n",
      "Train Epoch: 8 [57344/60000 (96%)]\tLoss: 0.825429\n",
      "Train Epoch: 8 [57472/60000 (96%)]\tLoss: 0.866967\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 1.027510\n",
      "Train Epoch: 8 [57728/60000 (96%)]\tLoss: 0.810509\n",
      "Train Epoch: 8 [57856/60000 (97%)]\tLoss: 0.702752\n",
      "Train Epoch: 8 [57984/60000 (97%)]\tLoss: 0.877236\n",
      "Train Epoch: 8 [58112/60000 (97%)]\tLoss: 0.655557\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.727070\n",
      "Train Epoch: 8 [58368/60000 (97%)]\tLoss: 0.717138\n",
      "Train Epoch: 8 [58496/60000 (98%)]\tLoss: 0.825218\n",
      "Train Epoch: 8 [58624/60000 (98%)]\tLoss: 0.657616\n",
      "Train Epoch: 8 [58752/60000 (98%)]\tLoss: 0.856226\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.523842\n",
      "Train Epoch: 8 [59008/60000 (99%)]\tLoss: 0.491676\n",
      "Train Epoch: 8 [59136/60000 (99%)]\tLoss: 0.579963\n",
      "Train Epoch: 8 [59264/60000 (99%)]\tLoss: 1.044205\n",
      "Train Epoch: 8 [59392/60000 (99%)]\tLoss: 0.793353\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.722301\n",
      "Train Epoch: 8 [59648/60000 (100%)]\tLoss: 1.011883\n",
      "Train Epoch: 8 [59776/60000 (100%)]\tLoss: 0.598566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Training: Average loss: 0.3017, Accuracy: 55168/60000 (92%)\n",
      "Test: Average loss: 0.2856, Accuracy: 9233/10000 (92%)\n",
      "================================================================\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.688864\n",
      "Train Epoch: 9 [128/60000 (0%)]\tLoss: 0.961204\n",
      "Train Epoch: 9 [256/60000 (0%)]\tLoss: 0.725704\n",
      "Train Epoch: 9 [384/60000 (1%)]\tLoss: 0.879632\n",
      "Train Epoch: 9 [512/60000 (1%)]\tLoss: 1.024451\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.779481\n",
      "Train Epoch: 9 [768/60000 (1%)]\tLoss: 0.963135\n",
      "Train Epoch: 9 [896/60000 (1%)]\tLoss: 1.096658\n",
      "Train Epoch: 9 [1024/60000 (2%)]\tLoss: 1.185683\n",
      "Train Epoch: 9 [1152/60000 (2%)]\tLoss: 0.919065\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.959515\n",
      "Train Epoch: 9 [1408/60000 (2%)]\tLoss: 0.895580\n",
      "Train Epoch: 9 [1536/60000 (3%)]\tLoss: 0.848925\n",
      "Train Epoch: 9 [1664/60000 (3%)]\tLoss: 0.692486\n",
      "Train Epoch: 9 [1792/60000 (3%)]\tLoss: 0.802715\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.831672\n",
      "Train Epoch: 9 [2048/60000 (3%)]\tLoss: 0.721373\n",
      "Train Epoch: 9 [2176/60000 (4%)]\tLoss: 0.751029\n",
      "Train Epoch: 9 [2304/60000 (4%)]\tLoss: 0.867270\n",
      "Train Epoch: 9 [2432/60000 (4%)]\tLoss: 0.694503\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.722965\n",
      "Train Epoch: 9 [2688/60000 (4%)]\tLoss: 0.816518\n",
      "Train Epoch: 9 [2816/60000 (5%)]\tLoss: 0.977890\n",
      "Train Epoch: 9 [2944/60000 (5%)]\tLoss: 0.890277\n",
      "Train Epoch: 9 [3072/60000 (5%)]\tLoss: 0.902491\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.828537\n",
      "Train Epoch: 9 [3328/60000 (6%)]\tLoss: 0.925717\n",
      "Train Epoch: 9 [3456/60000 (6%)]\tLoss: 0.874460\n",
      "Train Epoch: 9 [3584/60000 (6%)]\tLoss: 0.840535\n",
      "Train Epoch: 9 [3712/60000 (6%)]\tLoss: 0.916076\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.679731\n",
      "Train Epoch: 9 [3968/60000 (7%)]\tLoss: 0.817059\n",
      "Train Epoch: 9 [4096/60000 (7%)]\tLoss: 0.831250\n",
      "Train Epoch: 9 [4224/60000 (7%)]\tLoss: 0.817118\n",
      "Train Epoch: 9 [4352/60000 (7%)]\tLoss: 1.014232\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.653575\n",
      "Train Epoch: 9 [4608/60000 (8%)]\tLoss: 0.861662\n",
      "Train Epoch: 9 [4736/60000 (8%)]\tLoss: 0.914165\n",
      "Train Epoch: 9 [4864/60000 (8%)]\tLoss: 0.924043\n",
      "Train Epoch: 9 [4992/60000 (8%)]\tLoss: 0.821733\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 1.012084\n",
      "Train Epoch: 9 [5248/60000 (9%)]\tLoss: 0.874507\n",
      "Train Epoch: 9 [5376/60000 (9%)]\tLoss: 0.691178\n",
      "Train Epoch: 9 [5504/60000 (9%)]\tLoss: 0.839726\n",
      "Train Epoch: 9 [5632/60000 (9%)]\tLoss: 0.768554\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.919457\n",
      "Train Epoch: 9 [5888/60000 (10%)]\tLoss: 0.787940\n",
      "Train Epoch: 9 [6016/60000 (10%)]\tLoss: 0.618401\n",
      "Train Epoch: 9 [6144/60000 (10%)]\tLoss: 0.920694\n",
      "Train Epoch: 9 [6272/60000 (10%)]\tLoss: 0.757843\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.827843\n",
      "Train Epoch: 9 [6528/60000 (11%)]\tLoss: 0.721367\n",
      "Train Epoch: 9 [6656/60000 (11%)]\tLoss: 0.856064\n",
      "Train Epoch: 9 [6784/60000 (11%)]\tLoss: 0.936196\n",
      "Train Epoch: 9 [6912/60000 (12%)]\tLoss: 0.984412\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.717415\n",
      "Train Epoch: 9 [7168/60000 (12%)]\tLoss: 0.927639\n",
      "Train Epoch: 9 [7296/60000 (12%)]\tLoss: 0.918563\n",
      "Train Epoch: 9 [7424/60000 (12%)]\tLoss: 0.766862\n",
      "Train Epoch: 9 [7552/60000 (13%)]\tLoss: 0.764088\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.844258\n",
      "Train Epoch: 9 [7808/60000 (13%)]\tLoss: 1.064815\n",
      "Train Epoch: 9 [7936/60000 (13%)]\tLoss: 0.766524\n",
      "Train Epoch: 9 [8064/60000 (13%)]\tLoss: 0.930772\n",
      "Train Epoch: 9 [8192/60000 (14%)]\tLoss: 0.981147\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.848669\n",
      "Train Epoch: 9 [8448/60000 (14%)]\tLoss: 0.812866\n",
      "Train Epoch: 9 [8576/60000 (14%)]\tLoss: 1.044313\n",
      "Train Epoch: 9 [8704/60000 (15%)]\tLoss: 1.166393\n",
      "Train Epoch: 9 [8832/60000 (15%)]\tLoss: 1.287933\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.702215\n",
      "Train Epoch: 9 [9088/60000 (15%)]\tLoss: 0.847492\n",
      "Train Epoch: 9 [9216/60000 (15%)]\tLoss: 0.827465\n",
      "Train Epoch: 9 [9344/60000 (16%)]\tLoss: 0.718045\n",
      "Train Epoch: 9 [9472/60000 (16%)]\tLoss: 0.951094\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.680859\n",
      "Train Epoch: 9 [9728/60000 (16%)]\tLoss: 0.888148\n",
      "Train Epoch: 9 [9856/60000 (16%)]\tLoss: 0.796460\n",
      "Train Epoch: 9 [9984/60000 (17%)]\tLoss: 0.775823\n",
      "Train Epoch: 9 [10112/60000 (17%)]\tLoss: 0.771265\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.994669\n",
      "Train Epoch: 9 [10368/60000 (17%)]\tLoss: 0.672061\n",
      "Train Epoch: 9 [10496/60000 (18%)]\tLoss: 0.743562\n",
      "Train Epoch: 9 [10624/60000 (18%)]\tLoss: 0.792948\n",
      "Train Epoch: 9 [10752/60000 (18%)]\tLoss: 1.008733\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 1.002220\n",
      "Train Epoch: 9 [11008/60000 (18%)]\tLoss: 0.810740\n",
      "Train Epoch: 9 [11136/60000 (19%)]\tLoss: 0.899058\n",
      "Train Epoch: 9 [11264/60000 (19%)]\tLoss: 0.863881\n",
      "Train Epoch: 9 [11392/60000 (19%)]\tLoss: 0.903106\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 1.216544\n",
      "Train Epoch: 9 [11648/60000 (19%)]\tLoss: 1.033795\n",
      "Train Epoch: 9 [11776/60000 (20%)]\tLoss: 0.888946\n",
      "Train Epoch: 9 [11904/60000 (20%)]\tLoss: 0.836838\n",
      "Train Epoch: 9 [12032/60000 (20%)]\tLoss: 0.963659\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.844441\n",
      "Train Epoch: 9 [12288/60000 (21%)]\tLoss: 1.016653\n",
      "Train Epoch: 9 [12416/60000 (21%)]\tLoss: 1.048160\n",
      "Train Epoch: 9 [12544/60000 (21%)]\tLoss: 1.022928\n",
      "Train Epoch: 9 [12672/60000 (21%)]\tLoss: 0.811943\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.791803\n",
      "Train Epoch: 9 [12928/60000 (22%)]\tLoss: 1.074742\n",
      "Train Epoch: 9 [13056/60000 (22%)]\tLoss: 1.113408\n",
      "Train Epoch: 9 [13184/60000 (22%)]\tLoss: 0.748897\n",
      "Train Epoch: 9 [13312/60000 (22%)]\tLoss: 0.848953\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.752861\n",
      "Train Epoch: 9 [13568/60000 (23%)]\tLoss: 0.825269\n",
      "Train Epoch: 9 [13696/60000 (23%)]\tLoss: 0.903868\n",
      "Train Epoch: 9 [13824/60000 (23%)]\tLoss: 0.775368\n",
      "Train Epoch: 9 [13952/60000 (23%)]\tLoss: 1.124357\n",
      "Train Epoch: 9 [14080/60000 (24%)]\tLoss: 0.864239\n",
      "Train Epoch: 9 [14208/60000 (24%)]\tLoss: 1.054852\n",
      "Train Epoch: 9 [14336/60000 (24%)]\tLoss: 1.102623\n",
      "Train Epoch: 9 [14464/60000 (24%)]\tLoss: 0.862566\n",
      "Train Epoch: 9 [14592/60000 (24%)]\tLoss: 1.318351\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 1.103135\n",
      "Train Epoch: 9 [14848/60000 (25%)]\tLoss: 0.765065\n",
      "Train Epoch: 9 [14976/60000 (25%)]\tLoss: 0.765331\n",
      "Train Epoch: 9 [15104/60000 (25%)]\tLoss: 1.005244\n",
      "Train Epoch: 9 [15232/60000 (25%)]\tLoss: 0.893586\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.761841\n",
      "Train Epoch: 9 [15488/60000 (26%)]\tLoss: 0.844442\n",
      "Train Epoch: 9 [15616/60000 (26%)]\tLoss: 0.805507\n",
      "Train Epoch: 9 [15744/60000 (26%)]\tLoss: 1.208745\n",
      "Train Epoch: 9 [15872/60000 (26%)]\tLoss: 1.031035\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 1.017508\n",
      "Train Epoch: 9 [16128/60000 (27%)]\tLoss: 0.741865\n",
      "Train Epoch: 9 [16256/60000 (27%)]\tLoss: 0.714564\n",
      "Train Epoch: 9 [16384/60000 (27%)]\tLoss: 0.800915\n",
      "Train Epoch: 9 [16512/60000 (28%)]\tLoss: 0.722894\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.943187\n",
      "Train Epoch: 9 [16768/60000 (28%)]\tLoss: 1.043111\n",
      "Train Epoch: 9 [16896/60000 (28%)]\tLoss: 0.999762\n",
      "Train Epoch: 9 [17024/60000 (28%)]\tLoss: 1.043345\n",
      "Train Epoch: 9 [17152/60000 (29%)]\tLoss: 0.900646\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.683761\n",
      "Train Epoch: 9 [17408/60000 (29%)]\tLoss: 0.963711\n",
      "Train Epoch: 9 [17536/60000 (29%)]\tLoss: 1.063155\n",
      "Train Epoch: 9 [17664/60000 (29%)]\tLoss: 0.897509\n",
      "Train Epoch: 9 [17792/60000 (30%)]\tLoss: 0.950014\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.778842\n",
      "Train Epoch: 9 [18048/60000 (30%)]\tLoss: 0.770992\n",
      "Train Epoch: 9 [18176/60000 (30%)]\tLoss: 0.658780\n",
      "Train Epoch: 9 [18304/60000 (31%)]\tLoss: 0.887367\n",
      "Train Epoch: 9 [18432/60000 (31%)]\tLoss: 0.778033\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.889439\n",
      "Train Epoch: 9 [18688/60000 (31%)]\tLoss: 0.856001\n",
      "Train Epoch: 9 [18816/60000 (31%)]\tLoss: 0.711151\n",
      "Train Epoch: 9 [18944/60000 (32%)]\tLoss: 0.989883\n",
      "Train Epoch: 9 [19072/60000 (32%)]\tLoss: 1.011763\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.903787\n",
      "Train Epoch: 9 [19328/60000 (32%)]\tLoss: 0.879456\n",
      "Train Epoch: 9 [19456/60000 (32%)]\tLoss: 0.950621\n",
      "Train Epoch: 9 [19584/60000 (33%)]\tLoss: 0.746122\n",
      "Train Epoch: 9 [19712/60000 (33%)]\tLoss: 0.745517\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.837939\n",
      "Train Epoch: 9 [19968/60000 (33%)]\tLoss: 0.986570\n",
      "Train Epoch: 9 [20096/60000 (34%)]\tLoss: 0.931160\n",
      "Train Epoch: 9 [20224/60000 (34%)]\tLoss: 0.927079\n",
      "Train Epoch: 9 [20352/60000 (34%)]\tLoss: 0.674254\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.900968\n",
      "Train Epoch: 9 [20608/60000 (34%)]\tLoss: 0.975222\n",
      "Train Epoch: 9 [20736/60000 (35%)]\tLoss: 1.075459\n",
      "Train Epoch: 9 [20864/60000 (35%)]\tLoss: 1.120014\n",
      "Train Epoch: 9 [20992/60000 (35%)]\tLoss: 0.729808\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.864692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [21248/60000 (35%)]\tLoss: 0.816383\n",
      "Train Epoch: 9 [21376/60000 (36%)]\tLoss: 0.907150\n",
      "Train Epoch: 9 [21504/60000 (36%)]\tLoss: 0.970526\n",
      "Train Epoch: 9 [21632/60000 (36%)]\tLoss: 0.882759\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.594517\n",
      "Train Epoch: 9 [21888/60000 (37%)]\tLoss: 0.712533\n",
      "Train Epoch: 9 [22016/60000 (37%)]\tLoss: 0.885149\n",
      "Train Epoch: 9 [22144/60000 (37%)]\tLoss: 0.925642\n",
      "Train Epoch: 9 [22272/60000 (37%)]\tLoss: 0.809460\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.964160\n",
      "Train Epoch: 9 [22528/60000 (38%)]\tLoss: 1.155730\n",
      "Train Epoch: 9 [22656/60000 (38%)]\tLoss: 0.903325\n",
      "Train Epoch: 9 [22784/60000 (38%)]\tLoss: 0.796273\n",
      "Train Epoch: 9 [22912/60000 (38%)]\tLoss: 0.675368\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.849849\n",
      "Train Epoch: 9 [23168/60000 (39%)]\tLoss: 0.858223\n",
      "Train Epoch: 9 [23296/60000 (39%)]\tLoss: 0.837628\n",
      "Train Epoch: 9 [23424/60000 (39%)]\tLoss: 0.759517\n",
      "Train Epoch: 9 [23552/60000 (39%)]\tLoss: 0.853977\n",
      "Train Epoch: 9 [23680/60000 (40%)]\tLoss: 0.871801\n",
      "Train Epoch: 9 [23808/60000 (40%)]\tLoss: 0.983113\n",
      "Train Epoch: 9 [23936/60000 (40%)]\tLoss: 0.957289\n",
      "Train Epoch: 9 [24064/60000 (40%)]\tLoss: 0.742163\n",
      "Train Epoch: 9 [24192/60000 (40%)]\tLoss: 0.966714\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.805400\n",
      "Train Epoch: 9 [24448/60000 (41%)]\tLoss: 0.897873\n",
      "Train Epoch: 9 [24576/60000 (41%)]\tLoss: 0.873640\n",
      "Train Epoch: 9 [24704/60000 (41%)]\tLoss: 1.092887\n",
      "Train Epoch: 9 [24832/60000 (41%)]\tLoss: 1.096862\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.739292\n",
      "Train Epoch: 9 [25088/60000 (42%)]\tLoss: 0.891723\n",
      "Train Epoch: 9 [25216/60000 (42%)]\tLoss: 0.790844\n",
      "Train Epoch: 9 [25344/60000 (42%)]\tLoss: 0.616956\n",
      "Train Epoch: 9 [25472/60000 (43%)]\tLoss: 0.912841\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.881248\n",
      "Train Epoch: 9 [25728/60000 (43%)]\tLoss: 0.917913\n",
      "Train Epoch: 9 [25856/60000 (43%)]\tLoss: 0.840348\n",
      "Train Epoch: 9 [25984/60000 (43%)]\tLoss: 0.808480\n",
      "Train Epoch: 9 [26112/60000 (44%)]\tLoss: 0.775638\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.804956\n",
      "Train Epoch: 9 [26368/60000 (44%)]\tLoss: 0.985102\n",
      "Train Epoch: 9 [26496/60000 (44%)]\tLoss: 0.859220\n",
      "Train Epoch: 9 [26624/60000 (44%)]\tLoss: 1.016592\n",
      "Train Epoch: 9 [26752/60000 (45%)]\tLoss: 0.866946\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.709282\n",
      "Train Epoch: 9 [27008/60000 (45%)]\tLoss: 0.918542\n",
      "Train Epoch: 9 [27136/60000 (45%)]\tLoss: 1.050795\n",
      "Train Epoch: 9 [27264/60000 (46%)]\tLoss: 0.875088\n",
      "Train Epoch: 9 [27392/60000 (46%)]\tLoss: 0.877350\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.873796\n",
      "Train Epoch: 9 [27648/60000 (46%)]\tLoss: 0.927357\n",
      "Train Epoch: 9 [27776/60000 (46%)]\tLoss: 0.878208\n",
      "Train Epoch: 9 [27904/60000 (47%)]\tLoss: 0.802671\n",
      "Train Epoch: 9 [28032/60000 (47%)]\tLoss: 0.744971\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.899930\n",
      "Train Epoch: 9 [28288/60000 (47%)]\tLoss: 0.904085\n",
      "Train Epoch: 9 [28416/60000 (47%)]\tLoss: 0.862696\n",
      "Train Epoch: 9 [28544/60000 (48%)]\tLoss: 1.081362\n",
      "Train Epoch: 9 [28672/60000 (48%)]\tLoss: 0.934744\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.697869\n",
      "Train Epoch: 9 [28928/60000 (48%)]\tLoss: 0.881419\n",
      "Train Epoch: 9 [29056/60000 (49%)]\tLoss: 1.005790\n",
      "Train Epoch: 9 [29184/60000 (49%)]\tLoss: 0.812661\n",
      "Train Epoch: 9 [29312/60000 (49%)]\tLoss: 0.962996\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.649932\n",
      "Train Epoch: 9 [29568/60000 (49%)]\tLoss: 0.792489\n",
      "Train Epoch: 9 [29696/60000 (50%)]\tLoss: 0.956676\n",
      "Train Epoch: 9 [29824/60000 (50%)]\tLoss: 0.940589\n",
      "Train Epoch: 9 [29952/60000 (50%)]\tLoss: 1.006889\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.992038\n",
      "Train Epoch: 9 [30208/60000 (50%)]\tLoss: 0.785894\n",
      "Train Epoch: 9 [30336/60000 (51%)]\tLoss: 0.813488\n",
      "Train Epoch: 9 [30464/60000 (51%)]\tLoss: 0.930725\n",
      "Train Epoch: 9 [30592/60000 (51%)]\tLoss: 1.045290\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.840576\n",
      "Train Epoch: 9 [30848/60000 (51%)]\tLoss: 1.016495\n",
      "Train Epoch: 9 [30976/60000 (52%)]\tLoss: 0.853911\n",
      "Train Epoch: 9 [31104/60000 (52%)]\tLoss: 0.946132\n",
      "Train Epoch: 9 [31232/60000 (52%)]\tLoss: 0.937837\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 1.017180\n",
      "Train Epoch: 9 [31488/60000 (53%)]\tLoss: 0.741663\n",
      "Train Epoch: 9 [31616/60000 (53%)]\tLoss: 1.242036\n",
      "Train Epoch: 9 [31744/60000 (53%)]\tLoss: 0.866818\n",
      "Train Epoch: 9 [31872/60000 (53%)]\tLoss: 0.892666\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.872422\n",
      "Train Epoch: 9 [32128/60000 (54%)]\tLoss: 0.884618\n",
      "Train Epoch: 9 [32256/60000 (54%)]\tLoss: 1.023564\n",
      "Train Epoch: 9 [32384/60000 (54%)]\tLoss: 1.133383\n",
      "Train Epoch: 9 [32512/60000 (54%)]\tLoss: 0.737651\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.677575\n",
      "Train Epoch: 9 [32768/60000 (55%)]\tLoss: 0.952422\n",
      "Train Epoch: 9 [32896/60000 (55%)]\tLoss: 0.786773\n",
      "Train Epoch: 9 [33024/60000 (55%)]\tLoss: 0.848300\n",
      "Train Epoch: 9 [33152/60000 (55%)]\tLoss: 0.816437\n",
      "Train Epoch: 9 [33280/60000 (56%)]\tLoss: 0.769591\n",
      "Train Epoch: 9 [33408/60000 (56%)]\tLoss: 0.934168\n",
      "Train Epoch: 9 [33536/60000 (56%)]\tLoss: 0.800983\n",
      "Train Epoch: 9 [33664/60000 (56%)]\tLoss: 0.809622\n",
      "Train Epoch: 9 [33792/60000 (56%)]\tLoss: 0.692238\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.797263\n",
      "Train Epoch: 9 [34048/60000 (57%)]\tLoss: 0.828936\n",
      "Train Epoch: 9 [34176/60000 (57%)]\tLoss: 0.731798\n",
      "Train Epoch: 9 [34304/60000 (57%)]\tLoss: 0.897292\n",
      "Train Epoch: 9 [34432/60000 (57%)]\tLoss: 0.860534\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 1.049117\n",
      "Train Epoch: 9 [34688/60000 (58%)]\tLoss: 0.992773\n",
      "Train Epoch: 9 [34816/60000 (58%)]\tLoss: 1.070712\n",
      "Train Epoch: 9 [34944/60000 (58%)]\tLoss: 0.916463\n",
      "Train Epoch: 9 [35072/60000 (59%)]\tLoss: 0.804653\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.831868\n",
      "Train Epoch: 9 [35328/60000 (59%)]\tLoss: 0.700304\n",
      "Train Epoch: 9 [35456/60000 (59%)]\tLoss: 0.809247\n",
      "Train Epoch: 9 [35584/60000 (59%)]\tLoss: 0.866583\n",
      "Train Epoch: 9 [35712/60000 (60%)]\tLoss: 0.771217\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.747369\n",
      "Train Epoch: 9 [35968/60000 (60%)]\tLoss: 0.960256\n",
      "Train Epoch: 9 [36096/60000 (60%)]\tLoss: 0.881741\n",
      "Train Epoch: 9 [36224/60000 (60%)]\tLoss: 0.753062\n",
      "Train Epoch: 9 [36352/60000 (61%)]\tLoss: 0.873492\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.861031\n",
      "Train Epoch: 9 [36608/60000 (61%)]\tLoss: 0.840984\n",
      "Train Epoch: 9 [36736/60000 (61%)]\tLoss: 0.809681\n",
      "Train Epoch: 9 [36864/60000 (62%)]\tLoss: 0.835385\n",
      "Train Epoch: 9 [36992/60000 (62%)]\tLoss: 1.095000\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.871322\n",
      "Train Epoch: 9 [37248/60000 (62%)]\tLoss: 1.094231\n",
      "Train Epoch: 9 [37376/60000 (62%)]\tLoss: 1.136550\n",
      "Train Epoch: 9 [37504/60000 (63%)]\tLoss: 0.903190\n",
      "Train Epoch: 9 [37632/60000 (63%)]\tLoss: 0.832065\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.747148\n",
      "Train Epoch: 9 [37888/60000 (63%)]\tLoss: 0.868290\n",
      "Train Epoch: 9 [38016/60000 (63%)]\tLoss: 0.794749\n",
      "Train Epoch: 9 [38144/60000 (64%)]\tLoss: 1.004012\n",
      "Train Epoch: 9 [38272/60000 (64%)]\tLoss: 1.003214\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.686183\n",
      "Train Epoch: 9 [38528/60000 (64%)]\tLoss: 0.947844\n",
      "Train Epoch: 9 [38656/60000 (65%)]\tLoss: 0.944985\n",
      "Train Epoch: 9 [38784/60000 (65%)]\tLoss: 0.682558\n",
      "Train Epoch: 9 [38912/60000 (65%)]\tLoss: 0.925022\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.740569\n",
      "Train Epoch: 9 [39168/60000 (65%)]\tLoss: 0.842741\n",
      "Train Epoch: 9 [39296/60000 (66%)]\tLoss: 1.005414\n",
      "Train Epoch: 9 [39424/60000 (66%)]\tLoss: 1.018011\n",
      "Train Epoch: 9 [39552/60000 (66%)]\tLoss: 0.911287\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.993140\n",
      "Train Epoch: 9 [39808/60000 (66%)]\tLoss: 1.004425\n",
      "Train Epoch: 9 [39936/60000 (67%)]\tLoss: 0.730908\n",
      "Train Epoch: 9 [40064/60000 (67%)]\tLoss: 0.848365\n",
      "Train Epoch: 9 [40192/60000 (67%)]\tLoss: 0.900127\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.853540\n",
      "Train Epoch: 9 [40448/60000 (68%)]\tLoss: 0.736305\n",
      "Train Epoch: 9 [40576/60000 (68%)]\tLoss: 0.827988\n",
      "Train Epoch: 9 [40704/60000 (68%)]\tLoss: 0.824688\n",
      "Train Epoch: 9 [40832/60000 (68%)]\tLoss: 0.758494\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.845151\n",
      "Train Epoch: 9 [41088/60000 (69%)]\tLoss: 0.752604\n",
      "Train Epoch: 9 [41216/60000 (69%)]\tLoss: 1.230292\n",
      "Train Epoch: 9 [41344/60000 (69%)]\tLoss: 1.008136\n",
      "Train Epoch: 9 [41472/60000 (69%)]\tLoss: 1.031152\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.835109\n",
      "Train Epoch: 9 [41728/60000 (70%)]\tLoss: 0.836890\n",
      "Train Epoch: 9 [41856/60000 (70%)]\tLoss: 0.832800\n",
      "Train Epoch: 9 [41984/60000 (70%)]\tLoss: 0.894894\n",
      "Train Epoch: 9 [42112/60000 (70%)]\tLoss: 0.964661\n",
      "Train Epoch: 9 [42240/60000 (71%)]\tLoss: 1.075485\n",
      "Train Epoch: 9 [42368/60000 (71%)]\tLoss: 0.952742\n",
      "Train Epoch: 9 [42496/60000 (71%)]\tLoss: 0.923226\n",
      "Train Epoch: 9 [42624/60000 (71%)]\tLoss: 0.925851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [42752/60000 (71%)]\tLoss: 0.975184\n",
      "Train Epoch: 9 [42880/60000 (72%)]\tLoss: 1.004514\n",
      "Train Epoch: 9 [43008/60000 (72%)]\tLoss: 1.082426\n",
      "Train Epoch: 9 [43136/60000 (72%)]\tLoss: 0.844962\n",
      "Train Epoch: 9 [43264/60000 (72%)]\tLoss: 0.717296\n",
      "Train Epoch: 9 [43392/60000 (72%)]\tLoss: 0.690689\n",
      "Train Epoch: 9 [43520/60000 (73%)]\tLoss: 0.671771\n",
      "Train Epoch: 9 [43648/60000 (73%)]\tLoss: 0.942545\n",
      "Train Epoch: 9 [43776/60000 (73%)]\tLoss: 0.965612\n",
      "Train Epoch: 9 [43904/60000 (73%)]\tLoss: 0.884820\n",
      "Train Epoch: 9 [44032/60000 (74%)]\tLoss: 0.861668\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.986639\n",
      "Train Epoch: 9 [44288/60000 (74%)]\tLoss: 0.834007\n",
      "Train Epoch: 9 [44416/60000 (74%)]\tLoss: 1.026369\n",
      "Train Epoch: 9 [44544/60000 (74%)]\tLoss: 0.586651\n",
      "Train Epoch: 9 [44672/60000 (75%)]\tLoss: 0.829755\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.926782\n",
      "Train Epoch: 9 [44928/60000 (75%)]\tLoss: 0.913379\n",
      "Train Epoch: 9 [45056/60000 (75%)]\tLoss: 0.925028\n",
      "Train Epoch: 9 [45184/60000 (75%)]\tLoss: 0.655592\n",
      "Train Epoch: 9 [45312/60000 (76%)]\tLoss: 0.902141\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.929961\n",
      "Train Epoch: 9 [45568/60000 (76%)]\tLoss: 0.873852\n",
      "Train Epoch: 9 [45696/60000 (76%)]\tLoss: 0.848891\n",
      "Train Epoch: 9 [45824/60000 (76%)]\tLoss: 0.977990\n",
      "Train Epoch: 9 [45952/60000 (77%)]\tLoss: 1.039698\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.848175\n",
      "Train Epoch: 9 [46208/60000 (77%)]\tLoss: 1.020797\n",
      "Train Epoch: 9 [46336/60000 (77%)]\tLoss: 0.830852\n",
      "Train Epoch: 9 [46464/60000 (78%)]\tLoss: 0.738997\n",
      "Train Epoch: 9 [46592/60000 (78%)]\tLoss: 0.772683\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.789234\n",
      "Train Epoch: 9 [46848/60000 (78%)]\tLoss: 0.744426\n",
      "Train Epoch: 9 [46976/60000 (78%)]\tLoss: 0.848316\n",
      "Train Epoch: 9 [47104/60000 (79%)]\tLoss: 0.700893\n",
      "Train Epoch: 9 [47232/60000 (79%)]\tLoss: 0.966539\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.958384\n",
      "Train Epoch: 9 [47488/60000 (79%)]\tLoss: 0.955963\n",
      "Train Epoch: 9 [47616/60000 (79%)]\tLoss: 0.768486\n",
      "Train Epoch: 9 [47744/60000 (80%)]\tLoss: 0.762826\n",
      "Train Epoch: 9 [47872/60000 (80%)]\tLoss: 0.956916\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.793205\n",
      "Train Epoch: 9 [48128/60000 (80%)]\tLoss: 0.654168\n",
      "Train Epoch: 9 [48256/60000 (81%)]\tLoss: 0.807397\n",
      "Train Epoch: 9 [48384/60000 (81%)]\tLoss: 0.801476\n",
      "Train Epoch: 9 [48512/60000 (81%)]\tLoss: 0.771721\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.852241\n",
      "Train Epoch: 9 [48768/60000 (81%)]\tLoss: 0.622432\n",
      "Train Epoch: 9 [48896/60000 (82%)]\tLoss: 1.078344\n",
      "Train Epoch: 9 [49024/60000 (82%)]\tLoss: 0.981892\n",
      "Train Epoch: 9 [49152/60000 (82%)]\tLoss: 0.940994\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.613986\n",
      "Train Epoch: 9 [49408/60000 (82%)]\tLoss: 1.014259\n",
      "Train Epoch: 9 [49536/60000 (83%)]\tLoss: 1.133240\n",
      "Train Epoch: 9 [49664/60000 (83%)]\tLoss: 0.741205\n",
      "Train Epoch: 9 [49792/60000 (83%)]\tLoss: 0.971075\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.853960\n",
      "Train Epoch: 9 [50048/60000 (84%)]\tLoss: 1.032103\n",
      "Train Epoch: 9 [50176/60000 (84%)]\tLoss: 1.005606\n",
      "Train Epoch: 9 [50304/60000 (84%)]\tLoss: 1.399033\n",
      "Train Epoch: 9 [50432/60000 (84%)]\tLoss: 0.834052\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.901562\n",
      "Train Epoch: 9 [50688/60000 (85%)]\tLoss: 1.138393\n",
      "Train Epoch: 9 [50816/60000 (85%)]\tLoss: 0.806780\n",
      "Train Epoch: 9 [50944/60000 (85%)]\tLoss: 0.701988\n",
      "Train Epoch: 9 [51072/60000 (85%)]\tLoss: 0.866840\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.907537\n",
      "Train Epoch: 9 [51328/60000 (86%)]\tLoss: 0.737983\n",
      "Train Epoch: 9 [51456/60000 (86%)]\tLoss: 0.820993\n",
      "Train Epoch: 9 [51584/60000 (86%)]\tLoss: 0.667772\n",
      "Train Epoch: 9 [51712/60000 (86%)]\tLoss: 0.810422\n",
      "Train Epoch: 9 [51840/60000 (87%)]\tLoss: 0.817338\n",
      "Train Epoch: 9 [51968/60000 (87%)]\tLoss: 0.978536\n",
      "Train Epoch: 9 [52096/60000 (87%)]\tLoss: 1.052821\n",
      "Train Epoch: 9 [52224/60000 (87%)]\tLoss: 0.841898\n",
      "Train Epoch: 9 [52352/60000 (87%)]\tLoss: 0.709237\n",
      "Train Epoch: 9 [52480/60000 (88%)]\tLoss: 0.572554\n",
      "Train Epoch: 9 [52608/60000 (88%)]\tLoss: 0.910480\n",
      "Train Epoch: 9 [52736/60000 (88%)]\tLoss: 1.000309\n",
      "Train Epoch: 9 [52864/60000 (88%)]\tLoss: 1.202826\n",
      "Train Epoch: 9 [52992/60000 (88%)]\tLoss: 0.851291\n",
      "Train Epoch: 9 [53120/60000 (89%)]\tLoss: 0.910487\n",
      "Train Epoch: 9 [53248/60000 (89%)]\tLoss: 0.660380\n",
      "Train Epoch: 9 [53376/60000 (89%)]\tLoss: 0.723542\n",
      "Train Epoch: 9 [53504/60000 (89%)]\tLoss: 0.893774\n",
      "Train Epoch: 9 [53632/60000 (90%)]\tLoss: 0.763987\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.843965\n",
      "Train Epoch: 9 [53888/60000 (90%)]\tLoss: 0.857447\n",
      "Train Epoch: 9 [54016/60000 (90%)]\tLoss: 0.762577\n",
      "Train Epoch: 9 [54144/60000 (90%)]\tLoss: 0.674625\n",
      "Train Epoch: 9 [54272/60000 (91%)]\tLoss: 0.821908\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.763162\n",
      "Train Epoch: 9 [54528/60000 (91%)]\tLoss: 0.811036\n",
      "Train Epoch: 9 [54656/60000 (91%)]\tLoss: 0.686196\n",
      "Train Epoch: 9 [54784/60000 (91%)]\tLoss: 0.947791\n",
      "Train Epoch: 9 [54912/60000 (92%)]\tLoss: 1.003790\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.824139\n",
      "Train Epoch: 9 [55168/60000 (92%)]\tLoss: 0.812125\n",
      "Train Epoch: 9 [55296/60000 (92%)]\tLoss: 0.679452\n",
      "Train Epoch: 9 [55424/60000 (93%)]\tLoss: 0.710635\n",
      "Train Epoch: 9 [55552/60000 (93%)]\tLoss: 0.752085\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.743069\n",
      "Train Epoch: 9 [55808/60000 (93%)]\tLoss: 0.734133\n",
      "Train Epoch: 9 [55936/60000 (93%)]\tLoss: 0.791480\n",
      "Train Epoch: 9 [56064/60000 (94%)]\tLoss: 0.778450\n",
      "Train Epoch: 9 [56192/60000 (94%)]\tLoss: 0.987954\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.791995\n",
      "Train Epoch: 9 [56448/60000 (94%)]\tLoss: 0.964779\n",
      "Train Epoch: 9 [56576/60000 (94%)]\tLoss: 0.812170\n",
      "Train Epoch: 9 [56704/60000 (95%)]\tLoss: 0.719250\n",
      "Train Epoch: 9 [56832/60000 (95%)]\tLoss: 0.763645\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.894873\n",
      "Train Epoch: 9 [57088/60000 (95%)]\tLoss: 0.783551\n",
      "Train Epoch: 9 [57216/60000 (96%)]\tLoss: 1.058852\n",
      "Train Epoch: 9 [57344/60000 (96%)]\tLoss: 0.911550\n",
      "Train Epoch: 9 [57472/60000 (96%)]\tLoss: 0.826635\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.978515\n",
      "Train Epoch: 9 [57728/60000 (96%)]\tLoss: 0.877854\n",
      "Train Epoch: 9 [57856/60000 (97%)]\tLoss: 0.720691\n",
      "Train Epoch: 9 [57984/60000 (97%)]\tLoss: 0.813523\n",
      "Train Epoch: 9 [58112/60000 (97%)]\tLoss: 0.547444\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.725671\n",
      "Train Epoch: 9 [58368/60000 (97%)]\tLoss: 0.719881\n",
      "Train Epoch: 9 [58496/60000 (98%)]\tLoss: 0.710307\n",
      "Train Epoch: 9 [58624/60000 (98%)]\tLoss: 0.588578\n",
      "Train Epoch: 9 [58752/60000 (98%)]\tLoss: 0.834925\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.494075\n",
      "Train Epoch: 9 [59008/60000 (99%)]\tLoss: 0.607847\n",
      "Train Epoch: 9 [59136/60000 (99%)]\tLoss: 0.502260\n",
      "Train Epoch: 9 [59264/60000 (99%)]\tLoss: 0.986297\n",
      "Train Epoch: 9 [59392/60000 (99%)]\tLoss: 0.737252\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.637046\n",
      "Train Epoch: 9 [59648/60000 (100%)]\tLoss: 1.095796\n",
      "Train Epoch: 9 [59776/60000 (100%)]\tLoss: 0.603215\n",
      "================================================================\n",
      "Training: Average loss: 0.2773, Accuracy: 55545/60000 (93%)\n",
      "Test: Average loss: 0.2619, Accuracy: 9288/10000 (93%)\n",
      "================================================================\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.743218\n",
      "Train Epoch: 10 [128/60000 (0%)]\tLoss: 0.895491\n",
      "Train Epoch: 10 [256/60000 (0%)]\tLoss: 0.793303\n",
      "Train Epoch: 10 [384/60000 (1%)]\tLoss: 0.861158\n",
      "Train Epoch: 10 [512/60000 (1%)]\tLoss: 0.758650\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.731485\n",
      "Train Epoch: 10 [768/60000 (1%)]\tLoss: 0.860109\n",
      "Train Epoch: 10 [896/60000 (1%)]\tLoss: 0.836231\n",
      "Train Epoch: 10 [1024/60000 (2%)]\tLoss: 1.182588\n",
      "Train Epoch: 10 [1152/60000 (2%)]\tLoss: 0.886384\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.972295\n",
      "Train Epoch: 10 [1408/60000 (2%)]\tLoss: 0.852641\n",
      "Train Epoch: 10 [1536/60000 (3%)]\tLoss: 0.951593\n",
      "Train Epoch: 10 [1664/60000 (3%)]\tLoss: 0.575484\n",
      "Train Epoch: 10 [1792/60000 (3%)]\tLoss: 0.679991\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.773892\n",
      "Train Epoch: 10 [2048/60000 (3%)]\tLoss: 0.731608\n",
      "Train Epoch: 10 [2176/60000 (4%)]\tLoss: 0.658493\n",
      "Train Epoch: 10 [2304/60000 (4%)]\tLoss: 0.918844\n",
      "Train Epoch: 10 [2432/60000 (4%)]\tLoss: 0.720805\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.876108\n",
      "Train Epoch: 10 [2688/60000 (4%)]\tLoss: 0.826823\n",
      "Train Epoch: 10 [2816/60000 (5%)]\tLoss: 0.759742\n",
      "Train Epoch: 10 [2944/60000 (5%)]\tLoss: 0.884730\n",
      "Train Epoch: 10 [3072/60000 (5%)]\tLoss: 0.724067\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.747758\n",
      "Train Epoch: 10 [3328/60000 (6%)]\tLoss: 0.836987\n",
      "Train Epoch: 10 [3456/60000 (6%)]\tLoss: 0.837826\n",
      "Train Epoch: 10 [3584/60000 (6%)]\tLoss: 0.868994\n",
      "Train Epoch: 10 [3712/60000 (6%)]\tLoss: 0.905176\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.717353\n",
      "Train Epoch: 10 [3968/60000 (7%)]\tLoss: 0.839302\n",
      "Train Epoch: 10 [4096/60000 (7%)]\tLoss: 0.799994\n",
      "Train Epoch: 10 [4224/60000 (7%)]\tLoss: 0.772066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [4352/60000 (7%)]\tLoss: 0.772268\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.846602\n",
      "Train Epoch: 10 [4608/60000 (8%)]\tLoss: 0.865307\n",
      "Train Epoch: 10 [4736/60000 (8%)]\tLoss: 0.792320\n",
      "Train Epoch: 10 [4864/60000 (8%)]\tLoss: 0.944879\n",
      "Train Epoch: 10 [4992/60000 (8%)]\tLoss: 0.812102\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.847820\n",
      "Train Epoch: 10 [5248/60000 (9%)]\tLoss: 0.872395\n",
      "Train Epoch: 10 [5376/60000 (9%)]\tLoss: 0.697886\n",
      "Train Epoch: 10 [5504/60000 (9%)]\tLoss: 0.893446\n",
      "Train Epoch: 10 [5632/60000 (9%)]\tLoss: 0.920152\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.855448\n",
      "Train Epoch: 10 [5888/60000 (10%)]\tLoss: 0.695593\n",
      "Train Epoch: 10 [6016/60000 (10%)]\tLoss: 0.589952\n",
      "Train Epoch: 10 [6144/60000 (10%)]\tLoss: 0.766556\n",
      "Train Epoch: 10 [6272/60000 (10%)]\tLoss: 0.769606\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.963921\n",
      "Train Epoch: 10 [6528/60000 (11%)]\tLoss: 0.727961\n",
      "Train Epoch: 10 [6656/60000 (11%)]\tLoss: 0.744731\n",
      "Train Epoch: 10 [6784/60000 (11%)]\tLoss: 0.845074\n",
      "Train Epoch: 10 [6912/60000 (12%)]\tLoss: 1.005510\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.867614\n",
      "Train Epoch: 10 [7168/60000 (12%)]\tLoss: 1.120693\n",
      "Train Epoch: 10 [7296/60000 (12%)]\tLoss: 0.857919\n",
      "Train Epoch: 10 [7424/60000 (12%)]\tLoss: 0.796210\n",
      "Train Epoch: 10 [7552/60000 (13%)]\tLoss: 0.776797\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.834221\n",
      "Train Epoch: 10 [7808/60000 (13%)]\tLoss: 0.901614\n",
      "Train Epoch: 10 [7936/60000 (13%)]\tLoss: 0.886828\n",
      "Train Epoch: 10 [8064/60000 (13%)]\tLoss: 0.815077\n",
      "Train Epoch: 10 [8192/60000 (14%)]\tLoss: 1.062810\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.869714\n",
      "Train Epoch: 10 [8448/60000 (14%)]\tLoss: 0.858212\n",
      "Train Epoch: 10 [8576/60000 (14%)]\tLoss: 0.875013\n",
      "Train Epoch: 10 [8704/60000 (15%)]\tLoss: 1.105940\n",
      "Train Epoch: 10 [8832/60000 (15%)]\tLoss: 1.093044\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.646707\n",
      "Train Epoch: 10 [9088/60000 (15%)]\tLoss: 0.800375\n",
      "Train Epoch: 10 [9216/60000 (15%)]\tLoss: 0.782184\n",
      "Train Epoch: 10 [9344/60000 (16%)]\tLoss: 0.924283\n",
      "Train Epoch: 10 [9472/60000 (16%)]\tLoss: 0.929604\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.719807\n",
      "Train Epoch: 10 [9728/60000 (16%)]\tLoss: 0.716945\n",
      "Train Epoch: 10 [9856/60000 (16%)]\tLoss: 0.731312\n",
      "Train Epoch: 10 [9984/60000 (17%)]\tLoss: 0.862267\n",
      "Train Epoch: 10 [10112/60000 (17%)]\tLoss: 0.959129\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.932213\n",
      "Train Epoch: 10 [10368/60000 (17%)]\tLoss: 0.700883\n",
      "Train Epoch: 10 [10496/60000 (18%)]\tLoss: 0.759853\n",
      "Train Epoch: 10 [10624/60000 (18%)]\tLoss: 0.687237\n",
      "Train Epoch: 10 [10752/60000 (18%)]\tLoss: 0.863002\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.837530\n",
      "Train Epoch: 10 [11008/60000 (18%)]\tLoss: 0.682351\n",
      "Train Epoch: 10 [11136/60000 (19%)]\tLoss: 0.833526\n",
      "Train Epoch: 10 [11264/60000 (19%)]\tLoss: 0.788564\n",
      "Train Epoch: 10 [11392/60000 (19%)]\tLoss: 0.855804\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.989852\n",
      "Train Epoch: 10 [11648/60000 (19%)]\tLoss: 1.048313\n",
      "Train Epoch: 10 [11776/60000 (20%)]\tLoss: 0.868774\n",
      "Train Epoch: 10 [11904/60000 (20%)]\tLoss: 0.799124\n",
      "Train Epoch: 10 [12032/60000 (20%)]\tLoss: 0.766968\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.897544\n",
      "Train Epoch: 10 [12288/60000 (21%)]\tLoss: 0.954688\n",
      "Train Epoch: 10 [12416/60000 (21%)]\tLoss: 0.743050\n",
      "Train Epoch: 10 [12544/60000 (21%)]\tLoss: 0.982909\n",
      "Train Epoch: 10 [12672/60000 (21%)]\tLoss: 0.806994\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.774512\n",
      "Train Epoch: 10 [12928/60000 (22%)]\tLoss: 1.133021\n",
      "Train Epoch: 10 [13056/60000 (22%)]\tLoss: 1.088708\n",
      "Train Epoch: 10 [13184/60000 (22%)]\tLoss: 0.644801\n",
      "Train Epoch: 10 [13312/60000 (22%)]\tLoss: 0.863128\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.744572\n",
      "Train Epoch: 10 [13568/60000 (23%)]\tLoss: 0.744936\n",
      "Train Epoch: 10 [13696/60000 (23%)]\tLoss: 0.883620\n",
      "Train Epoch: 10 [13824/60000 (23%)]\tLoss: 0.983808\n",
      "Train Epoch: 10 [13952/60000 (23%)]\tLoss: 1.031704\n",
      "Train Epoch: 10 [14080/60000 (24%)]\tLoss: 0.979513\n",
      "Train Epoch: 10 [14208/60000 (24%)]\tLoss: 1.203412\n",
      "Train Epoch: 10 [14336/60000 (24%)]\tLoss: 0.989082\n",
      "Train Epoch: 10 [14464/60000 (24%)]\tLoss: 0.918020\n",
      "Train Epoch: 10 [14592/60000 (24%)]\tLoss: 1.117373\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 1.258591\n",
      "Train Epoch: 10 [14848/60000 (25%)]\tLoss: 0.713315\n",
      "Train Epoch: 10 [14976/60000 (25%)]\tLoss: 0.666253\n",
      "Train Epoch: 10 [15104/60000 (25%)]\tLoss: 0.990631\n",
      "Train Epoch: 10 [15232/60000 (25%)]\tLoss: 0.767483\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.656993\n",
      "Train Epoch: 10 [15488/60000 (26%)]\tLoss: 0.640273\n",
      "Train Epoch: 10 [15616/60000 (26%)]\tLoss: 0.830775\n",
      "Train Epoch: 10 [15744/60000 (26%)]\tLoss: 0.911656\n",
      "Train Epoch: 10 [15872/60000 (26%)]\tLoss: 0.827364\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 1.048665\n",
      "Train Epoch: 10 [16128/60000 (27%)]\tLoss: 0.867923\n",
      "Train Epoch: 10 [16256/60000 (27%)]\tLoss: 0.796034\n",
      "Train Epoch: 10 [16384/60000 (27%)]\tLoss: 0.661254\n",
      "Train Epoch: 10 [16512/60000 (28%)]\tLoss: 0.846864\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.840948\n",
      "Train Epoch: 10 [16768/60000 (28%)]\tLoss: 1.015096\n",
      "Train Epoch: 10 [16896/60000 (28%)]\tLoss: 0.897120\n",
      "Train Epoch: 10 [17024/60000 (28%)]\tLoss: 0.941981\n",
      "Train Epoch: 10 [17152/60000 (29%)]\tLoss: 0.944722\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.782782\n",
      "Train Epoch: 10 [17408/60000 (29%)]\tLoss: 0.808483\n",
      "Train Epoch: 10 [17536/60000 (29%)]\tLoss: 1.048200\n",
      "Train Epoch: 10 [17664/60000 (29%)]\tLoss: 0.907455\n",
      "Train Epoch: 10 [17792/60000 (30%)]\tLoss: 0.852971\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.756250\n",
      "Train Epoch: 10 [18048/60000 (30%)]\tLoss: 0.817209\n",
      "Train Epoch: 10 [18176/60000 (30%)]\tLoss: 0.587676\n",
      "Train Epoch: 10 [18304/60000 (31%)]\tLoss: 0.722003\n",
      "Train Epoch: 10 [18432/60000 (31%)]\tLoss: 0.802284\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.754894\n",
      "Train Epoch: 10 [18688/60000 (31%)]\tLoss: 0.783289\n",
      "Train Epoch: 10 [18816/60000 (31%)]\tLoss: 0.787679\n",
      "Train Epoch: 10 [18944/60000 (32%)]\tLoss: 0.735252\n",
      "Train Epoch: 10 [19072/60000 (32%)]\tLoss: 0.901432\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.960228\n",
      "Train Epoch: 10 [19328/60000 (32%)]\tLoss: 0.843859\n",
      "Train Epoch: 10 [19456/60000 (32%)]\tLoss: 0.745788\n",
      "Train Epoch: 10 [19584/60000 (33%)]\tLoss: 0.712846\n",
      "Train Epoch: 10 [19712/60000 (33%)]\tLoss: 0.591511\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.783412\n",
      "Train Epoch: 10 [19968/60000 (33%)]\tLoss: 0.858907\n",
      "Train Epoch: 10 [20096/60000 (34%)]\tLoss: 1.055690\n",
      "Train Epoch: 10 [20224/60000 (34%)]\tLoss: 0.814340\n",
      "Train Epoch: 10 [20352/60000 (34%)]\tLoss: 0.637520\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.763203\n",
      "Train Epoch: 10 [20608/60000 (34%)]\tLoss: 0.998159\n",
      "Train Epoch: 10 [20736/60000 (35%)]\tLoss: 1.068150\n",
      "Train Epoch: 10 [20864/60000 (35%)]\tLoss: 1.091427\n",
      "Train Epoch: 10 [20992/60000 (35%)]\tLoss: 0.731076\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.723208\n",
      "Train Epoch: 10 [21248/60000 (35%)]\tLoss: 0.804911\n",
      "Train Epoch: 10 [21376/60000 (36%)]\tLoss: 0.860403\n",
      "Train Epoch: 10 [21504/60000 (36%)]\tLoss: 0.767254\n",
      "Train Epoch: 10 [21632/60000 (36%)]\tLoss: 0.736178\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.609486\n",
      "Train Epoch: 10 [21888/60000 (37%)]\tLoss: 0.729228\n",
      "Train Epoch: 10 [22016/60000 (37%)]\tLoss: 0.907065\n",
      "Train Epoch: 10 [22144/60000 (37%)]\tLoss: 0.843151\n",
      "Train Epoch: 10 [22272/60000 (37%)]\tLoss: 0.767782\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 1.000688\n",
      "Train Epoch: 10 [22528/60000 (38%)]\tLoss: 1.051286\n",
      "Train Epoch: 10 [22656/60000 (38%)]\tLoss: 0.848783\n",
      "Train Epoch: 10 [22784/60000 (38%)]\tLoss: 0.688258\n",
      "Train Epoch: 10 [22912/60000 (38%)]\tLoss: 0.664178\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.865626\n",
      "Train Epoch: 10 [23168/60000 (39%)]\tLoss: 0.791945\n",
      "Train Epoch: 10 [23296/60000 (39%)]\tLoss: 0.757437\n",
      "Train Epoch: 10 [23424/60000 (39%)]\tLoss: 0.703081\n",
      "Train Epoch: 10 [23552/60000 (39%)]\tLoss: 0.883211\n",
      "Train Epoch: 10 [23680/60000 (40%)]\tLoss: 0.963916\n",
      "Train Epoch: 10 [23808/60000 (40%)]\tLoss: 0.876062\n",
      "Train Epoch: 10 [23936/60000 (40%)]\tLoss: 0.827745\n",
      "Train Epoch: 10 [24064/60000 (40%)]\tLoss: 0.631284\n",
      "Train Epoch: 10 [24192/60000 (40%)]\tLoss: 1.011376\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.881017\n",
      "Train Epoch: 10 [24448/60000 (41%)]\tLoss: 0.891778\n",
      "Train Epoch: 10 [24576/60000 (41%)]\tLoss: 0.860803\n",
      "Train Epoch: 10 [24704/60000 (41%)]\tLoss: 1.035143\n",
      "Train Epoch: 10 [24832/60000 (41%)]\tLoss: 0.890981\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.714734\n",
      "Train Epoch: 10 [25088/60000 (42%)]\tLoss: 0.794291\n",
      "Train Epoch: 10 [25216/60000 (42%)]\tLoss: 0.890384\n",
      "Train Epoch: 10 [25344/60000 (42%)]\tLoss: 0.568469\n",
      "Train Epoch: 10 [25472/60000 (43%)]\tLoss: 0.692515\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.767083\n",
      "Train Epoch: 10 [25728/60000 (43%)]\tLoss: 0.844001\n",
      "Train Epoch: 10 [25856/60000 (43%)]\tLoss: 0.850769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [25984/60000 (43%)]\tLoss: 0.728790\n",
      "Train Epoch: 10 [26112/60000 (44%)]\tLoss: 0.756640\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.785091\n",
      "Train Epoch: 10 [26368/60000 (44%)]\tLoss: 1.027460\n",
      "Train Epoch: 10 [26496/60000 (44%)]\tLoss: 0.854686\n",
      "Train Epoch: 10 [26624/60000 (44%)]\tLoss: 1.189771\n",
      "Train Epoch: 10 [26752/60000 (45%)]\tLoss: 0.815148\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.765471\n",
      "Train Epoch: 10 [27008/60000 (45%)]\tLoss: 0.831482\n",
      "Train Epoch: 10 [27136/60000 (45%)]\tLoss: 1.117274\n",
      "Train Epoch: 10 [27264/60000 (46%)]\tLoss: 0.773063\n",
      "Train Epoch: 10 [27392/60000 (46%)]\tLoss: 0.841708\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.869107\n",
      "Train Epoch: 10 [27648/60000 (46%)]\tLoss: 0.763303\n",
      "Train Epoch: 10 [27776/60000 (46%)]\tLoss: 0.815671\n",
      "Train Epoch: 10 [27904/60000 (47%)]\tLoss: 0.739398\n",
      "Train Epoch: 10 [28032/60000 (47%)]\tLoss: 0.719395\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.713345\n",
      "Train Epoch: 10 [28288/60000 (47%)]\tLoss: 0.955935\n",
      "Train Epoch: 10 [28416/60000 (47%)]\tLoss: 0.917788\n",
      "Train Epoch: 10 [28544/60000 (48%)]\tLoss: 1.056237\n",
      "Train Epoch: 10 [28672/60000 (48%)]\tLoss: 0.892477\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.731626\n",
      "Train Epoch: 10 [28928/60000 (48%)]\tLoss: 0.874645\n",
      "Train Epoch: 10 [29056/60000 (49%)]\tLoss: 0.868102\n",
      "Train Epoch: 10 [29184/60000 (49%)]\tLoss: 0.907683\n",
      "Train Epoch: 10 [29312/60000 (49%)]\tLoss: 1.019683\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.746686\n",
      "Train Epoch: 10 [29568/60000 (49%)]\tLoss: 0.671973\n",
      "Train Epoch: 10 [29696/60000 (50%)]\tLoss: 0.918715\n",
      "Train Epoch: 10 [29824/60000 (50%)]\tLoss: 1.027122\n",
      "Train Epoch: 10 [29952/60000 (50%)]\tLoss: 0.964967\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.927996\n",
      "Train Epoch: 10 [30208/60000 (50%)]\tLoss: 0.928968\n",
      "Train Epoch: 10 [30336/60000 (51%)]\tLoss: 0.826950\n",
      "Train Epoch: 10 [30464/60000 (51%)]\tLoss: 0.991706\n",
      "Train Epoch: 10 [30592/60000 (51%)]\tLoss: 1.004666\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.938945\n",
      "Train Epoch: 10 [30848/60000 (51%)]\tLoss: 0.978961\n",
      "Train Epoch: 10 [30976/60000 (52%)]\tLoss: 0.869434\n",
      "Train Epoch: 10 [31104/60000 (52%)]\tLoss: 0.958571\n",
      "Train Epoch: 10 [31232/60000 (52%)]\tLoss: 0.957039\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.938781\n",
      "Train Epoch: 10 [31488/60000 (53%)]\tLoss: 0.816833\n",
      "Train Epoch: 10 [31616/60000 (53%)]\tLoss: 1.163362\n",
      "Train Epoch: 10 [31744/60000 (53%)]\tLoss: 0.969904\n",
      "Train Epoch: 10 [31872/60000 (53%)]\tLoss: 0.771748\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.782841\n",
      "Train Epoch: 10 [32128/60000 (54%)]\tLoss: 1.032638\n",
      "Train Epoch: 10 [32256/60000 (54%)]\tLoss: 0.984869\n",
      "Train Epoch: 10 [32384/60000 (54%)]\tLoss: 1.022472\n",
      "Train Epoch: 10 [32512/60000 (54%)]\tLoss: 0.692858\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.874294\n",
      "Train Epoch: 10 [32768/60000 (55%)]\tLoss: 0.888933\n",
      "Train Epoch: 10 [32896/60000 (55%)]\tLoss: 0.845182\n",
      "Train Epoch: 10 [33024/60000 (55%)]\tLoss: 0.866001\n",
      "Train Epoch: 10 [33152/60000 (55%)]\tLoss: 0.856967\n",
      "Train Epoch: 10 [33280/60000 (56%)]\tLoss: 0.951711\n",
      "Train Epoch: 10 [33408/60000 (56%)]\tLoss: 0.923632\n",
      "Train Epoch: 10 [33536/60000 (56%)]\tLoss: 0.747890\n",
      "Train Epoch: 10 [33664/60000 (56%)]\tLoss: 0.794070\n",
      "Train Epoch: 10 [33792/60000 (56%)]\tLoss: 0.544621\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.736544\n",
      "Train Epoch: 10 [34048/60000 (57%)]\tLoss: 0.810212\n",
      "Train Epoch: 10 [34176/60000 (57%)]\tLoss: 0.586345\n",
      "Train Epoch: 10 [34304/60000 (57%)]\tLoss: 0.831489\n",
      "Train Epoch: 10 [34432/60000 (57%)]\tLoss: 0.855094\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.805871\n",
      "Train Epoch: 10 [34688/60000 (58%)]\tLoss: 0.981583\n",
      "Train Epoch: 10 [34816/60000 (58%)]\tLoss: 0.875996\n",
      "Train Epoch: 10 [34944/60000 (58%)]\tLoss: 0.680433\n",
      "Train Epoch: 10 [35072/60000 (59%)]\tLoss: 0.703330\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.883515\n",
      "Train Epoch: 10 [35328/60000 (59%)]\tLoss: 0.828729\n",
      "Train Epoch: 10 [35456/60000 (59%)]\tLoss: 0.745303\n",
      "Train Epoch: 10 [35584/60000 (59%)]\tLoss: 0.862797\n",
      "Train Epoch: 10 [35712/60000 (60%)]\tLoss: 0.648810\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.827003\n",
      "Train Epoch: 10 [35968/60000 (60%)]\tLoss: 0.697493\n",
      "Train Epoch: 10 [36096/60000 (60%)]\tLoss: 0.806307\n",
      "Train Epoch: 10 [36224/60000 (60%)]\tLoss: 0.725046\n",
      "Train Epoch: 10 [36352/60000 (61%)]\tLoss: 0.883885\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.759724\n",
      "Train Epoch: 10 [36608/60000 (61%)]\tLoss: 0.673488\n",
      "Train Epoch: 10 [36736/60000 (61%)]\tLoss: 0.836083\n",
      "Train Epoch: 10 [36864/60000 (62%)]\tLoss: 0.770886\n",
      "Train Epoch: 10 [36992/60000 (62%)]\tLoss: 0.861546\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.827319\n",
      "Train Epoch: 10 [37248/60000 (62%)]\tLoss: 0.987856\n",
      "Train Epoch: 10 [37376/60000 (62%)]\tLoss: 1.033860\n",
      "Train Epoch: 10 [37504/60000 (63%)]\tLoss: 0.846216\n",
      "Train Epoch: 10 [37632/60000 (63%)]\tLoss: 0.892175\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.879586\n",
      "Train Epoch: 10 [37888/60000 (63%)]\tLoss: 0.809036\n",
      "Train Epoch: 10 [38016/60000 (63%)]\tLoss: 0.791756\n",
      "Train Epoch: 10 [38144/60000 (64%)]\tLoss: 0.844598\n",
      "Train Epoch: 10 [38272/60000 (64%)]\tLoss: 1.000370\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.870193\n",
      "Train Epoch: 10 [38528/60000 (64%)]\tLoss: 0.992815\n",
      "Train Epoch: 10 [38656/60000 (65%)]\tLoss: 0.766779\n",
      "Train Epoch: 10 [38784/60000 (65%)]\tLoss: 0.663737\n",
      "Train Epoch: 10 [38912/60000 (65%)]\tLoss: 0.780576\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.598688\n",
      "Train Epoch: 10 [39168/60000 (65%)]\tLoss: 0.812246\n",
      "Train Epoch: 10 [39296/60000 (66%)]\tLoss: 1.260644\n",
      "Train Epoch: 10 [39424/60000 (66%)]\tLoss: 0.972166\n",
      "Train Epoch: 10 [39552/60000 (66%)]\tLoss: 0.926539\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.898404\n",
      "Train Epoch: 10 [39808/60000 (66%)]\tLoss: 1.006349\n",
      "Train Epoch: 10 [39936/60000 (67%)]\tLoss: 0.821581\n",
      "Train Epoch: 10 [40064/60000 (67%)]\tLoss: 0.679884\n",
      "Train Epoch: 10 [40192/60000 (67%)]\tLoss: 0.792810\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.574817\n",
      "Train Epoch: 10 [40448/60000 (68%)]\tLoss: 0.782984\n",
      "Train Epoch: 10 [40576/60000 (68%)]\tLoss: 0.812854\n",
      "Train Epoch: 10 [40704/60000 (68%)]\tLoss: 0.761042\n",
      "Train Epoch: 10 [40832/60000 (68%)]\tLoss: 0.656882\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.905047\n",
      "Train Epoch: 10 [41088/60000 (69%)]\tLoss: 0.726158\n",
      "Train Epoch: 10 [41216/60000 (69%)]\tLoss: 1.088334\n",
      "Train Epoch: 10 [41344/60000 (69%)]\tLoss: 1.000655\n",
      "Train Epoch: 10 [41472/60000 (69%)]\tLoss: 0.924303\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.921897\n",
      "Train Epoch: 10 [41728/60000 (70%)]\tLoss: 0.841283\n",
      "Train Epoch: 10 [41856/60000 (70%)]\tLoss: 0.982820\n",
      "Train Epoch: 10 [41984/60000 (70%)]\tLoss: 0.818385\n",
      "Train Epoch: 10 [42112/60000 (70%)]\tLoss: 1.017615\n",
      "Train Epoch: 10 [42240/60000 (71%)]\tLoss: 0.944835\n",
      "Train Epoch: 10 [42368/60000 (71%)]\tLoss: 0.901438\n",
      "Train Epoch: 10 [42496/60000 (71%)]\tLoss: 0.816828\n",
      "Train Epoch: 10 [42624/60000 (71%)]\tLoss: 0.900229\n",
      "Train Epoch: 10 [42752/60000 (71%)]\tLoss: 0.966092\n",
      "Train Epoch: 10 [42880/60000 (72%)]\tLoss: 0.937578\n",
      "Train Epoch: 10 [43008/60000 (72%)]\tLoss: 0.945624\n",
      "Train Epoch: 10 [43136/60000 (72%)]\tLoss: 0.782363\n",
      "Train Epoch: 10 [43264/60000 (72%)]\tLoss: 0.566999\n",
      "Train Epoch: 10 [43392/60000 (72%)]\tLoss: 0.694588\n",
      "Train Epoch: 10 [43520/60000 (73%)]\tLoss: 0.727334\n",
      "Train Epoch: 10 [43648/60000 (73%)]\tLoss: 0.697969\n",
      "Train Epoch: 10 [43776/60000 (73%)]\tLoss: 0.858813\n",
      "Train Epoch: 10 [43904/60000 (73%)]\tLoss: 0.869679\n",
      "Train Epoch: 10 [44032/60000 (74%)]\tLoss: 0.869854\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.952771\n",
      "Train Epoch: 10 [44288/60000 (74%)]\tLoss: 0.737423\n",
      "Train Epoch: 10 [44416/60000 (74%)]\tLoss: 0.796038\n",
      "Train Epoch: 10 [44544/60000 (74%)]\tLoss: 0.610007\n",
      "Train Epoch: 10 [44672/60000 (75%)]\tLoss: 0.797060\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.979769\n",
      "Train Epoch: 10 [44928/60000 (75%)]\tLoss: 1.000906\n",
      "Train Epoch: 10 [45056/60000 (75%)]\tLoss: 0.927753\n",
      "Train Epoch: 10 [45184/60000 (75%)]\tLoss: 0.708569\n",
      "Train Epoch: 10 [45312/60000 (76%)]\tLoss: 0.669131\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.999038\n",
      "Train Epoch: 10 [45568/60000 (76%)]\tLoss: 0.892129\n",
      "Train Epoch: 10 [45696/60000 (76%)]\tLoss: 0.739719\n",
      "Train Epoch: 10 [45824/60000 (76%)]\tLoss: 0.890721\n",
      "Train Epoch: 10 [45952/60000 (77%)]\tLoss: 0.970611\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.945545\n",
      "Train Epoch: 10 [46208/60000 (77%)]\tLoss: 0.910244\n",
      "Train Epoch: 10 [46336/60000 (77%)]\tLoss: 0.925740\n",
      "Train Epoch: 10 [46464/60000 (78%)]\tLoss: 0.579498\n",
      "Train Epoch: 10 [46592/60000 (78%)]\tLoss: 0.787611\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.713457\n",
      "Train Epoch: 10 [46848/60000 (78%)]\tLoss: 0.669502\n",
      "Train Epoch: 10 [46976/60000 (78%)]\tLoss: 0.658614\n",
      "Train Epoch: 10 [47104/60000 (79%)]\tLoss: 0.774643\n",
      "Train Epoch: 10 [47232/60000 (79%)]\tLoss: 0.963637\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.822458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [47488/60000 (79%)]\tLoss: 0.954622\n",
      "Train Epoch: 10 [47616/60000 (79%)]\tLoss: 0.809008\n",
      "Train Epoch: 10 [47744/60000 (80%)]\tLoss: 0.644200\n",
      "Train Epoch: 10 [47872/60000 (80%)]\tLoss: 1.041409\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.717706\n",
      "Train Epoch: 10 [48128/60000 (80%)]\tLoss: 0.678076\n",
      "Train Epoch: 10 [48256/60000 (81%)]\tLoss: 0.942967\n",
      "Train Epoch: 10 [48384/60000 (81%)]\tLoss: 0.677030\n",
      "Train Epoch: 10 [48512/60000 (81%)]\tLoss: 1.067687\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.640952\n",
      "Train Epoch: 10 [48768/60000 (81%)]\tLoss: 0.710992\n",
      "Train Epoch: 10 [48896/60000 (82%)]\tLoss: 1.041772\n",
      "Train Epoch: 10 [49024/60000 (82%)]\tLoss: 0.869199\n",
      "Train Epoch: 10 [49152/60000 (82%)]\tLoss: 0.876655\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.725624\n",
      "Train Epoch: 10 [49408/60000 (82%)]\tLoss: 1.088197\n",
      "Train Epoch: 10 [49536/60000 (83%)]\tLoss: 1.196614\n",
      "Train Epoch: 10 [49664/60000 (83%)]\tLoss: 0.911537\n",
      "Train Epoch: 10 [49792/60000 (83%)]\tLoss: 1.017697\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.853329\n",
      "Train Epoch: 10 [50048/60000 (84%)]\tLoss: 0.878711\n",
      "Train Epoch: 10 [50176/60000 (84%)]\tLoss: 0.764930\n",
      "Train Epoch: 10 [50304/60000 (84%)]\tLoss: 1.051314\n",
      "Train Epoch: 10 [50432/60000 (84%)]\tLoss: 0.797542\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.969400\n",
      "Train Epoch: 10 [50688/60000 (85%)]\tLoss: 0.823647\n",
      "Train Epoch: 10 [50816/60000 (85%)]\tLoss: 0.689478\n",
      "Train Epoch: 10 [50944/60000 (85%)]\tLoss: 0.594841\n",
      "Train Epoch: 10 [51072/60000 (85%)]\tLoss: 0.941681\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.872621\n",
      "Train Epoch: 10 [51328/60000 (86%)]\tLoss: 0.663510\n",
      "Train Epoch: 10 [51456/60000 (86%)]\tLoss: 0.692063\n",
      "Train Epoch: 10 [51584/60000 (86%)]\tLoss: 0.676058\n",
      "Train Epoch: 10 [51712/60000 (86%)]\tLoss: 0.827636\n",
      "Train Epoch: 10 [51840/60000 (87%)]\tLoss: 0.850284\n",
      "Train Epoch: 10 [51968/60000 (87%)]\tLoss: 0.974719\n",
      "Train Epoch: 10 [52096/60000 (87%)]\tLoss: 0.949777\n",
      "Train Epoch: 10 [52224/60000 (87%)]\tLoss: 0.891747\n",
      "Train Epoch: 10 [52352/60000 (87%)]\tLoss: 0.640067\n",
      "Train Epoch: 10 [52480/60000 (88%)]\tLoss: 0.529327\n",
      "Train Epoch: 10 [52608/60000 (88%)]\tLoss: 0.926428\n",
      "Train Epoch: 10 [52736/60000 (88%)]\tLoss: 1.021092\n",
      "Train Epoch: 10 [52864/60000 (88%)]\tLoss: 1.107033\n",
      "Train Epoch: 10 [52992/60000 (88%)]\tLoss: 0.807826\n",
      "Train Epoch: 10 [53120/60000 (89%)]\tLoss: 0.880110\n",
      "Train Epoch: 10 [53248/60000 (89%)]\tLoss: 0.629949\n",
      "Train Epoch: 10 [53376/60000 (89%)]\tLoss: 0.738525\n",
      "Train Epoch: 10 [53504/60000 (89%)]\tLoss: 0.950086\n",
      "Train Epoch: 10 [53632/60000 (90%)]\tLoss: 0.710947\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.693850\n",
      "Train Epoch: 10 [53888/60000 (90%)]\tLoss: 0.851445\n",
      "Train Epoch: 10 [54016/60000 (90%)]\tLoss: 0.783614\n",
      "Train Epoch: 10 [54144/60000 (90%)]\tLoss: 0.685656\n",
      "Train Epoch: 10 [54272/60000 (91%)]\tLoss: 0.710001\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.639752\n",
      "Train Epoch: 10 [54528/60000 (91%)]\tLoss: 0.752420\n",
      "Train Epoch: 10 [54656/60000 (91%)]\tLoss: 0.800301\n",
      "Train Epoch: 10 [54784/60000 (91%)]\tLoss: 0.896001\n",
      "Train Epoch: 10 [54912/60000 (92%)]\tLoss: 0.782610\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.726220\n",
      "Train Epoch: 10 [55168/60000 (92%)]\tLoss: 0.791429\n",
      "Train Epoch: 10 [55296/60000 (92%)]\tLoss: 0.816101\n",
      "Train Epoch: 10 [55424/60000 (93%)]\tLoss: 0.710020\n",
      "Train Epoch: 10 [55552/60000 (93%)]\tLoss: 0.655381\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.763270\n",
      "Train Epoch: 10 [55808/60000 (93%)]\tLoss: 0.739919\n",
      "Train Epoch: 10 [55936/60000 (93%)]\tLoss: 0.623401\n",
      "Train Epoch: 10 [56064/60000 (94%)]\tLoss: 0.775568\n",
      "Train Epoch: 10 [56192/60000 (94%)]\tLoss: 0.884202\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.699903\n",
      "Train Epoch: 10 [56448/60000 (94%)]\tLoss: 0.745635\n",
      "Train Epoch: 10 [56576/60000 (94%)]\tLoss: 0.832852\n",
      "Train Epoch: 10 [56704/60000 (95%)]\tLoss: 0.602284\n",
      "Train Epoch: 10 [56832/60000 (95%)]\tLoss: 0.694752\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.845553\n",
      "Train Epoch: 10 [57088/60000 (95%)]\tLoss: 0.771682\n",
      "Train Epoch: 10 [57216/60000 (96%)]\tLoss: 0.925096\n",
      "Train Epoch: 10 [57344/60000 (96%)]\tLoss: 0.781698\n",
      "Train Epoch: 10 [57472/60000 (96%)]\tLoss: 0.894975\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.866622\n",
      "Train Epoch: 10 [57728/60000 (96%)]\tLoss: 0.721661\n",
      "Train Epoch: 10 [57856/60000 (97%)]\tLoss: 0.689491\n",
      "Train Epoch: 10 [57984/60000 (97%)]\tLoss: 0.613760\n",
      "Train Epoch: 10 [58112/60000 (97%)]\tLoss: 0.632550\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.652038\n",
      "Train Epoch: 10 [58368/60000 (97%)]\tLoss: 0.620674\n",
      "Train Epoch: 10 [58496/60000 (98%)]\tLoss: 0.620292\n",
      "Train Epoch: 10 [58624/60000 (98%)]\tLoss: 0.584261\n",
      "Train Epoch: 10 [58752/60000 (98%)]\tLoss: 0.651250\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.449169\n",
      "Train Epoch: 10 [59008/60000 (99%)]\tLoss: 0.553295\n",
      "Train Epoch: 10 [59136/60000 (99%)]\tLoss: 0.528515\n",
      "Train Epoch: 10 [59264/60000 (99%)]\tLoss: 0.898837\n",
      "Train Epoch: 10 [59392/60000 (99%)]\tLoss: 0.789055\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.571905\n",
      "Train Epoch: 10 [59648/60000 (100%)]\tLoss: 0.864385\n",
      "Train Epoch: 10 [59776/60000 (100%)]\tLoss: 0.593386\n",
      "================================================================\n",
      "Training: Average loss: 0.2576, Accuracy: 55800/60000 (93%)\n",
      "Test: Average loss: 0.2415, Accuracy: 9337/10000 (93%)\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "if TrainTRADES:\n",
    "    ## initialize model\n",
    "    model_TRADES = Net().to(DEVICE)\n",
    "    ## training params\n",
    "    lr = 0.01\n",
    "    optimizer = optim.SGD(model_TRADES.parameters(), lr=lr)\n",
    "    epochs = 10\n",
    "    ## train model\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # adjust learning rate for SGD\n",
    "        #adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        # adversarial training\n",
    "        train(args, model_TRADES, DEVICE, train_loader, optimizer, epoch)\n",
    "\n",
    "        # evaluation on natural examples\n",
    "        print('================================================================')\n",
    "        eval_train(model_TRADES, DEVICE, train_loader)\n",
    "        eval_test(model_TRADES, DEVICE, val_loader)\n",
    "        print('================================================================')\n",
    "\n",
    "        \n",
    "    '''\n",
    "    history_natural = olympic.fit(\n",
    "        model_TRADES,\n",
    "        optimiser,\n",
    "        nn.KLDivLoss(size_average=False),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=trades_obj,\n",
    "        #update_fn_kwargs={'adversary': entropySmoothing, 'k': 30, 'step': 0.03, 'eps': 0.3, 'norm': 'inf', 'gamma':1e-5},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5)\n",
    "        ]\n",
    "    )\n",
    "    '''\n",
    "    ## verify validation accuracy\n",
    "    #print('final validation accuracy:')\n",
    "    #valscore = olympic.evaluate(model_TRADES, val_loader, metrics=['accuracy'],\n",
    "    #                 prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/TRADES_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_TRADES,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING MART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING MMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD ALL PRE-TRAINED MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSGD = False\n",
    "TrainESGD = False\n",
    "TrainL2 = False\n",
    "TrainLInf = False\n",
    "TrainSAT2 = False\n",
    "TrainSATInf = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load all the pre-trained models\n",
    "if dataset=='MNIST':\n",
    "    if not TrainSGD:\n",
    "        model_SGD = torch.load('../trainedmodels/MNIST/SGD_ep10_lr0.1.pt').to(DEVICE)\n",
    "    if not TrainESGD:    \n",
    "        model_ESGD = torch.load('../trainedmodels/MNIST/ESGD_ep5_lr0.1.pt').to(DEVICE)\n",
    "    if not TrainLInf:\n",
    "        adv_model_linf = torch.load('../trainedmodels/MNIST/AT2_ep2_lr0.1.pt').to(DEVICE)\n",
    "    if not TrainL2:\n",
    "        adv_model_l2 = torch.load('../trainedmodels/MNIST/ATInf_ep2_lr0.1.pt').to(DEVICE)\n",
    "    if not TrainSAT2:\n",
    "        model_SAT2 = torch.load('../trainedmodels/MNIST/SAT2_ep2_lr0.1.pt').to(DEVICE)\n",
    "    if not TrainSATInf:\n",
    "        model_SATInf = torch.load('../trainedmodels/MNIST/SATInf_ep2_lr0.1.pt').to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE NETWORK OUTPUT AT DIFFERENT LEVELS OF ATTACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_adversarial_examples(model, x, y, l2_eps=5.0, linf_eps=0.2):\n",
    "    x = x.unsqueeze(0).to(DEVICE)\n",
    "    y =  torch.tensor([y]).to(DEVICE)\n",
    "    \n",
    "    ## l2 and linf attacks\n",
    "    x_adv_l2 = pgd(model, x, y, torch.nn.CrossEntropyLoss(), k=30, step=1.0, eps=l2_eps, norm=2)\n",
    "    x_adv_linf = iterated_fgsm(model, x, y, torch.nn.CrossEntropyLoss(), k=60, step=0.01, eps=linf_eps, norm='inf')\n",
    "    \n",
    "    y_pred = model(x)\n",
    "    y_pred_l2 = model(x_adv_l2)\n",
    "    y_pred_linf = model(x_adv_linf)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "    \n",
    "    axes[0].imshow(x[0, 0].cpu().numpy(), cmap='gray')\n",
    "    axes[0].set_title(\n",
    "        f'Natural, '\n",
    "        f'P({ y_pred.argmax(dim=1).item()}) = '\n",
    "        f'{np.round(y_pred.softmax(dim=1)[0, y_pred.argmax(dim=1).item()].item(), 3)}')\n",
    "    axes[0].set_xticks([])\n",
    "    axes[0].set_yticks([])\n",
    "    \n",
    "    axes[1].imshow(x_adv_l2[0, 0].cpu().numpy(), cmap='gray')\n",
    "    axes[1].set_title(\n",
    "        f'$L^2$ adversary, '\n",
    "        f'eps={l2_eps}, '\n",
    "        f'P({y_pred_l2.argmax(dim=1).item()}) = '\n",
    "        f'{np.round(y_pred_l2.softmax(dim=1)[0, y_pred_l2.argmax(dim=1).item()].item(), 3)}')\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "    \n",
    "    axes[2].imshow(x_adv_linf[0, 0].cpu().numpy(), cmap='gray')\n",
    "    axes[2].set_title(\n",
    "        '$L^{\\infty}$ adversary, '\n",
    "        f'eps={linf_eps}, '\n",
    "        f'P({y_pred_l2.argmax(dim=1).item()}) = '\n",
    "        f'{np.round(y_pred_linf.softmax(dim=1)[0, y_pred_linf.argmax(dim=1).item()].item(), 3)}')\n",
    "    axes[2].set_xticks([])\n",
    "    axes[2].set_yticks([])\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate sgd model with PGD attack and FGSM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    visualise_adversarial_examples(model_SGD, *val[1])\n",
    "    visualise_adversarial_examples(model_SGD, *val[2])\n",
    "    visualise_adversarial_examples(model_SGD, *val[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Adversarial L-2 model with PGD attack and FGSM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    visualise_adversarial_examples(adv_model_l2, *val[1])\n",
    "    visualise_adversarial_examples(adv_model_l2, *val[6])\n",
    "    visualise_adversarial_examples(adv_model_l2, *val[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying adversarial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infnorm(x):\n",
    "    infn = torch.max(torch.abs(x.detach().cpu()))\n",
    "    return infn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_against_adversary(model, k, eps, step, norm):\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    for x, y in val_loader:\n",
    "        total += x.size(0)\n",
    "        \n",
    "        if norm == 2:\n",
    "            x_adv = pgd(\n",
    "                model, x.to(DEVICE), y.to(DEVICE), torch.nn.CrossEntropyLoss(), k=k, step=step, eps=eps, norm=2)\n",
    "            print('rel. l2-norm of x_adv-x:',torch.norm(x_adv.detach().cpu()-x)/np.sqrt(x.size(0)))#/torch.norm(x))\n",
    "        elif norm == 'inf':\n",
    "            x_adv = iterated_fgsm(\n",
    "                model, x.to(DEVICE), y.to(DEVICE), torch.nn.CrossEntropyLoss(), k=k, step=step, eps=eps, norm='inf')\n",
    "            print('rel. linf-norm of x_adv-x:',infnorm(x_adv.detach().cpu()-x)/infnorm(x))\n",
    "        y_pred = model(x_adv)\n",
    "\n",
    "        acc += olympic.metrics.accuracy(y.to(DEVICE), y_pred) * x.size(0)\n",
    "\n",
    "    return acc/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate robust models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadResults = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps: 0.0\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "evaluating SATInf network...\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "if not loadResults:\n",
    "    pgd_attack_range = np.arange(0, 6.1, 1./3)\n",
    "    acc_SGD = []\n",
    "    acc_ESGD = []\n",
    "    acc_l2 = []\n",
    "    acc_linf = []\n",
    "    acc_SAT2 = []\n",
    "    acc_SATInf = []\n",
    "    acc_TRADES = []\n",
    "    for eps in pgd_attack_range:\n",
    "        print('eps:',eps)\n",
    "        print('evaluating SGD network...')\n",
    "        acc_SGD.append(evaluate_against_adversary(model_SGD, k=20, eps=eps, step=0.5, norm=2))\n",
    "        print('evaluating ESGD network...')\n",
    "        acc_ESGD.append(evaluate_against_adversary(model_ESGD, k=20, eps=eps, step=0.5, norm=2))\n",
    "        print('evaluating SAT2 network...')\n",
    "        acc_SAT2.append(evaluate_against_adversary(model_SAT2, k=30, eps=eps, step=0.3, norm=2))\n",
    "        print('evaluating SATInf network...')\n",
    "        acc_SATInf.append(evaluate_against_adversary(model_SATInf, k=30, eps=eps, step=0.25, norm=2))        \n",
    "        print('evaluating linf network...')\n",
    "        acc_linf.append(evaluate_against_adversary(adv_model_linf, k=30, eps=eps*1.2, step=1.5, norm=2))\n",
    "        print('evaluating l2 network...')\n",
    "        acc_l2.append(evaluate_against_adversary(adv_model_l2, k=30, eps=eps*1.2, step=1.5, norm=2))\n",
    "        print('evaluating TRADES network...')\n",
    "        acc_TRADES.append(evaluate_against_adversary(model_TRADES, k=30, eps=eps, step=1.5, norm=2))        \n",
    "print(\"time elapsed:\",time.time()-t1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not loadResults:    \n",
    "    accData = [acc_SGD,acc_ESGD,acc_l2,acc_linf,acc_SAT2,acc_SATInf]\n",
    "    np.save('../results/accData_l2.npy',accData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadResults:\n",
    "    pgd_attack_range = np.arange(0.0, 6.1, 1./3)\n",
    "    accData2 = np.load('../results/accData_l2.npy')\n",
    "    [acc_SGD,acc_ESGD,acc_l2,acc_linf,acc_SAT2,acc_SATInf] = accData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('ggplot'):\n",
    "    plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelcolor\"] = \"black\"\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(15,10))\n",
    "    plt.figure(figsize=(14,7))\n",
    "    axes.set_title('$L^2$-bounded adversary')\n",
    "    axes.plot(pgd_attack_range, acc_SGD, label='SGD')\n",
    "    axes.plot(pgd_attack_range, acc_ESGD, label='Entropy-SGD')\n",
    "    axes.plot(pgd_attack_range, acc_SAT2, label='Data-Entropy-SGD ($L_2$)')\n",
    "    axes.plot(pgd_attack_range, acc_SATInf, label='Data-Entropy-SGD ($L_\\infty$)')\n",
    "    axes.plot(pgd_attack_range, acc_l2, label='$L2$ training')\n",
    "    axes.plot(pgd_attack_range, acc_linf, label='$L{\\infty}$ training')\n",
    "    axes.vlines([3], 0, 1, colors=COLOURS[1], linestyle='--')\n",
    "    axes.set_ylabel('Accuracy')\n",
    "    axes.set_xlabel('Epsilon')\n",
    "    axes.set_ylim((0,1))\n",
    "    axes.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadResultsFGSM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "if not loadResultsFGSM:\n",
    "    fgsm_attack_range = np.arange(0.0, 0.52, 0.025)\n",
    "    fgsm_acc_linf = []\n",
    "    fgsm_acc_l2 = []\n",
    "    fgsm_acc_SGD = []\n",
    "    fgsm_acc_ESGD = []\n",
    "    fgsm_acc_SAT2 = []\n",
    "    fgsm_acc_SATInf = []\n",
    "    for eps in fgsm_attack_range:\n",
    "        print('eps:',eps)\n",
    "        print('evaluating SGD network...')\n",
    "        fgsm_acc_SGD.append(evaluate_against_adversary(model_SGD, k=20, eps=eps, step=0.1, norm='inf'))\n",
    "        print('evaluating ESGD network...')\n",
    "        fgsm_acc_ESGD.append(evaluate_against_adversary(model_ESGD, k=20, eps=eps, step=0.1, norm='inf'))\n",
    "        print('evaluating SAT2 network...')\n",
    "        fgsm_acc_SAT2.append(evaluate_against_adversary(model_SAT2, k=10, eps=eps, step=0.1, norm='inf'))\n",
    "        print('evaluating SATInf network...')\n",
    "        fgsm_acc_SATInf.append(evaluate_against_adversary(model_SATInf, k=10, eps=eps, step=0.1, norm='inf'))        \n",
    "        print('evaluating linf network...')\n",
    "        fgsm_acc_linf.append(evaluate_against_adversary(adv_model_linf, k=50, eps=eps, step=0.02, norm='inf'))\n",
    "        print('evaluating l2 network...')\n",
    "        fgsm_acc_l2.append(evaluate_against_adversary(adv_model_l2, k=50, eps=eps, step=0.02, norm='inf'))\n",
    "    \n",
    "print(\"time elapsed:\",time.time()-t1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not loadResultsFGSM:    \n",
    "    fgsmaccData = [fgsm_acc_SGD,fgsm_acc_ESGD,fgsm_acc_l2,fgsm_acc_linf,fgsm_acc_SAT2,fgsm_acc_SATInf]\n",
    "    np.save('../results/fgsmaccData.npy',fgsmaccData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadResultsFGSM:\n",
    "    fgsm_attack_range = np.arange(0.0, 0.52, 0.025)\n",
    "    accData2 = np.load('../results/fgsmaccData.npy')\n",
    "    [fgsm_acc_SGD,fgsm_acc_ESGD,fgsm_acc_l2,fgsm_acc_linf,fgsm_acc_SAT2,fgsm_acc_SATInf] = accData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('ggplot'):\n",
    "    plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelcolor\"] = \"black\"\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(15,10))\n",
    "    plt.figure(figsize=(14,7))\n",
    "    axes.set_title('$L^\\infty$-bounded adversary')\n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_SGD, label='SGD')\n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_ESGD, label='Entropy-SGD')\n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_SAT2, label='Data-Entropy-SGD ($L_2$)')\n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_SATInf, label='Data-Entropy-SGD ($L_\\infty$)')    \n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_l2, label='$L2$ training')\n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_linf, label='$L{\\infty}$ training')\n",
    "    axes.vlines([0.25], 0, 1, colors=COLOURS[1], linestyle='--')\n",
    "    axes.set_ylabel('Accuracy')\n",
    "    axes.set_xlabel('Epsilon')\n",
    "    axes.set_ylim((0,1))\n",
    "    axes.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
