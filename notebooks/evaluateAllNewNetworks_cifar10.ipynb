{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Adversarial Training (StochAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vanila SGD: \n",
    "MNIST - 99%+ (most cnns), CIFAR10 - 93%+ (resnet18), 96%+ (wideresnet) \n",
    "\n",
    "MNIST:\n",
    "\n",
    "adversarial attacks: \n",
    "l-inf @ eps = 80/255 @20 steps: TRADES - 96.07% - (4 layer cnn), MART 96.4%, MMA 95.5%, PGD - 96.01% - (4 layer cnn)\n",
    "\n",
    "adversarial attacks:\n",
    "l-2 @ eps = 32/255 (check): TRADES, MMA, PGD\n",
    "\n",
    "CIFAR10:\n",
    "\n",
    "adversarial attacks: \n",
    "l-inf @ eps = 8/255 @20 steps: \n",
    "TRADES 53-56% - (WRN-34-10), MART 57-58% (WRN-34-10), MMA 47%, PGD 48% - (WRN-32-10)// 49% - (WRN-34-10), Std - 0.03%\n",
    "https://openreview.net/pdf?id=rklOg6EFwS (Table 4)\n",
    "\n",
    "adversarial attacks: \n",
    "l-inf @ eps = 8/255 @20 steps: \n",
    "[ResNet10] TRADES 45.4%, MART 46.6%, MMA 37.26%, PGD 42.27%, Std 0.14%\n",
    "\n",
    "Benign accuracies: TRADES 84.92%, MART 83.62%, MMA 84.36, PGD 87.14%, Std 95.8% [wideresnet]\n",
    "https://openreview.net/pdf?id=Ms9zjhVB5R (Table 1)\n",
    "\n",
    "adversarial attacks:\n",
    "l-2 @ eps = 32/255 (check): TRADES, MART, MMA, PGD\n",
    "\n",
    "TBD: CWinf attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained models for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download pretrained models and place in ../trainedmodels/MNIST or ../trainedmodels/CIFAR10 respectively\n",
    "\n",
    "### TRADES :\n",
    "https://github.com/yaodongyu/TRADES (MNIST: small cnn, CIFAR10: WideResNet34)\n",
    "### MMA : \n",
    "https://github.com/BorealisAI/mma_training (MNIST: lenet5, CIFAR10: WideResNet28)\n",
    "### MART :\n",
    " https://github.com/YisenWang/MART (CIFAR10: ResNet18 and WideResNet34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from multiprocessing import cpu_count\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import olympic\n",
    "import sys\n",
    "from typing import Union, Callable, Tuple\n",
    "sys.path.append('../adversarial/')\n",
    "sys.path.append('../architectures/')\n",
    "from functional import boundary, iterated_fgsm, local_search, pgd, entropySmoothing\n",
    "from ESGD_utils import *\n",
    "import pickle\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse, math, random\n",
    "import ESGD_optim\n",
    "from trades import trades_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place data folders outside working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = 'CIFAR10' # [MNIST, CIFAR10]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "bsz = 128\n",
    "if dataset == 'MNIST':\n",
    "    train = datasets.MNIST('../../data/MNIST', train=True, transform=transform, download=True)\n",
    "    val = datasets.MNIST('../../data/MNIST', train=False, transform=transform, download=True)\n",
    "elif dataset == 'CIFAR10':\n",
    "    train = datasets.CIFAR10('../../data/CIFAR10', train=True, transform=transform, download=True)\n",
    "    val = datasets.CIFAR10('../../data/CIFAR10', train=False, transform=transform, download=True)\n",
    "    \n",
    "train_loader = DataLoader(train, batch_size=128, num_workers=cpu_count(),drop_last=True)\n",
    "val_loader = DataLoader(val, batch_size=128, num_workers=cpu_count(),drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALIZE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='MNIST':\n",
    "    from net_mnist import Net, NetSoft, model_cnn\n",
    "    Net = model_cnn\n",
    "    NetName = 'model_cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='CIFAR10':\n",
    "    #[ResNet18,ResNet34,ResNet50,WideResNet]\n",
    "    from resnet import ResNet18,ResNet34,ResNet50\n",
    "    from wideresnet import WideResNet\n",
    "    Net = WideResNet\n",
    "    NetName = 'WideResNet'\n",
    "    #Net = ResNet18\n",
    "    #NetName = 'ResNet18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wideresnet.WideResNet"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM SEED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fea5d5140f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.set_num_threads(2)\n",
    "if DEVICE=='cuda':\n",
    "    torch.cuda.set_device(-1)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    cudnn.benchmark = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD PRETRAINED OR TRAIN NEW MODELS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSGD = False\n",
    "TrainESGD = False\n",
    "TrainL2 = False\n",
    "TrainLInf = False\n",
    "TrainSAT2 = False\n",
    "TrainSATInf = True\n",
    "TrainTRADES = False\n",
    "TrainTRADESInf = False\n",
    "# tbd: add training modules for MART(inf only), MMA and MMAInf - always keep False\n",
    "TrainMART = False \n",
    "TrainMMA = False\n",
    "TrainMMAInf = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN NAIVE MODEL USING SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if TrainSGD:\n",
    "    ## initialize model\n",
    "    model_SGD = Net().to(DEVICE)\n",
    "    ## training params\n",
    "    lr = 0.001\n",
    "    optimiser = optim.SGD(model_SGD.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    epochs = 10\n",
    "    ## train model\n",
    "    history_natural = olympic.fit(\n",
    "        model_SGD,\n",
    "        optimiser,\n",
    "        loss_fn,\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5)\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation accuracy\n",
    "    print('final validation accuracy:')\n",
    "    valscore = olympic.evaluate(model_SGD, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    print(valscore)\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/'+NetName+'_SGD_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_SGD,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING ENTROPY SGD (ESGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_training(model, optimiser, loss_fn, x, y, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    def helper():\n",
    "        def feval():\n",
    "            #x, y = Variable(x), Variable(y.squeeze())\n",
    "            bsz = x.size(0)\n",
    "            optimiser.zero_grad()\n",
    "            yh = model(x)\n",
    "            f = loss_fn.forward(yh, y)\n",
    "            f.backward()\n",
    "\n",
    "            yp = yh.argmax(axis=1)\n",
    "            prec1 = 100*torch.sum(yp == y)//bsz\n",
    "            err = 100.-prec1.item()\n",
    "\n",
    "            return (f.data.item(), err)\n",
    "        return feval\n",
    "\n",
    "    loss, err = optimiser.step(helper(), model, loss_fn)\n",
    "    loss = torch.tensor(loss)\n",
    "    return loss, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TrainESGD:\n",
    "    ## initialize model\n",
    "    model_ESGD = Net().to(DEVICE)\n",
    "    ## training parameters\n",
    "    lr = 0.01 \n",
    "    l2 = 0.0 #l2 regularization\n",
    "    L = 0    #langevin iterations\n",
    "    gamma = 1e-4 \n",
    "    scoping = 1e-3\n",
    "    noise = 1e-4\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    epochs = 5\n",
    "    optimiser = ESGD_optim.EntropySGD(model_ESGD.parameters(),\n",
    "            config = dict(lr=lr, momentum=0.9, nesterov=True, weight_decay=l2,\n",
    "            L=L, eps=noise, g0=gamma, g1=scoping))\n",
    "    ## train model\n",
    "    history_natural = olympic.fit(\n",
    "        model_ESGD,\n",
    "        optimiser,\n",
    "        loss_fn,\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=entropy_training,\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5)\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation accuracy\n",
    "    print('final validation accuracy:')\n",
    "    valacc = olympic.evaluate(model_ESGD, val_loader, metrics=['accuracy'],\n",
    "                         prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    print(valacc['val_accuracy'])\n",
    "    ## save trained model\n",
    "    modelname = '../trainedmodels/'+dataset+'/'+NetName+'_ESGD_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_ESGD,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING PGD SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infnorm(x):\n",
    "    infn = torch.max(torch.abs(x.detach().cpu()))\n",
    "    return infn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training(model, optimiser, loss_fn, x, y, epoch, adversary, k, step, eps, norm, random):\n",
    "    \"\"\"Performs a single update against a specified adversary\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # Adversial perturbation\n",
    "    x_adv = adversary(model, x, y, loss_fn, k=k, step=step, eps=eps, norm=norm, random=True, debug=False)\n",
    "    #print('l2:',torch.norm(x_adv.detach().cpu()-x.detach().cpu())/np.sqrt(x.detach().cpu().size(0)))    \n",
    "    #print('linf:',infnorm(x_adv.detach().cpu()-x.detach().cpu())/infnorm(x))    \n",
    "    adjust_learning_rate(optimiser,epoch,lr_init)    \n",
    "\n",
    "    optimiser.zero_grad()\n",
    "    y_pred = model(x_adv)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    return loss, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, lr_init):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = lr_init* (0.1 ** (epoch // 40))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l2 ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TrainL2:\n",
    "    ## initialize model\n",
    "    adv_model_l2 = Net().to(DEVICE)\n",
    "    lr = 0.1\n",
    "    optimiser = optim.SGD(adv_model_l2.parameters(), lr=lr)\n",
    "    epochs = 5\n",
    "    ## train model\n",
    "    training_history_l2 = olympic.fit(\n",
    "        adv_model_l2,\n",
    "        optimiser,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=adversarial_training,\n",
    "        update_fn_kwargs={'adversary': pgd, 'k': 10, 'step': 0.01, 'eps': 3.0, 'norm': 2, 'random':True},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_delta=0.005, monitor='val_accuracy')\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation accuracy\n",
    "    print('final validation accuracy:')\n",
    "    valacc = olympic.evaluate(adv_model_l2, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    print(valacc['val_accuracy'])\n",
    "    ## save trained model\n",
    "    modelname = '../trainedmodels/'+dataset+'/'+NetName+'_AT2_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(adv_model_l2,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linf ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TrainLInf:\n",
    "    ## initialize model\n",
    "    adv_model_linf = Net().to(DEVICE)\n",
    "    ## train params\n",
    "    lr = 0.1\n",
    "    lr_init = 0.1\n",
    "    optimiser = optim.SGD(adv_model_linf.parameters(), lr=lr)\n",
    "    epochs = 2\n",
    "    ## train model\n",
    "    training_history_linf = olympic.fit(\n",
    "        adv_model_linf,\n",
    "        optimiser,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=adversarial_training,\n",
    "        update_fn_kwargs={'adversary': iterated_fgsm,'k': 7, 'step': 2, 'eps': 0.032, 'norm': 'inf', 'random':True},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_delta=0.005, monitor='val_accuracy')\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation\n",
    "    print('final validation accuracy:')\n",
    "    valacc = olympic.evaluate(adv_model_linf, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    \n",
    "    ## save trained model\n",
    "    modelname = '../trainedmodels/'+dataset+'/'+NetName+'_ATInf_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(adv_model_linf,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training_entropy(model, optimiser, loss_fn, x, y, epoch, adversary, k, step, eps, norm, gamma, ep):\n",
    "    \"\"\"Performs a single update against a specified adversary\"\"\"\n",
    "    model.train()\n",
    "    adjust_learning_rate(optimiser,epoch,lr_init)   \n",
    "           \n",
    "    # Adversial perturbation\n",
    "    #alpha = 0.8\n",
    "    N = 4\n",
    "    loss = 0\n",
    "    for l in range(N):\n",
    "        x_adv = adversary(model, x, y, loss_fn, k=k, step=step, eps=eps, norm=norm, random=True, gamma=gamma, ep=ep, debug=False)\n",
    "        optimiser.zero_grad()\n",
    "        y_pred = model(x_adv)\n",
    "        #loss = loss + loss_fn(y_pred,y)\n",
    "        loss = (1-0.9)*loss + 0.9*loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    return loss, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TrainSAT2:\n",
    "    ## initialize model\n",
    "    #model_SAT2 = model_cnn().to(DEVICE)\n",
    "    model_SAT2 = Net().to(DEVICE)\n",
    "    ## train params\n",
    "    lr = 0.1\n",
    "    lr_init = 0.1\n",
    "    optimiser = optim.SGD(model_SAT2.parameters(), lr=lr)\n",
    "    epochs = 5\n",
    "    ## train model\n",
    "    training_history_entropySmoothing = olympic.fit(\n",
    "        model_SAT2,\n",
    "        optimiser,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=adversarial_training_entropy,\n",
    "        update_fn_kwargs={'adversary': entropySmoothing, 'k': 10, 'step': 0.01, 'eps': 3.0, 'norm': 2, 'gamma':1e-5, 'ep':1e-5},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_delta=0.005, monitor='val_accuracy')\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation\n",
    "    print('final validation accuracy:')\n",
    "    olympic.evaluate(model_SAT2, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/'+NetName+'_SAT2_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_SAT2,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_entropy(model, optimiser, loss_fn, trainloader, epoch, adversary, N, step, eps, norm, gamma, ep):\n",
    "    \"\"\"Performs a single update against a specified adversary\"\"\"\n",
    "    model.train()\n",
    "    alpha = 0.9\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        x, y = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "                   \n",
    "        loss = 0\n",
    "        for l in range(N):\n",
    "            x_adv = adversary(model, x, y, loss_fn, k=1, step=step, eps=eps, norm=norm, random=True, gamma=gamma, ep=ep, debug=False)\n",
    "            optimiser.zero_grad()\n",
    "            y_pred = model(x_adv)\n",
    "            loss = (1-alpha)*loss + alpha*loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        # print progress\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(x), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.343079\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-67001c301a42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# adversarial training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         train_entropy(model_SATInf, optimiser, nn.CrossEntropyLoss(), train_loader, epoch, entropySmoothing, \n\u001b[0m\u001b[1;32m     22\u001b[0m               N=Nlang,step=step_satinf,eps=eps_satinf,norm='inf',gamma=gamma,ep=1e-6)\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-ebcab1a54f7d>\u001b[0m in \u001b[0;36mtrain_entropy\u001b[0;34m(model, optimiser, loss_fn, trainloader, epoch, adversary, N, step, eps, norm, gamma, ep)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mx_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/StochAT/architectures/wideresnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/StochAT/architectures/wideresnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/StochAT/architectures/wideresnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequalInOut\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdroprate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdroprate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2012\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2014\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2015\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if TrainSATInf:\n",
    "    t1 = time.time()\n",
    "\n",
    "    model_SATInf = Net().to(DEVICE)\n",
    "    ## training params\n",
    "    lr = 0.1\n",
    "    lr_init = 0.1\n",
    "    optimiser = optim.SGD(model_SATInf.parameters(), lr=lr)\n",
    "    epochs = 50\n",
    "    step_satinf = 2\n",
    "    eps_satinf = 0.032\n",
    "    Nlang = 5\n",
    "    gamma = 1e-4\n",
    "    ## train model\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # adjust learning rate for SGD\n",
    "        adjust_learning_rate(optimiser, epoch, lr_init)\n",
    "\n",
    "        # adversarial training\n",
    "        train_entropy(model_SATInf, optimiser, nn.CrossEntropyLoss(), train_loader, epoch, entropySmoothing, \n",
    "              N=Nlang,step=step_satinf,eps=eps_satinf,norm='inf',gamma=gamma,ep=1e-6)\n",
    "\n",
    "        if epoch %3 == 0:\n",
    "            # evaluation on natural examples\n",
    "            print('================================================================')\n",
    "            eval_test(model_SATInf, DEVICE, val_loader)\n",
    "            print('================================================================')\n",
    "            \n",
    "        if epoch%10 == 0:\n",
    "            modelname = '../trainedmodels/'+dataset+'/'+NetName+'_SATInf_ep'+str(epochs)+'_N_'+str(Nlang)+'_step_'+str(step_satinf)+'_lr'+str(lr)+'.pt'\n",
    "            torch.save(model_SATInf,modelname)           \n",
    "\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/'+NetName+'_SATInf_ep'+str(epochs)+'_'+str(Nlang)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_SATInf,modelname)\n",
    "    print('time elapsed:',time.time()-t1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING TRADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['test_batch_size'] = 128\n",
    "args['no_cuda'] = False\n",
    "args['epsilon'] = 0.3\n",
    "args['num_steps'] = 5\n",
    "args['step_size'] = 0.01\n",
    "args['random'] =True,\n",
    "args['white_box_attack']=True\n",
    "args['log_interval'] = 100\n",
    "args['beta'] = 1.0\n",
    "args['log_interval'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calculate robust loss\n",
    "        loss = trades_loss(model=model,\n",
    "                           x_natural=data,\n",
    "                           y=target,\n",
    "                           optimizer=optimizer,\n",
    "                           step_size=args['step_size'],\n",
    "                           epsilon=args['epsilon'],\n",
    "                           perturb_steps=args['num_steps'],\n",
    "                           beta=args['beta'],\n",
    "                           distance = 'l_2')\n",
    "        \n",
    "\n",
    "        #print('outloss pre step:',loss)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        optimizer.step()\n",
    "        #print('outloss post step:',loss.item())\n",
    "\n",
    "        # print progress\n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_train(model, device, train_loader):\n",
    "    model.eval()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            train_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print('Training: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        train_loss, correct, len(train_loader.dataset),\n",
    "        100. * correct / len(train_loader.dataset)))\n",
    "    training_accuracy = correct / len(train_loader.dataset)\n",
    "    return train_loss, training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TrainTRADES:\n",
    "    args['attack'] = 'l_2' #or 'l_inf'\n",
    "    ## initialize model\n",
    "    #model_TRADES = model_cnn().to(DEVICE)\n",
    "    model_TRADES = Net().to(DEVICE)\n",
    "    ## training params\n",
    "    lr = 0.1\n",
    "    optimizer = optim.SGD(model_TRADES.parameters(), lr=lr)\n",
    "    epochs = 10\n",
    "    ## train model\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # adjust learning rate for SGD\n",
    "        #adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        # adversarial training\n",
    "        train(args, model_TRADES, DEVICE, train_loader, optimizer, epoch)\n",
    "\n",
    "        # evaluation on natural examples\n",
    "        print('================================================================')\n",
    "        eval_train(model_TRADES, DEVICE, train_loader)\n",
    "        eval_test(model_TRADES, DEVICE, val_loader)\n",
    "        print('================================================================')\n",
    "\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/'+NetName+'_TRADES_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_TRADES,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TrainTRADESInf:\n",
    "    args['attack'] = 'l_inf' \n",
    "    ## initialize model\n",
    "    model_TRADESInf = Net().to(DEVICE)\n",
    "    ## training params\n",
    "    lr = 0.1\n",
    "    optimizer = optim.SGD(model_TRADESInf.parameters(), lr=lr)\n",
    "    epochs = 10\n",
    "    ## train model\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # adjust learning rate for SGD\n",
    "        #adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        # adversarial training\n",
    "        train(args, model_TRADESInf, DEVICE, train_loader, optimizer, epoch)\n",
    "\n",
    "        # evaluation on natural examples\n",
    "        print('================================================================')\n",
    "        eval_train(model_TRADESInf, DEVICE, train_loader)\n",
    "        eval_test(model_TRADESInf, DEVICE, val_loader)\n",
    "        print('================================================================')\n",
    "\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/'+NetName+'_TRADESInf_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_TRADESInf,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING MART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING MMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD ALL PRE-TRAINED MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSGD = TrainSGD*True\n",
    "TrainESGD = TrainESGD*True\n",
    "TrainL2 = TrainL2*True\n",
    "TrainLInf = TrainLInf*True\n",
    "TrainSAT2 = TrainSAT2*True\n",
    "TrainSATInf = TrainSATInf*True\n",
    "TrainTRADES = TrainTRADES*True\n",
    "TrainTRADESInf = TrainTRADESInf*True\n",
    "TrainMART = TrainMART*False\n",
    "TrainMMA = TrainMMA*False\n",
    "TrainMMAInf = TrainMMAInf*False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTRADESInf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load all the pre-trained models\n",
    "if not TrainSGD:\n",
    "    model_SGD = torch.load('../trainedmodels/'+dataset+'/SGD_ep10_lr0.1.pt').to(DEVICE)\n",
    "if not TrainESGD:    \n",
    "    model_ESGD = torch.load('../trainedmodels/'+dataset+'/ESGD_ep5_lr0.1.pt').to(DEVICE)\n",
    "if not TrainL2:\n",
    "    adv_model_linf = torch.load('../trainedmodels/'+dataset+'/AT2_ep2_lr0.1.pt').to(DEVICE)\n",
    "if not TrainLInf:\n",
    "    adv_model_l2 = torch.load('../trainedmodels/'+dataset+'/ATInf_ep2_lr0.1.pt').to(DEVICE)\n",
    "if not TrainSAT2:\n",
    "    model_SAT2 = torch.load('../trainedmodels/'+dataset+'/SAT2_ep2_lr0.1.pt').to(DEVICE)\n",
    "if not TrainSATInf:\n",
    "    model_SATInf = torch.load('../trainedmodels/'+dataset+'/SATInf_ep2_lr0.1.pt').to(DEVICE)\n",
    "if not TrainTRADES:\n",
    "    model_TRADES = torch.load('../trainedmodels/'+dataset+'/TRADES_ep2_lr0.1.pt').to(DEVICE)\n",
    "if not TrainTRADESInf:\n",
    "    model_TRADES = torch.load('../trainedmodels/'+dataset+'/TRADESInf_ep2_lr0.1.pt').to(DEVICE)    \n",
    "'''\n",
    "if not TrainMART:\n",
    "    if dataset=='CIFAR10':\n",
    "        model_MART = Net()\n",
    "        if NetName == 'ResNet18':\n",
    "            dics = torch.load('../trainedmodels/'+dataset+'/ResNet18_model_MART.pt')\n",
    "        if NetName == 'WideResNet':\n",
    "            dics = torch.load('../trainedmodels/'+dataset+'/rob_cifar_mart.pt')            \n",
    "        model_MART.load_state_dict(dics)\n",
    "        model_MART = model_MART.to(DEVICE)\n",
    "if not TrainMMA:\n",
    "    model_MMA = torch.load('../trainedmodels/'+dataset+'/'+dataset.lower()+'-L2-MMA-4.0-sd0/model_best.pt')\n",
    "    model_MMAInf = torch.load('../trainedmodels/'+dataset+'/'+dataset.lower()+'-Linf-MMA-0.45-sd0/model_best.pt')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying adversarial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infnorm(x):\n",
    "    infn = torch.max(torch.abs(x.detach().cpu()))\n",
    "    return infn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_against_adversary(model, k, eps, step, norm):\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    for x, y in val_loader:\n",
    "        total += x.size(0)\n",
    "        \n",
    "        if norm == 2:\n",
    "            x_adv = pgd(\n",
    "                model, x.to(DEVICE), y.to(DEVICE), torch.nn.CrossEntropyLoss(), k=k, step=step, eps=eps, norm=2)\n",
    "            print('rel. l2-norm of x_adv-x:',torch.norm(x_adv.detach().cpu()-x)/np.sqrt(x.size(0)))#/torch.norm(x))\n",
    "        elif norm == 'inf':\n",
    "            x_adv = iterated_fgsm(\n",
    "                model, x.to(DEVICE), y.to(DEVICE), torch.nn.CrossEntropyLoss(), k=k, step=step, eps=eps, norm='inf')\n",
    "            print('rel. linf-norm of x_adv-x:',infnorm(x_adv.detach().cpu()-x)/infnorm(x))\n",
    "        y_pred = model(x_adv)\n",
    "\n",
    "        acc += olympic.metrics.accuracy(y.to(DEVICE), y_pred) * x.size(0)\n",
    "\n",
    "    return acc/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate robust models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadResults = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "if not loadResults:\n",
    "    pgd_attack_range = [3.0] #np.arange(0, 6.1, 1./3)\n",
    "    acc_SGD = []\n",
    "    acc_ESGD = []\n",
    "    acc_l2 = []\n",
    "    acc_SAT2 = []\n",
    "    acc_TRADES = []\n",
    "    acc_MMA = []\n",
    "    for eps in pgd_attack_range:\n",
    "        print('eps:',eps)\n",
    "        print('evaluating SGD network...')\n",
    "        acc_SGD.append(evaluate_against_adversary(model_SGD, k=20, eps=eps, step=0.5, norm=2))\n",
    "        print('evaluating ESGD network...')\n",
    "        acc_ESGD.append(evaluate_against_adversary(model_ESGD, k=20, eps=eps, step=0.5, norm=2))\n",
    "        print('evaluating SAT2 network...')\n",
    "        acc_SAT2.append(evaluate_against_adversary(model_SAT2, k=30, eps=eps, step=0.3, norm=2))\n",
    "        print('evaluating l2 network...')\n",
    "        acc_l2.append(evaluate_against_adversary(adv_model_l2, k=30, eps=eps, step=1.5, norm=2))\n",
    "        print('evaluating TRADES network...')\n",
    "        acc_TRADES.append(evaluate_against_adversary(model_TRADES, k=30, eps=eps, step=1.5, norm=2))  \n",
    "        #print('evaluating MART network...')\n",
    "        #acc_MMA.append(evaluate_against_adversary(model_MMA, k=30, eps=eps, step=1.5, norm=2))          \n",
    "print(\"time elapsed:\",time.time()-t1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not loadResults:    \n",
    "    accData = [acc_SGD,acc_ESGD,acc_l2,acc_SAT2,acc_TRADES,acc_MMA]\n",
    "    np.save('../results/accData_l2.npy',accData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if loadResults:\n",
    "    pgd_attack_range = [3.0] #np.arange(0.0, 6.1, 1./3)\n",
    "    accData2 = np.load('../results/accData_l2.npy')\n",
    "    [acc_SGD,acc_ESGD,acc_l2,acc_SAT2,acc_TRADES,acc_MMA] = accData2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with plt.style.context('ggplot'):\n",
    "    COLOURS = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    #MARKERS = plt.rcParams['axes.prop_cycle'].by_key()['marker']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if len(pgd_attack_range) > 1:\n",
    "    with plt.style.context('ggplot'):\n",
    "        plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "        plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "        plt.rcParams[\"axes.labelcolor\"] = \"black\"\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(15,10))\n",
    "        plt.figure(figsize=(14,7))\n",
    "        axes.set_title('$L^2$-bounded adversary')\n",
    "        axes.plot(pgd_attack_range, acc_SGD, label='SGD')\n",
    "        axes.plot(pgd_attack_range, acc_ESGD, label='Entropy-SGD')\n",
    "        axes.plot(pgd_attack_range, acc_SAT2, label='Data-Entropy-SGD ($L_2$)')\n",
    "        axes.plot(pgd_attack_range, acc_l2, label='$L2$ training')\n",
    "        axes.plot(pgd_attack_range, acc_TRADES, label='TRADES training')\n",
    "        axes.plot(pgd_attack_range, acc_MMA, label='MMA training')\n",
    "\n",
    "        axes.vlines([3], 0, 1, colors=COLOURS[1], linestyle='--')\n",
    "        axes.set_ylabel('Accuracy')\n",
    "        axes.set_xlabel('Epsilon')\n",
    "        axes.set_ylim((0,1))\n",
    "        axes.legend()\n",
    "else:\n",
    "    print(accData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadResultsFGSM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "if not loadResultsFGSM:\n",
    "    fgsm_attack_range = [0.03] #np.arange(0.0, 0.52, 0.025)\n",
    "    fgsm_acc_linf = []\n",
    "    #fgsm_acc_SGD = []\n",
    "    #fgsm_acc_ESGD = []\n",
    "    fgsm_acc_SATInf = []\n",
    "    fgsm_acc_linf = []\n",
    "    #fgsm_acc_TRADESInf = []\n",
    "    #fgsm_acc_MART = []\n",
    "    #fgsm_acc_MMAInf = []\n",
    "    for eps in fgsm_attack_range:\n",
    "        print('eps:',eps)\n",
    "        #print('evaluating SGD network...')\n",
    "        #fgsm_acc_SGD.append(evaluate_against_adversary(model_SGD, k=20, eps=eps, step=0.1, norm='inf'))\n",
    "        #print('evaluating ESGD network;\n",
    "        #fgsm_acc_ESGD.append(evaluate_against_adversary(model_ESGD, k=20, eps=eps, step=0.1, norm='inf'))\n",
    "        print('evaluating SATInf network...')\n",
    "        fgsm_acc_SATInf.append(evaluate_against_adversary(model_SATInf, k=10, eps=eps, step=0.1, norm='inf'))        \n",
    "        print('evaluating linf network...')\n",
    "        fgsm_acc_linf.append(evaluate_against_adversary(adv_model_linf, k=10, eps=eps, step=0.1, norm='inf'))\n",
    "        #print('evaluating TRADES network...')\n",
    "        #fgsm_acc_TRADESInf.append(evaluate_against_adversary(model_TRADESInf, k=50, eps=eps, step=0.02, norm='inf'))\n",
    "        #print('evaluating MART network...')\n",
    "        #fgsm_acc_MART.append(evaluate_against_adversary(model_MART, k=50, eps=eps, step=0.02, norm='inf'))\n",
    "        #print('evaluating MMA network...')\n",
    "        #fgsm_acc_MMAInf.append(evaluate_against_adversary(model_MMAInf, k=50, eps=eps, step=0.02, norm='inf'))\n",
    "         \n",
    "print(\"time elapsed:\",time.time()-t1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if not loadResultsFGSM:    \n",
    "    fgsmaccData = [fgsm_acc_SGD,fgsm_acc_ESGD,fgsm_acc_linf,fgsm_acc_SATInf, fgsm_acc_TRADESInf, fgsm_acc_MART, fgsm_acc_MMAInf]\n",
    "    np.save('../results/fgsmaccData.npy',fgsmaccData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm_acc_SATInf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm_acc_linf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fgsm_acc_linf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if loadResultsFGSM:\n",
    "    fgsm_attack_range = [8/255] #np.arange(0.0, 0.52, 0.025)\n",
    "    accData2 = np.load('../results/fgsmaccData.npy')\n",
    "    [fgsm_acc_SGD,fgsm_acc_ESGD,fgsm_acc_linf,fgsm_acc_SATInf, fgsm_acc_TRADESInf, fgsm_acc_MART, fgsm_acc_MMAInf] = accData2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if len(fgsm_attack_range) > 1:\n",
    "    with plt.style.context('ggplot'):\n",
    "        plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "        plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "        plt.rcParams[\"axes.labelcolor\"] = \"black\"\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(15,10))\n",
    "        plt.figure(figsize=(14,7))\n",
    "        axes.set_title('$L^\\infty$-bounded adversary')\n",
    "        axes.plot(fgsm_attack_range, fgsm_acc_SGD, label='SGD')\n",
    "        axes.plot(fgsm_attack_range, fgsm_acc_ESGD, label='Entropy-SGD')\n",
    "        axes.plot(fgsm_attack_range, fgsm_acc_SATInf, label='Data-Entropy-SGD ($L_\\infty$)')    \n",
    "        axes.plot(fgsm_attack_range, fgsm_acc_linf, label='$L{\\infty}$ training')\n",
    "        axes.plot(fgsm_attack_range, fgsm_acc_TRADES, label='TRADES training')\n",
    "        axes.vlines([0.25], 0, 1, colors=COLOURS[1], linestyle='--')\n",
    "        axes.set_ylabel('Accuracy')\n",
    "        axes.set_xlabel('Epsilon')\n",
    "        axes.set_ylim((0,1))\n",
    "        axes.legend()\n",
    "else:\n",
    "    print(fgsmaccData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tempFGSMSATInf = []\n",
    "tempFGSMSATInf.append(evaluate_against_adversary(model_SATInf_test1, k=10, eps=eps, step=0.01, norm='inf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tempFGSMSATInf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
