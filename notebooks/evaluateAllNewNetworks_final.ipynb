{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Adversarial Training (StochAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from multiprocessing import cpu_count\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import olympic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Union, Callable, Tuple\n",
    "sys.path.append('../adversarial/')\n",
    "sys.path.append('../architectures/')\n",
    "from functional import boundary, iterated_fgsm, local_search, pgd, entropySmoothing\n",
    "from ESGD_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "import argparse, math, random\n",
    "import ESGD_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trades import trades_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'MNIST' # [MNIST, CIFAR10]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "bsz = 128\n",
    "if dataset == 'MNIST':\n",
    "    train = datasets.MNIST('../../data/MNIST', train=True, transform=transform, download=True)\n",
    "    val = datasets.MNIST('../../data/MNIST', train=False, transform=transform, download=True)\n",
    "elif dataset == 'CIFAR10':\n",
    "    train = datasets.CIFAR10('../../data/CIFAR10', train=True, transform=transform, download=True)\n",
    "    val = datasets.CIFAR10('../../data/CIFAR10', train=False, transform=transform, download=True)\n",
    "    \n",
    "train_loader = DataLoader(train, batch_size=128, num_workers=cpu_count(),drop_last=True)\n",
    "val_loader = DataLoader(val, batch_size=128, num_workers=cpu_count(),drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALIZE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='MNIST':\n",
    "    from net_mnist import Net, NetSoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='CIFAR10':\n",
    "    #[ResNet18,ResNet34,ResNet50,WideResNet]\n",
    "    from resnet import ResNet18,ResNet34,ResNet50\n",
    "    from wideresnet import WideResNet\n",
    "    Net = ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM SEED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa8a0c79570>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.set_num_threads(2)\n",
    "if DEVICE=='cuda':\n",
    "    torch.cuda.set_device(-1)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    cudnn.benchmark = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD PRETRAINED OR TRAIN NEW MODELS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSGD = True\n",
    "TrainESGD = True\n",
    "TrainL2 = True\n",
    "TrainLInf = True\n",
    "TrainSAT2 = True\n",
    "TrainSATInf = True\n",
    "TrainTRADES = True\n",
    "TrainMART = False\n",
    "TrainMMA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN NAIVE MODEL USING SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 468/468 [00:02<00:00, 196.50it/s, loss=0.973, accuracy=0.672, val_loss=0.193, val_accuracy=0.941]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:02<00:00, 192.97it/s, loss=0.397, accuracy=0.878, val_loss=0.121, val_accuracy=0.961]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:02<00:00, 205.85it/s, loss=0.309, accuracy=0.908, val_loss=0.107, val_accuracy=0.966]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:02<00:00, 202.72it/s, loss=0.269, accuracy=0.92, val_loss=0.0888, val_accuracy=0.97]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:02<00:00, 206.54it/s, loss=0.246, accuracy=0.927, val_loss=0.079, val_accuracy=0.974]\n",
      "Epoch 6: 100%|██████████| 468/468 [00:02<00:00, 200.15it/s, loss=0.226, accuracy=0.933, val_loss=0.0746, val_accuracy=0.977]\n",
      "Epoch 7: 100%|██████████| 468/468 [00:02<00:00, 200.59it/s, loss=0.207, accuracy=0.938, val_loss=0.0664, val_accuracy=0.979]\n",
      "Epoch 8: 100%|██████████| 468/468 [00:02<00:00, 197.09it/s, loss=0.198, accuracy=0.94, val_loss=0.0638, val_accuracy=0.979]\n",
      "Epoch 9: 100%|██████████| 468/468 [00:02<00:00, 196.31it/s, loss=0.186, accuracy=0.945, val_loss=0.0607, val_accuracy=0.98]\n",
      "Epoch 10: 100%|██████████| 468/468 [00:02<00:00, 203.35it/s, loss=0.181, accuracy=0.948, val_loss=0.0569, val_accuracy=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_accuracy': 0.981270032051282}\n"
     ]
    }
   ],
   "source": [
    "if TrainSGD:\n",
    "    ## initialize model\n",
    "    model_SGD = NetSoft().to(DEVICE)\n",
    "    ## training params\n",
    "    lr = 0.1\n",
    "    optimiser = optim.SGD(model_SGD.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    epochs = 10\n",
    "    ## train model\n",
    "    history_natural = olympic.fit(\n",
    "        model_SGD,\n",
    "        optimiser,\n",
    "        loss_fn,\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5)\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation accuracy\n",
    "    print('final validation accuracy:')\n",
    "    valscore = olympic.evaluate(model_SGD, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    print(valscore)\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/SGD_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_SGD,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING ENTROPY SGD (ESGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_training(model, optimiser, loss_fn, x, y, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    def helper():\n",
    "        def feval():\n",
    "            #x, y = Variable(x), Variable(y.squeeze())\n",
    "            bsz = x.size(0)\n",
    "            optimiser.zero_grad()\n",
    "            yh = model(x)\n",
    "            f = loss_fn.forward(yh, y)\n",
    "            f.backward()\n",
    "\n",
    "            yp = yh.argmax(axis=1)\n",
    "            prec1 = 100*torch.sum(yp == y)//bsz\n",
    "            err = 100.-prec1.item()\n",
    "\n",
    "            return (f.data.item(), err)\n",
    "        return feval\n",
    "\n",
    "    loss, err = optimiser.step(helper(), model, loss_fn)\n",
    "    loss = torch.tensor(loss)\n",
    "    return loss, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../adversarial/ESGD_optim.py:98: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  mdw.mul_(mom).add_(1-damp, dw)\n",
      "Epoch 1: 100%|██████████| 468/468 [00:02<00:00, 161.94it/s, loss=0.577, accuracy=0.817, val_loss=0.123, val_accuracy=0.962]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:02<00:00, 164.65it/s, loss=0.329, accuracy=0.9, val_loss=0.0973, val_accuracy=0.971]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:02<00:00, 165.74it/s, loss=0.306, accuracy=0.91, val_loss=0.0991, val_accuracy=0.972]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:02<00:00, 165.80it/s, loss=0.292, accuracy=0.916, val_loss=0.0765, val_accuracy=0.98]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:02<00:00, 165.27it/s, loss=0.279, accuracy=0.92, val_loss=0.0741, val_accuracy=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9792668269230769\n"
     ]
    }
   ],
   "source": [
    "if TrainESGD:\n",
    "    ## initialize model\n",
    "    model_ESGD = NetSoft().to(DEVICE)\n",
    "    ## training parameters\n",
    "    lr = 0.1 \n",
    "    l2 = 0.0 #l2 regularization\n",
    "    L = 0    #langevin iterations\n",
    "    gamma = 1e-4 \n",
    "    scoping = 1e-3\n",
    "    noise = 1e-4\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    epochs = 5\n",
    "    optimiser = ESGD_optim.EntropySGD(model_ESGD.parameters(),\n",
    "            config = dict(lr=lr, momentum=0.9, nesterov=True, weight_decay=l2,\n",
    "            L=L, eps=noise, g0=gamma, g1=scoping))\n",
    "    ## train model\n",
    "    history_natural = olympic.fit(\n",
    "        model_ESGD,\n",
    "        optimiser,\n",
    "        loss_fn,\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=entropy_training,\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5)\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation accuracy\n",
    "    print('final validation accuracy:')\n",
    "    valacc = olympic.evaluate(model_ESGD, val_loader, metrics=['accuracy'],\n",
    "                         prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    print(valacc['val_accuracy'])\n",
    "    ## save trained model\n",
    "    modelname = '../trainedmodels/'+dataset+'/ESGD_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_ESGD,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING PGD SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infnorm(x):\n",
    "    infn = torch.max(torch.abs(x.detach().cpu()))\n",
    "    return infn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training(model, optimiser, loss_fn, x, y, epoch, adversary, k, step, eps, norm, random):\n",
    "    \"\"\"Performs a single update against a specified adversary\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    # Adversial perturbation\n",
    "    x_adv = adversary(model, x, y, loss_fn, k=k, step=step, eps=eps, norm=norm, random=True)\n",
    "    #print('l2:',torch.norm(x_adv.detach().cpu()-x.detach().cpu())/np.sqrt(x.detach().cpu().size(0)))    \n",
    "    #print('linf:',infnorm(x_adv.detach().cpu()-x.detach().cpu())/infnorm(x))    \n",
    "\n",
    "    optimiser.zero_grad()\n",
    "    y_pred = model(x_adv)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    return loss, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l2 ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 468/468 [00:03<00:00, 118.89it/s, loss=2.21, accuracy=0.211, val_loss=1.76, val_accuracy=0.631]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:03<00:00, 120.16it/s, loss=1.26, accuracy=0.59, val_loss=0.551, val_accuracy=0.85]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:03<00:00, 120.86it/s, loss=0.809, accuracy=0.741, val_loss=0.377, val_accuracy=0.892]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:03<00:00, 123.91it/s, loss=0.656, accuracy=0.795, val_loss=0.294, val_accuracy=0.916]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:03<00:00, 121.20it/s, loss=0.585, accuracy=0.82, val_loss=0.253, val_accuracy=0.927]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9269831730769231\n"
     ]
    }
   ],
   "source": [
    "if TrainL2:\n",
    "    ## initialize model\n",
    "    adv_model_l2 = NetSoft().to(DEVICE)\n",
    "    lr = 0.01\n",
    "    optimiser = optim.SGD(adv_model_l2.parameters(), lr=lr)\n",
    "    epochs = 5\n",
    "    ## train model\n",
    "    training_history_l2 = olympic.fit(\n",
    "        adv_model_l2,\n",
    "        optimiser,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=adversarial_training,\n",
    "        update_fn_kwargs={'adversary': pgd, 'k': 2, 'step': 0.05, 'eps': 1.0, 'norm': 2, 'random':True},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_delta=0.005, monitor='val_accuracy')\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation accuracy\n",
    "    print('final validation accuracy:')\n",
    "    valacc = olympic.evaluate(adv_model_l2, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    print(valacc['val_accuracy'])\n",
    "    ## save trained model\n",
    "    modelname = '../trainedmodels/'+dataset+'/AT2_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(adv_model_l2,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linf ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 468/468 [00:03<00:00, 129.08it/s, loss=2.3, accuracy=0.126, val_loss=2.24, val_accuracy=0.429]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:03<00:00, 132.89it/s, loss=2.03, accuracy=0.312, val_loss=1.13, val_accuracy=0.74]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:03<00:00, 133.42it/s, loss=1.32, accuracy=0.556, val_loss=0.56, val_accuracy=0.85]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:03<00:00, 132.20it/s, loss=1.04, accuracy=0.65, val_loss=0.415, val_accuracy=0.896]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:03<00:00, 129.36it/s, loss=0.9, accuracy=0.704, val_loss=0.334, val_accuracy=0.915]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if TrainLInf:\n",
    "    ## initialize model\n",
    "    adv_model_linf = NetSoft().to(DEVICE)\n",
    "    ## train params\n",
    "    lr = 0.01\n",
    "    optimiser = optim.SGD(adv_model_linf.parameters(), lr=lr)\n",
    "    epochs = 5\n",
    "    ## train model\n",
    "    training_history_linf = olympic.fit(\n",
    "        adv_model_linf,\n",
    "        optimiser,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=adversarial_training,\n",
    "        update_fn_kwargs={'adversary': iterated_fgsm,'k': 2, 'step': 0.05, 'eps': 0.1, 'norm': 'inf', 'random':True},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_delta=0.005, monitor='val_accuracy')\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation\n",
    "    print('final validation accuracy:')\n",
    "    valacc = olympic.evaluate(adv_model_linf, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    \n",
    "    ## save trained model\n",
    "    modelname = '../trainedmodels/'+dataset+'/ATInf_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(adv_model_linf,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training_entropy(model, optimiser, loss_fn, x, y, epoch, adversary, k, step, eps, norm, gamma):\n",
    "    \"\"\"Performs a single update against a specified adversary\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # Adversial perturbation\n",
    "    #alpha = 0.8\n",
    "    N = 1\n",
    "    loss = 0\n",
    "    for l in range(N):\n",
    "        x_adv = adversary(model, x, y, loss_fn, k=k, step=step, eps=eps, norm=norm, random=True, gamma=gamma)\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        y_pred = model(x_adv)\n",
    "        loss = loss + loss_fn(y_pred,y)\n",
    "        #loss = (1-alpha)*loss + alpha*loss_fn(y_pred, y)\n",
    "    loss = loss/N\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    return loss, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 468/468 [00:04<00:00, 116.79it/s, loss=2.28, accuracy=0.152, val_loss=2.17, val_accuracy=0.47]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:03<00:00, 118.56it/s, loss=1.65, accuracy=0.462, val_loss=0.683, val_accuracy=0.825]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:03<00:00, 117.27it/s, loss=0.896, accuracy=0.714, val_loss=0.398, val_accuracy=0.892]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:03<00:00, 118.69it/s, loss=0.695, accuracy=0.785, val_loss=0.31, val_accuracy=0.913]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:04<00:00, 115.59it/s, loss=0.595, accuracy=0.816, val_loss=0.255, val_accuracy=0.927]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if TrainSAT2:\n",
    "    ## initialize model\n",
    "    model_SAT2 = NetSoft().to(DEVICE)\n",
    "    ## train params\n",
    "    lr = 0.01\n",
    "    optimiser = optim.SGD(model_SAT2.parameters(), lr=lr)\n",
    "    epochs = 5\n",
    "    ## train model\n",
    "    training_history_entropySmoothing = olympic.fit(\n",
    "        model_SAT2,\n",
    "        optimiser,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=adversarial_training_entropy,\n",
    "        update_fn_kwargs={'adversary': entropySmoothing, 'k': 2, 'step': 0.05, 'eps': 1.0, 'norm': 2, 'gamma':1e-5},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_delta=0.005, monitor='val_accuracy')\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation\n",
    "    print('final validation accuracy:')\n",
    "    olympic.evaluate(model_SAT2, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/SAT2_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_SAT2,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 468/468 [00:03<00:00, 123.15it/s, loss=2.22, accuracy=0.201, val_loss=1.83, val_accuracy=0.591]\n",
      "Epoch 2: 100%|██████████| 468/468 [00:03<00:00, 121.94it/s, loss=1.43, accuracy=0.525, val_loss=0.613, val_accuracy=0.841]\n",
      "Epoch 3: 100%|██████████| 468/468 [00:03<00:00, 122.64it/s, loss=0.89, accuracy=0.709, val_loss=0.392, val_accuracy=0.896]\n",
      "Epoch 4: 100%|██████████| 468/468 [00:03<00:00, 122.90it/s, loss=0.726, accuracy=0.771, val_loss=0.307, val_accuracy=0.913]\n",
      "Epoch 5: 100%|██████████| 468/468 [00:03<00:00, 122.39it/s, loss=0.637, accuracy=0.801, val_loss=0.264, val_accuracy=0.925]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "final validation accuracy:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if TrainSATInf:\n",
    "    ## initialize model\n",
    "    model_SATInf = NetSoft().to(DEVICE)\n",
    "    ## train params\n",
    "    lr = 0.01\n",
    "    optimiser = optim.SGD(model_SATInf.parameters(), lr=lr)\n",
    "    epochs = 5\n",
    "    ## train model\n",
    "    training_history_entropySmoothing = olympic.fit(\n",
    "        model_SATInf,\n",
    "        optimiser,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=adversarial_training_entropy,\n",
    "        update_fn_kwargs={'adversary': entropySmoothing, 'k': 2, 'step': 0.05, 'eps': 0.1, 'norm': 'inf', 'gamma':1e-5},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_delta=0.005, monitor='val_accuracy')\n",
    "        ]\n",
    "    )\n",
    "    ## verify validation\n",
    "    print('final validation accuracy:')\n",
    "    olympic.evaluate(model_SATInf, val_loader, metrics=['accuracy'],\n",
    "                     prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/SATInf_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_SATInf,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING TRADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['test_batch_size'] = 128\n",
    "args['no_cuda'] = False\n",
    "args['epsilon'] = 0.3\n",
    "args['num_steps'] = 5\n",
    "args['step_size'] = 0.01\n",
    "args['random'] =True,\n",
    "args['model_path']='./checkpoints/model_mnist_smallcnn.pt'\n",
    "args['source_model_path'] ='./checkpoints/model_mnist_smallcnn.pt'\n",
    "args['target_model_path'] = './checkpoints/model_mnist_smallcnn.pt'\n",
    "args['white_box_attack']=True\n",
    "args['log_interval'] = 100\n",
    "args['beta'] = 1.0\n",
    "args['log_interval'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # calculate robust loss\n",
    "        loss = trades_loss(model=model,\n",
    "                           x_natural=data,\n",
    "                           y=target,\n",
    "                           optimizer=optimizer,\n",
    "                           step_size=args['step_size'],\n",
    "                           epsilon=args['epsilon'],\n",
    "                           perturb_steps=args['num_steps'],\n",
    "                           beta=args['beta'],\n",
    "                           distance = 'l_2')\n",
    "        \n",
    "\n",
    "        #print('outloss pre step:',loss)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        optimizer.step()\n",
    "        #print('outloss post step:',loss.item())\n",
    "\n",
    "        # print progress\n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_train(model, device, train_loader):\n",
    "    model.eval()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            train_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print('Training: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        train_loss, correct, len(train_loader.dataset),\n",
    "        100. * correct / len(train_loader.dataset)))\n",
    "    training_accuracy = correct / len(train_loader.dataset)\n",
    "    return train_loss, training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauri/.local/lib/python3.8/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306984\n",
      "Train Epoch: 1 [128/60000 (0%)]\tLoss: 2.296862\n",
      "Train Epoch: 1 [256/60000 (0%)]\tLoss: 2.301613\n",
      "Train Epoch: 1 [384/60000 (1%)]\tLoss: 2.299722\n",
      "Train Epoch: 1 [512/60000 (1%)]\tLoss: 2.315302\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.305764\n",
      "Train Epoch: 1 [768/60000 (1%)]\tLoss: 2.306420\n",
      "Train Epoch: 1 [896/60000 (1%)]\tLoss: 2.314331\n",
      "Train Epoch: 1 [1024/60000 (2%)]\tLoss: 2.311337\n",
      "Train Epoch: 1 [1152/60000 (2%)]\tLoss: 2.294602\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.305999\n",
      "Train Epoch: 1 [1408/60000 (2%)]\tLoss: 2.312844\n",
      "Train Epoch: 1 [1536/60000 (3%)]\tLoss: 2.291073\n",
      "Train Epoch: 1 [1664/60000 (3%)]\tLoss: 2.304793\n",
      "Train Epoch: 1 [1792/60000 (3%)]\tLoss: 2.310278\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.301413\n",
      "Train Epoch: 1 [2048/60000 (3%)]\tLoss: 2.304006\n",
      "Train Epoch: 1 [2176/60000 (4%)]\tLoss: 2.300539\n",
      "Train Epoch: 1 [2304/60000 (4%)]\tLoss: 2.302885\n",
      "Train Epoch: 1 [2432/60000 (4%)]\tLoss: 2.302083\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.295130\n",
      "Train Epoch: 1 [2688/60000 (4%)]\tLoss: 2.305964\n",
      "Train Epoch: 1 [2816/60000 (5%)]\tLoss: 2.303977\n",
      "Train Epoch: 1 [2944/60000 (5%)]\tLoss: 2.300716\n",
      "Train Epoch: 1 [3072/60000 (5%)]\tLoss: 2.290028\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.309671\n",
      "Train Epoch: 1 [3328/60000 (6%)]\tLoss: 2.295816\n",
      "Train Epoch: 1 [3456/60000 (6%)]\tLoss: 2.307115\n",
      "Train Epoch: 1 [3584/60000 (6%)]\tLoss: 2.297179\n",
      "Train Epoch: 1 [3712/60000 (6%)]\tLoss: 2.291954\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.309320\n",
      "Train Epoch: 1 [3968/60000 (7%)]\tLoss: 2.297604\n",
      "Train Epoch: 1 [4096/60000 (7%)]\tLoss: 2.296226\n",
      "Train Epoch: 1 [4224/60000 (7%)]\tLoss: 2.302537\n",
      "Train Epoch: 1 [4352/60000 (7%)]\tLoss: 2.289370\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.298866\n",
      "Train Epoch: 1 [4608/60000 (8%)]\tLoss: 2.296605\n",
      "Train Epoch: 1 [4736/60000 (8%)]\tLoss: 2.293006\n",
      "Train Epoch: 1 [4864/60000 (8%)]\tLoss: 2.304394\n",
      "Train Epoch: 1 [4992/60000 (8%)]\tLoss: 2.301077\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.300137\n",
      "Train Epoch: 1 [5248/60000 (9%)]\tLoss: 2.304439\n",
      "Train Epoch: 1 [5376/60000 (9%)]\tLoss: 2.304138\n",
      "Train Epoch: 1 [5504/60000 (9%)]\tLoss: 2.312087\n",
      "Train Epoch: 1 [5632/60000 (9%)]\tLoss: 2.298209\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.298174\n",
      "Train Epoch: 1 [5888/60000 (10%)]\tLoss: 2.297739\n",
      "Train Epoch: 1 [6016/60000 (10%)]\tLoss: 2.295539\n",
      "Train Epoch: 1 [6144/60000 (10%)]\tLoss: 2.305153\n",
      "Train Epoch: 1 [6272/60000 (10%)]\tLoss: 2.297119\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.289709\n",
      "Train Epoch: 1 [6528/60000 (11%)]\tLoss: 2.298548\n",
      "Train Epoch: 1 [6656/60000 (11%)]\tLoss: 2.300339\n",
      "Train Epoch: 1 [6784/60000 (11%)]\tLoss: 2.294642\n",
      "Train Epoch: 1 [6912/60000 (12%)]\tLoss: 2.302586\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.290642\n",
      "Train Epoch: 1 [7168/60000 (12%)]\tLoss: 2.301025\n",
      "Train Epoch: 1 [7296/60000 (12%)]\tLoss: 2.302253\n",
      "Train Epoch: 1 [7424/60000 (12%)]\tLoss: 2.298853\n",
      "Train Epoch: 1 [7552/60000 (13%)]\tLoss: 2.296004\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.286462\n",
      "Train Epoch: 1 [7808/60000 (13%)]\tLoss: 2.308223\n",
      "Train Epoch: 1 [7936/60000 (13%)]\tLoss: 2.291991\n",
      "Train Epoch: 1 [8064/60000 (13%)]\tLoss: 2.304863\n",
      "Train Epoch: 1 [8192/60000 (14%)]\tLoss: 2.298209\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.295758\n",
      "Train Epoch: 1 [8448/60000 (14%)]\tLoss: 2.302133\n",
      "Train Epoch: 1 [8576/60000 (14%)]\tLoss: 2.289156\n",
      "Train Epoch: 1 [8704/60000 (15%)]\tLoss: 2.293960\n",
      "Train Epoch: 1 [8832/60000 (15%)]\tLoss: 2.285636\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.300541\n",
      "Train Epoch: 1 [9088/60000 (15%)]\tLoss: 2.289891\n",
      "Train Epoch: 1 [9216/60000 (15%)]\tLoss: 2.295643\n",
      "Train Epoch: 1 [9344/60000 (16%)]\tLoss: 2.311261\n",
      "Train Epoch: 1 [9472/60000 (16%)]\tLoss: 2.295401\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.284727\n",
      "Train Epoch: 1 [9728/60000 (16%)]\tLoss: 2.288955\n",
      "Train Epoch: 1 [9856/60000 (16%)]\tLoss: 2.288838\n",
      "Train Epoch: 1 [9984/60000 (17%)]\tLoss: 2.287816\n",
      "Train Epoch: 1 [10112/60000 (17%)]\tLoss: 2.298735\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.306188\n",
      "Train Epoch: 1 [10368/60000 (17%)]\tLoss: 2.283316\n",
      "Train Epoch: 1 [10496/60000 (18%)]\tLoss: 2.291311\n",
      "Train Epoch: 1 [10624/60000 (18%)]\tLoss: 2.294564\n",
      "Train Epoch: 1 [10752/60000 (18%)]\tLoss: 2.291286\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.288965\n",
      "Train Epoch: 1 [11008/60000 (18%)]\tLoss: 2.288106\n",
      "Train Epoch: 1 [11136/60000 (19%)]\tLoss: 2.293125\n",
      "Train Epoch: 1 [11264/60000 (19%)]\tLoss: 2.297791\n",
      "Train Epoch: 1 [11392/60000 (19%)]\tLoss: 2.292397\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.306428\n",
      "Train Epoch: 1 [11648/60000 (19%)]\tLoss: 2.301650\n",
      "Train Epoch: 1 [11776/60000 (20%)]\tLoss: 2.300636\n",
      "Train Epoch: 1 [11904/60000 (20%)]\tLoss: 2.297713\n",
      "Train Epoch: 1 [12032/60000 (20%)]\tLoss: 2.290550\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.291132\n",
      "Train Epoch: 1 [12288/60000 (21%)]\tLoss: 2.295327\n",
      "Train Epoch: 1 [12416/60000 (21%)]\tLoss: 2.285999\n",
      "Train Epoch: 1 [12544/60000 (21%)]\tLoss: 2.296805\n",
      "Train Epoch: 1 [12672/60000 (21%)]\tLoss: 2.295589\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.286664\n",
      "Train Epoch: 1 [12928/60000 (22%)]\tLoss: 2.286218\n",
      "Train Epoch: 1 [13056/60000 (22%)]\tLoss: 2.297516\n",
      "Train Epoch: 1 [13184/60000 (22%)]\tLoss: 2.288687\n",
      "Train Epoch: 1 [13312/60000 (22%)]\tLoss: 2.290955\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.290466\n",
      "Train Epoch: 1 [13568/60000 (23%)]\tLoss: 2.280094\n",
      "Train Epoch: 1 [13696/60000 (23%)]\tLoss: 2.295090\n",
      "Train Epoch: 1 [13824/60000 (23%)]\tLoss: 2.295398\n",
      "Train Epoch: 1 [13952/60000 (23%)]\tLoss: 2.285385\n",
      "Train Epoch: 1 [14080/60000 (24%)]\tLoss: 2.295492\n",
      "Train Epoch: 1 [14208/60000 (24%)]\tLoss: 2.288213\n",
      "Train Epoch: 1 [14336/60000 (24%)]\tLoss: 2.287492\n",
      "Train Epoch: 1 [14464/60000 (24%)]\tLoss: 2.293920\n",
      "Train Epoch: 1 [14592/60000 (24%)]\tLoss: 2.293285\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.289538\n",
      "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 2.291728\n",
      "Train Epoch: 1 [14976/60000 (25%)]\tLoss: 2.282580\n",
      "Train Epoch: 1 [15104/60000 (25%)]\tLoss: 2.292122\n",
      "Train Epoch: 1 [15232/60000 (25%)]\tLoss: 2.291218\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.282611\n",
      "Train Epoch: 1 [15488/60000 (26%)]\tLoss: 2.292384\n",
      "Train Epoch: 1 [15616/60000 (26%)]\tLoss: 2.291614\n",
      "Train Epoch: 1 [15744/60000 (26%)]\tLoss: 2.295838\n",
      "Train Epoch: 1 [15872/60000 (26%)]\tLoss: 2.298714\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.284127\n",
      "Train Epoch: 1 [16128/60000 (27%)]\tLoss: 2.289295\n",
      "Train Epoch: 1 [16256/60000 (27%)]\tLoss: 2.286209\n",
      "Train Epoch: 1 [16384/60000 (27%)]\tLoss: 2.287388\n",
      "Train Epoch: 1 [16512/60000 (28%)]\tLoss: 2.287718\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.282964\n",
      "Train Epoch: 1 [16768/60000 (28%)]\tLoss: 2.290572\n",
      "Train Epoch: 1 [16896/60000 (28%)]\tLoss: 2.288029\n",
      "Train Epoch: 1 [17024/60000 (28%)]\tLoss: 2.287263\n",
      "Train Epoch: 1 [17152/60000 (29%)]\tLoss: 2.287484\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.291452\n",
      "Train Epoch: 1 [17408/60000 (29%)]\tLoss: 2.300331\n",
      "Train Epoch: 1 [17536/60000 (29%)]\tLoss: 2.294150\n",
      "Train Epoch: 1 [17664/60000 (29%)]\tLoss: 2.287123\n",
      "Train Epoch: 1 [17792/60000 (30%)]\tLoss: 2.284379\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.286918\n",
      "Train Epoch: 1 [18048/60000 (30%)]\tLoss: 2.286417\n",
      "Train Epoch: 1 [18176/60000 (30%)]\tLoss: 2.281417\n",
      "Train Epoch: 1 [18304/60000 (31%)]\tLoss: 2.290898\n",
      "Train Epoch: 1 [18432/60000 (31%)]\tLoss: 2.287812\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.285237\n",
      "Train Epoch: 1 [18688/60000 (31%)]\tLoss: 2.284597\n",
      "Train Epoch: 1 [18816/60000 (31%)]\tLoss: 2.292165\n",
      "Train Epoch: 1 [18944/60000 (32%)]\tLoss: 2.284476\n",
      "Train Epoch: 1 [19072/60000 (32%)]\tLoss: 2.295326\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.283992\n",
      "Train Epoch: 1 [19328/60000 (32%)]\tLoss: 2.286898\n",
      "Train Epoch: 1 [19456/60000 (32%)]\tLoss: 2.281214\n",
      "Train Epoch: 1 [19584/60000 (33%)]\tLoss: 2.286569\n",
      "Train Epoch: 1 [19712/60000 (33%)]\tLoss: 2.283755\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.283755\n",
      "Train Epoch: 1 [19968/60000 (33%)]\tLoss: 2.292687\n",
      "Train Epoch: 1 [20096/60000 (34%)]\tLoss: 2.282930\n",
      "Train Epoch: 1 [20224/60000 (34%)]\tLoss: 2.277289\n",
      "Train Epoch: 1 [20352/60000 (34%)]\tLoss: 2.277321\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.278499\n",
      "Train Epoch: 1 [20608/60000 (34%)]\tLoss: 2.279438\n",
      "Train Epoch: 1 [20736/60000 (35%)]\tLoss: 2.284080\n",
      "Train Epoch: 1 [20864/60000 (35%)]\tLoss: 2.283916\n",
      "Train Epoch: 1 [20992/60000 (35%)]\tLoss: 2.280484\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.281658\n",
      "Train Epoch: 1 [21248/60000 (35%)]\tLoss: 2.278455\n",
      "Train Epoch: 1 [21376/60000 (36%)]\tLoss: 2.285768\n",
      "Train Epoch: 1 [21504/60000 (36%)]\tLoss: 2.278281\n",
      "Train Epoch: 1 [21632/60000 (36%)]\tLoss: 2.277831\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.272024\n",
      "Train Epoch: 1 [21888/60000 (37%)]\tLoss: 2.280843\n",
      "Train Epoch: 1 [22016/60000 (37%)]\tLoss: 2.275190\n",
      "Train Epoch: 1 [22144/60000 (37%)]\tLoss: 2.282823\n",
      "Train Epoch: 1 [22272/60000 (37%)]\tLoss: 2.281430\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.288346\n",
      "Train Epoch: 1 [22528/60000 (38%)]\tLoss: 2.278592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [22656/60000 (38%)]\tLoss: 2.280075\n",
      "Train Epoch: 1 [22784/60000 (38%)]\tLoss: 2.292664\n",
      "Train Epoch: 1 [22912/60000 (38%)]\tLoss: 2.275429\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.279511\n",
      "Train Epoch: 1 [23168/60000 (39%)]\tLoss: 2.284936\n",
      "Train Epoch: 1 [23296/60000 (39%)]\tLoss: 2.271880\n",
      "Train Epoch: 1 [23424/60000 (39%)]\tLoss: 2.283242\n",
      "Train Epoch: 1 [23552/60000 (39%)]\tLoss: 2.283988\n",
      "Train Epoch: 1 [23680/60000 (40%)]\tLoss: 2.280494\n",
      "Train Epoch: 1 [23808/60000 (40%)]\tLoss: 2.280482\n",
      "Train Epoch: 1 [23936/60000 (40%)]\tLoss: 2.282231\n",
      "Train Epoch: 1 [24064/60000 (40%)]\tLoss: 2.274110\n",
      "Train Epoch: 1 [24192/60000 (40%)]\tLoss: 2.277295\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.283407\n",
      "Train Epoch: 1 [24448/60000 (41%)]\tLoss: 2.272648\n",
      "Train Epoch: 1 [24576/60000 (41%)]\tLoss: 2.277533\n",
      "Train Epoch: 1 [24704/60000 (41%)]\tLoss: 2.280505\n",
      "Train Epoch: 1 [24832/60000 (41%)]\tLoss: 2.287986\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.273162\n",
      "Train Epoch: 1 [25088/60000 (42%)]\tLoss: 2.280904\n",
      "Train Epoch: 1 [25216/60000 (42%)]\tLoss: 2.274546\n",
      "Train Epoch: 1 [25344/60000 (42%)]\tLoss: 2.275323\n",
      "Train Epoch: 1 [25472/60000 (43%)]\tLoss: 2.274606\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.271204\n",
      "Train Epoch: 1 [25728/60000 (43%)]\tLoss: 2.277926\n",
      "Train Epoch: 1 [25856/60000 (43%)]\tLoss: 2.281893\n",
      "Train Epoch: 1 [25984/60000 (43%)]\tLoss: 2.278909\n",
      "Train Epoch: 1 [26112/60000 (44%)]\tLoss: 2.269154\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.283935\n",
      "Train Epoch: 1 [26368/60000 (44%)]\tLoss: 2.279950\n",
      "Train Epoch: 1 [26496/60000 (44%)]\tLoss: 2.269022\n",
      "Train Epoch: 1 [26624/60000 (44%)]\tLoss: 2.268058\n",
      "Train Epoch: 1 [26752/60000 (45%)]\tLoss: 2.268264\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.276709\n",
      "Train Epoch: 1 [27008/60000 (45%)]\tLoss: 2.282175\n",
      "Train Epoch: 1 [27136/60000 (45%)]\tLoss: 2.268685\n",
      "Train Epoch: 1 [27264/60000 (46%)]\tLoss: 2.262390\n",
      "Train Epoch: 1 [27392/60000 (46%)]\tLoss: 2.277486\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.274414\n",
      "Train Epoch: 1 [27648/60000 (46%)]\tLoss: 2.267462\n",
      "Train Epoch: 1 [27776/60000 (46%)]\tLoss: 2.275539\n",
      "Train Epoch: 1 [27904/60000 (47%)]\tLoss: 2.274356\n",
      "Train Epoch: 1 [28032/60000 (47%)]\tLoss: 2.257374\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.262803\n",
      "Train Epoch: 1 [28288/60000 (47%)]\tLoss: 2.282218\n",
      "Train Epoch: 1 [28416/60000 (47%)]\tLoss: 2.268889\n",
      "Train Epoch: 1 [28544/60000 (48%)]\tLoss: 2.280669\n",
      "Train Epoch: 1 [28672/60000 (48%)]\tLoss: 2.276877\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.272889\n",
      "Train Epoch: 1 [28928/60000 (48%)]\tLoss: 2.270688\n",
      "Train Epoch: 1 [29056/60000 (49%)]\tLoss: 2.272472\n",
      "Train Epoch: 1 [29184/60000 (49%)]\tLoss: 2.274732\n",
      "Train Epoch: 1 [29312/60000 (49%)]\tLoss: 2.265483\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.266203\n",
      "Train Epoch: 1 [29568/60000 (49%)]\tLoss: 2.268691\n",
      "Train Epoch: 1 [29696/60000 (50%)]\tLoss: 2.287658\n",
      "Train Epoch: 1 [29824/60000 (50%)]\tLoss: 2.292843\n",
      "Train Epoch: 1 [29952/60000 (50%)]\tLoss: 2.274293\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.275773\n",
      "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 2.271388\n",
      "Train Epoch: 1 [30336/60000 (51%)]\tLoss: 2.260585\n",
      "Train Epoch: 1 [30464/60000 (51%)]\tLoss: 2.274998\n",
      "Train Epoch: 1 [30592/60000 (51%)]\tLoss: 2.264923\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.260786\n",
      "Train Epoch: 1 [30848/60000 (51%)]\tLoss: 2.271670\n",
      "Train Epoch: 1 [30976/60000 (52%)]\tLoss: 2.266082\n",
      "Train Epoch: 1 [31104/60000 (52%)]\tLoss: 2.261388\n",
      "Train Epoch: 1 [31232/60000 (52%)]\tLoss: 2.275068\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.275337\n",
      "Train Epoch: 1 [31488/60000 (53%)]\tLoss: 2.273165\n",
      "Train Epoch: 1 [31616/60000 (53%)]\tLoss: 2.265371\n",
      "Train Epoch: 1 [31744/60000 (53%)]\tLoss: 2.267474\n",
      "Train Epoch: 1 [31872/60000 (53%)]\tLoss: 2.270955\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.260451\n",
      "Train Epoch: 1 [32128/60000 (54%)]\tLoss: 2.282649\n",
      "Train Epoch: 1 [32256/60000 (54%)]\tLoss: 2.273981\n",
      "Train Epoch: 1 [32384/60000 (54%)]\tLoss: 2.266769\n",
      "Train Epoch: 1 [32512/60000 (54%)]\tLoss: 2.276499\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 2.259630\n",
      "Train Epoch: 1 [32768/60000 (55%)]\tLoss: 2.259896\n",
      "Train Epoch: 1 [32896/60000 (55%)]\tLoss: 2.248671\n",
      "Train Epoch: 1 [33024/60000 (55%)]\tLoss: 2.286094\n",
      "Train Epoch: 1 [33152/60000 (55%)]\tLoss: 2.262742\n",
      "Train Epoch: 1 [33280/60000 (56%)]\tLoss: 2.266241\n",
      "Train Epoch: 1 [33408/60000 (56%)]\tLoss: 2.267535\n",
      "Train Epoch: 1 [33536/60000 (56%)]\tLoss: 2.261612\n",
      "Train Epoch: 1 [33664/60000 (56%)]\tLoss: 2.253906\n",
      "Train Epoch: 1 [33792/60000 (56%)]\tLoss: 2.246258\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.263395\n",
      "Train Epoch: 1 [34048/60000 (57%)]\tLoss: 2.262133\n",
      "Train Epoch: 1 [34176/60000 (57%)]\tLoss: 2.253714\n",
      "Train Epoch: 1 [34304/60000 (57%)]\tLoss: 2.258560\n",
      "Train Epoch: 1 [34432/60000 (57%)]\tLoss: 2.277095\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.263700\n",
      "Train Epoch: 1 [34688/60000 (58%)]\tLoss: 2.253453\n",
      "Train Epoch: 1 [34816/60000 (58%)]\tLoss: 2.258873\n",
      "Train Epoch: 1 [34944/60000 (58%)]\tLoss: 2.264141\n",
      "Train Epoch: 1 [35072/60000 (59%)]\tLoss: 2.260730\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.264564\n",
      "Train Epoch: 1 [35328/60000 (59%)]\tLoss: 2.249883\n",
      "Train Epoch: 1 [35456/60000 (59%)]\tLoss: 2.262614\n",
      "Train Epoch: 1 [35584/60000 (59%)]\tLoss: 2.244811\n",
      "Train Epoch: 1 [35712/60000 (60%)]\tLoss: 2.248631\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.253171\n",
      "Train Epoch: 1 [35968/60000 (60%)]\tLoss: 2.256032\n",
      "Train Epoch: 1 [36096/60000 (60%)]\tLoss: 2.245811\n",
      "Train Epoch: 1 [36224/60000 (60%)]\tLoss: 2.243170\n",
      "Train Epoch: 1 [36352/60000 (61%)]\tLoss: 2.253076\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 2.260533\n",
      "Train Epoch: 1 [36608/60000 (61%)]\tLoss: 2.240580\n",
      "Train Epoch: 1 [36736/60000 (61%)]\tLoss: 2.234606\n",
      "Train Epoch: 1 [36864/60000 (62%)]\tLoss: 2.243047\n",
      "Train Epoch: 1 [36992/60000 (62%)]\tLoss: 2.261485\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.250299\n",
      "Train Epoch: 1 [37248/60000 (62%)]\tLoss: 2.244007\n",
      "Train Epoch: 1 [37376/60000 (62%)]\tLoss: 2.261443\n",
      "Train Epoch: 1 [37504/60000 (63%)]\tLoss: 2.259943\n",
      "Train Epoch: 1 [37632/60000 (63%)]\tLoss: 2.228092\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 2.252823\n",
      "Train Epoch: 1 [37888/60000 (63%)]\tLoss: 2.258094\n",
      "Train Epoch: 1 [38016/60000 (63%)]\tLoss: 2.247919\n",
      "Train Epoch: 1 [38144/60000 (64%)]\tLoss: 2.261106\n",
      "Train Epoch: 1 [38272/60000 (64%)]\tLoss: 2.257332\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.236158\n",
      "Train Epoch: 1 [38528/60000 (64%)]\tLoss: 2.266202\n",
      "Train Epoch: 1 [38656/60000 (65%)]\tLoss: 2.262776\n",
      "Train Epoch: 1 [38784/60000 (65%)]\tLoss: 2.246353\n",
      "Train Epoch: 1 [38912/60000 (65%)]\tLoss: 2.249081\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 2.237433\n",
      "Train Epoch: 1 [39168/60000 (65%)]\tLoss: 2.242686\n",
      "Train Epoch: 1 [39296/60000 (66%)]\tLoss: 2.254459\n",
      "Train Epoch: 1 [39424/60000 (66%)]\tLoss: 2.248996\n",
      "Train Epoch: 1 [39552/60000 (66%)]\tLoss: 2.248093\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 2.261368\n",
      "Train Epoch: 1 [39808/60000 (66%)]\tLoss: 2.241514\n",
      "Train Epoch: 1 [39936/60000 (67%)]\tLoss: 2.245436\n",
      "Train Epoch: 1 [40064/60000 (67%)]\tLoss: 2.231570\n",
      "Train Epoch: 1 [40192/60000 (67%)]\tLoss: 2.252610\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 2.233025\n",
      "Train Epoch: 1 [40448/60000 (68%)]\tLoss: 2.245657\n",
      "Train Epoch: 1 [40576/60000 (68%)]\tLoss: 2.247348\n",
      "Train Epoch: 1 [40704/60000 (68%)]\tLoss: 2.257815\n",
      "Train Epoch: 1 [40832/60000 (68%)]\tLoss: 2.231877\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.224654\n",
      "Train Epoch: 1 [41088/60000 (69%)]\tLoss: 2.242036\n",
      "Train Epoch: 1 [41216/60000 (69%)]\tLoss: 2.248105\n",
      "Train Epoch: 1 [41344/60000 (69%)]\tLoss: 2.245825\n",
      "Train Epoch: 1 [41472/60000 (69%)]\tLoss: 2.268466\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 2.249188\n",
      "Train Epoch: 1 [41728/60000 (70%)]\tLoss: 2.244941\n",
      "Train Epoch: 1 [41856/60000 (70%)]\tLoss: 2.254232\n",
      "Train Epoch: 1 [41984/60000 (70%)]\tLoss: 2.244754\n",
      "Train Epoch: 1 [42112/60000 (70%)]\tLoss: 2.248994\n",
      "Train Epoch: 1 [42240/60000 (71%)]\tLoss: 2.256063\n",
      "Train Epoch: 1 [42368/60000 (71%)]\tLoss: 2.219090\n",
      "Train Epoch: 1 [42496/60000 (71%)]\tLoss: 2.240088\n",
      "Train Epoch: 1 [42624/60000 (71%)]\tLoss: 2.260379\n",
      "Train Epoch: 1 [42752/60000 (71%)]\tLoss: 2.241117\n",
      "Train Epoch: 1 [42880/60000 (72%)]\tLoss: 2.245068\n",
      "Train Epoch: 1 [43008/60000 (72%)]\tLoss: 2.250035\n",
      "Train Epoch: 1 [43136/60000 (72%)]\tLoss: 2.222200\n",
      "Train Epoch: 1 [43264/60000 (72%)]\tLoss: 2.228958\n",
      "Train Epoch: 1 [43392/60000 (72%)]\tLoss: 2.235742\n",
      "Train Epoch: 1 [43520/60000 (73%)]\tLoss: 2.240418\n",
      "Train Epoch: 1 [43648/60000 (73%)]\tLoss: 2.234204\n",
      "Train Epoch: 1 [43776/60000 (73%)]\tLoss: 2.234373\n",
      "Train Epoch: 1 [43904/60000 (73%)]\tLoss: 2.242520\n",
      "Train Epoch: 1 [44032/60000 (74%)]\tLoss: 2.252928\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 2.233921\n",
      "Train Epoch: 1 [44288/60000 (74%)]\tLoss: 2.235693\n",
      "Train Epoch: 1 [44416/60000 (74%)]\tLoss: 2.231959\n",
      "Train Epoch: 1 [44544/60000 (74%)]\tLoss: 2.231462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [44672/60000 (75%)]\tLoss: 2.224964\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.238142\n",
      "Train Epoch: 1 [44928/60000 (75%)]\tLoss: 2.231721\n",
      "Train Epoch: 1 [45056/60000 (75%)]\tLoss: 2.225406\n",
      "Train Epoch: 1 [45184/60000 (75%)]\tLoss: 2.223253\n",
      "Train Epoch: 1 [45312/60000 (76%)]\tLoss: 2.219129\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 2.220951\n",
      "Train Epoch: 1 [45568/60000 (76%)]\tLoss: 2.208453\n",
      "Train Epoch: 1 [45696/60000 (76%)]\tLoss: 2.211915\n",
      "Train Epoch: 1 [45824/60000 (76%)]\tLoss: 2.247065\n",
      "Train Epoch: 1 [45952/60000 (77%)]\tLoss: 2.218020\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 2.228865\n",
      "Train Epoch: 1 [46208/60000 (77%)]\tLoss: 2.245008\n",
      "Train Epoch: 1 [46336/60000 (77%)]\tLoss: 2.217327\n",
      "Train Epoch: 1 [46464/60000 (78%)]\tLoss: 2.208501\n",
      "Train Epoch: 1 [46592/60000 (78%)]\tLoss: 2.210084\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 2.235343\n",
      "Train Epoch: 1 [46848/60000 (78%)]\tLoss: 2.215467\n",
      "Train Epoch: 1 [46976/60000 (78%)]\tLoss: 2.227422\n",
      "Train Epoch: 1 [47104/60000 (79%)]\tLoss: 2.201626\n",
      "Train Epoch: 1 [47232/60000 (79%)]\tLoss: 2.242929\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 2.232848\n",
      "Train Epoch: 1 [47488/60000 (79%)]\tLoss: 2.229015\n",
      "Train Epoch: 1 [47616/60000 (79%)]\tLoss: 2.212103\n",
      "Train Epoch: 1 [47744/60000 (80%)]\tLoss: 2.197206\n",
      "Train Epoch: 1 [47872/60000 (80%)]\tLoss: 2.221811\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.219071\n",
      "Train Epoch: 1 [48128/60000 (80%)]\tLoss: 2.210132\n",
      "Train Epoch: 1 [48256/60000 (81%)]\tLoss: 2.209416\n",
      "Train Epoch: 1 [48384/60000 (81%)]\tLoss: 2.206353\n",
      "Train Epoch: 1 [48512/60000 (81%)]\tLoss: 2.193129\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 2.205713\n",
      "Train Epoch: 1 [48768/60000 (81%)]\tLoss: 2.199228\n",
      "Train Epoch: 1 [48896/60000 (82%)]\tLoss: 2.237936\n",
      "Train Epoch: 1 [49024/60000 (82%)]\tLoss: 2.239880\n",
      "Train Epoch: 1 [49152/60000 (82%)]\tLoss: 2.220475\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 2.219921\n",
      "Train Epoch: 1 [49408/60000 (82%)]\tLoss: 2.203964\n",
      "Train Epoch: 1 [49536/60000 (83%)]\tLoss: 2.230806\n",
      "Train Epoch: 1 [49664/60000 (83%)]\tLoss: 2.207012\n",
      "Train Epoch: 1 [49792/60000 (83%)]\tLoss: 2.195133\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 2.203540\n",
      "Train Epoch: 1 [50048/60000 (84%)]\tLoss: 2.204904\n",
      "Train Epoch: 1 [50176/60000 (84%)]\tLoss: 2.220978\n",
      "Train Epoch: 1 [50304/60000 (84%)]\tLoss: 2.229783\n",
      "Train Epoch: 1 [50432/60000 (84%)]\tLoss: 2.197741\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 2.203649\n",
      "Train Epoch: 1 [50688/60000 (85%)]\tLoss: 2.197156\n",
      "Train Epoch: 1 [50816/60000 (85%)]\tLoss: 2.198843\n",
      "Train Epoch: 1 [50944/60000 (85%)]\tLoss: 2.209231\n",
      "Train Epoch: 1 [51072/60000 (85%)]\tLoss: 2.237074\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.194639\n",
      "Train Epoch: 1 [51328/60000 (86%)]\tLoss: 2.181401\n",
      "Train Epoch: 1 [51456/60000 (86%)]\tLoss: 2.171473\n",
      "Train Epoch: 1 [51584/60000 (86%)]\tLoss: 2.190502\n",
      "Train Epoch: 1 [51712/60000 (86%)]\tLoss: 2.210158\n",
      "Train Epoch: 1 [51840/60000 (87%)]\tLoss: 2.193242\n",
      "Train Epoch: 1 [51968/60000 (87%)]\tLoss: 2.182127\n",
      "Train Epoch: 1 [52096/60000 (87%)]\tLoss: 2.229229\n",
      "Train Epoch: 1 [52224/60000 (87%)]\tLoss: 2.206947\n",
      "Train Epoch: 1 [52352/60000 (87%)]\tLoss: 2.171402\n",
      "Train Epoch: 1 [52480/60000 (88%)]\tLoss: 2.142904\n",
      "Train Epoch: 1 [52608/60000 (88%)]\tLoss: 2.178424\n",
      "Train Epoch: 1 [52736/60000 (88%)]\tLoss: 2.201999\n",
      "Train Epoch: 1 [52864/60000 (88%)]\tLoss: 2.196000\n",
      "Train Epoch: 1 [52992/60000 (88%)]\tLoss: 2.187556\n",
      "Train Epoch: 1 [53120/60000 (89%)]\tLoss: 2.207675\n",
      "Train Epoch: 1 [53248/60000 (89%)]\tLoss: 2.155624\n",
      "Train Epoch: 1 [53376/60000 (89%)]\tLoss: 2.202087\n",
      "Train Epoch: 1 [53504/60000 (89%)]\tLoss: 2.182407\n",
      "Train Epoch: 1 [53632/60000 (90%)]\tLoss: 2.200571\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 2.163116\n",
      "Train Epoch: 1 [53888/60000 (90%)]\tLoss: 2.204553\n",
      "Train Epoch: 1 [54016/60000 (90%)]\tLoss: 2.207486\n",
      "Train Epoch: 1 [54144/60000 (90%)]\tLoss: 2.178442\n",
      "Train Epoch: 1 [54272/60000 (91%)]\tLoss: 2.169089\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 2.183588\n",
      "Train Epoch: 1 [54528/60000 (91%)]\tLoss: 2.156610\n",
      "Train Epoch: 1 [54656/60000 (91%)]\tLoss: 2.186085\n",
      "Train Epoch: 1 [54784/60000 (91%)]\tLoss: 2.193013\n",
      "Train Epoch: 1 [54912/60000 (92%)]\tLoss: 2.200111\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 2.157659\n",
      "Train Epoch: 1 [55168/60000 (92%)]\tLoss: 2.134315\n",
      "Train Epoch: 1 [55296/60000 (92%)]\tLoss: 2.194059\n",
      "Train Epoch: 1 [55424/60000 (93%)]\tLoss: 2.167509\n",
      "Train Epoch: 1 [55552/60000 (93%)]\tLoss: 2.163375\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 2.166396\n",
      "Train Epoch: 1 [55808/60000 (93%)]\tLoss: 2.156502\n",
      "Train Epoch: 1 [55936/60000 (93%)]\tLoss: 2.165783\n",
      "Train Epoch: 1 [56064/60000 (94%)]\tLoss: 2.188120\n",
      "Train Epoch: 1 [56192/60000 (94%)]\tLoss: 2.183930\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 2.163882\n",
      "Train Epoch: 1 [56448/60000 (94%)]\tLoss: 2.156850\n",
      "Train Epoch: 1 [56576/60000 (94%)]\tLoss: 2.151442\n",
      "Train Epoch: 1 [56704/60000 (95%)]\tLoss: 2.140503\n",
      "Train Epoch: 1 [56832/60000 (95%)]\tLoss: 2.149251\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 2.200717\n",
      "Train Epoch: 1 [57088/60000 (95%)]\tLoss: 2.146589\n",
      "Train Epoch: 1 [57216/60000 (96%)]\tLoss: 2.200778\n",
      "Train Epoch: 1 [57344/60000 (96%)]\tLoss: 2.158754\n",
      "Train Epoch: 1 [57472/60000 (96%)]\tLoss: 2.187749\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.161816\n",
      "Train Epoch: 1 [57728/60000 (96%)]\tLoss: 2.152331\n",
      "Train Epoch: 1 [57856/60000 (97%)]\tLoss: 2.138615\n",
      "Train Epoch: 1 [57984/60000 (97%)]\tLoss: 2.173999\n",
      "Train Epoch: 1 [58112/60000 (97%)]\tLoss: 2.137710\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 2.178664\n",
      "Train Epoch: 1 [58368/60000 (97%)]\tLoss: 2.163090\n",
      "Train Epoch: 1 [58496/60000 (98%)]\tLoss: 2.128535\n",
      "Train Epoch: 1 [58624/60000 (98%)]\tLoss: 2.152628\n",
      "Train Epoch: 1 [58752/60000 (98%)]\tLoss: 2.130894\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 2.116902\n",
      "Train Epoch: 1 [59008/60000 (99%)]\tLoss: 2.083756\n",
      "Train Epoch: 1 [59136/60000 (99%)]\tLoss: 2.115020\n",
      "Train Epoch: 1 [59264/60000 (99%)]\tLoss: 2.200232\n",
      "Train Epoch: 1 [59392/60000 (99%)]\tLoss: 2.084787\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 2.126225\n",
      "Train Epoch: 1 [59648/60000 (100%)]\tLoss: 2.166033\n",
      "Train Epoch: 1 [59776/60000 (100%)]\tLoss: 2.112753\n",
      "================================================================\n",
      "Training: Average loss: 2.0742, Accuracy: 37876/60000 (63%)\n",
      "Test: Average loss: 2.0669, Accuracy: 6373/10000 (64%)\n",
      "================================================================\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.103805\n",
      "Train Epoch: 2 [128/60000 (0%)]\tLoss: 2.104804\n",
      "Train Epoch: 2 [256/60000 (0%)]\tLoss: 2.182788\n",
      "Train Epoch: 2 [384/60000 (1%)]\tLoss: 2.172671\n",
      "Train Epoch: 2 [512/60000 (1%)]\tLoss: 2.175133\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 2.143730\n",
      "Train Epoch: 2 [768/60000 (1%)]\tLoss: 2.157791\n",
      "Train Epoch: 2 [896/60000 (1%)]\tLoss: 2.202971\n",
      "Train Epoch: 2 [1024/60000 (2%)]\tLoss: 2.184453\n",
      "Train Epoch: 2 [1152/60000 (2%)]\tLoss: 2.176883\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 2.160345\n",
      "Train Epoch: 2 [1408/60000 (2%)]\tLoss: 2.145196\n",
      "Train Epoch: 2 [1536/60000 (3%)]\tLoss: 2.105025\n",
      "Train Epoch: 2 [1664/60000 (3%)]\tLoss: 2.106369\n",
      "Train Epoch: 2 [1792/60000 (3%)]\tLoss: 2.121894\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 2.117392\n",
      "Train Epoch: 2 [2048/60000 (3%)]\tLoss: 2.089467\n",
      "Train Epoch: 2 [2176/60000 (4%)]\tLoss: 2.114915\n",
      "Train Epoch: 2 [2304/60000 (4%)]\tLoss: 2.156788\n",
      "Train Epoch: 2 [2432/60000 (4%)]\tLoss: 2.113271\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 2.107441\n",
      "Train Epoch: 2 [2688/60000 (4%)]\tLoss: 2.127621\n",
      "Train Epoch: 2 [2816/60000 (5%)]\tLoss: 2.120337\n",
      "Train Epoch: 2 [2944/60000 (5%)]\tLoss: 2.136084\n",
      "Train Epoch: 2 [3072/60000 (5%)]\tLoss: 2.125337\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 2.120754\n",
      "Train Epoch: 2 [3328/60000 (6%)]\tLoss: 2.098581\n",
      "Train Epoch: 2 [3456/60000 (6%)]\tLoss: 2.148600\n",
      "Train Epoch: 2 [3584/60000 (6%)]\tLoss: 2.110518\n",
      "Train Epoch: 2 [3712/60000 (6%)]\tLoss: 2.067532\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 2.096172\n",
      "Train Epoch: 2 [3968/60000 (7%)]\tLoss: 2.134263\n",
      "Train Epoch: 2 [4096/60000 (7%)]\tLoss: 2.088216\n",
      "Train Epoch: 2 [4224/60000 (7%)]\tLoss: 2.081301\n",
      "Train Epoch: 2 [4352/60000 (7%)]\tLoss: 2.118519\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 2.038771\n",
      "Train Epoch: 2 [4608/60000 (8%)]\tLoss: 2.103996\n",
      "Train Epoch: 2 [4736/60000 (8%)]\tLoss: 2.120104\n",
      "Train Epoch: 2 [4864/60000 (8%)]\tLoss: 2.132779\n",
      "Train Epoch: 2 [4992/60000 (8%)]\tLoss: 2.106404\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 2.095128\n",
      "Train Epoch: 2 [5248/60000 (9%)]\tLoss: 2.055603\n",
      "Train Epoch: 2 [5376/60000 (9%)]\tLoss: 2.098083\n",
      "Train Epoch: 2 [5504/60000 (9%)]\tLoss: 2.076014\n",
      "Train Epoch: 2 [5632/60000 (9%)]\tLoss: 2.098893\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 2.115543\n",
      "Train Epoch: 2 [5888/60000 (10%)]\tLoss: 2.064274\n",
      "Train Epoch: 2 [6016/60000 (10%)]\tLoss: 2.067681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [6144/60000 (10%)]\tLoss: 2.117373\n",
      "Train Epoch: 2 [6272/60000 (10%)]\tLoss: 2.127830\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 2.099058\n",
      "Train Epoch: 2 [6528/60000 (11%)]\tLoss: 2.044782\n",
      "Train Epoch: 2 [6656/60000 (11%)]\tLoss: 2.057832\n",
      "Train Epoch: 2 [6784/60000 (11%)]\tLoss: 2.145565\n",
      "Train Epoch: 2 [6912/60000 (12%)]\tLoss: 2.049542\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 2.091748\n",
      "Train Epoch: 2 [7168/60000 (12%)]\tLoss: 2.119197\n",
      "Train Epoch: 2 [7296/60000 (12%)]\tLoss: 2.121116\n",
      "Train Epoch: 2 [7424/60000 (12%)]\tLoss: 2.118136\n",
      "Train Epoch: 2 [7552/60000 (13%)]\tLoss: 2.107317\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 2.107777\n",
      "Train Epoch: 2 [7808/60000 (13%)]\tLoss: 2.048890\n",
      "Train Epoch: 2 [7936/60000 (13%)]\tLoss: 2.030258\n",
      "Train Epoch: 2 [8064/60000 (13%)]\tLoss: 2.062024\n",
      "Train Epoch: 2 [8192/60000 (14%)]\tLoss: 2.069755\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 2.097136\n",
      "Train Epoch: 2 [8448/60000 (14%)]\tLoss: 2.053003\n",
      "Train Epoch: 2 [8576/60000 (14%)]\tLoss: 2.101554\n",
      "Train Epoch: 2 [8704/60000 (15%)]\tLoss: 2.083863\n",
      "Train Epoch: 2 [8832/60000 (15%)]\tLoss: 2.051058\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 1.988234\n",
      "Train Epoch: 2 [9088/60000 (15%)]\tLoss: 2.036846\n",
      "Train Epoch: 2 [9216/60000 (15%)]\tLoss: 2.059747\n",
      "Train Epoch: 2 [9344/60000 (16%)]\tLoss: 2.080165\n",
      "Train Epoch: 2 [9472/60000 (16%)]\tLoss: 2.035983\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 1.973285\n",
      "Train Epoch: 2 [9728/60000 (16%)]\tLoss: 2.065640\n",
      "Train Epoch: 2 [9856/60000 (16%)]\tLoss: 2.048413\n",
      "Train Epoch: 2 [9984/60000 (17%)]\tLoss: 2.051152\n",
      "Train Epoch: 2 [10112/60000 (17%)]\tLoss: 2.047434\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 2.012859\n",
      "Train Epoch: 2 [10368/60000 (17%)]\tLoss: 2.034793\n",
      "Train Epoch: 2 [10496/60000 (18%)]\tLoss: 2.004269\n",
      "Train Epoch: 2 [10624/60000 (18%)]\tLoss: 2.026886\n",
      "Train Epoch: 2 [10752/60000 (18%)]\tLoss: 2.038818\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 2.034482\n",
      "Train Epoch: 2 [11008/60000 (18%)]\tLoss: 2.017775\n",
      "Train Epoch: 2 [11136/60000 (19%)]\tLoss: 2.047077\n",
      "Train Epoch: 2 [11264/60000 (19%)]\tLoss: 2.026926\n",
      "Train Epoch: 2 [11392/60000 (19%)]\tLoss: 2.028591\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 2.064996\n",
      "Train Epoch: 2 [11648/60000 (19%)]\tLoss: 2.055360\n",
      "Train Epoch: 2 [11776/60000 (20%)]\tLoss: 2.038364\n",
      "Train Epoch: 2 [11904/60000 (20%)]\tLoss: 1.992821\n",
      "Train Epoch: 2 [12032/60000 (20%)]\tLoss: 2.023804\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 2.033803\n",
      "Train Epoch: 2 [12288/60000 (21%)]\tLoss: 2.065770\n",
      "Train Epoch: 2 [12416/60000 (21%)]\tLoss: 2.008219\n",
      "Train Epoch: 2 [12544/60000 (21%)]\tLoss: 2.050131\n",
      "Train Epoch: 2 [12672/60000 (21%)]\tLoss: 2.045643\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.055607\n",
      "Train Epoch: 2 [12928/60000 (22%)]\tLoss: 2.117824\n",
      "Train Epoch: 2 [13056/60000 (22%)]\tLoss: 2.060975\n",
      "Train Epoch: 2 [13184/60000 (22%)]\tLoss: 1.983855\n",
      "Train Epoch: 2 [13312/60000 (22%)]\tLoss: 2.085582\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 1.985307\n",
      "Train Epoch: 2 [13568/60000 (23%)]\tLoss: 2.004375\n",
      "Train Epoch: 2 [13696/60000 (23%)]\tLoss: 1.969454\n",
      "Train Epoch: 2 [13824/60000 (23%)]\tLoss: 2.081104\n",
      "Train Epoch: 2 [13952/60000 (23%)]\tLoss: 2.058601\n",
      "Train Epoch: 2 [14080/60000 (24%)]\tLoss: 1.981647\n",
      "Train Epoch: 2 [14208/60000 (24%)]\tLoss: 1.999335\n",
      "Train Epoch: 2 [14336/60000 (24%)]\tLoss: 1.972291\n",
      "Train Epoch: 2 [14464/60000 (24%)]\tLoss: 1.989146\n",
      "Train Epoch: 2 [14592/60000 (24%)]\tLoss: 2.069852\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 1.969859\n",
      "Train Epoch: 2 [14848/60000 (25%)]\tLoss: 1.978190\n",
      "Train Epoch: 2 [14976/60000 (25%)]\tLoss: 1.970178\n",
      "Train Epoch: 2 [15104/60000 (25%)]\tLoss: 2.001229\n",
      "Train Epoch: 2 [15232/60000 (25%)]\tLoss: 1.948899\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 1.967494\n",
      "Train Epoch: 2 [15488/60000 (26%)]\tLoss: 1.961318\n",
      "Train Epoch: 2 [15616/60000 (26%)]\tLoss: 1.982634\n",
      "Train Epoch: 2 [15744/60000 (26%)]\tLoss: 2.050929\n",
      "Train Epoch: 2 [15872/60000 (26%)]\tLoss: 2.053306\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.046443\n",
      "Train Epoch: 2 [16128/60000 (27%)]\tLoss: 2.012889\n",
      "Train Epoch: 2 [16256/60000 (27%)]\tLoss: 2.002656\n",
      "Train Epoch: 2 [16384/60000 (27%)]\tLoss: 1.974328\n",
      "Train Epoch: 2 [16512/60000 (28%)]\tLoss: 1.909076\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 1.958924\n",
      "Train Epoch: 2 [16768/60000 (28%)]\tLoss: 2.060653\n",
      "Train Epoch: 2 [16896/60000 (28%)]\tLoss: 2.042968\n",
      "Train Epoch: 2 [17024/60000 (28%)]\tLoss: 1.940710\n",
      "Train Epoch: 2 [17152/60000 (29%)]\tLoss: 1.990194\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 1.947504\n",
      "Train Epoch: 2 [17408/60000 (29%)]\tLoss: 1.997922\n",
      "Train Epoch: 2 [17536/60000 (29%)]\tLoss: 2.026333\n",
      "Train Epoch: 2 [17664/60000 (29%)]\tLoss: 2.043142\n",
      "Train Epoch: 2 [17792/60000 (30%)]\tLoss: 1.988614\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 1.945144\n",
      "Train Epoch: 2 [18048/60000 (30%)]\tLoss: 1.887599\n",
      "Train Epoch: 2 [18176/60000 (30%)]\tLoss: 1.908440\n",
      "Train Epoch: 2 [18304/60000 (31%)]\tLoss: 1.997601\n",
      "Train Epoch: 2 [18432/60000 (31%)]\tLoss: 1.974657\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 1.941514\n",
      "Train Epoch: 2 [18688/60000 (31%)]\tLoss: 1.973097\n",
      "Train Epoch: 2 [18816/60000 (31%)]\tLoss: 1.959550\n",
      "Train Epoch: 2 [18944/60000 (32%)]\tLoss: 1.980556\n",
      "Train Epoch: 2 [19072/60000 (32%)]\tLoss: 2.020065\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.934142\n",
      "Train Epoch: 2 [19328/60000 (32%)]\tLoss: 1.899049\n",
      "Train Epoch: 2 [19456/60000 (32%)]\tLoss: 1.865307\n",
      "Train Epoch: 2 [19584/60000 (33%)]\tLoss: 1.946224\n",
      "Train Epoch: 2 [19712/60000 (33%)]\tLoss: 1.911514\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 1.916746\n",
      "Train Epoch: 2 [19968/60000 (33%)]\tLoss: 1.942141\n",
      "Train Epoch: 2 [20096/60000 (34%)]\tLoss: 1.959893\n",
      "Train Epoch: 2 [20224/60000 (34%)]\tLoss: 1.983577\n",
      "Train Epoch: 2 [20352/60000 (34%)]\tLoss: 1.893839\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 1.908334\n",
      "Train Epoch: 2 [20608/60000 (34%)]\tLoss: 1.900031\n",
      "Train Epoch: 2 [20736/60000 (35%)]\tLoss: 1.922155\n",
      "Train Epoch: 2 [20864/60000 (35%)]\tLoss: 2.035431\n",
      "Train Epoch: 2 [20992/60000 (35%)]\tLoss: 1.867208\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 1.877457\n",
      "Train Epoch: 2 [21248/60000 (35%)]\tLoss: 1.900554\n",
      "Train Epoch: 2 [21376/60000 (36%)]\tLoss: 1.900472\n",
      "Train Epoch: 2 [21504/60000 (36%)]\tLoss: 1.977751\n",
      "Train Epoch: 2 [21632/60000 (36%)]\tLoss: 1.926509\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 1.788071\n",
      "Train Epoch: 2 [21888/60000 (37%)]\tLoss: 1.782644\n",
      "Train Epoch: 2 [22016/60000 (37%)]\tLoss: 1.903257\n",
      "Train Epoch: 2 [22144/60000 (37%)]\tLoss: 1.933095\n",
      "Train Epoch: 2 [22272/60000 (37%)]\tLoss: 1.892827\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 1.914902\n",
      "Train Epoch: 2 [22528/60000 (38%)]\tLoss: 1.957585\n",
      "Train Epoch: 2 [22656/60000 (38%)]\tLoss: 1.905238\n",
      "Train Epoch: 2 [22784/60000 (38%)]\tLoss: 1.877606\n",
      "Train Epoch: 2 [22912/60000 (38%)]\tLoss: 1.774729\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 1.942480\n",
      "Train Epoch: 2 [23168/60000 (39%)]\tLoss: 1.856737\n",
      "Train Epoch: 2 [23296/60000 (39%)]\tLoss: 1.878726\n",
      "Train Epoch: 2 [23424/60000 (39%)]\tLoss: 1.852253\n",
      "Train Epoch: 2 [23552/60000 (39%)]\tLoss: 1.898831\n",
      "Train Epoch: 2 [23680/60000 (40%)]\tLoss: 1.921637\n",
      "Train Epoch: 2 [23808/60000 (40%)]\tLoss: 1.910061\n",
      "Train Epoch: 2 [23936/60000 (40%)]\tLoss: 1.926773\n",
      "Train Epoch: 2 [24064/60000 (40%)]\tLoss: 1.843948\n",
      "Train Epoch: 2 [24192/60000 (40%)]\tLoss: 1.919520\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 1.866298\n",
      "Train Epoch: 2 [24448/60000 (41%)]\tLoss: 1.826849\n",
      "Train Epoch: 2 [24576/60000 (41%)]\tLoss: 1.794024\n",
      "Train Epoch: 2 [24704/60000 (41%)]\tLoss: 1.953129\n",
      "Train Epoch: 2 [24832/60000 (41%)]\tLoss: 1.916793\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 1.841134\n",
      "Train Epoch: 2 [25088/60000 (42%)]\tLoss: 1.857539\n",
      "Train Epoch: 2 [25216/60000 (42%)]\tLoss: 1.846045\n",
      "Train Epoch: 2 [25344/60000 (42%)]\tLoss: 1.859373\n",
      "Train Epoch: 2 [25472/60000 (43%)]\tLoss: 1.823834\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.846817\n",
      "Train Epoch: 2 [25728/60000 (43%)]\tLoss: 1.833744\n",
      "Train Epoch: 2 [25856/60000 (43%)]\tLoss: 1.887156\n",
      "Train Epoch: 2 [25984/60000 (43%)]\tLoss: 1.826493\n",
      "Train Epoch: 2 [26112/60000 (44%)]\tLoss: 1.848240\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 1.768488\n",
      "Train Epoch: 2 [26368/60000 (44%)]\tLoss: 1.933289\n",
      "Train Epoch: 2 [26496/60000 (44%)]\tLoss: 1.837279\n",
      "Train Epoch: 2 [26624/60000 (44%)]\tLoss: 1.832675\n",
      "Train Epoch: 2 [26752/60000 (45%)]\tLoss: 1.857547\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 1.830487\n",
      "Train Epoch: 2 [27008/60000 (45%)]\tLoss: 1.894934\n",
      "Train Epoch: 2 [27136/60000 (45%)]\tLoss: 1.867240\n",
      "Train Epoch: 2 [27264/60000 (46%)]\tLoss: 1.836286\n",
      "Train Epoch: 2 [27392/60000 (46%)]\tLoss: 1.841504\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 1.759049\n",
      "Train Epoch: 2 [27648/60000 (46%)]\tLoss: 1.830497\n",
      "Train Epoch: 2 [27776/60000 (46%)]\tLoss: 1.816513\n",
      "Train Epoch: 2 [27904/60000 (47%)]\tLoss: 1.789738\n",
      "Train Epoch: 2 [28032/60000 (47%)]\tLoss: 1.657033\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 1.770800\n",
      "Train Epoch: 2 [28288/60000 (47%)]\tLoss: 1.835364\n",
      "Train Epoch: 2 [28416/60000 (47%)]\tLoss: 1.842245\n",
      "Train Epoch: 2 [28544/60000 (48%)]\tLoss: 1.804524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [28672/60000 (48%)]\tLoss: 1.830768\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 1.783298\n",
      "Train Epoch: 2 [28928/60000 (48%)]\tLoss: 1.905145\n",
      "Train Epoch: 2 [29056/60000 (49%)]\tLoss: 1.922223\n",
      "Train Epoch: 2 [29184/60000 (49%)]\tLoss: 1.750807\n",
      "Train Epoch: 2 [29312/60000 (49%)]\tLoss: 1.770967\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 1.729061\n",
      "Train Epoch: 2 [29568/60000 (49%)]\tLoss: 1.770158\n",
      "Train Epoch: 2 [29696/60000 (50%)]\tLoss: 1.884751\n",
      "Train Epoch: 2 [29824/60000 (50%)]\tLoss: 1.909884\n",
      "Train Epoch: 2 [29952/60000 (50%)]\tLoss: 1.858840\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 1.958355\n",
      "Train Epoch: 2 [30208/60000 (50%)]\tLoss: 1.735425\n",
      "Train Epoch: 2 [30336/60000 (51%)]\tLoss: 1.838262\n",
      "Train Epoch: 2 [30464/60000 (51%)]\tLoss: 1.913623\n",
      "Train Epoch: 2 [30592/60000 (51%)]\tLoss: 1.837665\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.843752\n",
      "Train Epoch: 2 [30848/60000 (51%)]\tLoss: 1.802750\n",
      "Train Epoch: 2 [30976/60000 (52%)]\tLoss: 1.816552\n",
      "Train Epoch: 2 [31104/60000 (52%)]\tLoss: 1.746221\n",
      "Train Epoch: 2 [31232/60000 (52%)]\tLoss: 1.928265\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 1.867337\n",
      "Train Epoch: 2 [31488/60000 (53%)]\tLoss: 1.797028\n",
      "Train Epoch: 2 [31616/60000 (53%)]\tLoss: 1.877502\n",
      "Train Epoch: 2 [31744/60000 (53%)]\tLoss: 1.787572\n",
      "Train Epoch: 2 [31872/60000 (53%)]\tLoss: 1.733044\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.850554\n",
      "Train Epoch: 2 [32128/60000 (54%)]\tLoss: 1.904661\n",
      "Train Epoch: 2 [32256/60000 (54%)]\tLoss: 1.872214\n",
      "Train Epoch: 2 [32384/60000 (54%)]\tLoss: 1.891518\n",
      "Train Epoch: 2 [32512/60000 (54%)]\tLoss: 1.746695\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 1.840984\n",
      "Train Epoch: 2 [32768/60000 (55%)]\tLoss: 1.781025\n",
      "Train Epoch: 2 [32896/60000 (55%)]\tLoss: 1.828159\n",
      "Train Epoch: 2 [33024/60000 (55%)]\tLoss: 1.810374\n",
      "Train Epoch: 2 [33152/60000 (55%)]\tLoss: 1.804496\n",
      "Train Epoch: 2 [33280/60000 (56%)]\tLoss: 1.793445\n",
      "Train Epoch: 2 [33408/60000 (56%)]\tLoss: 1.776422\n",
      "Train Epoch: 2 [33536/60000 (56%)]\tLoss: 1.759963\n",
      "Train Epoch: 2 [33664/60000 (56%)]\tLoss: 1.773921\n",
      "Train Epoch: 2 [33792/60000 (56%)]\tLoss: 1.663741\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 1.744699\n",
      "Train Epoch: 2 [34048/60000 (57%)]\tLoss: 1.798368\n",
      "Train Epoch: 2 [34176/60000 (57%)]\tLoss: 1.648825\n",
      "Train Epoch: 2 [34304/60000 (57%)]\tLoss: 1.791298\n",
      "Train Epoch: 2 [34432/60000 (57%)]\tLoss: 1.739826\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 1.762858\n",
      "Train Epoch: 2 [34688/60000 (58%)]\tLoss: 1.823506\n",
      "Train Epoch: 2 [34816/60000 (58%)]\tLoss: 1.987745\n",
      "Train Epoch: 2 [34944/60000 (58%)]\tLoss: 1.781384\n",
      "Train Epoch: 2 [35072/60000 (59%)]\tLoss: 1.812928\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 1.840126\n",
      "Train Epoch: 2 [35328/60000 (59%)]\tLoss: 1.691405\n",
      "Train Epoch: 2 [35456/60000 (59%)]\tLoss: 1.684813\n",
      "Train Epoch: 2 [35584/60000 (59%)]\tLoss: 1.799372\n",
      "Train Epoch: 2 [35712/60000 (60%)]\tLoss: 1.752081\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 1.710196\n",
      "Train Epoch: 2 [35968/60000 (60%)]\tLoss: 1.816317\n",
      "Train Epoch: 2 [36096/60000 (60%)]\tLoss: 1.723813\n",
      "Train Epoch: 2 [36224/60000 (60%)]\tLoss: 1.623343\n",
      "Train Epoch: 2 [36352/60000 (61%)]\tLoss: 1.712186\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 1.717694\n",
      "Train Epoch: 2 [36608/60000 (61%)]\tLoss: 1.616681\n",
      "Train Epoch: 2 [36736/60000 (61%)]\tLoss: 1.728211\n",
      "Train Epoch: 2 [36864/60000 (62%)]\tLoss: 1.710071\n",
      "Train Epoch: 2 [36992/60000 (62%)]\tLoss: 1.840839\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 1.715733\n",
      "Train Epoch: 2 [37248/60000 (62%)]\tLoss: 1.846576\n",
      "Train Epoch: 2 [37376/60000 (62%)]\tLoss: 1.762283\n",
      "Train Epoch: 2 [37504/60000 (63%)]\tLoss: 1.692894\n",
      "Train Epoch: 2 [37632/60000 (63%)]\tLoss: 1.620888\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 1.735371\n",
      "Train Epoch: 2 [37888/60000 (63%)]\tLoss: 1.686607\n",
      "Train Epoch: 2 [38016/60000 (63%)]\tLoss: 1.747227\n",
      "Train Epoch: 2 [38144/60000 (64%)]\tLoss: 1.705650\n",
      "Train Epoch: 2 [38272/60000 (64%)]\tLoss: 1.833340\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.685033\n",
      "Train Epoch: 2 [38528/60000 (64%)]\tLoss: 1.841069\n",
      "Train Epoch: 2 [38656/60000 (65%)]\tLoss: 1.682407\n",
      "Train Epoch: 2 [38784/60000 (65%)]\tLoss: 1.680609\n",
      "Train Epoch: 2 [38912/60000 (65%)]\tLoss: 1.642969\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 1.546183\n",
      "Train Epoch: 2 [39168/60000 (65%)]\tLoss: 1.669539\n",
      "Train Epoch: 2 [39296/60000 (66%)]\tLoss: 1.756779\n",
      "Train Epoch: 2 [39424/60000 (66%)]\tLoss: 1.780446\n",
      "Train Epoch: 2 [39552/60000 (66%)]\tLoss: 1.698936\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 1.825810\n",
      "Train Epoch: 2 [39808/60000 (66%)]\tLoss: 1.799417\n",
      "Train Epoch: 2 [39936/60000 (67%)]\tLoss: 1.721075\n",
      "Train Epoch: 2 [40064/60000 (67%)]\tLoss: 1.660076\n",
      "Train Epoch: 2 [40192/60000 (67%)]\tLoss: 1.726493\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 1.612629\n",
      "Train Epoch: 2 [40448/60000 (68%)]\tLoss: 1.745970\n",
      "Train Epoch: 2 [40576/60000 (68%)]\tLoss: 1.788345\n",
      "Train Epoch: 2 [40704/60000 (68%)]\tLoss: 1.660885\n",
      "Train Epoch: 2 [40832/60000 (68%)]\tLoss: 1.631917\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.658168\n",
      "Train Epoch: 2 [41088/60000 (69%)]\tLoss: 1.716018\n",
      "Train Epoch: 2 [41216/60000 (69%)]\tLoss: 1.758112\n",
      "Train Epoch: 2 [41344/60000 (69%)]\tLoss: 1.770990\n",
      "Train Epoch: 2 [41472/60000 (69%)]\tLoss: 1.805298\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 1.611911\n",
      "Train Epoch: 2 [41728/60000 (70%)]\tLoss: 1.723031\n",
      "Train Epoch: 2 [41856/60000 (70%)]\tLoss: 1.760572\n",
      "Train Epoch: 2 [41984/60000 (70%)]\tLoss: 1.707439\n",
      "Train Epoch: 2 [42112/60000 (70%)]\tLoss: 1.801395\n",
      "Train Epoch: 2 [42240/60000 (71%)]\tLoss: 1.865914\n",
      "Train Epoch: 2 [42368/60000 (71%)]\tLoss: 1.675836\n",
      "Train Epoch: 2 [42496/60000 (71%)]\tLoss: 1.711837\n",
      "Train Epoch: 2 [42624/60000 (71%)]\tLoss: 1.689425\n",
      "Train Epoch: 2 [42752/60000 (71%)]\tLoss: 1.667848\n",
      "Train Epoch: 2 [42880/60000 (72%)]\tLoss: 1.697133\n",
      "Train Epoch: 2 [43008/60000 (72%)]\tLoss: 1.802502\n",
      "Train Epoch: 2 [43136/60000 (72%)]\tLoss: 1.672860\n",
      "Train Epoch: 2 [43264/60000 (72%)]\tLoss: 1.627833\n",
      "Train Epoch: 2 [43392/60000 (72%)]\tLoss: 1.682052\n",
      "Train Epoch: 2 [43520/60000 (73%)]\tLoss: 1.599679\n",
      "Train Epoch: 2 [43648/60000 (73%)]\tLoss: 1.753839\n",
      "Train Epoch: 2 [43776/60000 (73%)]\tLoss: 1.703615\n",
      "Train Epoch: 2 [43904/60000 (73%)]\tLoss: 1.655470\n",
      "Train Epoch: 2 [44032/60000 (74%)]\tLoss: 1.729868\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 1.756243\n",
      "Train Epoch: 2 [44288/60000 (74%)]\tLoss: 1.707528\n",
      "Train Epoch: 2 [44416/60000 (74%)]\tLoss: 1.597591\n",
      "Train Epoch: 2 [44544/60000 (74%)]\tLoss: 1.576211\n",
      "Train Epoch: 2 [44672/60000 (75%)]\tLoss: 1.727989\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.695727\n",
      "Train Epoch: 2 [44928/60000 (75%)]\tLoss: 1.588948\n",
      "Train Epoch: 2 [45056/60000 (75%)]\tLoss: 1.794563\n",
      "Train Epoch: 2 [45184/60000 (75%)]\tLoss: 1.639111\n",
      "Train Epoch: 2 [45312/60000 (76%)]\tLoss: 1.710990\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 1.671904\n",
      "Train Epoch: 2 [45568/60000 (76%)]\tLoss: 1.593352\n",
      "Train Epoch: 2 [45696/60000 (76%)]\tLoss: 1.691845\n",
      "Train Epoch: 2 [45824/60000 (76%)]\tLoss: 1.707062\n",
      "Train Epoch: 2 [45952/60000 (77%)]\tLoss: 1.620783\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 1.655476\n",
      "Train Epoch: 2 [46208/60000 (77%)]\tLoss: 1.650086\n",
      "Train Epoch: 2 [46336/60000 (77%)]\tLoss: 1.695611\n",
      "Train Epoch: 2 [46464/60000 (78%)]\tLoss: 1.534738\n",
      "Train Epoch: 2 [46592/60000 (78%)]\tLoss: 1.583310\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 1.618772\n",
      "Train Epoch: 2 [46848/60000 (78%)]\tLoss: 1.593727\n",
      "Train Epoch: 2 [46976/60000 (78%)]\tLoss: 1.644236\n",
      "Train Epoch: 2 [47104/60000 (79%)]\tLoss: 1.719700\n",
      "Train Epoch: 2 [47232/60000 (79%)]\tLoss: 1.694447\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 1.677624\n",
      "Train Epoch: 2 [47488/60000 (79%)]\tLoss: 1.728789\n",
      "Train Epoch: 2 [47616/60000 (79%)]\tLoss: 1.606624\n",
      "Train Epoch: 2 [47744/60000 (80%)]\tLoss: 1.566172\n",
      "Train Epoch: 2 [47872/60000 (80%)]\tLoss: 1.688500\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.588971\n",
      "Train Epoch: 2 [48128/60000 (80%)]\tLoss: 1.502777\n",
      "Train Epoch: 2 [48256/60000 (81%)]\tLoss: 1.600626\n",
      "Train Epoch: 2 [48384/60000 (81%)]\tLoss: 1.600397\n",
      "Train Epoch: 2 [48512/60000 (81%)]\tLoss: 1.553713\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 1.552507\n",
      "Train Epoch: 2 [48768/60000 (81%)]\tLoss: 1.589921\n",
      "Train Epoch: 2 [48896/60000 (82%)]\tLoss: 1.702944\n",
      "Train Epoch: 2 [49024/60000 (82%)]\tLoss: 1.696273\n",
      "Train Epoch: 2 [49152/60000 (82%)]\tLoss: 1.695594\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 1.633913\n",
      "Train Epoch: 2 [49408/60000 (82%)]\tLoss: 1.760581\n",
      "Train Epoch: 2 [49536/60000 (83%)]\tLoss: 1.803113\n",
      "Train Epoch: 2 [49664/60000 (83%)]\tLoss: 1.728737\n",
      "Train Epoch: 2 [49792/60000 (83%)]\tLoss: 1.626840\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 1.622475\n",
      "Train Epoch: 2 [50048/60000 (84%)]\tLoss: 1.609264\n",
      "Train Epoch: 2 [50176/60000 (84%)]\tLoss: 1.576796\n",
      "Train Epoch: 2 [50304/60000 (84%)]\tLoss: 1.758357\n",
      "Train Epoch: 2 [50432/60000 (84%)]\tLoss: 1.673692\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 1.600754\n",
      "Train Epoch: 2 [50688/60000 (85%)]\tLoss: 1.683418\n",
      "Train Epoch: 2 [50816/60000 (85%)]\tLoss: 1.610650\n",
      "Train Epoch: 2 [50944/60000 (85%)]\tLoss: 1.617922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [51072/60000 (85%)]\tLoss: 1.589620\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.619777\n",
      "Train Epoch: 2 [51328/60000 (86%)]\tLoss: 1.581535\n",
      "Train Epoch: 2 [51456/60000 (86%)]\tLoss: 1.492258\n",
      "Train Epoch: 2 [51584/60000 (86%)]\tLoss: 1.552118\n",
      "Train Epoch: 2 [51712/60000 (86%)]\tLoss: 1.644328\n",
      "Train Epoch: 2 [51840/60000 (87%)]\tLoss: 1.713613\n",
      "Train Epoch: 2 [51968/60000 (87%)]\tLoss: 1.652043\n",
      "Train Epoch: 2 [52096/60000 (87%)]\tLoss: 1.700860\n",
      "Train Epoch: 2 [52224/60000 (87%)]\tLoss: 1.572742\n",
      "Train Epoch: 2 [52352/60000 (87%)]\tLoss: 1.544599\n",
      "Train Epoch: 2 [52480/60000 (88%)]\tLoss: 1.462863\n",
      "Train Epoch: 2 [52608/60000 (88%)]\tLoss: 1.636984\n",
      "Train Epoch: 2 [52736/60000 (88%)]\tLoss: 1.727044\n",
      "Train Epoch: 2 [52864/60000 (88%)]\tLoss: 1.586764\n",
      "Train Epoch: 2 [52992/60000 (88%)]\tLoss: 1.562785\n",
      "Train Epoch: 2 [53120/60000 (89%)]\tLoss: 1.603533\n",
      "Train Epoch: 2 [53248/60000 (89%)]\tLoss: 1.489451\n",
      "Train Epoch: 2 [53376/60000 (89%)]\tLoss: 1.498428\n",
      "Train Epoch: 2 [53504/60000 (89%)]\tLoss: 1.686831\n",
      "Train Epoch: 2 [53632/60000 (90%)]\tLoss: 1.633700\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 1.475517\n",
      "Train Epoch: 2 [53888/60000 (90%)]\tLoss: 1.625004\n",
      "Train Epoch: 2 [54016/60000 (90%)]\tLoss: 1.662097\n",
      "Train Epoch: 2 [54144/60000 (90%)]\tLoss: 1.576941\n",
      "Train Epoch: 2 [54272/60000 (91%)]\tLoss: 1.544165\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 1.482876\n",
      "Train Epoch: 2 [54528/60000 (91%)]\tLoss: 1.529004\n",
      "Train Epoch: 2 [54656/60000 (91%)]\tLoss: 1.489548\n",
      "Train Epoch: 2 [54784/60000 (91%)]\tLoss: 1.629127\n",
      "Train Epoch: 2 [54912/60000 (92%)]\tLoss: 1.686095\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 1.488467\n",
      "Train Epoch: 2 [55168/60000 (92%)]\tLoss: 1.531667\n",
      "Train Epoch: 2 [55296/60000 (92%)]\tLoss: 1.571089\n",
      "Train Epoch: 2 [55424/60000 (93%)]\tLoss: 1.491631\n",
      "Train Epoch: 2 [55552/60000 (93%)]\tLoss: 1.548247\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 1.489354\n",
      "Train Epoch: 2 [55808/60000 (93%)]\tLoss: 1.530727\n",
      "Train Epoch: 2 [55936/60000 (93%)]\tLoss: 1.467544\n",
      "Train Epoch: 2 [56064/60000 (94%)]\tLoss: 1.616456\n",
      "Train Epoch: 2 [56192/60000 (94%)]\tLoss: 1.585073\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 1.605252\n",
      "Train Epoch: 2 [56448/60000 (94%)]\tLoss: 1.544670\n",
      "Train Epoch: 2 [56576/60000 (94%)]\tLoss: 1.510673\n",
      "Train Epoch: 2 [56704/60000 (95%)]\tLoss: 1.474377\n",
      "Train Epoch: 2 [56832/60000 (95%)]\tLoss: 1.502755\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 1.557347\n",
      "Train Epoch: 2 [57088/60000 (95%)]\tLoss: 1.548867\n",
      "Train Epoch: 2 [57216/60000 (96%)]\tLoss: 1.821779\n",
      "Train Epoch: 2 [57344/60000 (96%)]\tLoss: 1.589342\n",
      "Train Epoch: 2 [57472/60000 (96%)]\tLoss: 1.534403\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.511701\n",
      "Train Epoch: 2 [57728/60000 (96%)]\tLoss: 1.538145\n",
      "Train Epoch: 2 [57856/60000 (97%)]\tLoss: 1.460355\n",
      "Train Epoch: 2 [57984/60000 (97%)]\tLoss: 1.611189\n",
      "Train Epoch: 2 [58112/60000 (97%)]\tLoss: 1.423405\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 1.528809\n",
      "Train Epoch: 2 [58368/60000 (97%)]\tLoss: 1.545578\n",
      "Train Epoch: 2 [58496/60000 (98%)]\tLoss: 1.565901\n",
      "Train Epoch: 2 [58624/60000 (98%)]\tLoss: 1.437994\n",
      "Train Epoch: 2 [58752/60000 (98%)]\tLoss: 1.562483\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 1.300178\n",
      "Train Epoch: 2 [59008/60000 (99%)]\tLoss: 1.385122\n",
      "Train Epoch: 2 [59136/60000 (99%)]\tLoss: 1.445576\n",
      "Train Epoch: 2 [59264/60000 (99%)]\tLoss: 1.627483\n",
      "Train Epoch: 2 [59392/60000 (99%)]\tLoss: 1.554465\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 1.479540\n",
      "Train Epoch: 2 [59648/60000 (100%)]\tLoss: 1.608657\n",
      "Train Epoch: 2 [59776/60000 (100%)]\tLoss: 1.504056\n",
      "================================================================\n",
      "Training: Average loss: 1.0727, Accuracy: 49242/60000 (82%)\n",
      "Test: Average loss: 1.0481, Accuracy: 8344/10000 (83%)\n",
      "================================================================\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.465341\n",
      "Train Epoch: 3 [128/60000 (0%)]\tLoss: 1.502524\n",
      "Train Epoch: 3 [256/60000 (0%)]\tLoss: 1.494024\n",
      "Train Epoch: 3 [384/60000 (1%)]\tLoss: 1.519029\n",
      "Train Epoch: 3 [512/60000 (1%)]\tLoss: 1.586609\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 1.517393\n",
      "Train Epoch: 3 [768/60000 (1%)]\tLoss: 1.620207\n",
      "Train Epoch: 3 [896/60000 (1%)]\tLoss: 1.627195\n",
      "Train Epoch: 3 [1024/60000 (2%)]\tLoss: 1.716843\n",
      "Train Epoch: 3 [1152/60000 (2%)]\tLoss: 1.611615\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 1.657379\n",
      "Train Epoch: 3 [1408/60000 (2%)]\tLoss: 1.548334\n",
      "Train Epoch: 3 [1536/60000 (3%)]\tLoss: 1.572333\n",
      "Train Epoch: 3 [1664/60000 (3%)]\tLoss: 1.512273\n",
      "Train Epoch: 3 [1792/60000 (3%)]\tLoss: 1.405672\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 1.484079\n",
      "Train Epoch: 3 [2048/60000 (3%)]\tLoss: 1.492568\n",
      "Train Epoch: 3 [2176/60000 (4%)]\tLoss: 1.466470\n",
      "Train Epoch: 3 [2304/60000 (4%)]\tLoss: 1.477516\n",
      "Train Epoch: 3 [2432/60000 (4%)]\tLoss: 1.489954\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 1.437016\n",
      "Train Epoch: 3 [2688/60000 (4%)]\tLoss: 1.466802\n",
      "Train Epoch: 3 [2816/60000 (5%)]\tLoss: 1.504768\n",
      "Train Epoch: 3 [2944/60000 (5%)]\tLoss: 1.545625\n",
      "Train Epoch: 3 [3072/60000 (5%)]\tLoss: 1.504468\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 1.458143\n",
      "Train Epoch: 3 [3328/60000 (6%)]\tLoss: 1.593934\n",
      "Train Epoch: 3 [3456/60000 (6%)]\tLoss: 1.559108\n",
      "Train Epoch: 3 [3584/60000 (6%)]\tLoss: 1.402809\n",
      "Train Epoch: 3 [3712/60000 (6%)]\tLoss: 1.491441\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 1.453652\n",
      "Train Epoch: 3 [3968/60000 (7%)]\tLoss: 1.513921\n",
      "Train Epoch: 3 [4096/60000 (7%)]\tLoss: 1.536373\n",
      "Train Epoch: 3 [4224/60000 (7%)]\tLoss: 1.500646\n",
      "Train Epoch: 3 [4352/60000 (7%)]\tLoss: 1.429317\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 1.320632\n",
      "Train Epoch: 3 [4608/60000 (8%)]\tLoss: 1.429326\n",
      "Train Epoch: 3 [4736/60000 (8%)]\tLoss: 1.562622\n",
      "Train Epoch: 3 [4864/60000 (8%)]\tLoss: 1.578779\n",
      "Train Epoch: 3 [4992/60000 (8%)]\tLoss: 1.612477\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 1.598559\n",
      "Train Epoch: 3 [5248/60000 (9%)]\tLoss: 1.418307\n",
      "Train Epoch: 3 [5376/60000 (9%)]\tLoss: 1.432915\n",
      "Train Epoch: 3 [5504/60000 (9%)]\tLoss: 1.517896\n",
      "Train Epoch: 3 [5632/60000 (9%)]\tLoss: 1.518472\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 1.600443\n",
      "Train Epoch: 3 [5888/60000 (10%)]\tLoss: 1.471780\n",
      "Train Epoch: 3 [6016/60000 (10%)]\tLoss: 1.390538\n",
      "Train Epoch: 3 [6144/60000 (10%)]\tLoss: 1.532270\n",
      "Train Epoch: 3 [6272/60000 (10%)]\tLoss: 1.483495\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.502679\n",
      "Train Epoch: 3 [6528/60000 (11%)]\tLoss: 1.385425\n",
      "Train Epoch: 3 [6656/60000 (11%)]\tLoss: 1.453048\n",
      "Train Epoch: 3 [6784/60000 (11%)]\tLoss: 1.675014\n",
      "Train Epoch: 3 [6912/60000 (12%)]\tLoss: 1.478061\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 1.559806\n",
      "Train Epoch: 3 [7168/60000 (12%)]\tLoss: 1.596886\n",
      "Train Epoch: 3 [7296/60000 (12%)]\tLoss: 1.542888\n",
      "Train Epoch: 3 [7424/60000 (12%)]\tLoss: 1.512390\n",
      "Train Epoch: 3 [7552/60000 (13%)]\tLoss: 1.470183\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 1.496835\n",
      "Train Epoch: 3 [7808/60000 (13%)]\tLoss: 1.494635\n",
      "Train Epoch: 3 [7936/60000 (13%)]\tLoss: 1.388997\n",
      "Train Epoch: 3 [8064/60000 (13%)]\tLoss: 1.442961\n",
      "Train Epoch: 3 [8192/60000 (14%)]\tLoss: 1.645304\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 1.575752\n",
      "Train Epoch: 3 [8448/60000 (14%)]\tLoss: 1.468601\n",
      "Train Epoch: 3 [8576/60000 (14%)]\tLoss: 1.545776\n",
      "Train Epoch: 3 [8704/60000 (15%)]\tLoss: 1.531016\n",
      "Train Epoch: 3 [8832/60000 (15%)]\tLoss: 1.559011\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 1.277944\n",
      "Train Epoch: 3 [9088/60000 (15%)]\tLoss: 1.452805\n",
      "Train Epoch: 3 [9216/60000 (15%)]\tLoss: 1.422773\n",
      "Train Epoch: 3 [9344/60000 (16%)]\tLoss: 1.467973\n",
      "Train Epoch: 3 [9472/60000 (16%)]\tLoss: 1.492557\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 1.403476\n",
      "Train Epoch: 3 [9728/60000 (16%)]\tLoss: 1.464361\n",
      "Train Epoch: 3 [9856/60000 (16%)]\tLoss: 1.419686\n",
      "Train Epoch: 3 [9984/60000 (17%)]\tLoss: 1.507867\n",
      "Train Epoch: 3 [10112/60000 (17%)]\tLoss: 1.480755\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 1.401301\n",
      "Train Epoch: 3 [10368/60000 (17%)]\tLoss: 1.360500\n",
      "Train Epoch: 3 [10496/60000 (18%)]\tLoss: 1.476793\n",
      "Train Epoch: 3 [10624/60000 (18%)]\tLoss: 1.410480\n",
      "Train Epoch: 3 [10752/60000 (18%)]\tLoss: 1.414463\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 1.334412\n",
      "Train Epoch: 3 [11008/60000 (18%)]\tLoss: 1.416656\n",
      "Train Epoch: 3 [11136/60000 (19%)]\tLoss: 1.551714\n",
      "Train Epoch: 3 [11264/60000 (19%)]\tLoss: 1.390355\n",
      "Train Epoch: 3 [11392/60000 (19%)]\tLoss: 1.405961\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 1.582284\n",
      "Train Epoch: 3 [11648/60000 (19%)]\tLoss: 1.561943\n",
      "Train Epoch: 3 [11776/60000 (20%)]\tLoss: 1.480446\n",
      "Train Epoch: 3 [11904/60000 (20%)]\tLoss: 1.435000\n",
      "Train Epoch: 3 [12032/60000 (20%)]\tLoss: 1.476650\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 1.519185\n",
      "Train Epoch: 3 [12288/60000 (21%)]\tLoss: 1.509750\n",
      "Train Epoch: 3 [12416/60000 (21%)]\tLoss: 1.400618\n",
      "Train Epoch: 3 [12544/60000 (21%)]\tLoss: 1.608471\n",
      "Train Epoch: 3 [12672/60000 (21%)]\tLoss: 1.419527\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.397541\n",
      "Train Epoch: 3 [12928/60000 (22%)]\tLoss: 1.628093\n",
      "Train Epoch: 3 [13056/60000 (22%)]\tLoss: 1.661935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [13184/60000 (22%)]\tLoss: 1.402325\n",
      "Train Epoch: 3 [13312/60000 (22%)]\tLoss: 1.498176\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 1.334030\n",
      "Train Epoch: 3 [13568/60000 (23%)]\tLoss: 1.481858\n",
      "Train Epoch: 3 [13696/60000 (23%)]\tLoss: 1.425492\n",
      "Train Epoch: 3 [13824/60000 (23%)]\tLoss: 1.548652\n",
      "Train Epoch: 3 [13952/60000 (23%)]\tLoss: 1.593307\n",
      "Train Epoch: 3 [14080/60000 (24%)]\tLoss: 1.413580\n",
      "Train Epoch: 3 [14208/60000 (24%)]\tLoss: 1.612691\n",
      "Train Epoch: 3 [14336/60000 (24%)]\tLoss: 1.503004\n",
      "Train Epoch: 3 [14464/60000 (24%)]\tLoss: 1.505240\n",
      "Train Epoch: 3 [14592/60000 (24%)]\tLoss: 1.543779\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 1.572675\n",
      "Train Epoch: 3 [14848/60000 (25%)]\tLoss: 1.438109\n",
      "Train Epoch: 3 [14976/60000 (25%)]\tLoss: 1.332200\n",
      "Train Epoch: 3 [15104/60000 (25%)]\tLoss: 1.500387\n",
      "Train Epoch: 3 [15232/60000 (25%)]\tLoss: 1.461321\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 1.403428\n",
      "Train Epoch: 3 [15488/60000 (26%)]\tLoss: 1.351022\n",
      "Train Epoch: 3 [15616/60000 (26%)]\tLoss: 1.486539\n",
      "Train Epoch: 3 [15744/60000 (26%)]\tLoss: 1.581314\n",
      "Train Epoch: 3 [15872/60000 (26%)]\tLoss: 1.592976\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.552770\n",
      "Train Epoch: 3 [16128/60000 (27%)]\tLoss: 1.387646\n",
      "Train Epoch: 3 [16256/60000 (27%)]\tLoss: 1.439909\n",
      "Train Epoch: 3 [16384/60000 (27%)]\tLoss: 1.373278\n",
      "Train Epoch: 3 [16512/60000 (28%)]\tLoss: 1.350798\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 1.520422\n",
      "Train Epoch: 3 [16768/60000 (28%)]\tLoss: 1.572858\n",
      "Train Epoch: 3 [16896/60000 (28%)]\tLoss: 1.534875\n",
      "Train Epoch: 3 [17024/60000 (28%)]\tLoss: 1.376624\n",
      "Train Epoch: 3 [17152/60000 (29%)]\tLoss: 1.557585\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 1.342106\n",
      "Train Epoch: 3 [17408/60000 (29%)]\tLoss: 1.408233\n",
      "Train Epoch: 3 [17536/60000 (29%)]\tLoss: 1.559278\n",
      "Train Epoch: 3 [17664/60000 (29%)]\tLoss: 1.478206\n",
      "Train Epoch: 3 [17792/60000 (30%)]\tLoss: 1.592209\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 1.392723\n",
      "Train Epoch: 3 [18048/60000 (30%)]\tLoss: 1.401695\n",
      "Train Epoch: 3 [18176/60000 (30%)]\tLoss: 1.345756\n",
      "Train Epoch: 3 [18304/60000 (31%)]\tLoss: 1.442570\n",
      "Train Epoch: 3 [18432/60000 (31%)]\tLoss: 1.508223\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 1.421526\n",
      "Train Epoch: 3 [18688/60000 (31%)]\tLoss: 1.297722\n",
      "Train Epoch: 3 [18816/60000 (31%)]\tLoss: 1.328506\n",
      "Train Epoch: 3 [18944/60000 (32%)]\tLoss: 1.324010\n",
      "Train Epoch: 3 [19072/60000 (32%)]\tLoss: 1.515668\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.405319\n",
      "Train Epoch: 3 [19328/60000 (32%)]\tLoss: 1.347609\n",
      "Train Epoch: 3 [19456/60000 (32%)]\tLoss: 1.357550\n",
      "Train Epoch: 3 [19584/60000 (33%)]\tLoss: 1.347406\n",
      "Train Epoch: 3 [19712/60000 (33%)]\tLoss: 1.359454\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 1.370667\n",
      "Train Epoch: 3 [19968/60000 (33%)]\tLoss: 1.348080\n",
      "Train Epoch: 3 [20096/60000 (34%)]\tLoss: 1.417514\n",
      "Train Epoch: 3 [20224/60000 (34%)]\tLoss: 1.377881\n",
      "Train Epoch: 3 [20352/60000 (34%)]\tLoss: 1.269962\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 1.404925\n",
      "Train Epoch: 3 [20608/60000 (34%)]\tLoss: 1.384704\n",
      "Train Epoch: 3 [20736/60000 (35%)]\tLoss: 1.480834\n",
      "Train Epoch: 3 [20864/60000 (35%)]\tLoss: 1.597671\n",
      "Train Epoch: 3 [20992/60000 (35%)]\tLoss: 1.409363\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 1.384128\n",
      "Train Epoch: 3 [21248/60000 (35%)]\tLoss: 1.340296\n",
      "Train Epoch: 3 [21376/60000 (36%)]\tLoss: 1.397790\n",
      "Train Epoch: 3 [21504/60000 (36%)]\tLoss: 1.405818\n",
      "Train Epoch: 3 [21632/60000 (36%)]\tLoss: 1.377971\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 1.305820\n",
      "Train Epoch: 3 [21888/60000 (37%)]\tLoss: 1.250495\n",
      "Train Epoch: 3 [22016/60000 (37%)]\tLoss: 1.328860\n",
      "Train Epoch: 3 [22144/60000 (37%)]\tLoss: 1.528684\n",
      "Train Epoch: 3 [22272/60000 (37%)]\tLoss: 1.381633\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 1.535287\n",
      "Train Epoch: 3 [22528/60000 (38%)]\tLoss: 1.468709\n",
      "Train Epoch: 3 [22656/60000 (38%)]\tLoss: 1.449854\n",
      "Train Epoch: 3 [22784/60000 (38%)]\tLoss: 1.317298\n",
      "Train Epoch: 3 [22912/60000 (38%)]\tLoss: 1.280829\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 1.414355\n",
      "Train Epoch: 3 [23168/60000 (39%)]\tLoss: 1.333836\n",
      "Train Epoch: 3 [23296/60000 (39%)]\tLoss: 1.279193\n",
      "Train Epoch: 3 [23424/60000 (39%)]\tLoss: 1.451696\n",
      "Train Epoch: 3 [23552/60000 (39%)]\tLoss: 1.441939\n",
      "Train Epoch: 3 [23680/60000 (40%)]\tLoss: 1.529710\n",
      "Train Epoch: 3 [23808/60000 (40%)]\tLoss: 1.432234\n",
      "Train Epoch: 3 [23936/60000 (40%)]\tLoss: 1.479563\n",
      "Train Epoch: 3 [24064/60000 (40%)]\tLoss: 1.373091\n",
      "Train Epoch: 3 [24192/60000 (40%)]\tLoss: 1.522819\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 1.392835\n",
      "Train Epoch: 3 [24448/60000 (41%)]\tLoss: 1.368691\n",
      "Train Epoch: 3 [24576/60000 (41%)]\tLoss: 1.411033\n",
      "Train Epoch: 3 [24704/60000 (41%)]\tLoss: 1.518831\n",
      "Train Epoch: 3 [24832/60000 (41%)]\tLoss: 1.492891\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 1.321265\n",
      "Train Epoch: 3 [25088/60000 (42%)]\tLoss: 1.434527\n",
      "Train Epoch: 3 [25216/60000 (42%)]\tLoss: 1.409586\n",
      "Train Epoch: 3 [25344/60000 (42%)]\tLoss: 1.288185\n",
      "Train Epoch: 3 [25472/60000 (43%)]\tLoss: 1.311598\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.415439\n",
      "Train Epoch: 3 [25728/60000 (43%)]\tLoss: 1.394757\n",
      "Train Epoch: 3 [25856/60000 (43%)]\tLoss: 1.324965\n",
      "Train Epoch: 3 [25984/60000 (43%)]\tLoss: 1.299363\n",
      "Train Epoch: 3 [26112/60000 (44%)]\tLoss: 1.434349\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 1.388262\n",
      "Train Epoch: 3 [26368/60000 (44%)]\tLoss: 1.540111\n",
      "Train Epoch: 3 [26496/60000 (44%)]\tLoss: 1.385850\n",
      "Train Epoch: 3 [26624/60000 (44%)]\tLoss: 1.572807\n",
      "Train Epoch: 3 [26752/60000 (45%)]\tLoss: 1.241835\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 1.340731\n",
      "Train Epoch: 3 [27008/60000 (45%)]\tLoss: 1.362226\n",
      "Train Epoch: 3 [27136/60000 (45%)]\tLoss: 1.510051\n",
      "Train Epoch: 3 [27264/60000 (46%)]\tLoss: 1.380389\n",
      "Train Epoch: 3 [27392/60000 (46%)]\tLoss: 1.403323\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 1.350072\n",
      "Train Epoch: 3 [27648/60000 (46%)]\tLoss: 1.310749\n",
      "Train Epoch: 3 [27776/60000 (46%)]\tLoss: 1.424625\n",
      "Train Epoch: 3 [27904/60000 (47%)]\tLoss: 1.272223\n",
      "Train Epoch: 3 [28032/60000 (47%)]\tLoss: 1.317210\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 1.441983\n",
      "Train Epoch: 3 [28288/60000 (47%)]\tLoss: 1.350051\n",
      "Train Epoch: 3 [28416/60000 (47%)]\tLoss: 1.351748\n",
      "Train Epoch: 3 [28544/60000 (48%)]\tLoss: 1.390174\n",
      "Train Epoch: 3 [28672/60000 (48%)]\tLoss: 1.439781\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 1.409439\n",
      "Train Epoch: 3 [28928/60000 (48%)]\tLoss: 1.446969\n",
      "Train Epoch: 3 [29056/60000 (49%)]\tLoss: 1.533243\n",
      "Train Epoch: 3 [29184/60000 (49%)]\tLoss: 1.408594\n",
      "Train Epoch: 3 [29312/60000 (49%)]\tLoss: 1.293362\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 1.258666\n",
      "Train Epoch: 3 [29568/60000 (49%)]\tLoss: 1.349895\n",
      "Train Epoch: 3 [29696/60000 (50%)]\tLoss: 1.457208\n",
      "Train Epoch: 3 [29824/60000 (50%)]\tLoss: 1.570961\n",
      "Train Epoch: 3 [29952/60000 (50%)]\tLoss: 1.534584\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 1.466025\n",
      "Train Epoch: 3 [30208/60000 (50%)]\tLoss: 1.366489\n",
      "Train Epoch: 3 [30336/60000 (51%)]\tLoss: 1.271793\n",
      "Train Epoch: 3 [30464/60000 (51%)]\tLoss: 1.487768\n",
      "Train Epoch: 3 [30592/60000 (51%)]\tLoss: 1.506071\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 1.430137\n",
      "Train Epoch: 3 [30848/60000 (51%)]\tLoss: 1.388088\n",
      "Train Epoch: 3 [30976/60000 (52%)]\tLoss: 1.405440\n",
      "Train Epoch: 3 [31104/60000 (52%)]\tLoss: 1.362743\n",
      "Train Epoch: 3 [31232/60000 (52%)]\tLoss: 1.530048\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 1.446268\n",
      "Train Epoch: 3 [31488/60000 (53%)]\tLoss: 1.294051\n",
      "Train Epoch: 3 [31616/60000 (53%)]\tLoss: 1.483147\n",
      "Train Epoch: 3 [31744/60000 (53%)]\tLoss: 1.396683\n",
      "Train Epoch: 3 [31872/60000 (53%)]\tLoss: 1.233460\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.370770\n",
      "Train Epoch: 3 [32128/60000 (54%)]\tLoss: 1.452838\n",
      "Train Epoch: 3 [32256/60000 (54%)]\tLoss: 1.604987\n",
      "Train Epoch: 3 [32384/60000 (54%)]\tLoss: 1.457975\n",
      "Train Epoch: 3 [32512/60000 (54%)]\tLoss: 1.274998\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 1.310790\n",
      "Train Epoch: 3 [32768/60000 (55%)]\tLoss: 1.346202\n",
      "Train Epoch: 3 [32896/60000 (55%)]\tLoss: 1.363763\n",
      "Train Epoch: 3 [33024/60000 (55%)]\tLoss: 1.399521\n",
      "Train Epoch: 3 [33152/60000 (55%)]\tLoss: 1.382593\n",
      "Train Epoch: 3 [33280/60000 (56%)]\tLoss: 1.378465\n",
      "Train Epoch: 3 [33408/60000 (56%)]\tLoss: 1.383785\n",
      "Train Epoch: 3 [33536/60000 (56%)]\tLoss: 1.399611\n",
      "Train Epoch: 3 [33664/60000 (56%)]\tLoss: 1.396609\n",
      "Train Epoch: 3 [33792/60000 (56%)]\tLoss: 1.220667\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 1.257606\n",
      "Train Epoch: 3 [34048/60000 (57%)]\tLoss: 1.280714\n",
      "Train Epoch: 3 [34176/60000 (57%)]\tLoss: 1.267535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [34304/60000 (57%)]\tLoss: 1.400682\n",
      "Train Epoch: 3 [34432/60000 (57%)]\tLoss: 1.356450\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 1.462356\n",
      "Train Epoch: 3 [34688/60000 (58%)]\tLoss: 1.555747\n",
      "Train Epoch: 3 [34816/60000 (58%)]\tLoss: 1.479523\n",
      "Train Epoch: 3 [34944/60000 (58%)]\tLoss: 1.300501\n",
      "Train Epoch: 3 [35072/60000 (59%)]\tLoss: 1.394978\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 1.407902\n",
      "Train Epoch: 3 [35328/60000 (59%)]\tLoss: 1.305326\n",
      "Train Epoch: 3 [35456/60000 (59%)]\tLoss: 1.352494\n",
      "Train Epoch: 3 [35584/60000 (59%)]\tLoss: 1.394271\n",
      "Train Epoch: 3 [35712/60000 (60%)]\tLoss: 1.205280\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 1.258844\n",
      "Train Epoch: 3 [35968/60000 (60%)]\tLoss: 1.456295\n",
      "Train Epoch: 3 [36096/60000 (60%)]\tLoss: 1.319268\n",
      "Train Epoch: 3 [36224/60000 (60%)]\tLoss: 1.256676\n",
      "Train Epoch: 3 [36352/60000 (61%)]\tLoss: 1.357022\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 1.287446\n",
      "Train Epoch: 3 [36608/60000 (61%)]\tLoss: 1.253179\n",
      "Train Epoch: 3 [36736/60000 (61%)]\tLoss: 1.283235\n",
      "Train Epoch: 3 [36864/60000 (62%)]\tLoss: 1.239379\n",
      "Train Epoch: 3 [36992/60000 (62%)]\tLoss: 1.353029\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 1.339184\n",
      "Train Epoch: 3 [37248/60000 (62%)]\tLoss: 1.535001\n",
      "Train Epoch: 3 [37376/60000 (62%)]\tLoss: 1.525712\n",
      "Train Epoch: 3 [37504/60000 (63%)]\tLoss: 1.363027\n",
      "Train Epoch: 3 [37632/60000 (63%)]\tLoss: 1.215558\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 1.404824\n",
      "Train Epoch: 3 [37888/60000 (63%)]\tLoss: 1.266701\n",
      "Train Epoch: 3 [38016/60000 (63%)]\tLoss: 1.248746\n",
      "Train Epoch: 3 [38144/60000 (64%)]\tLoss: 1.259671\n",
      "Train Epoch: 3 [38272/60000 (64%)]\tLoss: 1.275063\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.306805\n",
      "Train Epoch: 3 [38528/60000 (64%)]\tLoss: 1.439255\n",
      "Train Epoch: 3 [38656/60000 (65%)]\tLoss: 1.243597\n",
      "Train Epoch: 3 [38784/60000 (65%)]\tLoss: 1.383307\n",
      "Train Epoch: 3 [38912/60000 (65%)]\tLoss: 1.284607\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 1.380965\n",
      "Train Epoch: 3 [39168/60000 (65%)]\tLoss: 1.281512\n",
      "Train Epoch: 3 [39296/60000 (66%)]\tLoss: 1.523193\n",
      "Train Epoch: 3 [39424/60000 (66%)]\tLoss: 1.508397\n",
      "Train Epoch: 3 [39552/60000 (66%)]\tLoss: 1.283402\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 1.414650\n",
      "Train Epoch: 3 [39808/60000 (66%)]\tLoss: 1.365203\n",
      "Train Epoch: 3 [39936/60000 (67%)]\tLoss: 1.377335\n",
      "Train Epoch: 3 [40064/60000 (67%)]\tLoss: 1.303067\n",
      "Train Epoch: 3 [40192/60000 (67%)]\tLoss: 1.308764\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 1.317130\n",
      "Train Epoch: 3 [40448/60000 (68%)]\tLoss: 1.322000\n",
      "Train Epoch: 3 [40576/60000 (68%)]\tLoss: 1.402540\n",
      "Train Epoch: 3 [40704/60000 (68%)]\tLoss: 1.371554\n",
      "Train Epoch: 3 [40832/60000 (68%)]\tLoss: 1.193631\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 1.311321\n",
      "Train Epoch: 3 [41088/60000 (69%)]\tLoss: 1.284806\n",
      "Train Epoch: 3 [41216/60000 (69%)]\tLoss: 1.429355\n",
      "Train Epoch: 3 [41344/60000 (69%)]\tLoss: 1.414222\n",
      "Train Epoch: 3 [41472/60000 (69%)]\tLoss: 1.484021\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 1.346727\n",
      "Train Epoch: 3 [41728/60000 (70%)]\tLoss: 1.339201\n",
      "Train Epoch: 3 [41856/60000 (70%)]\tLoss: 1.218240\n",
      "Train Epoch: 3 [41984/60000 (70%)]\tLoss: 1.402662\n",
      "Train Epoch: 3 [42112/60000 (70%)]\tLoss: 1.478153\n",
      "Train Epoch: 3 [42240/60000 (71%)]\tLoss: 1.532837\n",
      "Train Epoch: 3 [42368/60000 (71%)]\tLoss: 1.412620\n",
      "Train Epoch: 3 [42496/60000 (71%)]\tLoss: 1.455232\n",
      "Train Epoch: 3 [42624/60000 (71%)]\tLoss: 1.300773\n",
      "Train Epoch: 3 [42752/60000 (71%)]\tLoss: 1.312658\n",
      "Train Epoch: 3 [42880/60000 (72%)]\tLoss: 1.397677\n",
      "Train Epoch: 3 [43008/60000 (72%)]\tLoss: 1.478809\n",
      "Train Epoch: 3 [43136/60000 (72%)]\tLoss: 1.355705\n",
      "Train Epoch: 3 [43264/60000 (72%)]\tLoss: 1.185201\n",
      "Train Epoch: 3 [43392/60000 (72%)]\tLoss: 1.191427\n",
      "Train Epoch: 3 [43520/60000 (73%)]\tLoss: 1.197216\n",
      "Train Epoch: 3 [43648/60000 (73%)]\tLoss: 1.287801\n",
      "Train Epoch: 3 [43776/60000 (73%)]\tLoss: 1.272519\n",
      "Train Epoch: 3 [43904/60000 (73%)]\tLoss: 1.365428\n",
      "Train Epoch: 3 [44032/60000 (74%)]\tLoss: 1.393176\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 1.351311\n",
      "Train Epoch: 3 [44288/60000 (74%)]\tLoss: 1.426365\n",
      "Train Epoch: 3 [44416/60000 (74%)]\tLoss: 1.304059\n",
      "Train Epoch: 3 [44544/60000 (74%)]\tLoss: 1.175389\n",
      "Train Epoch: 3 [44672/60000 (75%)]\tLoss: 1.318445\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.381616\n",
      "Train Epoch: 3 [44928/60000 (75%)]\tLoss: 1.401920\n",
      "Train Epoch: 3 [45056/60000 (75%)]\tLoss: 1.349866\n",
      "Train Epoch: 3 [45184/60000 (75%)]\tLoss: 1.298540\n",
      "Train Epoch: 3 [45312/60000 (76%)]\tLoss: 1.270683\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 1.343691\n",
      "Train Epoch: 3 [45568/60000 (76%)]\tLoss: 1.206762\n",
      "Train Epoch: 3 [45696/60000 (76%)]\tLoss: 1.218417\n",
      "Train Epoch: 3 [45824/60000 (76%)]\tLoss: 1.391616\n",
      "Train Epoch: 3 [45952/60000 (77%)]\tLoss: 1.387313\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 1.316705\n",
      "Train Epoch: 3 [46208/60000 (77%)]\tLoss: 1.326678\n",
      "Train Epoch: 3 [46336/60000 (77%)]\tLoss: 1.428115\n",
      "Train Epoch: 3 [46464/60000 (78%)]\tLoss: 1.168561\n",
      "Train Epoch: 3 [46592/60000 (78%)]\tLoss: 1.297517\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 1.333453\n",
      "Train Epoch: 3 [46848/60000 (78%)]\tLoss: 1.258292\n",
      "Train Epoch: 3 [46976/60000 (78%)]\tLoss: 1.237159\n",
      "Train Epoch: 3 [47104/60000 (79%)]\tLoss: 1.227621\n",
      "Train Epoch: 3 [47232/60000 (79%)]\tLoss: 1.372488\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 1.441919\n",
      "Train Epoch: 3 [47488/60000 (79%)]\tLoss: 1.487821\n",
      "Train Epoch: 3 [47616/60000 (79%)]\tLoss: 1.304564\n",
      "Train Epoch: 3 [47744/60000 (80%)]\tLoss: 1.186983\n",
      "Train Epoch: 3 [47872/60000 (80%)]\tLoss: 1.422585\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.256871\n",
      "Train Epoch: 3 [48128/60000 (80%)]\tLoss: 1.196130\n",
      "Train Epoch: 3 [48256/60000 (81%)]\tLoss: 1.310963\n",
      "Train Epoch: 3 [48384/60000 (81%)]\tLoss: 1.192205\n",
      "Train Epoch: 3 [48512/60000 (81%)]\tLoss: 1.276969\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 1.238629\n",
      "Train Epoch: 3 [48768/60000 (81%)]\tLoss: 1.207011\n",
      "Train Epoch: 3 [48896/60000 (82%)]\tLoss: 1.512110\n",
      "Train Epoch: 3 [49024/60000 (82%)]\tLoss: 1.396342\n",
      "Train Epoch: 3 [49152/60000 (82%)]\tLoss: 1.443902\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 1.117319\n",
      "Train Epoch: 3 [49408/60000 (82%)]\tLoss: 1.475649\n",
      "Train Epoch: 3 [49536/60000 (83%)]\tLoss: 1.477296\n",
      "Train Epoch: 3 [49664/60000 (83%)]\tLoss: 1.271417\n",
      "Train Epoch: 3 [49792/60000 (83%)]\tLoss: 1.298540\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 1.306011\n",
      "Train Epoch: 3 [50048/60000 (84%)]\tLoss: 1.251829\n",
      "Train Epoch: 3 [50176/60000 (84%)]\tLoss: 1.290288\n",
      "Train Epoch: 3 [50304/60000 (84%)]\tLoss: 1.525593\n",
      "Train Epoch: 3 [50432/60000 (84%)]\tLoss: 1.238616\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 1.289062\n",
      "Train Epoch: 3 [50688/60000 (85%)]\tLoss: 1.318000\n",
      "Train Epoch: 3 [50816/60000 (85%)]\tLoss: 1.216894\n",
      "Train Epoch: 3 [50944/60000 (85%)]\tLoss: 1.177551\n",
      "Train Epoch: 3 [51072/60000 (85%)]\tLoss: 1.346563\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.480614\n",
      "Train Epoch: 3 [51328/60000 (86%)]\tLoss: 1.193761\n",
      "Train Epoch: 3 [51456/60000 (86%)]\tLoss: 1.097290\n",
      "Train Epoch: 3 [51584/60000 (86%)]\tLoss: 1.251167\n",
      "Train Epoch: 3 [51712/60000 (86%)]\tLoss: 1.312582\n",
      "Train Epoch: 3 [51840/60000 (87%)]\tLoss: 1.293483\n",
      "Train Epoch: 3 [51968/60000 (87%)]\tLoss: 1.457830\n",
      "Train Epoch: 3 [52096/60000 (87%)]\tLoss: 1.465033\n",
      "Train Epoch: 3 [52224/60000 (87%)]\tLoss: 1.253617\n",
      "Train Epoch: 3 [52352/60000 (87%)]\tLoss: 1.114980\n",
      "Train Epoch: 3 [52480/60000 (88%)]\tLoss: 1.051763\n",
      "Train Epoch: 3 [52608/60000 (88%)]\tLoss: 1.399659\n",
      "Train Epoch: 3 [52736/60000 (88%)]\tLoss: 1.470330\n",
      "Train Epoch: 3 [52864/60000 (88%)]\tLoss: 1.442160\n",
      "Train Epoch: 3 [52992/60000 (88%)]\tLoss: 1.281985\n",
      "Train Epoch: 3 [53120/60000 (89%)]\tLoss: 1.308561\n",
      "Train Epoch: 3 [53248/60000 (89%)]\tLoss: 1.283731\n",
      "Train Epoch: 3 [53376/60000 (89%)]\tLoss: 1.237472\n",
      "Train Epoch: 3 [53504/60000 (89%)]\tLoss: 1.348151\n",
      "Train Epoch: 3 [53632/60000 (90%)]\tLoss: 1.280462\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 1.159038\n",
      "Train Epoch: 3 [53888/60000 (90%)]\tLoss: 1.323132\n",
      "Train Epoch: 3 [54016/60000 (90%)]\tLoss: 1.335619\n",
      "Train Epoch: 3 [54144/60000 (90%)]\tLoss: 1.154303\n",
      "Train Epoch: 3 [54272/60000 (91%)]\tLoss: 1.288624\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 1.118999\n",
      "Train Epoch: 3 [54528/60000 (91%)]\tLoss: 1.277657\n",
      "Train Epoch: 3 [54656/60000 (91%)]\tLoss: 1.220930\n",
      "Train Epoch: 3 [54784/60000 (91%)]\tLoss: 1.356417\n",
      "Train Epoch: 3 [54912/60000 (92%)]\tLoss: 1.331483\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 1.193832\n",
      "Train Epoch: 3 [55168/60000 (92%)]\tLoss: 1.172530\n",
      "Train Epoch: 3 [55296/60000 (92%)]\tLoss: 1.264311\n",
      "Train Epoch: 3 [55424/60000 (93%)]\tLoss: 1.258071\n",
      "Train Epoch: 3 [55552/60000 (93%)]\tLoss: 1.238486\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 1.150635\n",
      "Train Epoch: 3 [55808/60000 (93%)]\tLoss: 1.086091\n",
      "Train Epoch: 3 [55936/60000 (93%)]\tLoss: 1.198296\n",
      "Train Epoch: 3 [56064/60000 (94%)]\tLoss: 1.226654\n",
      "Train Epoch: 3 [56192/60000 (94%)]\tLoss: 1.293981\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 1.165542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [56448/60000 (94%)]\tLoss: 1.310464\n",
      "Train Epoch: 3 [56576/60000 (94%)]\tLoss: 1.335332\n",
      "Train Epoch: 3 [56704/60000 (95%)]\tLoss: 1.169059\n",
      "Train Epoch: 3 [56832/60000 (95%)]\tLoss: 1.193006\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 1.278722\n",
      "Train Epoch: 3 [57088/60000 (95%)]\tLoss: 1.240184\n",
      "Train Epoch: 3 [57216/60000 (96%)]\tLoss: 1.482271\n",
      "Train Epoch: 3 [57344/60000 (96%)]\tLoss: 1.231536\n",
      "Train Epoch: 3 [57472/60000 (96%)]\tLoss: 1.139239\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.426372\n",
      "Train Epoch: 3 [57728/60000 (96%)]\tLoss: 1.376134\n",
      "Train Epoch: 3 [57856/60000 (97%)]\tLoss: 1.162246\n",
      "Train Epoch: 3 [57984/60000 (97%)]\tLoss: 1.242147\n",
      "Train Epoch: 3 [58112/60000 (97%)]\tLoss: 1.054925\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 1.056360\n",
      "Train Epoch: 3 [58368/60000 (97%)]\tLoss: 1.191705\n",
      "Train Epoch: 3 [58496/60000 (98%)]\tLoss: 1.085744\n",
      "Train Epoch: 3 [58624/60000 (98%)]\tLoss: 1.119882\n",
      "Train Epoch: 3 [58752/60000 (98%)]\tLoss: 1.273721\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 1.020870\n",
      "Train Epoch: 3 [59008/60000 (99%)]\tLoss: 1.047795\n",
      "Train Epoch: 3 [59136/60000 (99%)]\tLoss: 1.126836\n",
      "Train Epoch: 3 [59264/60000 (99%)]\tLoss: 1.255701\n",
      "Train Epoch: 3 [59392/60000 (99%)]\tLoss: 1.091674\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 1.088379\n",
      "Train Epoch: 3 [59648/60000 (100%)]\tLoss: 1.325401\n",
      "Train Epoch: 3 [59776/60000 (100%)]\tLoss: 1.134108\n",
      "================================================================\n",
      "Training: Average loss: 0.6414, Accuracy: 51935/60000 (87%)\n",
      "Test: Average loss: 0.6192, Accuracy: 8759/10000 (88%)\n",
      "================================================================\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.190070\n",
      "Train Epoch: 4 [128/60000 (0%)]\tLoss: 1.279266\n",
      "Train Epoch: 4 [256/60000 (0%)]\tLoss: 1.119939\n",
      "Train Epoch: 4 [384/60000 (1%)]\tLoss: 1.280869\n",
      "Train Epoch: 4 [512/60000 (1%)]\tLoss: 1.293295\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 1.237784\n",
      "Train Epoch: 4 [768/60000 (1%)]\tLoss: 1.339541\n",
      "Train Epoch: 4 [896/60000 (1%)]\tLoss: 1.485203\n",
      "Train Epoch: 4 [1024/60000 (2%)]\tLoss: 1.484199\n",
      "Train Epoch: 4 [1152/60000 (2%)]\tLoss: 1.301369\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 1.395715\n",
      "Train Epoch: 4 [1408/60000 (2%)]\tLoss: 1.239473\n",
      "Train Epoch: 4 [1536/60000 (3%)]\tLoss: 1.347831\n",
      "Train Epoch: 4 [1664/60000 (3%)]\tLoss: 1.202298\n",
      "Train Epoch: 4 [1792/60000 (3%)]\tLoss: 1.153746\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 1.183127\n",
      "Train Epoch: 4 [2048/60000 (3%)]\tLoss: 1.185673\n",
      "Train Epoch: 4 [2176/60000 (4%)]\tLoss: 1.262347\n",
      "Train Epoch: 4 [2304/60000 (4%)]\tLoss: 1.286267\n",
      "Train Epoch: 4 [2432/60000 (4%)]\tLoss: 1.190308\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 1.249341\n",
      "Train Epoch: 4 [2688/60000 (4%)]\tLoss: 1.183707\n",
      "Train Epoch: 4 [2816/60000 (5%)]\tLoss: 1.275946\n",
      "Train Epoch: 4 [2944/60000 (5%)]\tLoss: 1.280869\n",
      "Train Epoch: 4 [3072/60000 (5%)]\tLoss: 1.220229\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 1.096233\n",
      "Train Epoch: 4 [3328/60000 (6%)]\tLoss: 1.338140\n",
      "Train Epoch: 4 [3456/60000 (6%)]\tLoss: 1.302297\n",
      "Train Epoch: 4 [3584/60000 (6%)]\tLoss: 1.286709\n",
      "Train Epoch: 4 [3712/60000 (6%)]\tLoss: 1.338341\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 1.156081\n",
      "Train Epoch: 4 [3968/60000 (7%)]\tLoss: 1.314683\n",
      "Train Epoch: 4 [4096/60000 (7%)]\tLoss: 1.218928\n",
      "Train Epoch: 4 [4224/60000 (7%)]\tLoss: 1.141385\n",
      "Train Epoch: 4 [4352/60000 (7%)]\tLoss: 1.221119\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 1.083752\n",
      "Train Epoch: 4 [4608/60000 (8%)]\tLoss: 1.280822\n",
      "Train Epoch: 4 [4736/60000 (8%)]\tLoss: 1.321157\n",
      "Train Epoch: 4 [4864/60000 (8%)]\tLoss: 1.229870\n",
      "Train Epoch: 4 [4992/60000 (8%)]\tLoss: 1.346800\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 1.367676\n",
      "Train Epoch: 4 [5248/60000 (9%)]\tLoss: 1.282451\n",
      "Train Epoch: 4 [5376/60000 (9%)]\tLoss: 1.146840\n",
      "Train Epoch: 4 [5504/60000 (9%)]\tLoss: 1.292372\n",
      "Train Epoch: 4 [5632/60000 (9%)]\tLoss: 1.188678\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 1.248357\n",
      "Train Epoch: 4 [5888/60000 (10%)]\tLoss: 1.146625\n",
      "Train Epoch: 4 [6016/60000 (10%)]\tLoss: 1.091214\n",
      "Train Epoch: 4 [6144/60000 (10%)]\tLoss: 1.247228\n",
      "Train Epoch: 4 [6272/60000 (10%)]\tLoss: 1.150706\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 1.104652\n",
      "Train Epoch: 4 [6528/60000 (11%)]\tLoss: 1.012193\n",
      "Train Epoch: 4 [6656/60000 (11%)]\tLoss: 1.214670\n",
      "Train Epoch: 4 [6784/60000 (11%)]\tLoss: 1.368177\n",
      "Train Epoch: 4 [6912/60000 (12%)]\tLoss: 1.179641\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 1.210556\n",
      "Train Epoch: 4 [7168/60000 (12%)]\tLoss: 1.405629\n",
      "Train Epoch: 4 [7296/60000 (12%)]\tLoss: 1.321560\n",
      "Train Epoch: 4 [7424/60000 (12%)]\tLoss: 1.235628\n",
      "Train Epoch: 4 [7552/60000 (13%)]\tLoss: 1.271182\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 1.190150\n",
      "Train Epoch: 4 [7808/60000 (13%)]\tLoss: 1.446896\n",
      "Train Epoch: 4 [7936/60000 (13%)]\tLoss: 1.254692\n",
      "Train Epoch: 4 [8064/60000 (13%)]\tLoss: 1.087638\n",
      "Train Epoch: 4 [8192/60000 (14%)]\tLoss: 1.412875\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 1.276196\n",
      "Train Epoch: 4 [8448/60000 (14%)]\tLoss: 1.184355\n",
      "Train Epoch: 4 [8576/60000 (14%)]\tLoss: 1.394558\n",
      "Train Epoch: 4 [8704/60000 (15%)]\tLoss: 1.346555\n",
      "Train Epoch: 4 [8832/60000 (15%)]\tLoss: 1.365080\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 1.089564\n",
      "Train Epoch: 4 [9088/60000 (15%)]\tLoss: 1.233865\n",
      "Train Epoch: 4 [9216/60000 (15%)]\tLoss: 1.197392\n",
      "Train Epoch: 4 [9344/60000 (16%)]\tLoss: 1.221223\n",
      "Train Epoch: 4 [9472/60000 (16%)]\tLoss: 1.152032\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 1.087020\n",
      "Train Epoch: 4 [9728/60000 (16%)]\tLoss: 1.161859\n",
      "Train Epoch: 4 [9856/60000 (16%)]\tLoss: 1.095516\n",
      "Train Epoch: 4 [9984/60000 (17%)]\tLoss: 1.208225\n",
      "Train Epoch: 4 [10112/60000 (17%)]\tLoss: 1.171463\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 1.147729\n",
      "Train Epoch: 4 [10368/60000 (17%)]\tLoss: 1.129995\n",
      "Train Epoch: 4 [10496/60000 (18%)]\tLoss: 1.134955\n",
      "Train Epoch: 4 [10624/60000 (18%)]\tLoss: 1.170306\n",
      "Train Epoch: 4 [10752/60000 (18%)]\tLoss: 1.217577\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 1.276228\n",
      "Train Epoch: 4 [11008/60000 (18%)]\tLoss: 1.232653\n",
      "Train Epoch: 4 [11136/60000 (19%)]\tLoss: 1.232707\n",
      "Train Epoch: 4 [11264/60000 (19%)]\tLoss: 1.079853\n",
      "Train Epoch: 4 [11392/60000 (19%)]\tLoss: 1.014501\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 1.433056\n",
      "Train Epoch: 4 [11648/60000 (19%)]\tLoss: 1.389103\n",
      "Train Epoch: 4 [11776/60000 (20%)]\tLoss: 1.302592\n",
      "Train Epoch: 4 [11904/60000 (20%)]\tLoss: 1.278560\n",
      "Train Epoch: 4 [12032/60000 (20%)]\tLoss: 1.234699\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 1.273311\n",
      "Train Epoch: 4 [12288/60000 (21%)]\tLoss: 1.326910\n",
      "Train Epoch: 4 [12416/60000 (21%)]\tLoss: 1.360878\n",
      "Train Epoch: 4 [12544/60000 (21%)]\tLoss: 1.384688\n",
      "Train Epoch: 4 [12672/60000 (21%)]\tLoss: 1.147811\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.151294\n",
      "Train Epoch: 4 [12928/60000 (22%)]\tLoss: 1.478779\n",
      "Train Epoch: 4 [13056/60000 (22%)]\tLoss: 1.360507\n",
      "Train Epoch: 4 [13184/60000 (22%)]\tLoss: 1.126778\n",
      "Train Epoch: 4 [13312/60000 (22%)]\tLoss: 1.318108\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 1.145709\n",
      "Train Epoch: 4 [13568/60000 (23%)]\tLoss: 1.227220\n",
      "Train Epoch: 4 [13696/60000 (23%)]\tLoss: 1.301883\n",
      "Train Epoch: 4 [13824/60000 (23%)]\tLoss: 1.173312\n",
      "Train Epoch: 4 [13952/60000 (23%)]\tLoss: 1.330003\n",
      "Train Epoch: 4 [14080/60000 (24%)]\tLoss: 1.209578\n",
      "Train Epoch: 4 [14208/60000 (24%)]\tLoss: 1.410368\n",
      "Train Epoch: 4 [14336/60000 (24%)]\tLoss: 1.477160\n",
      "Train Epoch: 4 [14464/60000 (24%)]\tLoss: 1.331328\n",
      "Train Epoch: 4 [14592/60000 (24%)]\tLoss: 1.341014\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 1.399961\n",
      "Train Epoch: 4 [14848/60000 (25%)]\tLoss: 1.133025\n",
      "Train Epoch: 4 [14976/60000 (25%)]\tLoss: 1.081511\n",
      "Train Epoch: 4 [15104/60000 (25%)]\tLoss: 1.278987\n",
      "Train Epoch: 4 [15232/60000 (25%)]\tLoss: 1.217141\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 1.138374\n",
      "Train Epoch: 4 [15488/60000 (26%)]\tLoss: 1.085396\n",
      "Train Epoch: 4 [15616/60000 (26%)]\tLoss: 1.271071\n",
      "Train Epoch: 4 [15744/60000 (26%)]\tLoss: 1.398769\n",
      "Train Epoch: 4 [15872/60000 (26%)]\tLoss: 1.341484\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.306223\n",
      "Train Epoch: 4 [16128/60000 (27%)]\tLoss: 1.211635\n",
      "Train Epoch: 4 [16256/60000 (27%)]\tLoss: 1.088295\n",
      "Train Epoch: 4 [16384/60000 (27%)]\tLoss: 1.224540\n",
      "Train Epoch: 4 [16512/60000 (28%)]\tLoss: 1.137360\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 1.266795\n",
      "Train Epoch: 4 [16768/60000 (28%)]\tLoss: 1.416181\n",
      "Train Epoch: 4 [16896/60000 (28%)]\tLoss: 1.359970\n",
      "Train Epoch: 4 [17024/60000 (28%)]\tLoss: 1.160191\n",
      "Train Epoch: 4 [17152/60000 (29%)]\tLoss: 1.279833\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 1.129499\n",
      "Train Epoch: 4 [17408/60000 (29%)]\tLoss: 1.172760\n",
      "Train Epoch: 4 [17536/60000 (29%)]\tLoss: 1.421800\n",
      "Train Epoch: 4 [17664/60000 (29%)]\tLoss: 1.317659\n",
      "Train Epoch: 4 [17792/60000 (30%)]\tLoss: 1.293574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 1.207654\n",
      "Train Epoch: 4 [18048/60000 (30%)]\tLoss: 1.132084\n",
      "Train Epoch: 4 [18176/60000 (30%)]\tLoss: 1.096261\n",
      "Train Epoch: 4 [18304/60000 (31%)]\tLoss: 1.268672\n",
      "Train Epoch: 4 [18432/60000 (31%)]\tLoss: 1.197523\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 1.302903\n",
      "Train Epoch: 4 [18688/60000 (31%)]\tLoss: 1.152578\n",
      "Train Epoch: 4 [18816/60000 (31%)]\tLoss: 1.170304\n",
      "Train Epoch: 4 [18944/60000 (32%)]\tLoss: 1.306533\n",
      "Train Epoch: 4 [19072/60000 (32%)]\tLoss: 1.338907\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 1.180876\n",
      "Train Epoch: 4 [19328/60000 (32%)]\tLoss: 1.314431\n",
      "Train Epoch: 4 [19456/60000 (32%)]\tLoss: 1.279646\n",
      "Train Epoch: 4 [19584/60000 (33%)]\tLoss: 1.093232\n",
      "Train Epoch: 4 [19712/60000 (33%)]\tLoss: 1.011479\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 1.249761\n",
      "Train Epoch: 4 [19968/60000 (33%)]\tLoss: 1.309470\n",
      "Train Epoch: 4 [20096/60000 (34%)]\tLoss: 1.406680\n",
      "Train Epoch: 4 [20224/60000 (34%)]\tLoss: 1.209715\n",
      "Train Epoch: 4 [20352/60000 (34%)]\tLoss: 1.112756\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 1.145663\n",
      "Train Epoch: 4 [20608/60000 (34%)]\tLoss: 1.212629\n",
      "Train Epoch: 4 [20736/60000 (35%)]\tLoss: 1.248071\n",
      "Train Epoch: 4 [20864/60000 (35%)]\tLoss: 1.412333\n",
      "Train Epoch: 4 [20992/60000 (35%)]\tLoss: 1.312078\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 1.105315\n",
      "Train Epoch: 4 [21248/60000 (35%)]\tLoss: 1.147816\n",
      "Train Epoch: 4 [21376/60000 (36%)]\tLoss: 1.119985\n",
      "Train Epoch: 4 [21504/60000 (36%)]\tLoss: 1.065364\n",
      "Train Epoch: 4 [21632/60000 (36%)]\tLoss: 1.373716\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 1.005160\n",
      "Train Epoch: 4 [21888/60000 (37%)]\tLoss: 1.060884\n",
      "Train Epoch: 4 [22016/60000 (37%)]\tLoss: 1.217480\n",
      "Train Epoch: 4 [22144/60000 (37%)]\tLoss: 1.275847\n",
      "Train Epoch: 4 [22272/60000 (37%)]\tLoss: 1.147639\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 1.428293\n",
      "Train Epoch: 4 [22528/60000 (38%)]\tLoss: 1.420090\n",
      "Train Epoch: 4 [22656/60000 (38%)]\tLoss: 1.234691\n",
      "Train Epoch: 4 [22784/60000 (38%)]\tLoss: 1.174580\n",
      "Train Epoch: 4 [22912/60000 (38%)]\tLoss: 1.169247\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 1.252732\n",
      "Train Epoch: 4 [23168/60000 (39%)]\tLoss: 1.175147\n",
      "Train Epoch: 4 [23296/60000 (39%)]\tLoss: 1.103704\n",
      "Train Epoch: 4 [23424/60000 (39%)]\tLoss: 1.193373\n",
      "Train Epoch: 4 [23552/60000 (39%)]\tLoss: 1.175086\n",
      "Train Epoch: 4 [23680/60000 (40%)]\tLoss: 1.241359\n",
      "Train Epoch: 4 [23808/60000 (40%)]\tLoss: 1.240931\n",
      "Train Epoch: 4 [23936/60000 (40%)]\tLoss: 1.273572\n",
      "Train Epoch: 4 [24064/60000 (40%)]\tLoss: 1.216120\n",
      "Train Epoch: 4 [24192/60000 (40%)]\tLoss: 1.249317\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 1.170467\n",
      "Train Epoch: 4 [24448/60000 (41%)]\tLoss: 1.240222\n",
      "Train Epoch: 4 [24576/60000 (41%)]\tLoss: 1.399993\n",
      "Train Epoch: 4 [24704/60000 (41%)]\tLoss: 1.482194\n",
      "Train Epoch: 4 [24832/60000 (41%)]\tLoss: 1.309294\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 1.151063\n",
      "Train Epoch: 4 [25088/60000 (42%)]\tLoss: 1.144822\n",
      "Train Epoch: 4 [25216/60000 (42%)]\tLoss: 1.348822\n",
      "Train Epoch: 4 [25344/60000 (42%)]\tLoss: 1.014599\n",
      "Train Epoch: 4 [25472/60000 (43%)]\tLoss: 1.011120\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.223237\n",
      "Train Epoch: 4 [25728/60000 (43%)]\tLoss: 1.190504\n",
      "Train Epoch: 4 [25856/60000 (43%)]\tLoss: 1.197312\n",
      "Train Epoch: 4 [25984/60000 (43%)]\tLoss: 1.034378\n",
      "Train Epoch: 4 [26112/60000 (44%)]\tLoss: 1.143431\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 1.169244\n",
      "Train Epoch: 4 [26368/60000 (44%)]\tLoss: 1.315694\n",
      "Train Epoch: 4 [26496/60000 (44%)]\tLoss: 1.321826\n",
      "Train Epoch: 4 [26624/60000 (44%)]\tLoss: 1.344954\n",
      "Train Epoch: 4 [26752/60000 (45%)]\tLoss: 1.172732\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 1.259099\n",
      "Train Epoch: 4 [27008/60000 (45%)]\tLoss: 1.176624\n",
      "Train Epoch: 4 [27136/60000 (45%)]\tLoss: 1.502766\n",
      "Train Epoch: 4 [27264/60000 (46%)]\tLoss: 1.187552\n",
      "Train Epoch: 4 [27392/60000 (46%)]\tLoss: 1.238915\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 1.292972\n",
      "Train Epoch: 4 [27648/60000 (46%)]\tLoss: 1.145106\n",
      "Train Epoch: 4 [27776/60000 (46%)]\tLoss: 1.114696\n",
      "Train Epoch: 4 [27904/60000 (47%)]\tLoss: 1.103855\n",
      "Train Epoch: 4 [28032/60000 (47%)]\tLoss: 0.968668\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 1.249409\n",
      "Train Epoch: 4 [28288/60000 (47%)]\tLoss: 1.219123\n",
      "Train Epoch: 4 [28416/60000 (47%)]\tLoss: 1.220104\n",
      "Train Epoch: 4 [28544/60000 (48%)]\tLoss: 1.159756\n",
      "Train Epoch: 4 [28672/60000 (48%)]\tLoss: 1.239822\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 1.225604\n",
      "Train Epoch: 4 [28928/60000 (48%)]\tLoss: 1.229410\n",
      "Train Epoch: 4 [29056/60000 (49%)]\tLoss: 1.436774\n",
      "Train Epoch: 4 [29184/60000 (49%)]\tLoss: 1.215310\n",
      "Train Epoch: 4 [29312/60000 (49%)]\tLoss: 1.203140\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 1.027252\n",
      "Train Epoch: 4 [29568/60000 (49%)]\tLoss: 1.154795\n",
      "Train Epoch: 4 [29696/60000 (50%)]\tLoss: 1.319763\n",
      "Train Epoch: 4 [29824/60000 (50%)]\tLoss: 1.361165\n",
      "Train Epoch: 4 [29952/60000 (50%)]\tLoss: 1.282644\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 1.313286\n",
      "Train Epoch: 4 [30208/60000 (50%)]\tLoss: 1.221361\n",
      "Train Epoch: 4 [30336/60000 (51%)]\tLoss: 1.200964\n",
      "Train Epoch: 4 [30464/60000 (51%)]\tLoss: 1.245884\n",
      "Train Epoch: 4 [30592/60000 (51%)]\tLoss: 1.261685\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 1.215868\n",
      "Train Epoch: 4 [30848/60000 (51%)]\tLoss: 1.215061\n",
      "Train Epoch: 4 [30976/60000 (52%)]\tLoss: 1.125221\n",
      "Train Epoch: 4 [31104/60000 (52%)]\tLoss: 1.061421\n",
      "Train Epoch: 4 [31232/60000 (52%)]\tLoss: 1.348490\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 1.302935\n",
      "Train Epoch: 4 [31488/60000 (53%)]\tLoss: 1.188126\n",
      "Train Epoch: 4 [31616/60000 (53%)]\tLoss: 1.477159\n",
      "Train Epoch: 4 [31744/60000 (53%)]\tLoss: 1.182438\n",
      "Train Epoch: 4 [31872/60000 (53%)]\tLoss: 1.141497\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.216744\n",
      "Train Epoch: 4 [32128/60000 (54%)]\tLoss: 1.355267\n",
      "Train Epoch: 4 [32256/60000 (54%)]\tLoss: 1.434236\n",
      "Train Epoch: 4 [32384/60000 (54%)]\tLoss: 1.396458\n",
      "Train Epoch: 4 [32512/60000 (54%)]\tLoss: 1.077739\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 1.162232\n",
      "Train Epoch: 4 [32768/60000 (55%)]\tLoss: 1.149714\n",
      "Train Epoch: 4 [32896/60000 (55%)]\tLoss: 1.237149\n",
      "Train Epoch: 4 [33024/60000 (55%)]\tLoss: 1.316193\n",
      "Train Epoch: 4 [33152/60000 (55%)]\tLoss: 1.237276\n",
      "Train Epoch: 4 [33280/60000 (56%)]\tLoss: 1.265730\n",
      "Train Epoch: 4 [33408/60000 (56%)]\tLoss: 1.187510\n",
      "Train Epoch: 4 [33536/60000 (56%)]\tLoss: 1.059007\n",
      "Train Epoch: 4 [33664/60000 (56%)]\tLoss: 1.117642\n",
      "Train Epoch: 4 [33792/60000 (56%)]\tLoss: 0.984533\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 1.100834\n",
      "Train Epoch: 4 [34048/60000 (57%)]\tLoss: 1.144794\n",
      "Train Epoch: 4 [34176/60000 (57%)]\tLoss: 1.145869\n",
      "Train Epoch: 4 [34304/60000 (57%)]\tLoss: 1.056136\n",
      "Train Epoch: 4 [34432/60000 (57%)]\tLoss: 1.178395\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 1.240182\n",
      "Train Epoch: 4 [34688/60000 (58%)]\tLoss: 1.365016\n",
      "Train Epoch: 4 [34816/60000 (58%)]\tLoss: 1.285467\n",
      "Train Epoch: 4 [34944/60000 (58%)]\tLoss: 1.018611\n",
      "Train Epoch: 4 [35072/60000 (59%)]\tLoss: 1.125259\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 1.273345\n",
      "Train Epoch: 4 [35328/60000 (59%)]\tLoss: 1.087144\n",
      "Train Epoch: 4 [35456/60000 (59%)]\tLoss: 1.140023\n",
      "Train Epoch: 4 [35584/60000 (59%)]\tLoss: 1.201645\n",
      "Train Epoch: 4 [35712/60000 (60%)]\tLoss: 1.169329\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 1.196835\n",
      "Train Epoch: 4 [35968/60000 (60%)]\tLoss: 1.321149\n",
      "Train Epoch: 4 [36096/60000 (60%)]\tLoss: 1.080438\n",
      "Train Epoch: 4 [36224/60000 (60%)]\tLoss: 1.029762\n",
      "Train Epoch: 4 [36352/60000 (61%)]\tLoss: 1.249833\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 1.194926\n",
      "Train Epoch: 4 [36608/60000 (61%)]\tLoss: 1.107435\n",
      "Train Epoch: 4 [36736/60000 (61%)]\tLoss: 1.179216\n",
      "Train Epoch: 4 [36864/60000 (62%)]\tLoss: 1.110254\n",
      "Train Epoch: 4 [36992/60000 (62%)]\tLoss: 1.255572\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 1.137069\n",
      "Train Epoch: 4 [37248/60000 (62%)]\tLoss: 1.362349\n",
      "Train Epoch: 4 [37376/60000 (62%)]\tLoss: 1.405177\n",
      "Train Epoch: 4 [37504/60000 (63%)]\tLoss: 1.219332\n",
      "Train Epoch: 4 [37632/60000 (63%)]\tLoss: 1.166099\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 1.287014\n",
      "Train Epoch: 4 [37888/60000 (63%)]\tLoss: 1.196255\n",
      "Train Epoch: 4 [38016/60000 (63%)]\tLoss: 1.096530\n",
      "Train Epoch: 4 [38144/60000 (64%)]\tLoss: 1.256178\n",
      "Train Epoch: 4 [38272/60000 (64%)]\tLoss: 1.235625\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.085011\n",
      "Train Epoch: 4 [38528/60000 (64%)]\tLoss: 1.288616\n",
      "Train Epoch: 4 [38656/60000 (65%)]\tLoss: 1.079179\n",
      "Train Epoch: 4 [38784/60000 (65%)]\tLoss: 1.052713\n",
      "Train Epoch: 4 [38912/60000 (65%)]\tLoss: 1.074648\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.965249\n",
      "Train Epoch: 4 [39168/60000 (65%)]\tLoss: 1.107655\n",
      "Train Epoch: 4 [39296/60000 (66%)]\tLoss: 1.442287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [39424/60000 (66%)]\tLoss: 1.295762\n",
      "Train Epoch: 4 [39552/60000 (66%)]\tLoss: 1.080608\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 1.252315\n",
      "Train Epoch: 4 [39808/60000 (66%)]\tLoss: 1.233636\n",
      "Train Epoch: 4 [39936/60000 (67%)]\tLoss: 1.105808\n",
      "Train Epoch: 4 [40064/60000 (67%)]\tLoss: 1.116897\n",
      "Train Epoch: 4 [40192/60000 (67%)]\tLoss: 1.185127\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 1.067316\n",
      "Train Epoch: 4 [40448/60000 (68%)]\tLoss: 1.218182\n",
      "Train Epoch: 4 [40576/60000 (68%)]\tLoss: 1.160460\n",
      "Train Epoch: 4 [40704/60000 (68%)]\tLoss: 1.129543\n",
      "Train Epoch: 4 [40832/60000 (68%)]\tLoss: 0.940666\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 1.215525\n",
      "Train Epoch: 4 [41088/60000 (69%)]\tLoss: 1.107597\n",
      "Train Epoch: 4 [41216/60000 (69%)]\tLoss: 1.467473\n",
      "Train Epoch: 4 [41344/60000 (69%)]\tLoss: 1.334416\n",
      "Train Epoch: 4 [41472/60000 (69%)]\tLoss: 1.375512\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 1.058829\n",
      "Train Epoch: 4 [41728/60000 (70%)]\tLoss: 1.084842\n",
      "Train Epoch: 4 [41856/60000 (70%)]\tLoss: 1.140875\n",
      "Train Epoch: 4 [41984/60000 (70%)]\tLoss: 1.154198\n",
      "Train Epoch: 4 [42112/60000 (70%)]\tLoss: 1.287763\n",
      "Train Epoch: 4 [42240/60000 (71%)]\tLoss: 1.352825\n",
      "Train Epoch: 4 [42368/60000 (71%)]\tLoss: 1.216532\n",
      "Train Epoch: 4 [42496/60000 (71%)]\tLoss: 1.157350\n",
      "Train Epoch: 4 [42624/60000 (71%)]\tLoss: 1.210032\n",
      "Train Epoch: 4 [42752/60000 (71%)]\tLoss: 1.130352\n",
      "Train Epoch: 4 [42880/60000 (72%)]\tLoss: 1.300050\n",
      "Train Epoch: 4 [43008/60000 (72%)]\tLoss: 1.411299\n",
      "Train Epoch: 4 [43136/60000 (72%)]\tLoss: 1.066184\n",
      "Train Epoch: 4 [43264/60000 (72%)]\tLoss: 0.989292\n",
      "Train Epoch: 4 [43392/60000 (72%)]\tLoss: 1.013294\n",
      "Train Epoch: 4 [43520/60000 (73%)]\tLoss: 0.900794\n",
      "Train Epoch: 4 [43648/60000 (73%)]\tLoss: 1.214839\n",
      "Train Epoch: 4 [43776/60000 (73%)]\tLoss: 1.243968\n",
      "Train Epoch: 4 [43904/60000 (73%)]\tLoss: 1.087992\n",
      "Train Epoch: 4 [44032/60000 (74%)]\tLoss: 1.188702\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 1.252690\n",
      "Train Epoch: 4 [44288/60000 (74%)]\tLoss: 1.115112\n",
      "Train Epoch: 4 [44416/60000 (74%)]\tLoss: 1.015817\n",
      "Train Epoch: 4 [44544/60000 (74%)]\tLoss: 0.996958\n",
      "Train Epoch: 4 [44672/60000 (75%)]\tLoss: 1.136829\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 1.358989\n",
      "Train Epoch: 4 [44928/60000 (75%)]\tLoss: 1.212908\n",
      "Train Epoch: 4 [45056/60000 (75%)]\tLoss: 1.226998\n",
      "Train Epoch: 4 [45184/60000 (75%)]\tLoss: 1.129122\n",
      "Train Epoch: 4 [45312/60000 (76%)]\tLoss: 0.978025\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 1.231317\n",
      "Train Epoch: 4 [45568/60000 (76%)]\tLoss: 1.195507\n",
      "Train Epoch: 4 [45696/60000 (76%)]\tLoss: 1.263585\n",
      "Train Epoch: 4 [45824/60000 (76%)]\tLoss: 1.199382\n",
      "Train Epoch: 4 [45952/60000 (77%)]\tLoss: 1.102126\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 1.132703\n",
      "Train Epoch: 4 [46208/60000 (77%)]\tLoss: 1.161225\n",
      "Train Epoch: 4 [46336/60000 (77%)]\tLoss: 1.373175\n",
      "Train Epoch: 4 [46464/60000 (78%)]\tLoss: 1.052245\n",
      "Train Epoch: 4 [46592/60000 (78%)]\tLoss: 1.078357\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 1.138428\n",
      "Train Epoch: 4 [46848/60000 (78%)]\tLoss: 1.003648\n",
      "Train Epoch: 4 [46976/60000 (78%)]\tLoss: 1.136502\n",
      "Train Epoch: 4 [47104/60000 (79%)]\tLoss: 1.094610\n",
      "Train Epoch: 4 [47232/60000 (79%)]\tLoss: 1.241427\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 1.347567\n",
      "Train Epoch: 4 [47488/60000 (79%)]\tLoss: 1.200917\n",
      "Train Epoch: 4 [47616/60000 (79%)]\tLoss: 1.026882\n",
      "Train Epoch: 4 [47744/60000 (80%)]\tLoss: 1.075462\n",
      "Train Epoch: 4 [47872/60000 (80%)]\tLoss: 1.316862\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.024550\n",
      "Train Epoch: 4 [48128/60000 (80%)]\tLoss: 0.983213\n",
      "Train Epoch: 4 [48256/60000 (81%)]\tLoss: 1.250860\n",
      "Train Epoch: 4 [48384/60000 (81%)]\tLoss: 1.029389\n",
      "Train Epoch: 4 [48512/60000 (81%)]\tLoss: 1.054447\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.995413\n",
      "Train Epoch: 4 [48768/60000 (81%)]\tLoss: 1.126792\n",
      "Train Epoch: 4 [48896/60000 (82%)]\tLoss: 1.279909\n",
      "Train Epoch: 4 [49024/60000 (82%)]\tLoss: 1.236522\n",
      "Train Epoch: 4 [49152/60000 (82%)]\tLoss: 1.223936\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 1.045231\n",
      "Train Epoch: 4 [49408/60000 (82%)]\tLoss: 1.273549\n",
      "Train Epoch: 4 [49536/60000 (83%)]\tLoss: 1.366998\n",
      "Train Epoch: 4 [49664/60000 (83%)]\tLoss: 1.109557\n",
      "Train Epoch: 4 [49792/60000 (83%)]\tLoss: 1.270278\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 1.249238\n",
      "Train Epoch: 4 [50048/60000 (84%)]\tLoss: 1.076978\n",
      "Train Epoch: 4 [50176/60000 (84%)]\tLoss: 1.315584\n",
      "Train Epoch: 4 [50304/60000 (84%)]\tLoss: 1.366943\n",
      "Train Epoch: 4 [50432/60000 (84%)]\tLoss: 1.136621\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 1.077105\n",
      "Train Epoch: 4 [50688/60000 (85%)]\tLoss: 1.229809\n",
      "Train Epoch: 4 [50816/60000 (85%)]\tLoss: 1.044029\n",
      "Train Epoch: 4 [50944/60000 (85%)]\tLoss: 0.991624\n",
      "Train Epoch: 4 [51072/60000 (85%)]\tLoss: 1.185239\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.213941\n",
      "Train Epoch: 4 [51328/60000 (86%)]\tLoss: 1.074436\n",
      "Train Epoch: 4 [51456/60000 (86%)]\tLoss: 1.059320\n",
      "Train Epoch: 4 [51584/60000 (86%)]\tLoss: 1.128037\n",
      "Train Epoch: 4 [51712/60000 (86%)]\tLoss: 1.035916\n",
      "Train Epoch: 4 [51840/60000 (87%)]\tLoss: 1.216388\n",
      "Train Epoch: 4 [51968/60000 (87%)]\tLoss: 1.177607\n",
      "Train Epoch: 4 [52096/60000 (87%)]\tLoss: 1.348671\n",
      "Train Epoch: 4 [52224/60000 (87%)]\tLoss: 1.087868\n",
      "Train Epoch: 4 [52352/60000 (87%)]\tLoss: 1.060826\n",
      "Train Epoch: 4 [52480/60000 (88%)]\tLoss: 0.928480\n",
      "Train Epoch: 4 [52608/60000 (88%)]\tLoss: 1.187091\n",
      "Train Epoch: 4 [52736/60000 (88%)]\tLoss: 1.237798\n",
      "Train Epoch: 4 [52864/60000 (88%)]\tLoss: 1.519976\n",
      "Train Epoch: 4 [52992/60000 (88%)]\tLoss: 1.138829\n",
      "Train Epoch: 4 [53120/60000 (89%)]\tLoss: 1.214572\n",
      "Train Epoch: 4 [53248/60000 (89%)]\tLoss: 1.033458\n",
      "Train Epoch: 4 [53376/60000 (89%)]\tLoss: 1.171780\n",
      "Train Epoch: 4 [53504/60000 (89%)]\tLoss: 1.123101\n",
      "Train Epoch: 4 [53632/60000 (90%)]\tLoss: 1.151117\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 1.043209\n",
      "Train Epoch: 4 [53888/60000 (90%)]\tLoss: 1.143513\n",
      "Train Epoch: 4 [54016/60000 (90%)]\tLoss: 1.218853\n",
      "Train Epoch: 4 [54144/60000 (90%)]\tLoss: 1.082758\n",
      "Train Epoch: 4 [54272/60000 (91%)]\tLoss: 1.031704\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 1.016352\n",
      "Train Epoch: 4 [54528/60000 (91%)]\tLoss: 1.076935\n",
      "Train Epoch: 4 [54656/60000 (91%)]\tLoss: 0.980847\n",
      "Train Epoch: 4 [54784/60000 (91%)]\tLoss: 1.229445\n",
      "Train Epoch: 4 [54912/60000 (92%)]\tLoss: 1.235296\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 1.011366\n",
      "Train Epoch: 4 [55168/60000 (92%)]\tLoss: 0.975396\n",
      "Train Epoch: 4 [55296/60000 (92%)]\tLoss: 1.142704\n",
      "Train Epoch: 4 [55424/60000 (93%)]\tLoss: 1.083732\n",
      "Train Epoch: 4 [55552/60000 (93%)]\tLoss: 1.046307\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 1.042765\n",
      "Train Epoch: 4 [55808/60000 (93%)]\tLoss: 1.056434\n",
      "Train Epoch: 4 [55936/60000 (93%)]\tLoss: 1.073031\n",
      "Train Epoch: 4 [56064/60000 (94%)]\tLoss: 1.128220\n",
      "Train Epoch: 4 [56192/60000 (94%)]\tLoss: 1.133696\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 1.061033\n",
      "Train Epoch: 4 [56448/60000 (94%)]\tLoss: 1.127726\n",
      "Train Epoch: 4 [56576/60000 (94%)]\tLoss: 1.129181\n",
      "Train Epoch: 4 [56704/60000 (95%)]\tLoss: 0.884576\n",
      "Train Epoch: 4 [56832/60000 (95%)]\tLoss: 1.071867\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 1.129718\n",
      "Train Epoch: 4 [57088/60000 (95%)]\tLoss: 1.099055\n",
      "Train Epoch: 4 [57216/60000 (96%)]\tLoss: 1.358887\n",
      "Train Epoch: 4 [57344/60000 (96%)]\tLoss: 1.204568\n",
      "Train Epoch: 4 [57472/60000 (96%)]\tLoss: 1.221826\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 1.178385\n",
      "Train Epoch: 4 [57728/60000 (96%)]\tLoss: 1.150914\n",
      "Train Epoch: 4 [57856/60000 (97%)]\tLoss: 1.008725\n",
      "Train Epoch: 4 [57984/60000 (97%)]\tLoss: 1.016693\n",
      "Train Epoch: 4 [58112/60000 (97%)]\tLoss: 0.925109\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 1.046519\n",
      "Train Epoch: 4 [58368/60000 (97%)]\tLoss: 1.061142\n",
      "Train Epoch: 4 [58496/60000 (98%)]\tLoss: 1.022540\n",
      "Train Epoch: 4 [58624/60000 (98%)]\tLoss: 0.974734\n",
      "Train Epoch: 4 [58752/60000 (98%)]\tLoss: 1.088934\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.823480\n",
      "Train Epoch: 4 [59008/60000 (99%)]\tLoss: 0.904685\n",
      "Train Epoch: 4 [59136/60000 (99%)]\tLoss: 0.907175\n",
      "Train Epoch: 4 [59264/60000 (99%)]\tLoss: 1.256556\n",
      "Train Epoch: 4 [59392/60000 (99%)]\tLoss: 0.998611\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 1.016833\n",
      "Train Epoch: 4 [59648/60000 (100%)]\tLoss: 1.332367\n",
      "Train Epoch: 4 [59776/60000 (100%)]\tLoss: 0.928516\n",
      "================================================================\n",
      "Training: Average loss: 0.4977, Accuracy: 53177/60000 (89%)\n",
      "Test: Average loss: 0.4784, Accuracy: 8913/10000 (89%)\n",
      "================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.155546\n",
      "Train Epoch: 5 [128/60000 (0%)]\tLoss: 1.162005\n",
      "Train Epoch: 5 [256/60000 (0%)]\tLoss: 1.050108\n",
      "Train Epoch: 5 [384/60000 (1%)]\tLoss: 1.094493\n",
      "Train Epoch: 5 [512/60000 (1%)]\tLoss: 1.209744\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.950250\n",
      "Train Epoch: 5 [768/60000 (1%)]\tLoss: 1.294509\n",
      "Train Epoch: 5 [896/60000 (1%)]\tLoss: 1.182575\n",
      "Train Epoch: 5 [1024/60000 (2%)]\tLoss: 1.350753\n",
      "Train Epoch: 5 [1152/60000 (2%)]\tLoss: 1.092785\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 1.167883\n",
      "Train Epoch: 5 [1408/60000 (2%)]\tLoss: 1.158268\n",
      "Train Epoch: 5 [1536/60000 (3%)]\tLoss: 1.122755\n",
      "Train Epoch: 5 [1664/60000 (3%)]\tLoss: 1.130487\n",
      "Train Epoch: 5 [1792/60000 (3%)]\tLoss: 0.968398\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 1.131233\n",
      "Train Epoch: 5 [2048/60000 (3%)]\tLoss: 0.981224\n",
      "Train Epoch: 5 [2176/60000 (4%)]\tLoss: 0.985499\n",
      "Train Epoch: 5 [2304/60000 (4%)]\tLoss: 1.046505\n",
      "Train Epoch: 5 [2432/60000 (4%)]\tLoss: 1.098275\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 1.080137\n",
      "Train Epoch: 5 [2688/60000 (4%)]\tLoss: 0.952380\n",
      "Train Epoch: 5 [2816/60000 (5%)]\tLoss: 1.037605\n",
      "Train Epoch: 5 [2944/60000 (5%)]\tLoss: 1.205501\n",
      "Train Epoch: 5 [3072/60000 (5%)]\tLoss: 1.083070\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 1.121261\n",
      "Train Epoch: 5 [3328/60000 (6%)]\tLoss: 1.197649\n",
      "Train Epoch: 5 [3456/60000 (6%)]\tLoss: 1.194021\n",
      "Train Epoch: 5 [3584/60000 (6%)]\tLoss: 1.067181\n",
      "Train Epoch: 5 [3712/60000 (6%)]\tLoss: 1.183310\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.939489\n",
      "Train Epoch: 5 [3968/60000 (7%)]\tLoss: 1.095169\n",
      "Train Epoch: 5 [4096/60000 (7%)]\tLoss: 1.147597\n",
      "Train Epoch: 5 [4224/60000 (7%)]\tLoss: 1.182928\n",
      "Train Epoch: 5 [4352/60000 (7%)]\tLoss: 1.071024\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.991593\n",
      "Train Epoch: 5 [4608/60000 (8%)]\tLoss: 1.155877\n",
      "Train Epoch: 5 [4736/60000 (8%)]\tLoss: 1.286282\n",
      "Train Epoch: 5 [4864/60000 (8%)]\tLoss: 1.142569\n",
      "Train Epoch: 5 [4992/60000 (8%)]\tLoss: 1.153526\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 1.269769\n",
      "Train Epoch: 5 [5248/60000 (9%)]\tLoss: 1.187096\n",
      "Train Epoch: 5 [5376/60000 (9%)]\tLoss: 1.141713\n",
      "Train Epoch: 5 [5504/60000 (9%)]\tLoss: 1.127065\n",
      "Train Epoch: 5 [5632/60000 (9%)]\tLoss: 1.053948\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 1.148778\n",
      "Train Epoch: 5 [5888/60000 (10%)]\tLoss: 1.136536\n",
      "Train Epoch: 5 [6016/60000 (10%)]\tLoss: 0.945864\n",
      "Train Epoch: 5 [6144/60000 (10%)]\tLoss: 1.076322\n",
      "Train Epoch: 5 [6272/60000 (10%)]\tLoss: 1.085616\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 1.124427\n",
      "Train Epoch: 5 [6528/60000 (11%)]\tLoss: 0.928206\n",
      "Train Epoch: 5 [6656/60000 (11%)]\tLoss: 1.053650\n",
      "Train Epoch: 5 [6784/60000 (11%)]\tLoss: 1.383042\n",
      "Train Epoch: 5 [6912/60000 (12%)]\tLoss: 1.263214\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 1.083045\n",
      "Train Epoch: 5 [7168/60000 (12%)]\tLoss: 1.321269\n",
      "Train Epoch: 5 [7296/60000 (12%)]\tLoss: 1.241267\n",
      "Train Epoch: 5 [7424/60000 (12%)]\tLoss: 1.112622\n",
      "Train Epoch: 5 [7552/60000 (13%)]\tLoss: 1.119181\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 1.157748\n",
      "Train Epoch: 5 [7808/60000 (13%)]\tLoss: 1.247203\n",
      "Train Epoch: 5 [7936/60000 (13%)]\tLoss: 1.025299\n",
      "Train Epoch: 5 [8064/60000 (13%)]\tLoss: 1.105243\n",
      "Train Epoch: 5 [8192/60000 (14%)]\tLoss: 1.340785\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 1.112771\n",
      "Train Epoch: 5 [8448/60000 (14%)]\tLoss: 1.069561\n",
      "Train Epoch: 5 [8576/60000 (14%)]\tLoss: 1.121343\n",
      "Train Epoch: 5 [8704/60000 (15%)]\tLoss: 1.291608\n",
      "Train Epoch: 5 [8832/60000 (15%)]\tLoss: 1.355101\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.954256\n",
      "Train Epoch: 5 [9088/60000 (15%)]\tLoss: 1.018225\n",
      "Train Epoch: 5 [9216/60000 (15%)]\tLoss: 1.101918\n",
      "Train Epoch: 5 [9344/60000 (16%)]\tLoss: 1.179622\n",
      "Train Epoch: 5 [9472/60000 (16%)]\tLoss: 1.066353\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.998732\n",
      "Train Epoch: 5 [9728/60000 (16%)]\tLoss: 1.063566\n",
      "Train Epoch: 5 [9856/60000 (16%)]\tLoss: 1.008431\n",
      "Train Epoch: 5 [9984/60000 (17%)]\tLoss: 1.061756\n",
      "Train Epoch: 5 [10112/60000 (17%)]\tLoss: 1.153405\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 1.063264\n",
      "Train Epoch: 5 [10368/60000 (17%)]\tLoss: 1.063803\n",
      "Train Epoch: 5 [10496/60000 (18%)]\tLoss: 1.022175\n",
      "Train Epoch: 5 [10624/60000 (18%)]\tLoss: 1.138438\n",
      "Train Epoch: 5 [10752/60000 (18%)]\tLoss: 1.143411\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 1.146243\n",
      "Train Epoch: 5 [11008/60000 (18%)]\tLoss: 1.126109\n",
      "Train Epoch: 5 [11136/60000 (19%)]\tLoss: 1.075243\n",
      "Train Epoch: 5 [11264/60000 (19%)]\tLoss: 1.024976\n",
      "Train Epoch: 5 [11392/60000 (19%)]\tLoss: 0.963752\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 1.230695\n",
      "Train Epoch: 5 [11648/60000 (19%)]\tLoss: 1.374408\n",
      "Train Epoch: 5 [11776/60000 (20%)]\tLoss: 1.132026\n",
      "Train Epoch: 5 [11904/60000 (20%)]\tLoss: 1.082715\n",
      "Train Epoch: 5 [12032/60000 (20%)]\tLoss: 1.148003\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 1.116305\n",
      "Train Epoch: 5 [12288/60000 (21%)]\tLoss: 1.256178\n",
      "Train Epoch: 5 [12416/60000 (21%)]\tLoss: 1.171483\n",
      "Train Epoch: 5 [12544/60000 (21%)]\tLoss: 1.226716\n",
      "Train Epoch: 5 [12672/60000 (21%)]\tLoss: 1.124887\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.038373\n",
      "Train Epoch: 5 [12928/60000 (22%)]\tLoss: 1.406256\n",
      "Train Epoch: 5 [13056/60000 (22%)]\tLoss: 1.261941\n",
      "Train Epoch: 5 [13184/60000 (22%)]\tLoss: 0.999832\n",
      "Train Epoch: 5 [13312/60000 (22%)]\tLoss: 1.109156\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 1.038839\n",
      "Train Epoch: 5 [13568/60000 (23%)]\tLoss: 1.193011\n",
      "Train Epoch: 5 [13696/60000 (23%)]\tLoss: 1.155576\n",
      "Train Epoch: 5 [13824/60000 (23%)]\tLoss: 1.072175\n",
      "Train Epoch: 5 [13952/60000 (23%)]\tLoss: 1.318273\n",
      "Train Epoch: 5 [14080/60000 (24%)]\tLoss: 1.195673\n",
      "Train Epoch: 5 [14208/60000 (24%)]\tLoss: 1.362959\n",
      "Train Epoch: 5 [14336/60000 (24%)]\tLoss: 1.246162\n",
      "Train Epoch: 5 [14464/60000 (24%)]\tLoss: 1.238515\n",
      "Train Epoch: 5 [14592/60000 (24%)]\tLoss: 1.215262\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 1.344382\n",
      "Train Epoch: 5 [14848/60000 (25%)]\tLoss: 1.057054\n",
      "Train Epoch: 5 [14976/60000 (25%)]\tLoss: 1.096047\n",
      "Train Epoch: 5 [15104/60000 (25%)]\tLoss: 1.123960\n",
      "Train Epoch: 5 [15232/60000 (25%)]\tLoss: 1.119278\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 1.099695\n",
      "Train Epoch: 5 [15488/60000 (26%)]\tLoss: 1.039876\n",
      "Train Epoch: 5 [15616/60000 (26%)]\tLoss: 1.165149\n",
      "Train Epoch: 5 [15744/60000 (26%)]\tLoss: 1.209703\n",
      "Train Epoch: 5 [15872/60000 (26%)]\tLoss: 1.173319\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.293769\n",
      "Train Epoch: 5 [16128/60000 (27%)]\tLoss: 1.042120\n",
      "Train Epoch: 5 [16256/60000 (27%)]\tLoss: 1.047116\n",
      "Train Epoch: 5 [16384/60000 (27%)]\tLoss: 0.931584\n",
      "Train Epoch: 5 [16512/60000 (28%)]\tLoss: 1.063110\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 1.156936\n",
      "Train Epoch: 5 [16768/60000 (28%)]\tLoss: 1.206115\n",
      "Train Epoch: 5 [16896/60000 (28%)]\tLoss: 1.224823\n",
      "Train Epoch: 5 [17024/60000 (28%)]\tLoss: 1.111203\n",
      "Train Epoch: 5 [17152/60000 (29%)]\tLoss: 1.097913\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 1.046244\n",
      "Train Epoch: 5 [17408/60000 (29%)]\tLoss: 1.087407\n",
      "Train Epoch: 5 [17536/60000 (29%)]\tLoss: 1.311999\n",
      "Train Epoch: 5 [17664/60000 (29%)]\tLoss: 1.092430\n",
      "Train Epoch: 5 [17792/60000 (30%)]\tLoss: 1.132251\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 1.055946\n",
      "Train Epoch: 5 [18048/60000 (30%)]\tLoss: 1.044732\n",
      "Train Epoch: 5 [18176/60000 (30%)]\tLoss: 0.867122\n",
      "Train Epoch: 5 [18304/60000 (31%)]\tLoss: 1.109362\n",
      "Train Epoch: 5 [18432/60000 (31%)]\tLoss: 1.098933\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 1.202401\n",
      "Train Epoch: 5 [18688/60000 (31%)]\tLoss: 1.071222\n",
      "Train Epoch: 5 [18816/60000 (31%)]\tLoss: 1.063759\n",
      "Train Epoch: 5 [18944/60000 (32%)]\tLoss: 1.207656\n",
      "Train Epoch: 5 [19072/60000 (32%)]\tLoss: 1.166056\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.937777\n",
      "Train Epoch: 5 [19328/60000 (32%)]\tLoss: 1.230300\n",
      "Train Epoch: 5 [19456/60000 (32%)]\tLoss: 1.110538\n",
      "Train Epoch: 5 [19584/60000 (33%)]\tLoss: 0.960579\n",
      "Train Epoch: 5 [19712/60000 (33%)]\tLoss: 0.936505\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 1.048689\n",
      "Train Epoch: 5 [19968/60000 (33%)]\tLoss: 1.174615\n",
      "Train Epoch: 5 [20096/60000 (34%)]\tLoss: 1.153572\n",
      "Train Epoch: 5 [20224/60000 (34%)]\tLoss: 1.139548\n",
      "Train Epoch: 5 [20352/60000 (34%)]\tLoss: 0.962629\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 1.069623\n",
      "Train Epoch: 5 [20608/60000 (34%)]\tLoss: 1.057546\n",
      "Train Epoch: 5 [20736/60000 (35%)]\tLoss: 1.205884\n",
      "Train Epoch: 5 [20864/60000 (35%)]\tLoss: 1.285836\n",
      "Train Epoch: 5 [20992/60000 (35%)]\tLoss: 1.098945\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.963482\n",
      "Train Epoch: 5 [21248/60000 (35%)]\tLoss: 1.102094\n",
      "Train Epoch: 5 [21376/60000 (36%)]\tLoss: 1.198673\n",
      "Train Epoch: 5 [21504/60000 (36%)]\tLoss: 1.158541\n",
      "Train Epoch: 5 [21632/60000 (36%)]\tLoss: 1.074936\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.921221\n",
      "Train Epoch: 5 [21888/60000 (37%)]\tLoss: 0.944792\n",
      "Train Epoch: 5 [22016/60000 (37%)]\tLoss: 1.142874\n",
      "Train Epoch: 5 [22144/60000 (37%)]\tLoss: 1.191085\n",
      "Train Epoch: 5 [22272/60000 (37%)]\tLoss: 1.032893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 1.278522\n",
      "Train Epoch: 5 [22528/60000 (38%)]\tLoss: 1.278320\n",
      "Train Epoch: 5 [22656/60000 (38%)]\tLoss: 1.064486\n",
      "Train Epoch: 5 [22784/60000 (38%)]\tLoss: 1.014677\n",
      "Train Epoch: 5 [22912/60000 (38%)]\tLoss: 1.058283\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 1.075641\n",
      "Train Epoch: 5 [23168/60000 (39%)]\tLoss: 1.033353\n",
      "Train Epoch: 5 [23296/60000 (39%)]\tLoss: 0.951113\n",
      "Train Epoch: 5 [23424/60000 (39%)]\tLoss: 1.169116\n",
      "Train Epoch: 5 [23552/60000 (39%)]\tLoss: 1.114299\n",
      "Train Epoch: 5 [23680/60000 (40%)]\tLoss: 1.220328\n",
      "Train Epoch: 5 [23808/60000 (40%)]\tLoss: 1.090182\n",
      "Train Epoch: 5 [23936/60000 (40%)]\tLoss: 1.120238\n",
      "Train Epoch: 5 [24064/60000 (40%)]\tLoss: 1.085670\n",
      "Train Epoch: 5 [24192/60000 (40%)]\tLoss: 1.257832\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.980685\n",
      "Train Epoch: 5 [24448/60000 (41%)]\tLoss: 1.035411\n",
      "Train Epoch: 5 [24576/60000 (41%)]\tLoss: 1.175304\n",
      "Train Epoch: 5 [24704/60000 (41%)]\tLoss: 1.388878\n",
      "Train Epoch: 5 [24832/60000 (41%)]\tLoss: 1.105511\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 1.106003\n",
      "Train Epoch: 5 [25088/60000 (42%)]\tLoss: 1.056274\n",
      "Train Epoch: 5 [25216/60000 (42%)]\tLoss: 1.096092\n",
      "Train Epoch: 5 [25344/60000 (42%)]\tLoss: 0.928388\n",
      "Train Epoch: 5 [25472/60000 (43%)]\tLoss: 0.997001\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.988521\n",
      "Train Epoch: 5 [25728/60000 (43%)]\tLoss: 1.105527\n",
      "Train Epoch: 5 [25856/60000 (43%)]\tLoss: 1.006501\n",
      "Train Epoch: 5 [25984/60000 (43%)]\tLoss: 0.864668\n",
      "Train Epoch: 5 [26112/60000 (44%)]\tLoss: 1.105507\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 1.087520\n",
      "Train Epoch: 5 [26368/60000 (44%)]\tLoss: 1.286492\n",
      "Train Epoch: 5 [26496/60000 (44%)]\tLoss: 1.279732\n",
      "Train Epoch: 5 [26624/60000 (44%)]\tLoss: 1.348514\n",
      "Train Epoch: 5 [26752/60000 (45%)]\tLoss: 1.060636\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 1.086339\n",
      "Train Epoch: 5 [27008/60000 (45%)]\tLoss: 1.025348\n",
      "Train Epoch: 5 [27136/60000 (45%)]\tLoss: 1.302054\n",
      "Train Epoch: 5 [27264/60000 (46%)]\tLoss: 1.217382\n",
      "Train Epoch: 5 [27392/60000 (46%)]\tLoss: 1.125322\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 1.050621\n",
      "Train Epoch: 5 [27648/60000 (46%)]\tLoss: 1.092003\n",
      "Train Epoch: 5 [27776/60000 (46%)]\tLoss: 1.063345\n",
      "Train Epoch: 5 [27904/60000 (47%)]\tLoss: 0.926985\n",
      "Train Epoch: 5 [28032/60000 (47%)]\tLoss: 0.859082\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 1.163640\n",
      "Train Epoch: 5 [28288/60000 (47%)]\tLoss: 1.196619\n",
      "Train Epoch: 5 [28416/60000 (47%)]\tLoss: 1.135782\n",
      "Train Epoch: 5 [28544/60000 (48%)]\tLoss: 1.193239\n",
      "Train Epoch: 5 [28672/60000 (48%)]\tLoss: 1.128100\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 1.033536\n",
      "Train Epoch: 5 [28928/60000 (48%)]\tLoss: 1.058665\n",
      "Train Epoch: 5 [29056/60000 (49%)]\tLoss: 1.252687\n",
      "Train Epoch: 5 [29184/60000 (49%)]\tLoss: 1.087650\n",
      "Train Epoch: 5 [29312/60000 (49%)]\tLoss: 1.158973\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.884116\n",
      "Train Epoch: 5 [29568/60000 (49%)]\tLoss: 1.075530\n",
      "Train Epoch: 5 [29696/60000 (50%)]\tLoss: 1.187165\n",
      "Train Epoch: 5 [29824/60000 (50%)]\tLoss: 1.260720\n",
      "Train Epoch: 5 [29952/60000 (50%)]\tLoss: 1.116977\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 1.324295\n",
      "Train Epoch: 5 [30208/60000 (50%)]\tLoss: 0.985398\n",
      "Train Epoch: 5 [30336/60000 (51%)]\tLoss: 1.095982\n",
      "Train Epoch: 5 [30464/60000 (51%)]\tLoss: 1.291622\n",
      "Train Epoch: 5 [30592/60000 (51%)]\tLoss: 1.228760\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.985762\n",
      "Train Epoch: 5 [30848/60000 (51%)]\tLoss: 1.216044\n",
      "Train Epoch: 5 [30976/60000 (52%)]\tLoss: 1.006597\n",
      "Train Epoch: 5 [31104/60000 (52%)]\tLoss: 1.209723\n",
      "Train Epoch: 5 [31232/60000 (52%)]\tLoss: 1.309431\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 1.191094\n",
      "Train Epoch: 5 [31488/60000 (53%)]\tLoss: 1.077584\n",
      "Train Epoch: 5 [31616/60000 (53%)]\tLoss: 1.338684\n",
      "Train Epoch: 5 [31744/60000 (53%)]\tLoss: 1.061856\n",
      "Train Epoch: 5 [31872/60000 (53%)]\tLoss: 1.062064\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.083549\n",
      "Train Epoch: 5 [32128/60000 (54%)]\tLoss: 1.343383\n",
      "Train Epoch: 5 [32256/60000 (54%)]\tLoss: 1.231154\n",
      "Train Epoch: 5 [32384/60000 (54%)]\tLoss: 1.303555\n",
      "Train Epoch: 5 [32512/60000 (54%)]\tLoss: 0.908850\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 1.003375\n",
      "Train Epoch: 5 [32768/60000 (55%)]\tLoss: 1.144110\n",
      "Train Epoch: 5 [32896/60000 (55%)]\tLoss: 1.035680\n",
      "Train Epoch: 5 [33024/60000 (55%)]\tLoss: 1.214486\n",
      "Train Epoch: 5 [33152/60000 (55%)]\tLoss: 1.055229\n",
      "Train Epoch: 5 [33280/60000 (56%)]\tLoss: 1.061023\n",
      "Train Epoch: 5 [33408/60000 (56%)]\tLoss: 1.065109\n",
      "Train Epoch: 5 [33536/60000 (56%)]\tLoss: 1.020760\n",
      "Train Epoch: 5 [33664/60000 (56%)]\tLoss: 1.062070\n",
      "Train Epoch: 5 [33792/60000 (56%)]\tLoss: 1.062370\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 1.024509\n",
      "Train Epoch: 5 [34048/60000 (57%)]\tLoss: 1.106792\n",
      "Train Epoch: 5 [34176/60000 (57%)]\tLoss: 0.960108\n",
      "Train Epoch: 5 [34304/60000 (57%)]\tLoss: 1.134238\n",
      "Train Epoch: 5 [34432/60000 (57%)]\tLoss: 0.966017\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 1.191800\n",
      "Train Epoch: 5 [34688/60000 (58%)]\tLoss: 1.287390\n",
      "Train Epoch: 5 [34816/60000 (58%)]\tLoss: 1.218431\n",
      "Train Epoch: 5 [34944/60000 (58%)]\tLoss: 1.006669\n",
      "Train Epoch: 5 [35072/60000 (59%)]\tLoss: 1.062791\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 1.068618\n",
      "Train Epoch: 5 [35328/60000 (59%)]\tLoss: 1.038639\n",
      "Train Epoch: 5 [35456/60000 (59%)]\tLoss: 1.038575\n",
      "Train Epoch: 5 [35584/60000 (59%)]\tLoss: 1.272462\n",
      "Train Epoch: 5 [35712/60000 (60%)]\tLoss: 0.977933\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.988129\n",
      "Train Epoch: 5 [35968/60000 (60%)]\tLoss: 1.046953\n",
      "Train Epoch: 5 [36096/60000 (60%)]\tLoss: 1.029375\n",
      "Train Epoch: 5 [36224/60000 (60%)]\tLoss: 1.040379\n",
      "Train Epoch: 5 [36352/60000 (61%)]\tLoss: 1.122608\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 1.144827\n",
      "Train Epoch: 5 [36608/60000 (61%)]\tLoss: 1.044872\n",
      "Train Epoch: 5 [36736/60000 (61%)]\tLoss: 1.127940\n",
      "Train Epoch: 5 [36864/60000 (62%)]\tLoss: 1.037018\n",
      "Train Epoch: 5 [36992/60000 (62%)]\tLoss: 1.211582\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 1.162258\n",
      "Train Epoch: 5 [37248/60000 (62%)]\tLoss: 1.308857\n",
      "Train Epoch: 5 [37376/60000 (62%)]\tLoss: 1.416620\n",
      "Train Epoch: 5 [37504/60000 (63%)]\tLoss: 1.079403\n",
      "Train Epoch: 5 [37632/60000 (63%)]\tLoss: 1.012329\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 1.084552\n",
      "Train Epoch: 5 [37888/60000 (63%)]\tLoss: 0.961175\n",
      "Train Epoch: 5 [38016/60000 (63%)]\tLoss: 1.130294\n",
      "Train Epoch: 5 [38144/60000 (64%)]\tLoss: 1.098305\n",
      "Train Epoch: 5 [38272/60000 (64%)]\tLoss: 1.290817\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.961649\n",
      "Train Epoch: 5 [38528/60000 (64%)]\tLoss: 1.164887\n",
      "Train Epoch: 5 [38656/60000 (65%)]\tLoss: 1.095091\n",
      "Train Epoch: 5 [38784/60000 (65%)]\tLoss: 1.034771\n",
      "Train Epoch: 5 [38912/60000 (65%)]\tLoss: 1.070824\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.857304\n",
      "Train Epoch: 5 [39168/60000 (65%)]\tLoss: 1.052606\n",
      "Train Epoch: 5 [39296/60000 (66%)]\tLoss: 1.324088\n",
      "Train Epoch: 5 [39424/60000 (66%)]\tLoss: 1.215584\n",
      "Train Epoch: 5 [39552/60000 (66%)]\tLoss: 1.078606\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.993804\n",
      "Train Epoch: 5 [39808/60000 (66%)]\tLoss: 1.263713\n",
      "Train Epoch: 5 [39936/60000 (67%)]\tLoss: 1.076725\n",
      "Train Epoch: 5 [40064/60000 (67%)]\tLoss: 0.998426\n",
      "Train Epoch: 5 [40192/60000 (67%)]\tLoss: 1.048945\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.854840\n",
      "Train Epoch: 5 [40448/60000 (68%)]\tLoss: 1.159140\n",
      "Train Epoch: 5 [40576/60000 (68%)]\tLoss: 1.139181\n",
      "Train Epoch: 5 [40704/60000 (68%)]\tLoss: 1.087908\n",
      "Train Epoch: 5 [40832/60000 (68%)]\tLoss: 0.917035\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.955794\n",
      "Train Epoch: 5 [41088/60000 (69%)]\tLoss: 1.091249\n",
      "Train Epoch: 5 [41216/60000 (69%)]\tLoss: 1.191725\n",
      "Train Epoch: 5 [41344/60000 (69%)]\tLoss: 1.256195\n",
      "Train Epoch: 5 [41472/60000 (69%)]\tLoss: 1.270666\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 1.125814\n",
      "Train Epoch: 5 [41728/60000 (70%)]\tLoss: 1.181298\n",
      "Train Epoch: 5 [41856/60000 (70%)]\tLoss: 1.091055\n",
      "Train Epoch: 5 [41984/60000 (70%)]\tLoss: 1.065962\n",
      "Train Epoch: 5 [42112/60000 (70%)]\tLoss: 1.162359\n",
      "Train Epoch: 5 [42240/60000 (71%)]\tLoss: 1.217924\n",
      "Train Epoch: 5 [42368/60000 (71%)]\tLoss: 1.118979\n",
      "Train Epoch: 5 [42496/60000 (71%)]\tLoss: 1.111893\n",
      "Train Epoch: 5 [42624/60000 (71%)]\tLoss: 1.041763\n",
      "Train Epoch: 5 [42752/60000 (71%)]\tLoss: 1.023175\n",
      "Train Epoch: 5 [42880/60000 (72%)]\tLoss: 1.189000\n",
      "Train Epoch: 5 [43008/60000 (72%)]\tLoss: 1.163566\n",
      "Train Epoch: 5 [43136/60000 (72%)]\tLoss: 0.946941\n",
      "Train Epoch: 5 [43264/60000 (72%)]\tLoss: 0.972517\n",
      "Train Epoch: 5 [43392/60000 (72%)]\tLoss: 0.890552\n",
      "Train Epoch: 5 [43520/60000 (73%)]\tLoss: 1.025594\n",
      "Train Epoch: 5 [43648/60000 (73%)]\tLoss: 1.060250\n",
      "Train Epoch: 5 [43776/60000 (73%)]\tLoss: 1.222755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [43904/60000 (73%)]\tLoss: 1.072506\n",
      "Train Epoch: 5 [44032/60000 (74%)]\tLoss: 1.055745\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 1.154040\n",
      "Train Epoch: 5 [44288/60000 (74%)]\tLoss: 0.976083\n",
      "Train Epoch: 5 [44416/60000 (74%)]\tLoss: 0.984970\n",
      "Train Epoch: 5 [44544/60000 (74%)]\tLoss: 0.848503\n",
      "Train Epoch: 5 [44672/60000 (75%)]\tLoss: 1.083702\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 1.236695\n",
      "Train Epoch: 5 [44928/60000 (75%)]\tLoss: 1.340373\n",
      "Train Epoch: 5 [45056/60000 (75%)]\tLoss: 1.195528\n",
      "Train Epoch: 5 [45184/60000 (75%)]\tLoss: 0.997245\n",
      "Train Epoch: 5 [45312/60000 (76%)]\tLoss: 0.928168\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 1.094852\n",
      "Train Epoch: 5 [45568/60000 (76%)]\tLoss: 1.078899\n",
      "Train Epoch: 5 [45696/60000 (76%)]\tLoss: 1.050313\n",
      "Train Epoch: 5 [45824/60000 (76%)]\tLoss: 1.163037\n",
      "Train Epoch: 5 [45952/60000 (77%)]\tLoss: 1.092577\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 1.070331\n",
      "Train Epoch: 5 [46208/60000 (77%)]\tLoss: 1.203439\n",
      "Train Epoch: 5 [46336/60000 (77%)]\tLoss: 1.168298\n",
      "Train Epoch: 5 [46464/60000 (78%)]\tLoss: 0.956103\n",
      "Train Epoch: 5 [46592/60000 (78%)]\tLoss: 0.990431\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.946406\n",
      "Train Epoch: 5 [46848/60000 (78%)]\tLoss: 0.895709\n",
      "Train Epoch: 5 [46976/60000 (78%)]\tLoss: 0.964610\n",
      "Train Epoch: 5 [47104/60000 (79%)]\tLoss: 0.955590\n",
      "Train Epoch: 5 [47232/60000 (79%)]\tLoss: 1.209882\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 1.094056\n",
      "Train Epoch: 5 [47488/60000 (79%)]\tLoss: 1.103013\n",
      "Train Epoch: 5 [47616/60000 (79%)]\tLoss: 1.081194\n",
      "Train Epoch: 5 [47744/60000 (80%)]\tLoss: 0.965395\n",
      "Train Epoch: 5 [47872/60000 (80%)]\tLoss: 1.157126\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 1.013001\n",
      "Train Epoch: 5 [48128/60000 (80%)]\tLoss: 0.767152\n",
      "Train Epoch: 5 [48256/60000 (81%)]\tLoss: 1.025311\n",
      "Train Epoch: 5 [48384/60000 (81%)]\tLoss: 0.931825\n",
      "Train Epoch: 5 [48512/60000 (81%)]\tLoss: 1.041233\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.999643\n",
      "Train Epoch: 5 [48768/60000 (81%)]\tLoss: 0.901754\n",
      "Train Epoch: 5 [48896/60000 (82%)]\tLoss: 1.277790\n",
      "Train Epoch: 5 [49024/60000 (82%)]\tLoss: 1.113611\n",
      "Train Epoch: 5 [49152/60000 (82%)]\tLoss: 1.222819\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.833734\n",
      "Train Epoch: 5 [49408/60000 (82%)]\tLoss: 1.280340\n",
      "Train Epoch: 5 [49536/60000 (83%)]\tLoss: 1.320748\n",
      "Train Epoch: 5 [49664/60000 (83%)]\tLoss: 1.006868\n",
      "Train Epoch: 5 [49792/60000 (83%)]\tLoss: 1.283912\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 1.032589\n",
      "Train Epoch: 5 [50048/60000 (84%)]\tLoss: 1.038743\n",
      "Train Epoch: 5 [50176/60000 (84%)]\tLoss: 0.989453\n",
      "Train Epoch: 5 [50304/60000 (84%)]\tLoss: 1.485005\n",
      "Train Epoch: 5 [50432/60000 (84%)]\tLoss: 0.929825\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 1.069602\n",
      "Train Epoch: 5 [50688/60000 (85%)]\tLoss: 1.098014\n",
      "Train Epoch: 5 [50816/60000 (85%)]\tLoss: 1.065750\n",
      "Train Epoch: 5 [50944/60000 (85%)]\tLoss: 0.849069\n",
      "Train Epoch: 5 [51072/60000 (85%)]\tLoss: 1.062336\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.071014\n",
      "Train Epoch: 5 [51328/60000 (86%)]\tLoss: 0.941309\n",
      "Train Epoch: 5 [51456/60000 (86%)]\tLoss: 0.950522\n",
      "Train Epoch: 5 [51584/60000 (86%)]\tLoss: 0.950978\n",
      "Train Epoch: 5 [51712/60000 (86%)]\tLoss: 0.911967\n",
      "Train Epoch: 5 [51840/60000 (87%)]\tLoss: 0.948699\n",
      "Train Epoch: 5 [51968/60000 (87%)]\tLoss: 1.263668\n",
      "Train Epoch: 5 [52096/60000 (87%)]\tLoss: 1.237539\n",
      "Train Epoch: 5 [52224/60000 (87%)]\tLoss: 1.053506\n",
      "Train Epoch: 5 [52352/60000 (87%)]\tLoss: 0.904632\n",
      "Train Epoch: 5 [52480/60000 (88%)]\tLoss: 0.797782\n",
      "Train Epoch: 5 [52608/60000 (88%)]\tLoss: 1.054524\n",
      "Train Epoch: 5 [52736/60000 (88%)]\tLoss: 1.192141\n",
      "Train Epoch: 5 [52864/60000 (88%)]\tLoss: 1.390653\n",
      "Train Epoch: 5 [52992/60000 (88%)]\tLoss: 1.100996\n",
      "Train Epoch: 5 [53120/60000 (89%)]\tLoss: 1.182482\n",
      "Train Epoch: 5 [53248/60000 (89%)]\tLoss: 0.839182\n",
      "Train Epoch: 5 [53376/60000 (89%)]\tLoss: 1.044431\n",
      "Train Epoch: 5 [53504/60000 (89%)]\tLoss: 1.162570\n",
      "Train Epoch: 5 [53632/60000 (90%)]\tLoss: 1.039104\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 1.070929\n",
      "Train Epoch: 5 [53888/60000 (90%)]\tLoss: 1.158709\n",
      "Train Epoch: 5 [54016/60000 (90%)]\tLoss: 1.098950\n",
      "Train Epoch: 5 [54144/60000 (90%)]\tLoss: 0.990025\n",
      "Train Epoch: 5 [54272/60000 (91%)]\tLoss: 0.961781\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.895380\n",
      "Train Epoch: 5 [54528/60000 (91%)]\tLoss: 0.880877\n",
      "Train Epoch: 5 [54656/60000 (91%)]\tLoss: 0.960048\n",
      "Train Epoch: 5 [54784/60000 (91%)]\tLoss: 1.104861\n",
      "Train Epoch: 5 [54912/60000 (92%)]\tLoss: 1.183660\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.849475\n",
      "Train Epoch: 5 [55168/60000 (92%)]\tLoss: 1.019791\n",
      "Train Epoch: 5 [55296/60000 (92%)]\tLoss: 0.902386\n",
      "Train Epoch: 5 [55424/60000 (93%)]\tLoss: 1.002554\n",
      "Train Epoch: 5 [55552/60000 (93%)]\tLoss: 0.846146\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 1.034772\n",
      "Train Epoch: 5 [55808/60000 (93%)]\tLoss: 0.976120\n",
      "Train Epoch: 5 [55936/60000 (93%)]\tLoss: 0.966535\n",
      "Train Epoch: 5 [56064/60000 (94%)]\tLoss: 0.943675\n",
      "Train Epoch: 5 [56192/60000 (94%)]\tLoss: 1.176341\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 1.006880\n",
      "Train Epoch: 5 [56448/60000 (94%)]\tLoss: 1.099727\n",
      "Train Epoch: 5 [56576/60000 (94%)]\tLoss: 1.090453\n",
      "Train Epoch: 5 [56704/60000 (95%)]\tLoss: 0.780290\n",
      "Train Epoch: 5 [56832/60000 (95%)]\tLoss: 0.858376\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 1.065808\n",
      "Train Epoch: 5 [57088/60000 (95%)]\tLoss: 0.881410\n",
      "Train Epoch: 5 [57216/60000 (96%)]\tLoss: 1.212168\n",
      "Train Epoch: 5 [57344/60000 (96%)]\tLoss: 1.051653\n",
      "Train Epoch: 5 [57472/60000 (96%)]\tLoss: 1.030620\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 1.064705\n",
      "Train Epoch: 5 [57728/60000 (96%)]\tLoss: 1.051187\n",
      "Train Epoch: 5 [57856/60000 (97%)]\tLoss: 0.878733\n",
      "Train Epoch: 5 [57984/60000 (97%)]\tLoss: 0.993441\n",
      "Train Epoch: 5 [58112/60000 (97%)]\tLoss: 0.831344\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.852346\n",
      "Train Epoch: 5 [58368/60000 (97%)]\tLoss: 0.841335\n",
      "Train Epoch: 5 [58496/60000 (98%)]\tLoss: 0.972828\n",
      "Train Epoch: 5 [58624/60000 (98%)]\tLoss: 0.835608\n",
      "Train Epoch: 5 [58752/60000 (98%)]\tLoss: 1.123911\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.768605\n",
      "Train Epoch: 5 [59008/60000 (99%)]\tLoss: 0.886431\n",
      "Train Epoch: 5 [59136/60000 (99%)]\tLoss: 0.913913\n",
      "Train Epoch: 5 [59264/60000 (99%)]\tLoss: 1.115697\n",
      "Train Epoch: 5 [59392/60000 (99%)]\tLoss: 0.824377\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.873733\n",
      "Train Epoch: 5 [59648/60000 (100%)]\tLoss: 1.222244\n",
      "Train Epoch: 5 [59776/60000 (100%)]\tLoss: 0.837197\n",
      "================================================================\n",
      "Training: Average loss: 0.4139, Accuracy: 53796/60000 (90%)\n",
      "Test: Average loss: 0.3961, Accuracy: 8995/10000 (90%)\n",
      "================================================================\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.034526\n",
      "Train Epoch: 6 [128/60000 (0%)]\tLoss: 1.088889\n",
      "Train Epoch: 6 [256/60000 (0%)]\tLoss: 0.889319\n",
      "Train Epoch: 6 [384/60000 (1%)]\tLoss: 1.020967\n",
      "Train Epoch: 6 [512/60000 (1%)]\tLoss: 0.986897\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.960048\n",
      "Train Epoch: 6 [768/60000 (1%)]\tLoss: 1.166026\n",
      "Train Epoch: 6 [896/60000 (1%)]\tLoss: 1.191154\n",
      "Train Epoch: 6 [1024/60000 (2%)]\tLoss: 1.261745\n",
      "Train Epoch: 6 [1152/60000 (2%)]\tLoss: 0.971596\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 1.024533\n",
      "Train Epoch: 6 [1408/60000 (2%)]\tLoss: 1.034922\n",
      "Train Epoch: 6 [1536/60000 (3%)]\tLoss: 1.050035\n",
      "Train Epoch: 6 [1664/60000 (3%)]\tLoss: 0.926686\n",
      "Train Epoch: 6 [1792/60000 (3%)]\tLoss: 1.037295\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 1.005253\n",
      "Train Epoch: 6 [2048/60000 (3%)]\tLoss: 0.971210\n",
      "Train Epoch: 6 [2176/60000 (4%)]\tLoss: 0.886630\n",
      "Train Epoch: 6 [2304/60000 (4%)]\tLoss: 0.964362\n",
      "Train Epoch: 6 [2432/60000 (4%)]\tLoss: 0.966641\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.925981\n",
      "Train Epoch: 6 [2688/60000 (4%)]\tLoss: 0.966385\n",
      "Train Epoch: 6 [2816/60000 (5%)]\tLoss: 0.994440\n",
      "Train Epoch: 6 [2944/60000 (5%)]\tLoss: 1.227557\n",
      "Train Epoch: 6 [3072/60000 (5%)]\tLoss: 0.995194\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 1.043189\n",
      "Train Epoch: 6 [3328/60000 (6%)]\tLoss: 1.085294\n",
      "Train Epoch: 6 [3456/60000 (6%)]\tLoss: 1.160408\n",
      "Train Epoch: 6 [3584/60000 (6%)]\tLoss: 1.070517\n",
      "Train Epoch: 6 [3712/60000 (6%)]\tLoss: 1.011902\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.859489\n",
      "Train Epoch: 6 [3968/60000 (7%)]\tLoss: 0.872212\n",
      "Train Epoch: 6 [4096/60000 (7%)]\tLoss: 1.109244\n",
      "Train Epoch: 6 [4224/60000 (7%)]\tLoss: 1.041474\n",
      "Train Epoch: 6 [4352/60000 (7%)]\tLoss: 1.011105\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.971621\n",
      "Train Epoch: 6 [4608/60000 (8%)]\tLoss: 0.978294\n",
      "Train Epoch: 6 [4736/60000 (8%)]\tLoss: 1.243362\n",
      "Train Epoch: 6 [4864/60000 (8%)]\tLoss: 1.033065\n",
      "Train Epoch: 6 [4992/60000 (8%)]\tLoss: 1.010676\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 1.204983\n",
      "Train Epoch: 6 [5248/60000 (9%)]\tLoss: 1.153621\n",
      "Train Epoch: 6 [5376/60000 (9%)]\tLoss: 0.865053\n",
      "Train Epoch: 6 [5504/60000 (9%)]\tLoss: 1.035933\n",
      "Train Epoch: 6 [5632/60000 (9%)]\tLoss: 0.998295\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 1.072269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [5888/60000 (10%)]\tLoss: 0.972645\n",
      "Train Epoch: 6 [6016/60000 (10%)]\tLoss: 0.708781\n",
      "Train Epoch: 6 [6144/60000 (10%)]\tLoss: 1.200084\n",
      "Train Epoch: 6 [6272/60000 (10%)]\tLoss: 1.017487\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 1.037846\n",
      "Train Epoch: 6 [6528/60000 (11%)]\tLoss: 0.931494\n",
      "Train Epoch: 6 [6656/60000 (11%)]\tLoss: 1.003819\n",
      "Train Epoch: 6 [6784/60000 (11%)]\tLoss: 1.101857\n",
      "Train Epoch: 6 [6912/60000 (12%)]\tLoss: 1.136886\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 1.079861\n",
      "Train Epoch: 6 [7168/60000 (12%)]\tLoss: 1.218195\n",
      "Train Epoch: 6 [7296/60000 (12%)]\tLoss: 1.226914\n",
      "Train Epoch: 6 [7424/60000 (12%)]\tLoss: 0.998770\n",
      "Train Epoch: 6 [7552/60000 (13%)]\tLoss: 1.135073\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 1.013658\n",
      "Train Epoch: 6 [7808/60000 (13%)]\tLoss: 1.143670\n",
      "Train Epoch: 6 [7936/60000 (13%)]\tLoss: 0.993368\n",
      "Train Epoch: 6 [8064/60000 (13%)]\tLoss: 1.096491\n",
      "Train Epoch: 6 [8192/60000 (14%)]\tLoss: 1.140323\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 1.042244\n",
      "Train Epoch: 6 [8448/60000 (14%)]\tLoss: 1.029926\n",
      "Train Epoch: 6 [8576/60000 (14%)]\tLoss: 1.188011\n",
      "Train Epoch: 6 [8704/60000 (15%)]\tLoss: 1.324336\n",
      "Train Epoch: 6 [8832/60000 (15%)]\tLoss: 1.191778\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.822866\n",
      "Train Epoch: 6 [9088/60000 (15%)]\tLoss: 1.018857\n",
      "Train Epoch: 6 [9216/60000 (15%)]\tLoss: 1.062029\n",
      "Train Epoch: 6 [9344/60000 (16%)]\tLoss: 1.034487\n",
      "Train Epoch: 6 [9472/60000 (16%)]\tLoss: 1.027802\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 1.014842\n",
      "Train Epoch: 6 [9728/60000 (16%)]\tLoss: 0.996976\n",
      "Train Epoch: 6 [9856/60000 (16%)]\tLoss: 0.999094\n",
      "Train Epoch: 6 [9984/60000 (17%)]\tLoss: 0.979734\n",
      "Train Epoch: 6 [10112/60000 (17%)]\tLoss: 0.987723\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.946127\n",
      "Train Epoch: 6 [10368/60000 (17%)]\tLoss: 0.755920\n",
      "Train Epoch: 6 [10496/60000 (18%)]\tLoss: 0.983248\n",
      "Train Epoch: 6 [10624/60000 (18%)]\tLoss: 0.915648\n",
      "Train Epoch: 6 [10752/60000 (18%)]\tLoss: 1.002420\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 1.001012\n",
      "Train Epoch: 6 [11008/60000 (18%)]\tLoss: 1.041193\n",
      "Train Epoch: 6 [11136/60000 (19%)]\tLoss: 1.112937\n",
      "Train Epoch: 6 [11264/60000 (19%)]\tLoss: 0.998087\n",
      "Train Epoch: 6 [11392/60000 (19%)]\tLoss: 0.963682\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 1.279490\n",
      "Train Epoch: 6 [11648/60000 (19%)]\tLoss: 1.252548\n",
      "Train Epoch: 6 [11776/60000 (20%)]\tLoss: 1.028804\n",
      "Train Epoch: 6 [11904/60000 (20%)]\tLoss: 1.017182\n",
      "Train Epoch: 6 [12032/60000 (20%)]\tLoss: 1.118139\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 1.027215\n",
      "Train Epoch: 6 [12288/60000 (21%)]\tLoss: 1.153598\n",
      "Train Epoch: 6 [12416/60000 (21%)]\tLoss: 1.138583\n",
      "Train Epoch: 6 [12544/60000 (21%)]\tLoss: 1.131323\n",
      "Train Epoch: 6 [12672/60000 (21%)]\tLoss: 1.076953\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.990827\n",
      "Train Epoch: 6 [12928/60000 (22%)]\tLoss: 1.310923\n",
      "Train Epoch: 6 [13056/60000 (22%)]\tLoss: 1.188515\n",
      "Train Epoch: 6 [13184/60000 (22%)]\tLoss: 0.940631\n",
      "Train Epoch: 6 [13312/60000 (22%)]\tLoss: 0.963715\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.887486\n",
      "Train Epoch: 6 [13568/60000 (23%)]\tLoss: 1.002995\n",
      "Train Epoch: 6 [13696/60000 (23%)]\tLoss: 1.027624\n",
      "Train Epoch: 6 [13824/60000 (23%)]\tLoss: 1.013597\n",
      "Train Epoch: 6 [13952/60000 (23%)]\tLoss: 1.180338\n",
      "Train Epoch: 6 [14080/60000 (24%)]\tLoss: 0.967805\n",
      "Train Epoch: 6 [14208/60000 (24%)]\tLoss: 1.196660\n",
      "Train Epoch: 6 [14336/60000 (24%)]\tLoss: 1.219217\n",
      "Train Epoch: 6 [14464/60000 (24%)]\tLoss: 1.092039\n",
      "Train Epoch: 6 [14592/60000 (24%)]\tLoss: 1.204296\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 1.336667\n",
      "Train Epoch: 6 [14848/60000 (25%)]\tLoss: 1.020802\n",
      "Train Epoch: 6 [14976/60000 (25%)]\tLoss: 0.975879\n",
      "Train Epoch: 6 [15104/60000 (25%)]\tLoss: 1.003477\n",
      "Train Epoch: 6 [15232/60000 (25%)]\tLoss: 0.986594\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 1.063579\n",
      "Train Epoch: 6 [15488/60000 (26%)]\tLoss: 0.944126\n",
      "Train Epoch: 6 [15616/60000 (26%)]\tLoss: 1.014995\n",
      "Train Epoch: 6 [15744/60000 (26%)]\tLoss: 1.174895\n",
      "Train Epoch: 6 [15872/60000 (26%)]\tLoss: 1.198855\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 1.146658\n",
      "Train Epoch: 6 [16128/60000 (27%)]\tLoss: 0.960172\n",
      "Train Epoch: 6 [16256/60000 (27%)]\tLoss: 0.875978\n",
      "Train Epoch: 6 [16384/60000 (27%)]\tLoss: 1.011010\n",
      "Train Epoch: 6 [16512/60000 (28%)]\tLoss: 0.931110\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 1.245107\n",
      "Train Epoch: 6 [16768/60000 (28%)]\tLoss: 1.061851\n",
      "Train Epoch: 6 [16896/60000 (28%)]\tLoss: 1.153667\n",
      "Train Epoch: 6 [17024/60000 (28%)]\tLoss: 1.045235\n",
      "Train Epoch: 6 [17152/60000 (29%)]\tLoss: 1.196580\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.969005\n",
      "Train Epoch: 6 [17408/60000 (29%)]\tLoss: 1.147920\n",
      "Train Epoch: 6 [17536/60000 (29%)]\tLoss: 1.255055\n",
      "Train Epoch: 6 [17664/60000 (29%)]\tLoss: 1.087629\n",
      "Train Epoch: 6 [17792/60000 (30%)]\tLoss: 1.066847\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 1.023646\n",
      "Train Epoch: 6 [18048/60000 (30%)]\tLoss: 0.817626\n",
      "Train Epoch: 6 [18176/60000 (30%)]\tLoss: 0.837244\n",
      "Train Epoch: 6 [18304/60000 (31%)]\tLoss: 1.192219\n",
      "Train Epoch: 6 [18432/60000 (31%)]\tLoss: 0.980852\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 1.034847\n",
      "Train Epoch: 6 [18688/60000 (31%)]\tLoss: 1.012373\n",
      "Train Epoch: 6 [18816/60000 (31%)]\tLoss: 1.024730\n",
      "Train Epoch: 6 [18944/60000 (32%)]\tLoss: 1.029011\n",
      "Train Epoch: 6 [19072/60000 (32%)]\tLoss: 1.204599\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 1.025142\n",
      "Train Epoch: 6 [19328/60000 (32%)]\tLoss: 1.110567\n",
      "Train Epoch: 6 [19456/60000 (32%)]\tLoss: 0.828652\n",
      "Train Epoch: 6 [19584/60000 (33%)]\tLoss: 0.993601\n",
      "Train Epoch: 6 [19712/60000 (33%)]\tLoss: 0.763469\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.998305\n",
      "Train Epoch: 6 [19968/60000 (33%)]\tLoss: 1.104330\n",
      "Train Epoch: 6 [20096/60000 (34%)]\tLoss: 1.168261\n",
      "Train Epoch: 6 [20224/60000 (34%)]\tLoss: 0.978245\n",
      "Train Epoch: 6 [20352/60000 (34%)]\tLoss: 0.839785\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 1.031513\n",
      "Train Epoch: 6 [20608/60000 (34%)]\tLoss: 1.149009\n",
      "Train Epoch: 6 [20736/60000 (35%)]\tLoss: 1.224273\n",
      "Train Epoch: 6 [20864/60000 (35%)]\tLoss: 1.200493\n",
      "Train Epoch: 6 [20992/60000 (35%)]\tLoss: 0.958081\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.917133\n",
      "Train Epoch: 6 [21248/60000 (35%)]\tLoss: 0.851456\n",
      "Train Epoch: 6 [21376/60000 (36%)]\tLoss: 0.992060\n",
      "Train Epoch: 6 [21504/60000 (36%)]\tLoss: 1.028336\n",
      "Train Epoch: 6 [21632/60000 (36%)]\tLoss: 1.067138\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.687595\n",
      "Train Epoch: 6 [21888/60000 (37%)]\tLoss: 0.977078\n",
      "Train Epoch: 6 [22016/60000 (37%)]\tLoss: 1.086793\n",
      "Train Epoch: 6 [22144/60000 (37%)]\tLoss: 1.044931\n",
      "Train Epoch: 6 [22272/60000 (37%)]\tLoss: 0.922978\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 1.080418\n",
      "Train Epoch: 6 [22528/60000 (38%)]\tLoss: 1.181204\n",
      "Train Epoch: 6 [22656/60000 (38%)]\tLoss: 1.028868\n",
      "Train Epoch: 6 [22784/60000 (38%)]\tLoss: 0.871471\n",
      "Train Epoch: 6 [22912/60000 (38%)]\tLoss: 0.890637\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 1.150791\n",
      "Train Epoch: 6 [23168/60000 (39%)]\tLoss: 0.845027\n",
      "Train Epoch: 6 [23296/60000 (39%)]\tLoss: 0.901761\n",
      "Train Epoch: 6 [23424/60000 (39%)]\tLoss: 0.939464\n",
      "Train Epoch: 6 [23552/60000 (39%)]\tLoss: 1.041088\n",
      "Train Epoch: 6 [23680/60000 (40%)]\tLoss: 1.103465\n",
      "Train Epoch: 6 [23808/60000 (40%)]\tLoss: 0.902564\n",
      "Train Epoch: 6 [23936/60000 (40%)]\tLoss: 1.126641\n",
      "Train Epoch: 6 [24064/60000 (40%)]\tLoss: 0.924702\n",
      "Train Epoch: 6 [24192/60000 (40%)]\tLoss: 1.154333\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.798858\n",
      "Train Epoch: 6 [24448/60000 (41%)]\tLoss: 1.157239\n",
      "Train Epoch: 6 [24576/60000 (41%)]\tLoss: 1.133916\n",
      "Train Epoch: 6 [24704/60000 (41%)]\tLoss: 1.210935\n",
      "Train Epoch: 6 [24832/60000 (41%)]\tLoss: 1.147022\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 1.045973\n",
      "Train Epoch: 6 [25088/60000 (42%)]\tLoss: 1.043892\n",
      "Train Epoch: 6 [25216/60000 (42%)]\tLoss: 1.098453\n",
      "Train Epoch: 6 [25344/60000 (42%)]\tLoss: 0.813452\n",
      "Train Epoch: 6 [25472/60000 (43%)]\tLoss: 0.899188\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.050687\n",
      "Train Epoch: 6 [25728/60000 (43%)]\tLoss: 0.950619\n",
      "Train Epoch: 6 [25856/60000 (43%)]\tLoss: 0.928684\n",
      "Train Epoch: 6 [25984/60000 (43%)]\tLoss: 0.807263\n",
      "Train Epoch: 6 [26112/60000 (44%)]\tLoss: 1.089074\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.855518\n",
      "Train Epoch: 6 [26368/60000 (44%)]\tLoss: 1.218809\n",
      "Train Epoch: 6 [26496/60000 (44%)]\tLoss: 1.107062\n",
      "Train Epoch: 6 [26624/60000 (44%)]\tLoss: 1.327919\n",
      "Train Epoch: 6 [26752/60000 (45%)]\tLoss: 1.017424\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 1.024935\n",
      "Train Epoch: 6 [27008/60000 (45%)]\tLoss: 1.032082\n",
      "Train Epoch: 6 [27136/60000 (45%)]\tLoss: 1.402147\n",
      "Train Epoch: 6 [27264/60000 (46%)]\tLoss: 1.099858\n",
      "Train Epoch: 6 [27392/60000 (46%)]\tLoss: 1.029625\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.994374\n",
      "Train Epoch: 6 [27648/60000 (46%)]\tLoss: 1.007388\n",
      "Train Epoch: 6 [27776/60000 (46%)]\tLoss: 0.984887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [27904/60000 (47%)]\tLoss: 0.728790\n",
      "Train Epoch: 6 [28032/60000 (47%)]\tLoss: 0.774599\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.889719\n",
      "Train Epoch: 6 [28288/60000 (47%)]\tLoss: 1.138283\n",
      "Train Epoch: 6 [28416/60000 (47%)]\tLoss: 1.085405\n",
      "Train Epoch: 6 [28544/60000 (48%)]\tLoss: 1.047590\n",
      "Train Epoch: 6 [28672/60000 (48%)]\tLoss: 1.077568\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 1.112333\n",
      "Train Epoch: 6 [28928/60000 (48%)]\tLoss: 1.139118\n",
      "Train Epoch: 6 [29056/60000 (49%)]\tLoss: 1.212244\n",
      "Train Epoch: 6 [29184/60000 (49%)]\tLoss: 1.018209\n",
      "Train Epoch: 6 [29312/60000 (49%)]\tLoss: 0.990133\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.953828\n",
      "Train Epoch: 6 [29568/60000 (49%)]\tLoss: 1.116565\n",
      "Train Epoch: 6 [29696/60000 (50%)]\tLoss: 1.114839\n",
      "Train Epoch: 6 [29824/60000 (50%)]\tLoss: 1.183293\n",
      "Train Epoch: 6 [29952/60000 (50%)]\tLoss: 1.014659\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 1.085425\n",
      "Train Epoch: 6 [30208/60000 (50%)]\tLoss: 1.050519\n",
      "Train Epoch: 6 [30336/60000 (51%)]\tLoss: 0.996686\n",
      "Train Epoch: 6 [30464/60000 (51%)]\tLoss: 0.979700\n",
      "Train Epoch: 6 [30592/60000 (51%)]\tLoss: 1.257883\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.972713\n",
      "Train Epoch: 6 [30848/60000 (51%)]\tLoss: 1.117760\n",
      "Train Epoch: 6 [30976/60000 (52%)]\tLoss: 0.975197\n",
      "Train Epoch: 6 [31104/60000 (52%)]\tLoss: 0.951404\n",
      "Train Epoch: 6 [31232/60000 (52%)]\tLoss: 1.242659\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 1.109632\n",
      "Train Epoch: 6 [31488/60000 (53%)]\tLoss: 1.012249\n",
      "Train Epoch: 6 [31616/60000 (53%)]\tLoss: 1.244506\n",
      "Train Epoch: 6 [31744/60000 (53%)]\tLoss: 0.903129\n",
      "Train Epoch: 6 [31872/60000 (53%)]\tLoss: 0.899647\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.039588\n",
      "Train Epoch: 6 [32128/60000 (54%)]\tLoss: 1.184881\n",
      "Train Epoch: 6 [32256/60000 (54%)]\tLoss: 1.254372\n",
      "Train Epoch: 6 [32384/60000 (54%)]\tLoss: 1.254130\n",
      "Train Epoch: 6 [32512/60000 (54%)]\tLoss: 0.875191\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.860102\n",
      "Train Epoch: 6 [32768/60000 (55%)]\tLoss: 1.110765\n",
      "Train Epoch: 6 [32896/60000 (55%)]\tLoss: 0.952087\n",
      "Train Epoch: 6 [33024/60000 (55%)]\tLoss: 1.122115\n",
      "Train Epoch: 6 [33152/60000 (55%)]\tLoss: 1.016933\n",
      "Train Epoch: 6 [33280/60000 (56%)]\tLoss: 1.049305\n",
      "Train Epoch: 6 [33408/60000 (56%)]\tLoss: 0.916148\n",
      "Train Epoch: 6 [33536/60000 (56%)]\tLoss: 0.861181\n",
      "Train Epoch: 6 [33664/60000 (56%)]\tLoss: 0.945174\n",
      "Train Epoch: 6 [33792/60000 (56%)]\tLoss: 0.807278\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.890820\n",
      "Train Epoch: 6 [34048/60000 (57%)]\tLoss: 0.982874\n",
      "Train Epoch: 6 [34176/60000 (57%)]\tLoss: 0.788431\n",
      "Train Epoch: 6 [34304/60000 (57%)]\tLoss: 0.936259\n",
      "Train Epoch: 6 [34432/60000 (57%)]\tLoss: 0.894703\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.977640\n",
      "Train Epoch: 6 [34688/60000 (58%)]\tLoss: 1.192295\n",
      "Train Epoch: 6 [34816/60000 (58%)]\tLoss: 1.128676\n",
      "Train Epoch: 6 [34944/60000 (58%)]\tLoss: 0.915117\n",
      "Train Epoch: 6 [35072/60000 (59%)]\tLoss: 0.984634\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.903890\n",
      "Train Epoch: 6 [35328/60000 (59%)]\tLoss: 0.899231\n",
      "Train Epoch: 6 [35456/60000 (59%)]\tLoss: 0.860239\n",
      "Train Epoch: 6 [35584/60000 (59%)]\tLoss: 1.074338\n",
      "Train Epoch: 6 [35712/60000 (60%)]\tLoss: 0.945647\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.889321\n",
      "Train Epoch: 6 [35968/60000 (60%)]\tLoss: 0.968361\n",
      "Train Epoch: 6 [36096/60000 (60%)]\tLoss: 1.045155\n",
      "Train Epoch: 6 [36224/60000 (60%)]\tLoss: 0.863000\n",
      "Train Epoch: 6 [36352/60000 (61%)]\tLoss: 1.024811\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 1.080799\n",
      "Train Epoch: 6 [36608/60000 (61%)]\tLoss: 0.765880\n",
      "Train Epoch: 6 [36736/60000 (61%)]\tLoss: 1.086115\n",
      "Train Epoch: 6 [36864/60000 (62%)]\tLoss: 1.016172\n",
      "Train Epoch: 6 [36992/60000 (62%)]\tLoss: 1.014451\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.996785\n",
      "Train Epoch: 6 [37248/60000 (62%)]\tLoss: 1.262830\n",
      "Train Epoch: 6 [37376/60000 (62%)]\tLoss: 1.262631\n",
      "Train Epoch: 6 [37504/60000 (63%)]\tLoss: 1.078420\n",
      "Train Epoch: 6 [37632/60000 (63%)]\tLoss: 0.997617\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 1.052165\n",
      "Train Epoch: 6 [37888/60000 (63%)]\tLoss: 0.868114\n",
      "Train Epoch: 6 [38016/60000 (63%)]\tLoss: 1.005055\n",
      "Train Epoch: 6 [38144/60000 (64%)]\tLoss: 1.039222\n",
      "Train Epoch: 6 [38272/60000 (64%)]\tLoss: 0.924442\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.897789\n",
      "Train Epoch: 6 [38528/60000 (64%)]\tLoss: 1.031489\n",
      "Train Epoch: 6 [38656/60000 (65%)]\tLoss: 1.046235\n",
      "Train Epoch: 6 [38784/60000 (65%)]\tLoss: 0.926295\n",
      "Train Epoch: 6 [38912/60000 (65%)]\tLoss: 1.024241\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.749484\n",
      "Train Epoch: 6 [39168/60000 (65%)]\tLoss: 0.975427\n",
      "Train Epoch: 6 [39296/60000 (66%)]\tLoss: 1.280270\n",
      "Train Epoch: 6 [39424/60000 (66%)]\tLoss: 1.029558\n",
      "Train Epoch: 6 [39552/60000 (66%)]\tLoss: 1.216794\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 1.109821\n",
      "Train Epoch: 6 [39808/60000 (66%)]\tLoss: 1.053915\n",
      "Train Epoch: 6 [39936/60000 (67%)]\tLoss: 0.962537\n",
      "Train Epoch: 6 [40064/60000 (67%)]\tLoss: 0.895157\n",
      "Train Epoch: 6 [40192/60000 (67%)]\tLoss: 1.016948\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.812642\n",
      "Train Epoch: 6 [40448/60000 (68%)]\tLoss: 1.143354\n",
      "Train Epoch: 6 [40576/60000 (68%)]\tLoss: 1.060644\n",
      "Train Epoch: 6 [40704/60000 (68%)]\tLoss: 0.908685\n",
      "Train Epoch: 6 [40832/60000 (68%)]\tLoss: 0.786973\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.995513\n",
      "Train Epoch: 6 [41088/60000 (69%)]\tLoss: 0.910653\n",
      "Train Epoch: 6 [41216/60000 (69%)]\tLoss: 1.141252\n",
      "Train Epoch: 6 [41344/60000 (69%)]\tLoss: 1.188230\n",
      "Train Epoch: 6 [41472/60000 (69%)]\tLoss: 1.064155\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 1.033391\n",
      "Train Epoch: 6 [41728/60000 (70%)]\tLoss: 0.992819\n",
      "Train Epoch: 6 [41856/60000 (70%)]\tLoss: 1.131791\n",
      "Train Epoch: 6 [41984/60000 (70%)]\tLoss: 0.932123\n",
      "Train Epoch: 6 [42112/60000 (70%)]\tLoss: 1.140462\n",
      "Train Epoch: 6 [42240/60000 (71%)]\tLoss: 1.160997\n",
      "Train Epoch: 6 [42368/60000 (71%)]\tLoss: 1.167083\n",
      "Train Epoch: 6 [42496/60000 (71%)]\tLoss: 1.063210\n",
      "Train Epoch: 6 [42624/60000 (71%)]\tLoss: 1.058725\n",
      "Train Epoch: 6 [42752/60000 (71%)]\tLoss: 0.994070\n",
      "Train Epoch: 6 [42880/60000 (72%)]\tLoss: 1.258180\n",
      "Train Epoch: 6 [43008/60000 (72%)]\tLoss: 1.230015\n",
      "Train Epoch: 6 [43136/60000 (72%)]\tLoss: 1.077360\n",
      "Train Epoch: 6 [43264/60000 (72%)]\tLoss: 0.966597\n",
      "Train Epoch: 6 [43392/60000 (72%)]\tLoss: 0.867650\n",
      "Train Epoch: 6 [43520/60000 (73%)]\tLoss: 0.883502\n",
      "Train Epoch: 6 [43648/60000 (73%)]\tLoss: 0.898842\n",
      "Train Epoch: 6 [43776/60000 (73%)]\tLoss: 1.154760\n",
      "Train Epoch: 6 [43904/60000 (73%)]\tLoss: 0.995959\n",
      "Train Epoch: 6 [44032/60000 (74%)]\tLoss: 1.090206\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 1.008197\n",
      "Train Epoch: 6 [44288/60000 (74%)]\tLoss: 1.004191\n",
      "Train Epoch: 6 [44416/60000 (74%)]\tLoss: 0.957112\n",
      "Train Epoch: 6 [44544/60000 (74%)]\tLoss: 0.810964\n",
      "Train Epoch: 6 [44672/60000 (75%)]\tLoss: 0.969476\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 1.165903\n",
      "Train Epoch: 6 [44928/60000 (75%)]\tLoss: 1.164185\n",
      "Train Epoch: 6 [45056/60000 (75%)]\tLoss: 1.099679\n",
      "Train Epoch: 6 [45184/60000 (75%)]\tLoss: 1.064655\n",
      "Train Epoch: 6 [45312/60000 (76%)]\tLoss: 0.939398\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 1.041170\n",
      "Train Epoch: 6 [45568/60000 (76%)]\tLoss: 0.939219\n",
      "Train Epoch: 6 [45696/60000 (76%)]\tLoss: 1.021233\n",
      "Train Epoch: 6 [45824/60000 (76%)]\tLoss: 1.133162\n",
      "Train Epoch: 6 [45952/60000 (77%)]\tLoss: 1.103888\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 1.020165\n",
      "Train Epoch: 6 [46208/60000 (77%)]\tLoss: 1.197769\n",
      "Train Epoch: 6 [46336/60000 (77%)]\tLoss: 1.148131\n",
      "Train Epoch: 6 [46464/60000 (78%)]\tLoss: 0.921640\n",
      "Train Epoch: 6 [46592/60000 (78%)]\tLoss: 0.941936\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 1.059690\n",
      "Train Epoch: 6 [46848/60000 (78%)]\tLoss: 0.835977\n",
      "Train Epoch: 6 [46976/60000 (78%)]\tLoss: 1.040464\n",
      "Train Epoch: 6 [47104/60000 (79%)]\tLoss: 1.008824\n",
      "Train Epoch: 6 [47232/60000 (79%)]\tLoss: 1.226583\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 1.101524\n",
      "Train Epoch: 6 [47488/60000 (79%)]\tLoss: 1.242700\n",
      "Train Epoch: 6 [47616/60000 (79%)]\tLoss: 0.962712\n",
      "Train Epoch: 6 [47744/60000 (80%)]\tLoss: 0.883560\n",
      "Train Epoch: 6 [47872/60000 (80%)]\tLoss: 1.142943\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.850232\n",
      "Train Epoch: 6 [48128/60000 (80%)]\tLoss: 0.765195\n",
      "Train Epoch: 6 [48256/60000 (81%)]\tLoss: 0.952480\n",
      "Train Epoch: 6 [48384/60000 (81%)]\tLoss: 0.836117\n",
      "Train Epoch: 6 [48512/60000 (81%)]\tLoss: 0.837866\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 1.034155\n",
      "Train Epoch: 6 [48768/60000 (81%)]\tLoss: 0.888344\n",
      "Train Epoch: 6 [48896/60000 (82%)]\tLoss: 1.202987\n",
      "Train Epoch: 6 [49024/60000 (82%)]\tLoss: 1.239362\n",
      "Train Epoch: 6 [49152/60000 (82%)]\tLoss: 1.223604\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.964753\n",
      "Train Epoch: 6 [49408/60000 (82%)]\tLoss: 1.135926\n",
      "Train Epoch: 6 [49536/60000 (83%)]\tLoss: 1.234365\n",
      "Train Epoch: 6 [49664/60000 (83%)]\tLoss: 0.871499\n",
      "Train Epoch: 6 [49792/60000 (83%)]\tLoss: 1.027797\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.934383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [50048/60000 (84%)]\tLoss: 0.983054\n",
      "Train Epoch: 6 [50176/60000 (84%)]\tLoss: 1.095457\n",
      "Train Epoch: 6 [50304/60000 (84%)]\tLoss: 1.314433\n",
      "Train Epoch: 6 [50432/60000 (84%)]\tLoss: 0.886040\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.930886\n",
      "Train Epoch: 6 [50688/60000 (85%)]\tLoss: 1.105791\n",
      "Train Epoch: 6 [50816/60000 (85%)]\tLoss: 0.986536\n",
      "Train Epoch: 6 [50944/60000 (85%)]\tLoss: 0.784054\n",
      "Train Epoch: 6 [51072/60000 (85%)]\tLoss: 1.000374\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.966970\n",
      "Train Epoch: 6 [51328/60000 (86%)]\tLoss: 0.865810\n",
      "Train Epoch: 6 [51456/60000 (86%)]\tLoss: 0.820168\n",
      "Train Epoch: 6 [51584/60000 (86%)]\tLoss: 0.828324\n",
      "Train Epoch: 6 [51712/60000 (86%)]\tLoss: 0.976310\n",
      "Train Epoch: 6 [51840/60000 (87%)]\tLoss: 1.023046\n",
      "Train Epoch: 6 [51968/60000 (87%)]\tLoss: 1.014522\n",
      "Train Epoch: 6 [52096/60000 (87%)]\tLoss: 1.170366\n",
      "Train Epoch: 6 [52224/60000 (87%)]\tLoss: 1.030451\n",
      "Train Epoch: 6 [52352/60000 (87%)]\tLoss: 0.836690\n",
      "Train Epoch: 6 [52480/60000 (88%)]\tLoss: 0.840179\n",
      "Train Epoch: 6 [52608/60000 (88%)]\tLoss: 1.127715\n",
      "Train Epoch: 6 [52736/60000 (88%)]\tLoss: 1.096716\n",
      "Train Epoch: 6 [52864/60000 (88%)]\tLoss: 1.369755\n",
      "Train Epoch: 6 [52992/60000 (88%)]\tLoss: 0.996619\n",
      "Train Epoch: 6 [53120/60000 (89%)]\tLoss: 1.169628\n",
      "Train Epoch: 6 [53248/60000 (89%)]\tLoss: 0.709387\n",
      "Train Epoch: 6 [53376/60000 (89%)]\tLoss: 0.947308\n",
      "Train Epoch: 6 [53504/60000 (89%)]\tLoss: 1.073163\n",
      "Train Epoch: 6 [53632/60000 (90%)]\tLoss: 0.908983\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.978208\n",
      "Train Epoch: 6 [53888/60000 (90%)]\tLoss: 1.193748\n",
      "Train Epoch: 6 [54016/60000 (90%)]\tLoss: 1.004493\n",
      "Train Epoch: 6 [54144/60000 (90%)]\tLoss: 0.848612\n",
      "Train Epoch: 6 [54272/60000 (91%)]\tLoss: 0.830752\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.879084\n",
      "Train Epoch: 6 [54528/60000 (91%)]\tLoss: 0.951693\n",
      "Train Epoch: 6 [54656/60000 (91%)]\tLoss: 0.917708\n",
      "Train Epoch: 6 [54784/60000 (91%)]\tLoss: 1.040107\n",
      "Train Epoch: 6 [54912/60000 (92%)]\tLoss: 1.247379\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.970135\n",
      "Train Epoch: 6 [55168/60000 (92%)]\tLoss: 0.865335\n",
      "Train Epoch: 6 [55296/60000 (92%)]\tLoss: 0.761547\n",
      "Train Epoch: 6 [55424/60000 (93%)]\tLoss: 1.058787\n",
      "Train Epoch: 6 [55552/60000 (93%)]\tLoss: 0.840148\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.954252\n",
      "Train Epoch: 6 [55808/60000 (93%)]\tLoss: 0.843467\n",
      "Train Epoch: 6 [55936/60000 (93%)]\tLoss: 0.851870\n",
      "Train Epoch: 6 [56064/60000 (94%)]\tLoss: 1.002393\n",
      "Train Epoch: 6 [56192/60000 (94%)]\tLoss: 0.984445\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.978768\n",
      "Train Epoch: 6 [56448/60000 (94%)]\tLoss: 0.981739\n",
      "Train Epoch: 6 [56576/60000 (94%)]\tLoss: 1.003989\n",
      "Train Epoch: 6 [56704/60000 (95%)]\tLoss: 0.742477\n",
      "Train Epoch: 6 [56832/60000 (95%)]\tLoss: 0.895861\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 1.025313\n",
      "Train Epoch: 6 [57088/60000 (95%)]\tLoss: 0.849026\n",
      "Train Epoch: 6 [57216/60000 (96%)]\tLoss: 1.143026\n",
      "Train Epoch: 6 [57344/60000 (96%)]\tLoss: 0.968628\n",
      "Train Epoch: 6 [57472/60000 (96%)]\tLoss: 0.964251\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.987524\n",
      "Train Epoch: 6 [57728/60000 (96%)]\tLoss: 0.946165\n",
      "Train Epoch: 6 [57856/60000 (97%)]\tLoss: 1.024746\n",
      "Train Epoch: 6 [57984/60000 (97%)]\tLoss: 0.932780\n",
      "Train Epoch: 6 [58112/60000 (97%)]\tLoss: 0.847936\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.756498\n",
      "Train Epoch: 6 [58368/60000 (97%)]\tLoss: 0.874324\n",
      "Train Epoch: 6 [58496/60000 (98%)]\tLoss: 0.797231\n",
      "Train Epoch: 6 [58624/60000 (98%)]\tLoss: 0.757748\n",
      "Train Epoch: 6 [58752/60000 (98%)]\tLoss: 0.886721\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.702406\n",
      "Train Epoch: 6 [59008/60000 (99%)]\tLoss: 0.637884\n",
      "Train Epoch: 6 [59136/60000 (99%)]\tLoss: 0.773062\n",
      "Train Epoch: 6 [59264/60000 (99%)]\tLoss: 1.074669\n",
      "Train Epoch: 6 [59392/60000 (99%)]\tLoss: 0.943660\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.877359\n",
      "Train Epoch: 6 [59648/60000 (100%)]\tLoss: 1.073951\n",
      "Train Epoch: 6 [59776/60000 (100%)]\tLoss: 0.746262\n",
      "================================================================\n",
      "Training: Average loss: 0.3675, Accuracy: 54388/60000 (91%)\n",
      "Test: Average loss: 0.3515, Accuracy: 9106/10000 (91%)\n",
      "================================================================\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.921980\n",
      "Train Epoch: 7 [128/60000 (0%)]\tLoss: 0.960755\n",
      "Train Epoch: 7 [256/60000 (0%)]\tLoss: 0.903713\n",
      "Train Epoch: 7 [384/60000 (1%)]\tLoss: 0.924514\n",
      "Train Epoch: 7 [512/60000 (1%)]\tLoss: 1.141376\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.904348\n",
      "Train Epoch: 7 [768/60000 (1%)]\tLoss: 1.137380\n",
      "Train Epoch: 7 [896/60000 (1%)]\tLoss: 1.058751\n",
      "Train Epoch: 7 [1024/60000 (2%)]\tLoss: 1.078819\n",
      "Train Epoch: 7 [1152/60000 (2%)]\tLoss: 1.056316\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 1.042025\n",
      "Train Epoch: 7 [1408/60000 (2%)]\tLoss: 1.023953\n",
      "Train Epoch: 7 [1536/60000 (3%)]\tLoss: 1.196740\n",
      "Train Epoch: 7 [1664/60000 (3%)]\tLoss: 0.869879\n",
      "Train Epoch: 7 [1792/60000 (3%)]\tLoss: 0.811021\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.919432\n",
      "Train Epoch: 7 [2048/60000 (3%)]\tLoss: 1.037651\n",
      "Train Epoch: 7 [2176/60000 (4%)]\tLoss: 0.901719\n",
      "Train Epoch: 7 [2304/60000 (4%)]\tLoss: 1.042145\n",
      "Train Epoch: 7 [2432/60000 (4%)]\tLoss: 0.820715\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.835380\n",
      "Train Epoch: 7 [2688/60000 (4%)]\tLoss: 0.887329\n",
      "Train Epoch: 7 [2816/60000 (5%)]\tLoss: 0.853863\n",
      "Train Epoch: 7 [2944/60000 (5%)]\tLoss: 1.076568\n",
      "Train Epoch: 7 [3072/60000 (5%)]\tLoss: 1.009976\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.947941\n",
      "Train Epoch: 7 [3328/60000 (6%)]\tLoss: 0.889188\n",
      "Train Epoch: 7 [3456/60000 (6%)]\tLoss: 0.882045\n",
      "Train Epoch: 7 [3584/60000 (6%)]\tLoss: 0.898155\n",
      "Train Epoch: 7 [3712/60000 (6%)]\tLoss: 1.026648\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.733131\n",
      "Train Epoch: 7 [3968/60000 (7%)]\tLoss: 1.027195\n",
      "Train Epoch: 7 [4096/60000 (7%)]\tLoss: 0.996753\n",
      "Train Epoch: 7 [4224/60000 (7%)]\tLoss: 0.937759\n",
      "Train Epoch: 7 [4352/60000 (7%)]\tLoss: 0.922628\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.789840\n",
      "Train Epoch: 7 [4608/60000 (8%)]\tLoss: 0.931512\n",
      "Train Epoch: 7 [4736/60000 (8%)]\tLoss: 1.035416\n",
      "Train Epoch: 7 [4864/60000 (8%)]\tLoss: 1.055680\n",
      "Train Epoch: 7 [4992/60000 (8%)]\tLoss: 1.046222\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 1.073120\n",
      "Train Epoch: 7 [5248/60000 (9%)]\tLoss: 1.059667\n",
      "Train Epoch: 7 [5376/60000 (9%)]\tLoss: 0.688458\n",
      "Train Epoch: 7 [5504/60000 (9%)]\tLoss: 0.961236\n",
      "Train Epoch: 7 [5632/60000 (9%)]\tLoss: 0.992157\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.959847\n",
      "Train Epoch: 7 [5888/60000 (10%)]\tLoss: 0.830497\n",
      "Train Epoch: 7 [6016/60000 (10%)]\tLoss: 0.687819\n",
      "Train Epoch: 7 [6144/60000 (10%)]\tLoss: 0.871156\n",
      "Train Epoch: 7 [6272/60000 (10%)]\tLoss: 0.886459\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 1.098032\n",
      "Train Epoch: 7 [6528/60000 (11%)]\tLoss: 0.917437\n",
      "Train Epoch: 7 [6656/60000 (11%)]\tLoss: 0.930996\n",
      "Train Epoch: 7 [6784/60000 (11%)]\tLoss: 1.000544\n",
      "Train Epoch: 7 [6912/60000 (12%)]\tLoss: 1.216340\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.988174\n",
      "Train Epoch: 7 [7168/60000 (12%)]\tLoss: 1.202736\n",
      "Train Epoch: 7 [7296/60000 (12%)]\tLoss: 0.913050\n",
      "Train Epoch: 7 [7424/60000 (12%)]\tLoss: 0.879784\n",
      "Train Epoch: 7 [7552/60000 (13%)]\tLoss: 0.953853\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 1.013412\n",
      "Train Epoch: 7 [7808/60000 (13%)]\tLoss: 1.187174\n",
      "Train Epoch: 7 [7936/60000 (13%)]\tLoss: 0.845568\n",
      "Train Epoch: 7 [8064/60000 (13%)]\tLoss: 0.940654\n",
      "Train Epoch: 7 [8192/60000 (14%)]\tLoss: 0.993803\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 1.043049\n",
      "Train Epoch: 7 [8448/60000 (14%)]\tLoss: 0.885330\n",
      "Train Epoch: 7 [8576/60000 (14%)]\tLoss: 1.124426\n",
      "Train Epoch: 7 [8704/60000 (15%)]\tLoss: 1.222431\n",
      "Train Epoch: 7 [8832/60000 (15%)]\tLoss: 1.150977\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.844700\n",
      "Train Epoch: 7 [9088/60000 (15%)]\tLoss: 0.919349\n",
      "Train Epoch: 7 [9216/60000 (15%)]\tLoss: 0.909548\n",
      "Train Epoch: 7 [9344/60000 (16%)]\tLoss: 0.915529\n",
      "Train Epoch: 7 [9472/60000 (16%)]\tLoss: 0.943758\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 1.007328\n",
      "Train Epoch: 7 [9728/60000 (16%)]\tLoss: 0.998465\n",
      "Train Epoch: 7 [9856/60000 (16%)]\tLoss: 0.807167\n",
      "Train Epoch: 7 [9984/60000 (17%)]\tLoss: 1.030530\n",
      "Train Epoch: 7 [10112/60000 (17%)]\tLoss: 0.944258\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.966598\n",
      "Train Epoch: 7 [10368/60000 (17%)]\tLoss: 0.710347\n",
      "Train Epoch: 7 [10496/60000 (18%)]\tLoss: 0.802277\n",
      "Train Epoch: 7 [10624/60000 (18%)]\tLoss: 1.002629\n",
      "Train Epoch: 7 [10752/60000 (18%)]\tLoss: 0.943673\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.861138\n",
      "Train Epoch: 7 [11008/60000 (18%)]\tLoss: 0.863027\n",
      "Train Epoch: 7 [11136/60000 (19%)]\tLoss: 1.046847\n",
      "Train Epoch: 7 [11264/60000 (19%)]\tLoss: 0.965149\n",
      "Train Epoch: 7 [11392/60000 (19%)]\tLoss: 0.987093\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 1.208864\n",
      "Train Epoch: 7 [11648/60000 (19%)]\tLoss: 1.165184\n",
      "Train Epoch: 7 [11776/60000 (20%)]\tLoss: 0.927249\n",
      "Train Epoch: 7 [11904/60000 (20%)]\tLoss: 0.957797\n",
      "Train Epoch: 7 [12032/60000 (20%)]\tLoss: 1.033560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 1.056501\n",
      "Train Epoch: 7 [12288/60000 (21%)]\tLoss: 0.935750\n",
      "Train Epoch: 7 [12416/60000 (21%)]\tLoss: 1.026054\n",
      "Train Epoch: 7 [12544/60000 (21%)]\tLoss: 1.049823\n",
      "Train Epoch: 7 [12672/60000 (21%)]\tLoss: 1.035064\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.954225\n",
      "Train Epoch: 7 [12928/60000 (22%)]\tLoss: 1.285213\n",
      "Train Epoch: 7 [13056/60000 (22%)]\tLoss: 1.251214\n",
      "Train Epoch: 7 [13184/60000 (22%)]\tLoss: 0.831344\n",
      "Train Epoch: 7 [13312/60000 (22%)]\tLoss: 0.942763\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.877714\n",
      "Train Epoch: 7 [13568/60000 (23%)]\tLoss: 0.963017\n",
      "Train Epoch: 7 [13696/60000 (23%)]\tLoss: 1.058520\n",
      "Train Epoch: 7 [13824/60000 (23%)]\tLoss: 0.973518\n",
      "Train Epoch: 7 [13952/60000 (23%)]\tLoss: 1.149018\n",
      "Train Epoch: 7 [14080/60000 (24%)]\tLoss: 0.995420\n",
      "Train Epoch: 7 [14208/60000 (24%)]\tLoss: 1.222093\n",
      "Train Epoch: 7 [14336/60000 (24%)]\tLoss: 1.103558\n",
      "Train Epoch: 7 [14464/60000 (24%)]\tLoss: 0.958845\n",
      "Train Epoch: 7 [14592/60000 (24%)]\tLoss: 1.237271\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 1.206753\n",
      "Train Epoch: 7 [14848/60000 (25%)]\tLoss: 1.014320\n",
      "Train Epoch: 7 [14976/60000 (25%)]\tLoss: 0.804867\n",
      "Train Epoch: 7 [15104/60000 (25%)]\tLoss: 0.901524\n",
      "Train Epoch: 7 [15232/60000 (25%)]\tLoss: 0.894434\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.908225\n",
      "Train Epoch: 7 [15488/60000 (26%)]\tLoss: 0.888981\n",
      "Train Epoch: 7 [15616/60000 (26%)]\tLoss: 0.989008\n",
      "Train Epoch: 7 [15744/60000 (26%)]\tLoss: 1.281177\n",
      "Train Epoch: 7 [15872/60000 (26%)]\tLoss: 1.130983\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 1.103312\n",
      "Train Epoch: 7 [16128/60000 (27%)]\tLoss: 0.985270\n",
      "Train Epoch: 7 [16256/60000 (27%)]\tLoss: 0.866080\n",
      "Train Epoch: 7 [16384/60000 (27%)]\tLoss: 0.813396\n",
      "Train Epoch: 7 [16512/60000 (28%)]\tLoss: 0.864126\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 1.155083\n",
      "Train Epoch: 7 [16768/60000 (28%)]\tLoss: 1.113117\n",
      "Train Epoch: 7 [16896/60000 (28%)]\tLoss: 1.164649\n",
      "Train Epoch: 7 [17024/60000 (28%)]\tLoss: 0.989146\n",
      "Train Epoch: 7 [17152/60000 (29%)]\tLoss: 0.992423\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.937885\n",
      "Train Epoch: 7 [17408/60000 (29%)]\tLoss: 0.979570\n",
      "Train Epoch: 7 [17536/60000 (29%)]\tLoss: 1.036290\n",
      "Train Epoch: 7 [17664/60000 (29%)]\tLoss: 1.017180\n",
      "Train Epoch: 7 [17792/60000 (30%)]\tLoss: 1.063714\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.891597\n",
      "Train Epoch: 7 [18048/60000 (30%)]\tLoss: 0.853585\n",
      "Train Epoch: 7 [18176/60000 (30%)]\tLoss: 0.763163\n",
      "Train Epoch: 7 [18304/60000 (31%)]\tLoss: 0.860114\n",
      "Train Epoch: 7 [18432/60000 (31%)]\tLoss: 1.028687\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 1.017416\n",
      "Train Epoch: 7 [18688/60000 (31%)]\tLoss: 0.992692\n",
      "Train Epoch: 7 [18816/60000 (31%)]\tLoss: 0.838726\n",
      "Train Epoch: 7 [18944/60000 (32%)]\tLoss: 1.095593\n",
      "Train Epoch: 7 [19072/60000 (32%)]\tLoss: 1.186246\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.944100\n",
      "Train Epoch: 7 [19328/60000 (32%)]\tLoss: 1.004177\n",
      "Train Epoch: 7 [19456/60000 (32%)]\tLoss: 0.877158\n",
      "Train Epoch: 7 [19584/60000 (33%)]\tLoss: 0.865915\n",
      "Train Epoch: 7 [19712/60000 (33%)]\tLoss: 0.814770\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.920538\n",
      "Train Epoch: 7 [19968/60000 (33%)]\tLoss: 1.072144\n",
      "Train Epoch: 7 [20096/60000 (34%)]\tLoss: 0.992792\n",
      "Train Epoch: 7 [20224/60000 (34%)]\tLoss: 0.926880\n",
      "Train Epoch: 7 [20352/60000 (34%)]\tLoss: 0.822535\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.946916\n",
      "Train Epoch: 7 [20608/60000 (34%)]\tLoss: 0.962376\n",
      "Train Epoch: 7 [20736/60000 (35%)]\tLoss: 1.045232\n",
      "Train Epoch: 7 [20864/60000 (35%)]\tLoss: 1.204941\n",
      "Train Epoch: 7 [20992/60000 (35%)]\tLoss: 0.918801\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.877576\n",
      "Train Epoch: 7 [21248/60000 (35%)]\tLoss: 0.800216\n",
      "Train Epoch: 7 [21376/60000 (36%)]\tLoss: 0.862482\n",
      "Train Epoch: 7 [21504/60000 (36%)]\tLoss: 1.007920\n",
      "Train Epoch: 7 [21632/60000 (36%)]\tLoss: 0.846390\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.693374\n",
      "Train Epoch: 7 [21888/60000 (37%)]\tLoss: 0.836015\n",
      "Train Epoch: 7 [22016/60000 (37%)]\tLoss: 0.985575\n",
      "Train Epoch: 7 [22144/60000 (37%)]\tLoss: 1.098167\n",
      "Train Epoch: 7 [22272/60000 (37%)]\tLoss: 0.871332\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 1.066318\n",
      "Train Epoch: 7 [22528/60000 (38%)]\tLoss: 1.173332\n",
      "Train Epoch: 7 [22656/60000 (38%)]\tLoss: 0.915963\n",
      "Train Epoch: 7 [22784/60000 (38%)]\tLoss: 0.940310\n",
      "Train Epoch: 7 [22912/60000 (38%)]\tLoss: 0.900714\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.993414\n",
      "Train Epoch: 7 [23168/60000 (39%)]\tLoss: 0.900100\n",
      "Train Epoch: 7 [23296/60000 (39%)]\tLoss: 0.801931\n",
      "Train Epoch: 7 [23424/60000 (39%)]\tLoss: 0.786481\n",
      "Train Epoch: 7 [23552/60000 (39%)]\tLoss: 0.969652\n",
      "Train Epoch: 7 [23680/60000 (40%)]\tLoss: 0.989978\n",
      "Train Epoch: 7 [23808/60000 (40%)]\tLoss: 1.049358\n",
      "Train Epoch: 7 [23936/60000 (40%)]\tLoss: 1.010543\n",
      "Train Epoch: 7 [24064/60000 (40%)]\tLoss: 0.861567\n",
      "Train Epoch: 7 [24192/60000 (40%)]\tLoss: 1.107427\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.852704\n",
      "Train Epoch: 7 [24448/60000 (41%)]\tLoss: 1.087890\n",
      "Train Epoch: 7 [24576/60000 (41%)]\tLoss: 1.006818\n",
      "Train Epoch: 7 [24704/60000 (41%)]\tLoss: 1.214661\n",
      "Train Epoch: 7 [24832/60000 (41%)]\tLoss: 1.045157\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.828763\n",
      "Train Epoch: 7 [25088/60000 (42%)]\tLoss: 0.940055\n",
      "Train Epoch: 7 [25216/60000 (42%)]\tLoss: 0.855016\n",
      "Train Epoch: 7 [25344/60000 (42%)]\tLoss: 0.653442\n",
      "Train Epoch: 7 [25472/60000 (43%)]\tLoss: 0.907031\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.010386\n",
      "Train Epoch: 7 [25728/60000 (43%)]\tLoss: 0.927486\n",
      "Train Epoch: 7 [25856/60000 (43%)]\tLoss: 0.894475\n",
      "Train Epoch: 7 [25984/60000 (43%)]\tLoss: 0.794217\n",
      "Train Epoch: 7 [26112/60000 (44%)]\tLoss: 0.866086\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.917516\n",
      "Train Epoch: 7 [26368/60000 (44%)]\tLoss: 1.107499\n",
      "Train Epoch: 7 [26496/60000 (44%)]\tLoss: 0.943126\n",
      "Train Epoch: 7 [26624/60000 (44%)]\tLoss: 1.124574\n",
      "Train Epoch: 7 [26752/60000 (45%)]\tLoss: 0.910066\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.841725\n",
      "Train Epoch: 7 [27008/60000 (45%)]\tLoss: 0.958641\n",
      "Train Epoch: 7 [27136/60000 (45%)]\tLoss: 1.194939\n",
      "Train Epoch: 7 [27264/60000 (46%)]\tLoss: 0.953442\n",
      "Train Epoch: 7 [27392/60000 (46%)]\tLoss: 0.951890\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.802998\n",
      "Train Epoch: 7 [27648/60000 (46%)]\tLoss: 0.991184\n",
      "Train Epoch: 7 [27776/60000 (46%)]\tLoss: 0.927739\n",
      "Train Epoch: 7 [27904/60000 (47%)]\tLoss: 0.744852\n",
      "Train Epoch: 7 [28032/60000 (47%)]\tLoss: 0.802777\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.816186\n",
      "Train Epoch: 7 [28288/60000 (47%)]\tLoss: 1.082414\n",
      "Train Epoch: 7 [28416/60000 (47%)]\tLoss: 1.042095\n",
      "Train Epoch: 7 [28544/60000 (48%)]\tLoss: 1.063025\n",
      "Train Epoch: 7 [28672/60000 (48%)]\tLoss: 1.024850\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.728630\n",
      "Train Epoch: 7 [28928/60000 (48%)]\tLoss: 0.929723\n",
      "Train Epoch: 7 [29056/60000 (49%)]\tLoss: 1.282247\n",
      "Train Epoch: 7 [29184/60000 (49%)]\tLoss: 0.953920\n",
      "Train Epoch: 7 [29312/60000 (49%)]\tLoss: 1.028679\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.910562\n",
      "Train Epoch: 7 [29568/60000 (49%)]\tLoss: 0.946599\n",
      "Train Epoch: 7 [29696/60000 (50%)]\tLoss: 1.136912\n",
      "Train Epoch: 7 [29824/60000 (50%)]\tLoss: 1.306603\n",
      "Train Epoch: 7 [29952/60000 (50%)]\tLoss: 1.114249\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 1.104185\n",
      "Train Epoch: 7 [30208/60000 (50%)]\tLoss: 0.920057\n",
      "Train Epoch: 7 [30336/60000 (51%)]\tLoss: 0.977247\n",
      "Train Epoch: 7 [30464/60000 (51%)]\tLoss: 1.011721\n",
      "Train Epoch: 7 [30592/60000 (51%)]\tLoss: 1.154374\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.921866\n",
      "Train Epoch: 7 [30848/60000 (51%)]\tLoss: 1.073782\n",
      "Train Epoch: 7 [30976/60000 (52%)]\tLoss: 0.900189\n",
      "Train Epoch: 7 [31104/60000 (52%)]\tLoss: 0.928843\n",
      "Train Epoch: 7 [31232/60000 (52%)]\tLoss: 1.085180\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.992825\n",
      "Train Epoch: 7 [31488/60000 (53%)]\tLoss: 1.066327\n",
      "Train Epoch: 7 [31616/60000 (53%)]\tLoss: 1.181426\n",
      "Train Epoch: 7 [31744/60000 (53%)]\tLoss: 0.947055\n",
      "Train Epoch: 7 [31872/60000 (53%)]\tLoss: 0.808509\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.007682\n",
      "Train Epoch: 7 [32128/60000 (54%)]\tLoss: 1.119666\n",
      "Train Epoch: 7 [32256/60000 (54%)]\tLoss: 1.042862\n",
      "Train Epoch: 7 [32384/60000 (54%)]\tLoss: 1.246003\n",
      "Train Epoch: 7 [32512/60000 (54%)]\tLoss: 1.023354\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.924199\n",
      "Train Epoch: 7 [32768/60000 (55%)]\tLoss: 1.060937\n",
      "Train Epoch: 7 [32896/60000 (55%)]\tLoss: 0.900087\n",
      "Train Epoch: 7 [33024/60000 (55%)]\tLoss: 0.942932\n",
      "Train Epoch: 7 [33152/60000 (55%)]\tLoss: 0.873568\n",
      "Train Epoch: 7 [33280/60000 (56%)]\tLoss: 0.946082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [33408/60000 (56%)]\tLoss: 0.881964\n",
      "Train Epoch: 7 [33536/60000 (56%)]\tLoss: 0.979513\n",
      "Train Epoch: 7 [33664/60000 (56%)]\tLoss: 0.907996\n",
      "Train Epoch: 7 [33792/60000 (56%)]\tLoss: 0.814556\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.856154\n",
      "Train Epoch: 7 [34048/60000 (57%)]\tLoss: 0.928254\n",
      "Train Epoch: 7 [34176/60000 (57%)]\tLoss: 0.895606\n",
      "Train Epoch: 7 [34304/60000 (57%)]\tLoss: 0.966213\n",
      "Train Epoch: 7 [34432/60000 (57%)]\tLoss: 0.973540\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.945185\n",
      "Train Epoch: 7 [34688/60000 (58%)]\tLoss: 1.186849\n",
      "Train Epoch: 7 [34816/60000 (58%)]\tLoss: 1.124424\n",
      "Train Epoch: 7 [34944/60000 (58%)]\tLoss: 0.847198\n",
      "Train Epoch: 7 [35072/60000 (59%)]\tLoss: 0.963100\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.919775\n",
      "Train Epoch: 7 [35328/60000 (59%)]\tLoss: 0.746177\n",
      "Train Epoch: 7 [35456/60000 (59%)]\tLoss: 0.920852\n",
      "Train Epoch: 7 [35584/60000 (59%)]\tLoss: 1.063922\n",
      "Train Epoch: 7 [35712/60000 (60%)]\tLoss: 0.730636\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 1.025966\n",
      "Train Epoch: 7 [35968/60000 (60%)]\tLoss: 0.999760\n",
      "Train Epoch: 7 [36096/60000 (60%)]\tLoss: 0.995362\n",
      "Train Epoch: 7 [36224/60000 (60%)]\tLoss: 0.944947\n",
      "Train Epoch: 7 [36352/60000 (61%)]\tLoss: 0.926147\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.881604\n",
      "Train Epoch: 7 [36608/60000 (61%)]\tLoss: 0.809064\n",
      "Train Epoch: 7 [36736/60000 (61%)]\tLoss: 1.008262\n",
      "Train Epoch: 7 [36864/60000 (62%)]\tLoss: 0.806374\n",
      "Train Epoch: 7 [36992/60000 (62%)]\tLoss: 1.107593\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.949055\n",
      "Train Epoch: 7 [37248/60000 (62%)]\tLoss: 1.108074\n",
      "Train Epoch: 7 [37376/60000 (62%)]\tLoss: 1.225932\n",
      "Train Epoch: 7 [37504/60000 (63%)]\tLoss: 1.037582\n",
      "Train Epoch: 7 [37632/60000 (63%)]\tLoss: 0.900252\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.853058\n",
      "Train Epoch: 7 [37888/60000 (63%)]\tLoss: 0.898975\n",
      "Train Epoch: 7 [38016/60000 (63%)]\tLoss: 0.878077\n",
      "Train Epoch: 7 [38144/60000 (64%)]\tLoss: 0.973345\n",
      "Train Epoch: 7 [38272/60000 (64%)]\tLoss: 1.038998\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.761435\n",
      "Train Epoch: 7 [38528/60000 (64%)]\tLoss: 0.948992\n",
      "Train Epoch: 7 [38656/60000 (65%)]\tLoss: 0.905038\n",
      "Train Epoch: 7 [38784/60000 (65%)]\tLoss: 0.840354\n",
      "Train Epoch: 7 [38912/60000 (65%)]\tLoss: 0.794670\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.781456\n",
      "Train Epoch: 7 [39168/60000 (65%)]\tLoss: 0.935726\n",
      "Train Epoch: 7 [39296/60000 (66%)]\tLoss: 1.116460\n",
      "Train Epoch: 7 [39424/60000 (66%)]\tLoss: 1.100562\n",
      "Train Epoch: 7 [39552/60000 (66%)]\tLoss: 0.938717\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.984732\n",
      "Train Epoch: 7 [39808/60000 (66%)]\tLoss: 1.042995\n",
      "Train Epoch: 7 [39936/60000 (67%)]\tLoss: 0.942338\n",
      "Train Epoch: 7 [40064/60000 (67%)]\tLoss: 0.847255\n",
      "Train Epoch: 7 [40192/60000 (67%)]\tLoss: 1.096035\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.861295\n",
      "Train Epoch: 7 [40448/60000 (68%)]\tLoss: 1.086549\n",
      "Train Epoch: 7 [40576/60000 (68%)]\tLoss: 1.095790\n",
      "Train Epoch: 7 [40704/60000 (68%)]\tLoss: 0.915434\n",
      "Train Epoch: 7 [40832/60000 (68%)]\tLoss: 0.778354\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 1.051608\n",
      "Train Epoch: 7 [41088/60000 (69%)]\tLoss: 0.904004\n",
      "Train Epoch: 7 [41216/60000 (69%)]\tLoss: 1.006706\n",
      "Train Epoch: 7 [41344/60000 (69%)]\tLoss: 1.047650\n",
      "Train Epoch: 7 [41472/60000 (69%)]\tLoss: 1.085628\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.878123\n",
      "Train Epoch: 7 [41728/60000 (70%)]\tLoss: 0.902829\n",
      "Train Epoch: 7 [41856/60000 (70%)]\tLoss: 1.014476\n",
      "Train Epoch: 7 [41984/60000 (70%)]\tLoss: 0.834155\n",
      "Train Epoch: 7 [42112/60000 (70%)]\tLoss: 1.055998\n",
      "Train Epoch: 7 [42240/60000 (71%)]\tLoss: 1.096023\n",
      "Train Epoch: 7 [42368/60000 (71%)]\tLoss: 1.053486\n",
      "Train Epoch: 7 [42496/60000 (71%)]\tLoss: 0.924913\n",
      "Train Epoch: 7 [42624/60000 (71%)]\tLoss: 0.922086\n",
      "Train Epoch: 7 [42752/60000 (71%)]\tLoss: 0.897045\n",
      "Train Epoch: 7 [42880/60000 (72%)]\tLoss: 1.092618\n",
      "Train Epoch: 7 [43008/60000 (72%)]\tLoss: 1.140830\n",
      "Train Epoch: 7 [43136/60000 (72%)]\tLoss: 0.853133\n",
      "Train Epoch: 7 [43264/60000 (72%)]\tLoss: 0.669440\n",
      "Train Epoch: 7 [43392/60000 (72%)]\tLoss: 0.797519\n",
      "Train Epoch: 7 [43520/60000 (73%)]\tLoss: 0.774779\n",
      "Train Epoch: 7 [43648/60000 (73%)]\tLoss: 0.855460\n",
      "Train Epoch: 7 [43776/60000 (73%)]\tLoss: 1.180072\n",
      "Train Epoch: 7 [43904/60000 (73%)]\tLoss: 1.046652\n",
      "Train Epoch: 7 [44032/60000 (74%)]\tLoss: 1.026745\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 1.069247\n",
      "Train Epoch: 7 [44288/60000 (74%)]\tLoss: 0.977688\n",
      "Train Epoch: 7 [44416/60000 (74%)]\tLoss: 0.874555\n",
      "Train Epoch: 7 [44544/60000 (74%)]\tLoss: 0.760169\n",
      "Train Epoch: 7 [44672/60000 (75%)]\tLoss: 0.795715\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 1.122293\n",
      "Train Epoch: 7 [44928/60000 (75%)]\tLoss: 1.111295\n",
      "Train Epoch: 7 [45056/60000 (75%)]\tLoss: 0.967084\n",
      "Train Epoch: 7 [45184/60000 (75%)]\tLoss: 0.849958\n",
      "Train Epoch: 7 [45312/60000 (76%)]\tLoss: 0.729427\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 1.080474\n",
      "Train Epoch: 7 [45568/60000 (76%)]\tLoss: 0.928369\n",
      "Train Epoch: 7 [45696/60000 (76%)]\tLoss: 1.019439\n",
      "Train Epoch: 7 [45824/60000 (76%)]\tLoss: 0.956119\n",
      "Train Epoch: 7 [45952/60000 (77%)]\tLoss: 0.973883\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.991613\n",
      "Train Epoch: 7 [46208/60000 (77%)]\tLoss: 0.997131\n",
      "Train Epoch: 7 [46336/60000 (77%)]\tLoss: 1.121359\n",
      "Train Epoch: 7 [46464/60000 (78%)]\tLoss: 0.778026\n",
      "Train Epoch: 7 [46592/60000 (78%)]\tLoss: 0.878507\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.826797\n",
      "Train Epoch: 7 [46848/60000 (78%)]\tLoss: 0.815950\n",
      "Train Epoch: 7 [46976/60000 (78%)]\tLoss: 0.913899\n",
      "Train Epoch: 7 [47104/60000 (79%)]\tLoss: 0.791919\n",
      "Train Epoch: 7 [47232/60000 (79%)]\tLoss: 1.092698\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 1.077237\n",
      "Train Epoch: 7 [47488/60000 (79%)]\tLoss: 0.955795\n",
      "Train Epoch: 7 [47616/60000 (79%)]\tLoss: 1.001164\n",
      "Train Epoch: 7 [47744/60000 (80%)]\tLoss: 0.981065\n",
      "Train Epoch: 7 [47872/60000 (80%)]\tLoss: 1.088556\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.803017\n",
      "Train Epoch: 7 [48128/60000 (80%)]\tLoss: 0.712451\n",
      "Train Epoch: 7 [48256/60000 (81%)]\tLoss: 0.846394\n",
      "Train Epoch: 7 [48384/60000 (81%)]\tLoss: 0.787090\n",
      "Train Epoch: 7 [48512/60000 (81%)]\tLoss: 0.994479\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.815477\n",
      "Train Epoch: 7 [48768/60000 (81%)]\tLoss: 0.910503\n",
      "Train Epoch: 7 [48896/60000 (82%)]\tLoss: 1.282704\n",
      "Train Epoch: 7 [49024/60000 (82%)]\tLoss: 1.090586\n",
      "Train Epoch: 7 [49152/60000 (82%)]\tLoss: 1.062827\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.723087\n",
      "Train Epoch: 7 [49408/60000 (82%)]\tLoss: 1.142494\n",
      "Train Epoch: 7 [49536/60000 (83%)]\tLoss: 1.161418\n",
      "Train Epoch: 7 [49664/60000 (83%)]\tLoss: 0.997209\n",
      "Train Epoch: 7 [49792/60000 (83%)]\tLoss: 1.143395\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.998379\n",
      "Train Epoch: 7 [50048/60000 (84%)]\tLoss: 0.902608\n",
      "Train Epoch: 7 [50176/60000 (84%)]\tLoss: 1.012010\n",
      "Train Epoch: 7 [50304/60000 (84%)]\tLoss: 1.323143\n",
      "Train Epoch: 7 [50432/60000 (84%)]\tLoss: 0.898240\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 1.061693\n",
      "Train Epoch: 7 [50688/60000 (85%)]\tLoss: 0.998984\n",
      "Train Epoch: 7 [50816/60000 (85%)]\tLoss: 0.997358\n",
      "Train Epoch: 7 [50944/60000 (85%)]\tLoss: 0.767483\n",
      "Train Epoch: 7 [51072/60000 (85%)]\tLoss: 0.885424\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 1.042717\n",
      "Train Epoch: 7 [51328/60000 (86%)]\tLoss: 0.865943\n",
      "Train Epoch: 7 [51456/60000 (86%)]\tLoss: 0.849750\n",
      "Train Epoch: 7 [51584/60000 (86%)]\tLoss: 0.722475\n",
      "Train Epoch: 7 [51712/60000 (86%)]\tLoss: 0.846438\n",
      "Train Epoch: 7 [51840/60000 (87%)]\tLoss: 0.888525\n",
      "Train Epoch: 7 [51968/60000 (87%)]\tLoss: 1.127648\n",
      "Train Epoch: 7 [52096/60000 (87%)]\tLoss: 1.114838\n",
      "Train Epoch: 7 [52224/60000 (87%)]\tLoss: 0.943710\n",
      "Train Epoch: 7 [52352/60000 (87%)]\tLoss: 0.786956\n",
      "Train Epoch: 7 [52480/60000 (88%)]\tLoss: 0.605879\n",
      "Train Epoch: 7 [52608/60000 (88%)]\tLoss: 0.995631\n",
      "Train Epoch: 7 [52736/60000 (88%)]\tLoss: 1.079890\n",
      "Train Epoch: 7 [52864/60000 (88%)]\tLoss: 1.286534\n",
      "Train Epoch: 7 [52992/60000 (88%)]\tLoss: 0.931733\n",
      "Train Epoch: 7 [53120/60000 (89%)]\tLoss: 0.899984\n",
      "Train Epoch: 7 [53248/60000 (89%)]\tLoss: 0.709960\n",
      "Train Epoch: 7 [53376/60000 (89%)]\tLoss: 0.840760\n",
      "Train Epoch: 7 [53504/60000 (89%)]\tLoss: 1.017825\n",
      "Train Epoch: 7 [53632/60000 (90%)]\tLoss: 0.963825\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.815687\n",
      "Train Epoch: 7 [53888/60000 (90%)]\tLoss: 1.062171\n",
      "Train Epoch: 7 [54016/60000 (90%)]\tLoss: 0.889929\n",
      "Train Epoch: 7 [54144/60000 (90%)]\tLoss: 0.800088\n",
      "Train Epoch: 7 [54272/60000 (91%)]\tLoss: 0.823292\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.745844\n",
      "Train Epoch: 7 [54528/60000 (91%)]\tLoss: 1.069304\n",
      "Train Epoch: 7 [54656/60000 (91%)]\tLoss: 0.818927\n",
      "Train Epoch: 7 [54784/60000 (91%)]\tLoss: 0.912919\n",
      "Train Epoch: 7 [54912/60000 (92%)]\tLoss: 0.998713\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.817362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [55168/60000 (92%)]\tLoss: 0.889496\n",
      "Train Epoch: 7 [55296/60000 (92%)]\tLoss: 0.736112\n",
      "Train Epoch: 7 [55424/60000 (93%)]\tLoss: 0.807903\n",
      "Train Epoch: 7 [55552/60000 (93%)]\tLoss: 0.765822\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.910263\n",
      "Train Epoch: 7 [55808/60000 (93%)]\tLoss: 0.809923\n",
      "Train Epoch: 7 [55936/60000 (93%)]\tLoss: 0.767853\n",
      "Train Epoch: 7 [56064/60000 (94%)]\tLoss: 0.789289\n",
      "Train Epoch: 7 [56192/60000 (94%)]\tLoss: 1.009079\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.838690\n",
      "Train Epoch: 7 [56448/60000 (94%)]\tLoss: 0.899032\n",
      "Train Epoch: 7 [56576/60000 (94%)]\tLoss: 0.871050\n",
      "Train Epoch: 7 [56704/60000 (95%)]\tLoss: 0.713182\n",
      "Train Epoch: 7 [56832/60000 (95%)]\tLoss: 0.866816\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.919812\n",
      "Train Epoch: 7 [57088/60000 (95%)]\tLoss: 0.801498\n",
      "Train Epoch: 7 [57216/60000 (96%)]\tLoss: 1.078270\n",
      "Train Epoch: 7 [57344/60000 (96%)]\tLoss: 0.890282\n",
      "Train Epoch: 7 [57472/60000 (96%)]\tLoss: 1.000520\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 1.033701\n",
      "Train Epoch: 7 [57728/60000 (96%)]\tLoss: 1.006590\n",
      "Train Epoch: 7 [57856/60000 (97%)]\tLoss: 0.813463\n",
      "Train Epoch: 7 [57984/60000 (97%)]\tLoss: 0.799048\n",
      "Train Epoch: 7 [58112/60000 (97%)]\tLoss: 0.722614\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.783519\n",
      "Train Epoch: 7 [58368/60000 (97%)]\tLoss: 0.819982\n",
      "Train Epoch: 7 [58496/60000 (98%)]\tLoss: 0.760161\n",
      "Train Epoch: 7 [58624/60000 (98%)]\tLoss: 0.739145\n",
      "Train Epoch: 7 [58752/60000 (98%)]\tLoss: 0.805159\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.691560\n",
      "Train Epoch: 7 [59008/60000 (99%)]\tLoss: 0.793279\n",
      "Train Epoch: 7 [59136/60000 (99%)]\tLoss: 0.795111\n",
      "Train Epoch: 7 [59264/60000 (99%)]\tLoss: 0.970099\n",
      "Train Epoch: 7 [59392/60000 (99%)]\tLoss: 0.848509\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.686957\n",
      "Train Epoch: 7 [59648/60000 (100%)]\tLoss: 1.160024\n",
      "Train Epoch: 7 [59776/60000 (100%)]\tLoss: 0.619924\n",
      "================================================================\n",
      "Training: Average loss: 0.3297, Accuracy: 54900/60000 (92%)\n",
      "Test: Average loss: 0.3131, Accuracy: 9195/10000 (92%)\n",
      "================================================================\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.897164\n",
      "Train Epoch: 8 [128/60000 (0%)]\tLoss: 1.027020\n",
      "Train Epoch: 8 [256/60000 (0%)]\tLoss: 0.787344\n",
      "Train Epoch: 8 [384/60000 (1%)]\tLoss: 0.966637\n",
      "Train Epoch: 8 [512/60000 (1%)]\tLoss: 1.150755\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.824119\n",
      "Train Epoch: 8 [768/60000 (1%)]\tLoss: 1.108821\n",
      "Train Epoch: 8 [896/60000 (1%)]\tLoss: 1.117004\n",
      "Train Epoch: 8 [1024/60000 (2%)]\tLoss: 1.183196\n",
      "Train Epoch: 8 [1152/60000 (2%)]\tLoss: 0.959345\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 1.026817\n",
      "Train Epoch: 8 [1408/60000 (2%)]\tLoss: 0.874166\n",
      "Train Epoch: 8 [1536/60000 (3%)]\tLoss: 0.939213\n",
      "Train Epoch: 8 [1664/60000 (3%)]\tLoss: 0.708260\n",
      "Train Epoch: 8 [1792/60000 (3%)]\tLoss: 0.734570\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.800336\n",
      "Train Epoch: 8 [2048/60000 (3%)]\tLoss: 0.787561\n",
      "Train Epoch: 8 [2176/60000 (4%)]\tLoss: 0.807790\n",
      "Train Epoch: 8 [2304/60000 (4%)]\tLoss: 1.095837\n",
      "Train Epoch: 8 [2432/60000 (4%)]\tLoss: 0.782777\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.782488\n",
      "Train Epoch: 8 [2688/60000 (4%)]\tLoss: 0.950895\n",
      "Train Epoch: 8 [2816/60000 (5%)]\tLoss: 0.894549\n",
      "Train Epoch: 8 [2944/60000 (5%)]\tLoss: 0.946159\n",
      "Train Epoch: 8 [3072/60000 (5%)]\tLoss: 0.866724\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.662699\n",
      "Train Epoch: 8 [3328/60000 (6%)]\tLoss: 0.948352\n",
      "Train Epoch: 8 [3456/60000 (6%)]\tLoss: 0.860530\n",
      "Train Epoch: 8 [3584/60000 (6%)]\tLoss: 0.983708\n",
      "Train Epoch: 8 [3712/60000 (6%)]\tLoss: 1.013538\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.835953\n",
      "Train Epoch: 8 [3968/60000 (7%)]\tLoss: 0.904684\n",
      "Train Epoch: 8 [4096/60000 (7%)]\tLoss: 0.912735\n",
      "Train Epoch: 8 [4224/60000 (7%)]\tLoss: 0.772667\n",
      "Train Epoch: 8 [4352/60000 (7%)]\tLoss: 0.958066\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.825886\n",
      "Train Epoch: 8 [4608/60000 (8%)]\tLoss: 0.813382\n",
      "Train Epoch: 8 [4736/60000 (8%)]\tLoss: 0.935352\n",
      "Train Epoch: 8 [4864/60000 (8%)]\tLoss: 0.920541\n",
      "Train Epoch: 8 [4992/60000 (8%)]\tLoss: 0.976627\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 1.039753\n",
      "Train Epoch: 8 [5248/60000 (9%)]\tLoss: 0.921728\n",
      "Train Epoch: 8 [5376/60000 (9%)]\tLoss: 0.743083\n",
      "Train Epoch: 8 [5504/60000 (9%)]\tLoss: 0.916443\n",
      "Train Epoch: 8 [5632/60000 (9%)]\tLoss: 0.886562\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.999841\n",
      "Train Epoch: 8 [5888/60000 (10%)]\tLoss: 0.952271\n",
      "Train Epoch: 8 [6016/60000 (10%)]\tLoss: 0.678183\n",
      "Train Epoch: 8 [6144/60000 (10%)]\tLoss: 0.981638\n",
      "Train Epoch: 8 [6272/60000 (10%)]\tLoss: 0.850032\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.921181\n",
      "Train Epoch: 8 [6528/60000 (11%)]\tLoss: 0.737280\n",
      "Train Epoch: 8 [6656/60000 (11%)]\tLoss: 0.902899\n",
      "Train Epoch: 8 [6784/60000 (11%)]\tLoss: 1.035427\n",
      "Train Epoch: 8 [6912/60000 (12%)]\tLoss: 1.002280\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.913336\n",
      "Train Epoch: 8 [7168/60000 (12%)]\tLoss: 0.977281\n",
      "Train Epoch: 8 [7296/60000 (12%)]\tLoss: 0.882745\n",
      "Train Epoch: 8 [7424/60000 (12%)]\tLoss: 0.865411\n",
      "Train Epoch: 8 [7552/60000 (13%)]\tLoss: 0.887116\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.967628\n",
      "Train Epoch: 8 [7808/60000 (13%)]\tLoss: 0.951866\n",
      "Train Epoch: 8 [7936/60000 (13%)]\tLoss: 0.850397\n",
      "Train Epoch: 8 [8064/60000 (13%)]\tLoss: 0.905268\n",
      "Train Epoch: 8 [8192/60000 (14%)]\tLoss: 1.101376\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.922952\n",
      "Train Epoch: 8 [8448/60000 (14%)]\tLoss: 0.855262\n",
      "Train Epoch: 8 [8576/60000 (14%)]\tLoss: 0.917424\n",
      "Train Epoch: 8 [8704/60000 (15%)]\tLoss: 1.003082\n",
      "Train Epoch: 8 [8832/60000 (15%)]\tLoss: 1.290458\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.747525\n",
      "Train Epoch: 8 [9088/60000 (15%)]\tLoss: 0.949880\n",
      "Train Epoch: 8 [9216/60000 (15%)]\tLoss: 0.807750\n",
      "Train Epoch: 8 [9344/60000 (16%)]\tLoss: 0.912022\n",
      "Train Epoch: 8 [9472/60000 (16%)]\tLoss: 0.974317\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.844548\n",
      "Train Epoch: 8 [9728/60000 (16%)]\tLoss: 0.915029\n",
      "Train Epoch: 8 [9856/60000 (16%)]\tLoss: 0.868922\n",
      "Train Epoch: 8 [9984/60000 (17%)]\tLoss: 0.903376\n",
      "Train Epoch: 8 [10112/60000 (17%)]\tLoss: 0.916607\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.922331\n",
      "Train Epoch: 8 [10368/60000 (17%)]\tLoss: 0.698027\n",
      "Train Epoch: 8 [10496/60000 (18%)]\tLoss: 0.799590\n",
      "Train Epoch: 8 [10624/60000 (18%)]\tLoss: 0.766714\n",
      "Train Epoch: 8 [10752/60000 (18%)]\tLoss: 0.952492\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.959657\n",
      "Train Epoch: 8 [11008/60000 (18%)]\tLoss: 0.844185\n",
      "Train Epoch: 8 [11136/60000 (19%)]\tLoss: 0.984972\n",
      "Train Epoch: 8 [11264/60000 (19%)]\tLoss: 0.898736\n",
      "Train Epoch: 8 [11392/60000 (19%)]\tLoss: 0.730410\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 1.247784\n",
      "Train Epoch: 8 [11648/60000 (19%)]\tLoss: 1.130390\n",
      "Train Epoch: 8 [11776/60000 (20%)]\tLoss: 0.968048\n",
      "Train Epoch: 8 [11904/60000 (20%)]\tLoss: 0.915837\n",
      "Train Epoch: 8 [12032/60000 (20%)]\tLoss: 1.010138\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.939122\n",
      "Train Epoch: 8 [12288/60000 (21%)]\tLoss: 0.946659\n",
      "Train Epoch: 8 [12416/60000 (21%)]\tLoss: 0.947237\n",
      "Train Epoch: 8 [12544/60000 (21%)]\tLoss: 1.167821\n",
      "Train Epoch: 8 [12672/60000 (21%)]\tLoss: 1.021838\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.922012\n",
      "Train Epoch: 8 [12928/60000 (22%)]\tLoss: 1.329195\n",
      "Train Epoch: 8 [13056/60000 (22%)]\tLoss: 1.102259\n",
      "Train Epoch: 8 [13184/60000 (22%)]\tLoss: 0.879968\n",
      "Train Epoch: 8 [13312/60000 (22%)]\tLoss: 0.959282\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.806300\n",
      "Train Epoch: 8 [13568/60000 (23%)]\tLoss: 0.972202\n",
      "Train Epoch: 8 [13696/60000 (23%)]\tLoss: 1.008830\n",
      "Train Epoch: 8 [13824/60000 (23%)]\tLoss: 0.876124\n",
      "Train Epoch: 8 [13952/60000 (23%)]\tLoss: 1.005293\n",
      "Train Epoch: 8 [14080/60000 (24%)]\tLoss: 0.810848\n",
      "Train Epoch: 8 [14208/60000 (24%)]\tLoss: 1.110819\n",
      "Train Epoch: 8 [14336/60000 (24%)]\tLoss: 1.030107\n",
      "Train Epoch: 8 [14464/60000 (24%)]\tLoss: 0.873930\n",
      "Train Epoch: 8 [14592/60000 (24%)]\tLoss: 1.214015\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 1.170250\n",
      "Train Epoch: 8 [14848/60000 (25%)]\tLoss: 0.964501\n",
      "Train Epoch: 8 [14976/60000 (25%)]\tLoss: 0.795248\n",
      "Train Epoch: 8 [15104/60000 (25%)]\tLoss: 0.943810\n",
      "Train Epoch: 8 [15232/60000 (25%)]\tLoss: 0.850704\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.779658\n",
      "Train Epoch: 8 [15488/60000 (26%)]\tLoss: 0.806428\n",
      "Train Epoch: 8 [15616/60000 (26%)]\tLoss: 0.991709\n",
      "Train Epoch: 8 [15744/60000 (26%)]\tLoss: 1.069065\n",
      "Train Epoch: 8 [15872/60000 (26%)]\tLoss: 0.892671\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 1.229608\n",
      "Train Epoch: 8 [16128/60000 (27%)]\tLoss: 0.877110\n",
      "Train Epoch: 8 [16256/60000 (27%)]\tLoss: 0.843295\n",
      "Train Epoch: 8 [16384/60000 (27%)]\tLoss: 0.837837\n",
      "Train Epoch: 8 [16512/60000 (28%)]\tLoss: 0.853731\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.935295\n",
      "Train Epoch: 8 [16768/60000 (28%)]\tLoss: 1.046692\n",
      "Train Epoch: 8 [16896/60000 (28%)]\tLoss: 1.142894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [17024/60000 (28%)]\tLoss: 0.931447\n",
      "Train Epoch: 8 [17152/60000 (29%)]\tLoss: 0.994390\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.877683\n",
      "Train Epoch: 8 [17408/60000 (29%)]\tLoss: 1.000554\n",
      "Train Epoch: 8 [17536/60000 (29%)]\tLoss: 1.129006\n",
      "Train Epoch: 8 [17664/60000 (29%)]\tLoss: 1.032172\n",
      "Train Epoch: 8 [17792/60000 (30%)]\tLoss: 0.987174\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.853489\n",
      "Train Epoch: 8 [18048/60000 (30%)]\tLoss: 0.794788\n",
      "Train Epoch: 8 [18176/60000 (30%)]\tLoss: 0.689941\n",
      "Train Epoch: 8 [18304/60000 (31%)]\tLoss: 0.984936\n",
      "Train Epoch: 8 [18432/60000 (31%)]\tLoss: 0.839432\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.795601\n",
      "Train Epoch: 8 [18688/60000 (31%)]\tLoss: 0.900524\n",
      "Train Epoch: 8 [18816/60000 (31%)]\tLoss: 0.744756\n",
      "Train Epoch: 8 [18944/60000 (32%)]\tLoss: 0.795911\n",
      "Train Epoch: 8 [19072/60000 (32%)]\tLoss: 1.092815\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.881015\n",
      "Train Epoch: 8 [19328/60000 (32%)]\tLoss: 0.915281\n",
      "Train Epoch: 8 [19456/60000 (32%)]\tLoss: 0.714498\n",
      "Train Epoch: 8 [19584/60000 (33%)]\tLoss: 0.711861\n",
      "Train Epoch: 8 [19712/60000 (33%)]\tLoss: 0.890156\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.927143\n",
      "Train Epoch: 8 [19968/60000 (33%)]\tLoss: 0.983968\n",
      "Train Epoch: 8 [20096/60000 (34%)]\tLoss: 1.122572\n",
      "Train Epoch: 8 [20224/60000 (34%)]\tLoss: 1.003767\n",
      "Train Epoch: 8 [20352/60000 (34%)]\tLoss: 0.589623\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 1.044293\n",
      "Train Epoch: 8 [20608/60000 (34%)]\tLoss: 0.964612\n",
      "Train Epoch: 8 [20736/60000 (35%)]\tLoss: 0.942319\n",
      "Train Epoch: 8 [20864/60000 (35%)]\tLoss: 1.132116\n",
      "Train Epoch: 8 [20992/60000 (35%)]\tLoss: 0.949468\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.903307\n",
      "Train Epoch: 8 [21248/60000 (35%)]\tLoss: 0.788572\n",
      "Train Epoch: 8 [21376/60000 (36%)]\tLoss: 0.977997\n",
      "Train Epoch: 8 [21504/60000 (36%)]\tLoss: 0.928028\n",
      "Train Epoch: 8 [21632/60000 (36%)]\tLoss: 0.856412\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.658395\n",
      "Train Epoch: 8 [21888/60000 (37%)]\tLoss: 0.843718\n",
      "Train Epoch: 8 [22016/60000 (37%)]\tLoss: 0.802592\n",
      "Train Epoch: 8 [22144/60000 (37%)]\tLoss: 0.973455\n",
      "Train Epoch: 8 [22272/60000 (37%)]\tLoss: 0.780329\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.998803\n",
      "Train Epoch: 8 [22528/60000 (38%)]\tLoss: 1.266078\n",
      "Train Epoch: 8 [22656/60000 (38%)]\tLoss: 1.064634\n",
      "Train Epoch: 8 [22784/60000 (38%)]\tLoss: 0.767485\n",
      "Train Epoch: 8 [22912/60000 (38%)]\tLoss: 0.744366\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.867151\n",
      "Train Epoch: 8 [23168/60000 (39%)]\tLoss: 0.857019\n",
      "Train Epoch: 8 [23296/60000 (39%)]\tLoss: 0.697547\n",
      "Train Epoch: 8 [23424/60000 (39%)]\tLoss: 0.878219\n",
      "Train Epoch: 8 [23552/60000 (39%)]\tLoss: 0.889602\n",
      "Train Epoch: 8 [23680/60000 (40%)]\tLoss: 0.953251\n",
      "Train Epoch: 8 [23808/60000 (40%)]\tLoss: 0.936236\n",
      "Train Epoch: 8 [23936/60000 (40%)]\tLoss: 0.918808\n",
      "Train Epoch: 8 [24064/60000 (40%)]\tLoss: 0.856063\n",
      "Train Epoch: 8 [24192/60000 (40%)]\tLoss: 0.990138\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.722124\n",
      "Train Epoch: 8 [24448/60000 (41%)]\tLoss: 0.968232\n",
      "Train Epoch: 8 [24576/60000 (41%)]\tLoss: 0.991858\n",
      "Train Epoch: 8 [24704/60000 (41%)]\tLoss: 0.992344\n",
      "Train Epoch: 8 [24832/60000 (41%)]\tLoss: 1.006338\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.847026\n",
      "Train Epoch: 8 [25088/60000 (42%)]\tLoss: 0.879401\n",
      "Train Epoch: 8 [25216/60000 (42%)]\tLoss: 0.948511\n",
      "Train Epoch: 8 [25344/60000 (42%)]\tLoss: 0.722325\n",
      "Train Epoch: 8 [25472/60000 (43%)]\tLoss: 0.750513\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.849241\n",
      "Train Epoch: 8 [25728/60000 (43%)]\tLoss: 0.914341\n",
      "Train Epoch: 8 [25856/60000 (43%)]\tLoss: 0.811252\n",
      "Train Epoch: 8 [25984/60000 (43%)]\tLoss: 0.825985\n",
      "Train Epoch: 8 [26112/60000 (44%)]\tLoss: 0.920628\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.821948\n",
      "Train Epoch: 8 [26368/60000 (44%)]\tLoss: 0.967415\n",
      "Train Epoch: 8 [26496/60000 (44%)]\tLoss: 1.047624\n",
      "Train Epoch: 8 [26624/60000 (44%)]\tLoss: 1.202513\n",
      "Train Epoch: 8 [26752/60000 (45%)]\tLoss: 0.893699\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.854242\n",
      "Train Epoch: 8 [27008/60000 (45%)]\tLoss: 0.935672\n",
      "Train Epoch: 8 [27136/60000 (45%)]\tLoss: 1.235355\n",
      "Train Epoch: 8 [27264/60000 (46%)]\tLoss: 0.866590\n",
      "Train Epoch: 8 [27392/60000 (46%)]\tLoss: 0.941671\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.769842\n",
      "Train Epoch: 8 [27648/60000 (46%)]\tLoss: 0.819520\n",
      "Train Epoch: 8 [27776/60000 (46%)]\tLoss: 0.919168\n",
      "Train Epoch: 8 [27904/60000 (47%)]\tLoss: 0.769274\n",
      "Train Epoch: 8 [28032/60000 (47%)]\tLoss: 0.782627\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.882383\n",
      "Train Epoch: 8 [28288/60000 (47%)]\tLoss: 0.903027\n",
      "Train Epoch: 8 [28416/60000 (47%)]\tLoss: 0.977251\n",
      "Train Epoch: 8 [28544/60000 (48%)]\tLoss: 1.015664\n",
      "Train Epoch: 8 [28672/60000 (48%)]\tLoss: 0.881224\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.896528\n",
      "Train Epoch: 8 [28928/60000 (48%)]\tLoss: 0.896650\n",
      "Train Epoch: 8 [29056/60000 (49%)]\tLoss: 1.033878\n",
      "Train Epoch: 8 [29184/60000 (49%)]\tLoss: 0.953161\n",
      "Train Epoch: 8 [29312/60000 (49%)]\tLoss: 1.020026\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.847535\n",
      "Train Epoch: 8 [29568/60000 (49%)]\tLoss: 0.775920\n",
      "Train Epoch: 8 [29696/60000 (50%)]\tLoss: 1.079972\n",
      "Train Epoch: 8 [29824/60000 (50%)]\tLoss: 1.084601\n",
      "Train Epoch: 8 [29952/60000 (50%)]\tLoss: 1.051670\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 1.072264\n",
      "Train Epoch: 8 [30208/60000 (50%)]\tLoss: 0.892928\n",
      "Train Epoch: 8 [30336/60000 (51%)]\tLoss: 0.855156\n",
      "Train Epoch: 8 [30464/60000 (51%)]\tLoss: 0.959890\n",
      "Train Epoch: 8 [30592/60000 (51%)]\tLoss: 1.039516\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.799859\n",
      "Train Epoch: 8 [30848/60000 (51%)]\tLoss: 1.028738\n",
      "Train Epoch: 8 [30976/60000 (52%)]\tLoss: 0.860708\n",
      "Train Epoch: 8 [31104/60000 (52%)]\tLoss: 0.970568\n",
      "Train Epoch: 8 [31232/60000 (52%)]\tLoss: 1.050433\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.925633\n",
      "Train Epoch: 8 [31488/60000 (53%)]\tLoss: 0.901811\n",
      "Train Epoch: 8 [31616/60000 (53%)]\tLoss: 1.090827\n",
      "Train Epoch: 8 [31744/60000 (53%)]\tLoss: 0.870549\n",
      "Train Epoch: 8 [31872/60000 (53%)]\tLoss: 0.883984\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.048300\n",
      "Train Epoch: 8 [32128/60000 (54%)]\tLoss: 0.961321\n",
      "Train Epoch: 8 [32256/60000 (54%)]\tLoss: 1.127537\n",
      "Train Epoch: 8 [32384/60000 (54%)]\tLoss: 1.163680\n",
      "Train Epoch: 8 [32512/60000 (54%)]\tLoss: 0.850024\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.805570\n",
      "Train Epoch: 8 [32768/60000 (55%)]\tLoss: 0.922521\n",
      "Train Epoch: 8 [32896/60000 (55%)]\tLoss: 0.821030\n",
      "Train Epoch: 8 [33024/60000 (55%)]\tLoss: 0.920546\n",
      "Train Epoch: 8 [33152/60000 (55%)]\tLoss: 0.910298\n",
      "Train Epoch: 8 [33280/60000 (56%)]\tLoss: 0.973016\n",
      "Train Epoch: 8 [33408/60000 (56%)]\tLoss: 0.883020\n",
      "Train Epoch: 8 [33536/60000 (56%)]\tLoss: 0.887379\n",
      "Train Epoch: 8 [33664/60000 (56%)]\tLoss: 0.946243\n",
      "Train Epoch: 8 [33792/60000 (56%)]\tLoss: 0.678319\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.809097\n",
      "Train Epoch: 8 [34048/60000 (57%)]\tLoss: 0.975269\n",
      "Train Epoch: 8 [34176/60000 (57%)]\tLoss: 0.751299\n",
      "Train Epoch: 8 [34304/60000 (57%)]\tLoss: 0.897762\n",
      "Train Epoch: 8 [34432/60000 (57%)]\tLoss: 0.943135\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.910592\n",
      "Train Epoch: 8 [34688/60000 (58%)]\tLoss: 1.094383\n",
      "Train Epoch: 8 [34816/60000 (58%)]\tLoss: 1.093102\n",
      "Train Epoch: 8 [34944/60000 (58%)]\tLoss: 0.908396\n",
      "Train Epoch: 8 [35072/60000 (59%)]\tLoss: 0.892683\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.848277\n",
      "Train Epoch: 8 [35328/60000 (59%)]\tLoss: 0.856020\n",
      "Train Epoch: 8 [35456/60000 (59%)]\tLoss: 0.798901\n",
      "Train Epoch: 8 [35584/60000 (59%)]\tLoss: 0.957857\n",
      "Train Epoch: 8 [35712/60000 (60%)]\tLoss: 0.767336\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.919153\n",
      "Train Epoch: 8 [35968/60000 (60%)]\tLoss: 0.907621\n",
      "Train Epoch: 8 [36096/60000 (60%)]\tLoss: 0.880827\n",
      "Train Epoch: 8 [36224/60000 (60%)]\tLoss: 0.670171\n",
      "Train Epoch: 8 [36352/60000 (61%)]\tLoss: 0.887218\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.824833\n",
      "Train Epoch: 8 [36608/60000 (61%)]\tLoss: 0.668990\n",
      "Train Epoch: 8 [36736/60000 (61%)]\tLoss: 0.979220\n",
      "Train Epoch: 8 [36864/60000 (62%)]\tLoss: 0.694817\n",
      "Train Epoch: 8 [36992/60000 (62%)]\tLoss: 1.016174\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.908358\n",
      "Train Epoch: 8 [37248/60000 (62%)]\tLoss: 1.042533\n",
      "Train Epoch: 8 [37376/60000 (62%)]\tLoss: 1.279361\n",
      "Train Epoch: 8 [37504/60000 (63%)]\tLoss: 0.980431\n",
      "Train Epoch: 8 [37632/60000 (63%)]\tLoss: 0.909003\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.844878\n",
      "Train Epoch: 8 [37888/60000 (63%)]\tLoss: 0.903796\n",
      "Train Epoch: 8 [38016/60000 (63%)]\tLoss: 0.807601\n",
      "Train Epoch: 8 [38144/60000 (64%)]\tLoss: 0.963311\n",
      "Train Epoch: 8 [38272/60000 (64%)]\tLoss: 1.001199\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.787196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [38528/60000 (64%)]\tLoss: 1.078774\n",
      "Train Epoch: 8 [38656/60000 (65%)]\tLoss: 0.861306\n",
      "Train Epoch: 8 [38784/60000 (65%)]\tLoss: 0.765641\n",
      "Train Epoch: 8 [38912/60000 (65%)]\tLoss: 0.721364\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.697387\n",
      "Train Epoch: 8 [39168/60000 (65%)]\tLoss: 0.812777\n",
      "Train Epoch: 8 [39296/60000 (66%)]\tLoss: 1.247250\n",
      "Train Epoch: 8 [39424/60000 (66%)]\tLoss: 0.922936\n",
      "Train Epoch: 8 [39552/60000 (66%)]\tLoss: 0.838281\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 1.022069\n",
      "Train Epoch: 8 [39808/60000 (66%)]\tLoss: 1.046807\n",
      "Train Epoch: 8 [39936/60000 (67%)]\tLoss: 0.870454\n",
      "Train Epoch: 8 [40064/60000 (67%)]\tLoss: 0.869337\n",
      "Train Epoch: 8 [40192/60000 (67%)]\tLoss: 0.968542\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.797562\n",
      "Train Epoch: 8 [40448/60000 (68%)]\tLoss: 0.847736\n",
      "Train Epoch: 8 [40576/60000 (68%)]\tLoss: 0.932397\n",
      "Train Epoch: 8 [40704/60000 (68%)]\tLoss: 0.900447\n",
      "Train Epoch: 8 [40832/60000 (68%)]\tLoss: 0.761478\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.954401\n",
      "Train Epoch: 8 [41088/60000 (69%)]\tLoss: 0.948646\n",
      "Train Epoch: 8 [41216/60000 (69%)]\tLoss: 1.366101\n",
      "Train Epoch: 8 [41344/60000 (69%)]\tLoss: 1.056859\n",
      "Train Epoch: 8 [41472/60000 (69%)]\tLoss: 0.953804\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.781500\n",
      "Train Epoch: 8 [41728/60000 (70%)]\tLoss: 0.743301\n",
      "Train Epoch: 8 [41856/60000 (70%)]\tLoss: 0.862330\n",
      "Train Epoch: 8 [41984/60000 (70%)]\tLoss: 1.038372\n",
      "Train Epoch: 8 [42112/60000 (70%)]\tLoss: 1.017706\n",
      "Train Epoch: 8 [42240/60000 (71%)]\tLoss: 1.130896\n",
      "Train Epoch: 8 [42368/60000 (71%)]\tLoss: 0.963582\n",
      "Train Epoch: 8 [42496/60000 (71%)]\tLoss: 0.872150\n",
      "Train Epoch: 8 [42624/60000 (71%)]\tLoss: 1.015527\n",
      "Train Epoch: 8 [42752/60000 (71%)]\tLoss: 0.964686\n",
      "Train Epoch: 8 [42880/60000 (72%)]\tLoss: 1.113796\n",
      "Train Epoch: 8 [43008/60000 (72%)]\tLoss: 1.025405\n",
      "Train Epoch: 8 [43136/60000 (72%)]\tLoss: 0.818419\n",
      "Train Epoch: 8 [43264/60000 (72%)]\tLoss: 0.606043\n",
      "Train Epoch: 8 [43392/60000 (72%)]\tLoss: 0.700768\n",
      "Train Epoch: 8 [43520/60000 (73%)]\tLoss: 0.676850\n",
      "Train Epoch: 8 [43648/60000 (73%)]\tLoss: 0.844405\n",
      "Train Epoch: 8 [43776/60000 (73%)]\tLoss: 0.855006\n",
      "Train Epoch: 8 [43904/60000 (73%)]\tLoss: 0.928826\n",
      "Train Epoch: 8 [44032/60000 (74%)]\tLoss: 0.987571\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 1.013075\n",
      "Train Epoch: 8 [44288/60000 (74%)]\tLoss: 1.029134\n",
      "Train Epoch: 8 [44416/60000 (74%)]\tLoss: 0.930942\n",
      "Train Epoch: 8 [44544/60000 (74%)]\tLoss: 0.722873\n",
      "Train Epoch: 8 [44672/60000 (75%)]\tLoss: 0.744447\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.942810\n",
      "Train Epoch: 8 [44928/60000 (75%)]\tLoss: 0.927799\n",
      "Train Epoch: 8 [45056/60000 (75%)]\tLoss: 0.883215\n",
      "Train Epoch: 8 [45184/60000 (75%)]\tLoss: 0.834290\n",
      "Train Epoch: 8 [45312/60000 (76%)]\tLoss: 0.757149\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 1.045830\n",
      "Train Epoch: 8 [45568/60000 (76%)]\tLoss: 0.813089\n",
      "Train Epoch: 8 [45696/60000 (76%)]\tLoss: 0.961493\n",
      "Train Epoch: 8 [45824/60000 (76%)]\tLoss: 0.985161\n",
      "Train Epoch: 8 [45952/60000 (77%)]\tLoss: 0.924417\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.882909\n",
      "Train Epoch: 8 [46208/60000 (77%)]\tLoss: 0.935749\n",
      "Train Epoch: 8 [46336/60000 (77%)]\tLoss: 1.043768\n",
      "Train Epoch: 8 [46464/60000 (78%)]\tLoss: 0.764985\n",
      "Train Epoch: 8 [46592/60000 (78%)]\tLoss: 0.842941\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.873846\n",
      "Train Epoch: 8 [46848/60000 (78%)]\tLoss: 0.748867\n",
      "Train Epoch: 8 [46976/60000 (78%)]\tLoss: 0.816853\n",
      "Train Epoch: 8 [47104/60000 (79%)]\tLoss: 0.851761\n",
      "Train Epoch: 8 [47232/60000 (79%)]\tLoss: 1.062306\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 1.072317\n",
      "Train Epoch: 8 [47488/60000 (79%)]\tLoss: 1.029560\n",
      "Train Epoch: 8 [47616/60000 (79%)]\tLoss: 0.897858\n",
      "Train Epoch: 8 [47744/60000 (80%)]\tLoss: 0.749536\n",
      "Train Epoch: 8 [47872/60000 (80%)]\tLoss: 0.995512\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.758542\n",
      "Train Epoch: 8 [48128/60000 (80%)]\tLoss: 0.797464\n",
      "Train Epoch: 8 [48256/60000 (81%)]\tLoss: 0.852570\n",
      "Train Epoch: 8 [48384/60000 (81%)]\tLoss: 0.768950\n",
      "Train Epoch: 8 [48512/60000 (81%)]\tLoss: 0.742994\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.753365\n",
      "Train Epoch: 8 [48768/60000 (81%)]\tLoss: 0.755339\n",
      "Train Epoch: 8 [48896/60000 (82%)]\tLoss: 1.199388\n",
      "Train Epoch: 8 [49024/60000 (82%)]\tLoss: 1.044745\n",
      "Train Epoch: 8 [49152/60000 (82%)]\tLoss: 0.957447\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.661071\n",
      "Train Epoch: 8 [49408/60000 (82%)]\tLoss: 1.043265\n",
      "Train Epoch: 8 [49536/60000 (83%)]\tLoss: 1.220430\n",
      "Train Epoch: 8 [49664/60000 (83%)]\tLoss: 0.869619\n",
      "Train Epoch: 8 [49792/60000 (83%)]\tLoss: 0.935399\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.854553\n",
      "Train Epoch: 8 [50048/60000 (84%)]\tLoss: 0.853001\n",
      "Train Epoch: 8 [50176/60000 (84%)]\tLoss: 0.940537\n",
      "Train Epoch: 8 [50304/60000 (84%)]\tLoss: 1.498196\n",
      "Train Epoch: 8 [50432/60000 (84%)]\tLoss: 0.976124\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.901988\n",
      "Train Epoch: 8 [50688/60000 (85%)]\tLoss: 0.933465\n",
      "Train Epoch: 8 [50816/60000 (85%)]\tLoss: 0.860266\n",
      "Train Epoch: 8 [50944/60000 (85%)]\tLoss: 0.745290\n",
      "Train Epoch: 8 [51072/60000 (85%)]\tLoss: 0.898730\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.854094\n",
      "Train Epoch: 8 [51328/60000 (86%)]\tLoss: 0.886975\n",
      "Train Epoch: 8 [51456/60000 (86%)]\tLoss: 0.809600\n",
      "Train Epoch: 8 [51584/60000 (86%)]\tLoss: 0.747128\n",
      "Train Epoch: 8 [51712/60000 (86%)]\tLoss: 1.004051\n",
      "Train Epoch: 8 [51840/60000 (87%)]\tLoss: 0.834423\n",
      "Train Epoch: 8 [51968/60000 (87%)]\tLoss: 1.096883\n",
      "Train Epoch: 8 [52096/60000 (87%)]\tLoss: 1.046409\n",
      "Train Epoch: 8 [52224/60000 (87%)]\tLoss: 1.036977\n",
      "Train Epoch: 8 [52352/60000 (87%)]\tLoss: 0.781468\n",
      "Train Epoch: 8 [52480/60000 (88%)]\tLoss: 0.581330\n",
      "Train Epoch: 8 [52608/60000 (88%)]\tLoss: 0.818989\n",
      "Train Epoch: 8 [52736/60000 (88%)]\tLoss: 1.087838\n",
      "Train Epoch: 8 [52864/60000 (88%)]\tLoss: 1.200901\n",
      "Train Epoch: 8 [52992/60000 (88%)]\tLoss: 0.989802\n",
      "Train Epoch: 8 [53120/60000 (89%)]\tLoss: 0.955170\n",
      "Train Epoch: 8 [53248/60000 (89%)]\tLoss: 0.814959\n",
      "Train Epoch: 8 [53376/60000 (89%)]\tLoss: 0.710242\n",
      "Train Epoch: 8 [53504/60000 (89%)]\tLoss: 0.903947\n",
      "Train Epoch: 8 [53632/60000 (90%)]\tLoss: 0.822998\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.753897\n",
      "Train Epoch: 8 [53888/60000 (90%)]\tLoss: 0.870643\n",
      "Train Epoch: 8 [54016/60000 (90%)]\tLoss: 1.002185\n",
      "Train Epoch: 8 [54144/60000 (90%)]\tLoss: 0.721488\n",
      "Train Epoch: 8 [54272/60000 (91%)]\tLoss: 0.918153\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.637054\n",
      "Train Epoch: 8 [54528/60000 (91%)]\tLoss: 0.832836\n",
      "Train Epoch: 8 [54656/60000 (91%)]\tLoss: 0.732960\n",
      "Train Epoch: 8 [54784/60000 (91%)]\tLoss: 0.915502\n",
      "Train Epoch: 8 [54912/60000 (92%)]\tLoss: 1.121471\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.713128\n",
      "Train Epoch: 8 [55168/60000 (92%)]\tLoss: 0.814973\n",
      "Train Epoch: 8 [55296/60000 (92%)]\tLoss: 0.744567\n",
      "Train Epoch: 8 [55424/60000 (93%)]\tLoss: 0.791840\n",
      "Train Epoch: 8 [55552/60000 (93%)]\tLoss: 0.779091\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.859777\n",
      "Train Epoch: 8 [55808/60000 (93%)]\tLoss: 0.808232\n",
      "Train Epoch: 8 [55936/60000 (93%)]\tLoss: 0.711274\n",
      "Train Epoch: 8 [56064/60000 (94%)]\tLoss: 0.741437\n",
      "Train Epoch: 8 [56192/60000 (94%)]\tLoss: 0.983153\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.832507\n",
      "Train Epoch: 8 [56448/60000 (94%)]\tLoss: 0.753948\n",
      "Train Epoch: 8 [56576/60000 (94%)]\tLoss: 0.943750\n",
      "Train Epoch: 8 [56704/60000 (95%)]\tLoss: 0.635766\n",
      "Train Epoch: 8 [56832/60000 (95%)]\tLoss: 0.810555\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.856404\n",
      "Train Epoch: 8 [57088/60000 (95%)]\tLoss: 0.757301\n",
      "Train Epoch: 8 [57216/60000 (96%)]\tLoss: 0.960665\n",
      "Train Epoch: 8 [57344/60000 (96%)]\tLoss: 0.825429\n",
      "Train Epoch: 8 [57472/60000 (96%)]\tLoss: 0.866967\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 1.027510\n",
      "Train Epoch: 8 [57728/60000 (96%)]\tLoss: 0.810509\n",
      "Train Epoch: 8 [57856/60000 (97%)]\tLoss: 0.702752\n",
      "Train Epoch: 8 [57984/60000 (97%)]\tLoss: 0.877236\n",
      "Train Epoch: 8 [58112/60000 (97%)]\tLoss: 0.655557\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.727070\n",
      "Train Epoch: 8 [58368/60000 (97%)]\tLoss: 0.717138\n",
      "Train Epoch: 8 [58496/60000 (98%)]\tLoss: 0.825218\n",
      "Train Epoch: 8 [58624/60000 (98%)]\tLoss: 0.657616\n",
      "Train Epoch: 8 [58752/60000 (98%)]\tLoss: 0.856226\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.523842\n",
      "Train Epoch: 8 [59008/60000 (99%)]\tLoss: 0.491676\n",
      "Train Epoch: 8 [59136/60000 (99%)]\tLoss: 0.579963\n",
      "Train Epoch: 8 [59264/60000 (99%)]\tLoss: 1.044205\n",
      "Train Epoch: 8 [59392/60000 (99%)]\tLoss: 0.793353\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.722301\n",
      "Train Epoch: 8 [59648/60000 (100%)]\tLoss: 1.011883\n",
      "Train Epoch: 8 [59776/60000 (100%)]\tLoss: 0.598566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Training: Average loss: 0.3017, Accuracy: 55168/60000 (92%)\n",
      "Test: Average loss: 0.2856, Accuracy: 9233/10000 (92%)\n",
      "================================================================\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.688864\n",
      "Train Epoch: 9 [128/60000 (0%)]\tLoss: 0.961204\n",
      "Train Epoch: 9 [256/60000 (0%)]\tLoss: 0.725704\n",
      "Train Epoch: 9 [384/60000 (1%)]\tLoss: 0.879632\n",
      "Train Epoch: 9 [512/60000 (1%)]\tLoss: 1.024451\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.779481\n",
      "Train Epoch: 9 [768/60000 (1%)]\tLoss: 0.963135\n",
      "Train Epoch: 9 [896/60000 (1%)]\tLoss: 1.096658\n",
      "Train Epoch: 9 [1024/60000 (2%)]\tLoss: 1.185683\n",
      "Train Epoch: 9 [1152/60000 (2%)]\tLoss: 0.919065\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.959515\n",
      "Train Epoch: 9 [1408/60000 (2%)]\tLoss: 0.895580\n",
      "Train Epoch: 9 [1536/60000 (3%)]\tLoss: 0.848925\n",
      "Train Epoch: 9 [1664/60000 (3%)]\tLoss: 0.692486\n",
      "Train Epoch: 9 [1792/60000 (3%)]\tLoss: 0.802715\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.831672\n",
      "Train Epoch: 9 [2048/60000 (3%)]\tLoss: 0.721373\n",
      "Train Epoch: 9 [2176/60000 (4%)]\tLoss: 0.751029\n",
      "Train Epoch: 9 [2304/60000 (4%)]\tLoss: 0.867270\n",
      "Train Epoch: 9 [2432/60000 (4%)]\tLoss: 0.694503\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.722965\n",
      "Train Epoch: 9 [2688/60000 (4%)]\tLoss: 0.816518\n",
      "Train Epoch: 9 [2816/60000 (5%)]\tLoss: 0.977890\n",
      "Train Epoch: 9 [2944/60000 (5%)]\tLoss: 0.890277\n",
      "Train Epoch: 9 [3072/60000 (5%)]\tLoss: 0.902491\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.828537\n",
      "Train Epoch: 9 [3328/60000 (6%)]\tLoss: 0.925717\n",
      "Train Epoch: 9 [3456/60000 (6%)]\tLoss: 0.874460\n",
      "Train Epoch: 9 [3584/60000 (6%)]\tLoss: 0.840535\n",
      "Train Epoch: 9 [3712/60000 (6%)]\tLoss: 0.916076\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.679731\n",
      "Train Epoch: 9 [3968/60000 (7%)]\tLoss: 0.817059\n",
      "Train Epoch: 9 [4096/60000 (7%)]\tLoss: 0.831250\n",
      "Train Epoch: 9 [4224/60000 (7%)]\tLoss: 0.817118\n",
      "Train Epoch: 9 [4352/60000 (7%)]\tLoss: 1.014232\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.653575\n",
      "Train Epoch: 9 [4608/60000 (8%)]\tLoss: 0.861662\n",
      "Train Epoch: 9 [4736/60000 (8%)]\tLoss: 0.914165\n",
      "Train Epoch: 9 [4864/60000 (8%)]\tLoss: 0.924043\n",
      "Train Epoch: 9 [4992/60000 (8%)]\tLoss: 0.821733\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 1.012084\n",
      "Train Epoch: 9 [5248/60000 (9%)]\tLoss: 0.874507\n",
      "Train Epoch: 9 [5376/60000 (9%)]\tLoss: 0.691178\n",
      "Train Epoch: 9 [5504/60000 (9%)]\tLoss: 0.839726\n",
      "Train Epoch: 9 [5632/60000 (9%)]\tLoss: 0.768554\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.919457\n",
      "Train Epoch: 9 [5888/60000 (10%)]\tLoss: 0.787940\n",
      "Train Epoch: 9 [6016/60000 (10%)]\tLoss: 0.618401\n",
      "Train Epoch: 9 [6144/60000 (10%)]\tLoss: 0.920694\n",
      "Train Epoch: 9 [6272/60000 (10%)]\tLoss: 0.757843\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.827843\n",
      "Train Epoch: 9 [6528/60000 (11%)]\tLoss: 0.721367\n",
      "Train Epoch: 9 [6656/60000 (11%)]\tLoss: 0.856064\n",
      "Train Epoch: 9 [6784/60000 (11%)]\tLoss: 0.936196\n",
      "Train Epoch: 9 [6912/60000 (12%)]\tLoss: 0.984412\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.717415\n",
      "Train Epoch: 9 [7168/60000 (12%)]\tLoss: 0.927639\n",
      "Train Epoch: 9 [7296/60000 (12%)]\tLoss: 0.918563\n",
      "Train Epoch: 9 [7424/60000 (12%)]\tLoss: 0.766862\n",
      "Train Epoch: 9 [7552/60000 (13%)]\tLoss: 0.764088\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.844258\n",
      "Train Epoch: 9 [7808/60000 (13%)]\tLoss: 1.064815\n",
      "Train Epoch: 9 [7936/60000 (13%)]\tLoss: 0.766524\n",
      "Train Epoch: 9 [8064/60000 (13%)]\tLoss: 0.930772\n",
      "Train Epoch: 9 [8192/60000 (14%)]\tLoss: 0.981147\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.848669\n",
      "Train Epoch: 9 [8448/60000 (14%)]\tLoss: 0.812866\n",
      "Train Epoch: 9 [8576/60000 (14%)]\tLoss: 1.044313\n",
      "Train Epoch: 9 [8704/60000 (15%)]\tLoss: 1.166393\n",
      "Train Epoch: 9 [8832/60000 (15%)]\tLoss: 1.287933\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.702215\n",
      "Train Epoch: 9 [9088/60000 (15%)]\tLoss: 0.847492\n",
      "Train Epoch: 9 [9216/60000 (15%)]\tLoss: 0.827465\n",
      "Train Epoch: 9 [9344/60000 (16%)]\tLoss: 0.718045\n",
      "Train Epoch: 9 [9472/60000 (16%)]\tLoss: 0.951094\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.680859\n",
      "Train Epoch: 9 [9728/60000 (16%)]\tLoss: 0.888148\n",
      "Train Epoch: 9 [9856/60000 (16%)]\tLoss: 0.796460\n",
      "Train Epoch: 9 [9984/60000 (17%)]\tLoss: 0.775823\n",
      "Train Epoch: 9 [10112/60000 (17%)]\tLoss: 0.771265\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.994669\n",
      "Train Epoch: 9 [10368/60000 (17%)]\tLoss: 0.672061\n",
      "Train Epoch: 9 [10496/60000 (18%)]\tLoss: 0.743562\n",
      "Train Epoch: 9 [10624/60000 (18%)]\tLoss: 0.792948\n",
      "Train Epoch: 9 [10752/60000 (18%)]\tLoss: 1.008733\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 1.002220\n",
      "Train Epoch: 9 [11008/60000 (18%)]\tLoss: 0.810740\n",
      "Train Epoch: 9 [11136/60000 (19%)]\tLoss: 0.899058\n",
      "Train Epoch: 9 [11264/60000 (19%)]\tLoss: 0.863881\n",
      "Train Epoch: 9 [11392/60000 (19%)]\tLoss: 0.903106\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 1.216544\n",
      "Train Epoch: 9 [11648/60000 (19%)]\tLoss: 1.033795\n",
      "Train Epoch: 9 [11776/60000 (20%)]\tLoss: 0.888946\n",
      "Train Epoch: 9 [11904/60000 (20%)]\tLoss: 0.836838\n",
      "Train Epoch: 9 [12032/60000 (20%)]\tLoss: 0.963659\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.844441\n",
      "Train Epoch: 9 [12288/60000 (21%)]\tLoss: 1.016653\n",
      "Train Epoch: 9 [12416/60000 (21%)]\tLoss: 1.048160\n",
      "Train Epoch: 9 [12544/60000 (21%)]\tLoss: 1.022928\n",
      "Train Epoch: 9 [12672/60000 (21%)]\tLoss: 0.811943\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.791803\n",
      "Train Epoch: 9 [12928/60000 (22%)]\tLoss: 1.074742\n",
      "Train Epoch: 9 [13056/60000 (22%)]\tLoss: 1.113408\n",
      "Train Epoch: 9 [13184/60000 (22%)]\tLoss: 0.748897\n",
      "Train Epoch: 9 [13312/60000 (22%)]\tLoss: 0.848953\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.752861\n",
      "Train Epoch: 9 [13568/60000 (23%)]\tLoss: 0.825269\n",
      "Train Epoch: 9 [13696/60000 (23%)]\tLoss: 0.903868\n",
      "Train Epoch: 9 [13824/60000 (23%)]\tLoss: 0.775368\n",
      "Train Epoch: 9 [13952/60000 (23%)]\tLoss: 1.124357\n",
      "Train Epoch: 9 [14080/60000 (24%)]\tLoss: 0.864239\n",
      "Train Epoch: 9 [14208/60000 (24%)]\tLoss: 1.054852\n",
      "Train Epoch: 9 [14336/60000 (24%)]\tLoss: 1.102623\n",
      "Train Epoch: 9 [14464/60000 (24%)]\tLoss: 0.862566\n",
      "Train Epoch: 9 [14592/60000 (24%)]\tLoss: 1.318351\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 1.103135\n",
      "Train Epoch: 9 [14848/60000 (25%)]\tLoss: 0.765065\n",
      "Train Epoch: 9 [14976/60000 (25%)]\tLoss: 0.765331\n",
      "Train Epoch: 9 [15104/60000 (25%)]\tLoss: 1.005244\n",
      "Train Epoch: 9 [15232/60000 (25%)]\tLoss: 0.893586\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.761841\n",
      "Train Epoch: 9 [15488/60000 (26%)]\tLoss: 0.844442\n",
      "Train Epoch: 9 [15616/60000 (26%)]\tLoss: 0.805507\n",
      "Train Epoch: 9 [15744/60000 (26%)]\tLoss: 1.208745\n",
      "Train Epoch: 9 [15872/60000 (26%)]\tLoss: 1.031035\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 1.017508\n",
      "Train Epoch: 9 [16128/60000 (27%)]\tLoss: 0.741865\n",
      "Train Epoch: 9 [16256/60000 (27%)]\tLoss: 0.714564\n",
      "Train Epoch: 9 [16384/60000 (27%)]\tLoss: 0.800915\n",
      "Train Epoch: 9 [16512/60000 (28%)]\tLoss: 0.722894\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.943187\n",
      "Train Epoch: 9 [16768/60000 (28%)]\tLoss: 1.043111\n",
      "Train Epoch: 9 [16896/60000 (28%)]\tLoss: 0.999762\n",
      "Train Epoch: 9 [17024/60000 (28%)]\tLoss: 1.043345\n",
      "Train Epoch: 9 [17152/60000 (29%)]\tLoss: 0.900646\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.683761\n",
      "Train Epoch: 9 [17408/60000 (29%)]\tLoss: 0.963711\n",
      "Train Epoch: 9 [17536/60000 (29%)]\tLoss: 1.063155\n",
      "Train Epoch: 9 [17664/60000 (29%)]\tLoss: 0.897509\n",
      "Train Epoch: 9 [17792/60000 (30%)]\tLoss: 0.950014\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.778842\n",
      "Train Epoch: 9 [18048/60000 (30%)]\tLoss: 0.770992\n",
      "Train Epoch: 9 [18176/60000 (30%)]\tLoss: 0.658780\n",
      "Train Epoch: 9 [18304/60000 (31%)]\tLoss: 0.887367\n",
      "Train Epoch: 9 [18432/60000 (31%)]\tLoss: 0.778033\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.889439\n",
      "Train Epoch: 9 [18688/60000 (31%)]\tLoss: 0.856001\n",
      "Train Epoch: 9 [18816/60000 (31%)]\tLoss: 0.711151\n",
      "Train Epoch: 9 [18944/60000 (32%)]\tLoss: 0.989883\n",
      "Train Epoch: 9 [19072/60000 (32%)]\tLoss: 1.011763\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.903787\n",
      "Train Epoch: 9 [19328/60000 (32%)]\tLoss: 0.879456\n",
      "Train Epoch: 9 [19456/60000 (32%)]\tLoss: 0.950621\n",
      "Train Epoch: 9 [19584/60000 (33%)]\tLoss: 0.746122\n",
      "Train Epoch: 9 [19712/60000 (33%)]\tLoss: 0.745517\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.837939\n",
      "Train Epoch: 9 [19968/60000 (33%)]\tLoss: 0.986570\n",
      "Train Epoch: 9 [20096/60000 (34%)]\tLoss: 0.931160\n",
      "Train Epoch: 9 [20224/60000 (34%)]\tLoss: 0.927079\n",
      "Train Epoch: 9 [20352/60000 (34%)]\tLoss: 0.674254\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.900968\n",
      "Train Epoch: 9 [20608/60000 (34%)]\tLoss: 0.975222\n",
      "Train Epoch: 9 [20736/60000 (35%)]\tLoss: 1.075459\n",
      "Train Epoch: 9 [20864/60000 (35%)]\tLoss: 1.120014\n",
      "Train Epoch: 9 [20992/60000 (35%)]\tLoss: 0.729808\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.864692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [21248/60000 (35%)]\tLoss: 0.816383\n",
      "Train Epoch: 9 [21376/60000 (36%)]\tLoss: 0.907150\n",
      "Train Epoch: 9 [21504/60000 (36%)]\tLoss: 0.970526\n",
      "Train Epoch: 9 [21632/60000 (36%)]\tLoss: 0.882759\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.594517\n",
      "Train Epoch: 9 [21888/60000 (37%)]\tLoss: 0.712533\n",
      "Train Epoch: 9 [22016/60000 (37%)]\tLoss: 0.885149\n",
      "Train Epoch: 9 [22144/60000 (37%)]\tLoss: 0.925642\n",
      "Train Epoch: 9 [22272/60000 (37%)]\tLoss: 0.809460\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.964160\n",
      "Train Epoch: 9 [22528/60000 (38%)]\tLoss: 1.155730\n",
      "Train Epoch: 9 [22656/60000 (38%)]\tLoss: 0.903325\n",
      "Train Epoch: 9 [22784/60000 (38%)]\tLoss: 0.796273\n",
      "Train Epoch: 9 [22912/60000 (38%)]\tLoss: 0.675368\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.849849\n",
      "Train Epoch: 9 [23168/60000 (39%)]\tLoss: 0.858223\n",
      "Train Epoch: 9 [23296/60000 (39%)]\tLoss: 0.837628\n",
      "Train Epoch: 9 [23424/60000 (39%)]\tLoss: 0.759517\n",
      "Train Epoch: 9 [23552/60000 (39%)]\tLoss: 0.853977\n",
      "Train Epoch: 9 [23680/60000 (40%)]\tLoss: 0.871801\n",
      "Train Epoch: 9 [23808/60000 (40%)]\tLoss: 0.983113\n",
      "Train Epoch: 9 [23936/60000 (40%)]\tLoss: 0.957289\n",
      "Train Epoch: 9 [24064/60000 (40%)]\tLoss: 0.742163\n",
      "Train Epoch: 9 [24192/60000 (40%)]\tLoss: 0.966714\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.805400\n",
      "Train Epoch: 9 [24448/60000 (41%)]\tLoss: 0.897873\n",
      "Train Epoch: 9 [24576/60000 (41%)]\tLoss: 0.873640\n",
      "Train Epoch: 9 [24704/60000 (41%)]\tLoss: 1.092887\n",
      "Train Epoch: 9 [24832/60000 (41%)]\tLoss: 1.096862\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.739292\n",
      "Train Epoch: 9 [25088/60000 (42%)]\tLoss: 0.891723\n",
      "Train Epoch: 9 [25216/60000 (42%)]\tLoss: 0.790844\n",
      "Train Epoch: 9 [25344/60000 (42%)]\tLoss: 0.616956\n",
      "Train Epoch: 9 [25472/60000 (43%)]\tLoss: 0.912841\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.881248\n",
      "Train Epoch: 9 [25728/60000 (43%)]\tLoss: 0.917913\n",
      "Train Epoch: 9 [25856/60000 (43%)]\tLoss: 0.840348\n",
      "Train Epoch: 9 [25984/60000 (43%)]\tLoss: 0.808480\n",
      "Train Epoch: 9 [26112/60000 (44%)]\tLoss: 0.775638\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.804956\n",
      "Train Epoch: 9 [26368/60000 (44%)]\tLoss: 0.985102\n",
      "Train Epoch: 9 [26496/60000 (44%)]\tLoss: 0.859220\n",
      "Train Epoch: 9 [26624/60000 (44%)]\tLoss: 1.016592\n",
      "Train Epoch: 9 [26752/60000 (45%)]\tLoss: 0.866946\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.709282\n",
      "Train Epoch: 9 [27008/60000 (45%)]\tLoss: 0.918542\n",
      "Train Epoch: 9 [27136/60000 (45%)]\tLoss: 1.050795\n",
      "Train Epoch: 9 [27264/60000 (46%)]\tLoss: 0.875088\n",
      "Train Epoch: 9 [27392/60000 (46%)]\tLoss: 0.877350\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.873796\n",
      "Train Epoch: 9 [27648/60000 (46%)]\tLoss: 0.927357\n",
      "Train Epoch: 9 [27776/60000 (46%)]\tLoss: 0.878208\n",
      "Train Epoch: 9 [27904/60000 (47%)]\tLoss: 0.802671\n",
      "Train Epoch: 9 [28032/60000 (47%)]\tLoss: 0.744971\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.899930\n",
      "Train Epoch: 9 [28288/60000 (47%)]\tLoss: 0.904085\n",
      "Train Epoch: 9 [28416/60000 (47%)]\tLoss: 0.862696\n",
      "Train Epoch: 9 [28544/60000 (48%)]\tLoss: 1.081362\n",
      "Train Epoch: 9 [28672/60000 (48%)]\tLoss: 0.934744\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.697869\n",
      "Train Epoch: 9 [28928/60000 (48%)]\tLoss: 0.881419\n",
      "Train Epoch: 9 [29056/60000 (49%)]\tLoss: 1.005790\n",
      "Train Epoch: 9 [29184/60000 (49%)]\tLoss: 0.812661\n",
      "Train Epoch: 9 [29312/60000 (49%)]\tLoss: 0.962996\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.649932\n",
      "Train Epoch: 9 [29568/60000 (49%)]\tLoss: 0.792489\n",
      "Train Epoch: 9 [29696/60000 (50%)]\tLoss: 0.956676\n",
      "Train Epoch: 9 [29824/60000 (50%)]\tLoss: 0.940589\n",
      "Train Epoch: 9 [29952/60000 (50%)]\tLoss: 1.006889\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.992038\n",
      "Train Epoch: 9 [30208/60000 (50%)]\tLoss: 0.785894\n",
      "Train Epoch: 9 [30336/60000 (51%)]\tLoss: 0.813488\n",
      "Train Epoch: 9 [30464/60000 (51%)]\tLoss: 0.930725\n",
      "Train Epoch: 9 [30592/60000 (51%)]\tLoss: 1.045290\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.840576\n",
      "Train Epoch: 9 [30848/60000 (51%)]\tLoss: 1.016495\n",
      "Train Epoch: 9 [30976/60000 (52%)]\tLoss: 0.853911\n",
      "Train Epoch: 9 [31104/60000 (52%)]\tLoss: 0.946132\n",
      "Train Epoch: 9 [31232/60000 (52%)]\tLoss: 0.937837\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 1.017180\n",
      "Train Epoch: 9 [31488/60000 (53%)]\tLoss: 0.741663\n",
      "Train Epoch: 9 [31616/60000 (53%)]\tLoss: 1.242036\n",
      "Train Epoch: 9 [31744/60000 (53%)]\tLoss: 0.866818\n",
      "Train Epoch: 9 [31872/60000 (53%)]\tLoss: 0.892666\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.872422\n",
      "Train Epoch: 9 [32128/60000 (54%)]\tLoss: 0.884618\n",
      "Train Epoch: 9 [32256/60000 (54%)]\tLoss: 1.023564\n",
      "Train Epoch: 9 [32384/60000 (54%)]\tLoss: 1.133383\n",
      "Train Epoch: 9 [32512/60000 (54%)]\tLoss: 0.737651\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.677575\n",
      "Train Epoch: 9 [32768/60000 (55%)]\tLoss: 0.952422\n",
      "Train Epoch: 9 [32896/60000 (55%)]\tLoss: 0.786773\n",
      "Train Epoch: 9 [33024/60000 (55%)]\tLoss: 0.848300\n",
      "Train Epoch: 9 [33152/60000 (55%)]\tLoss: 0.816437\n",
      "Train Epoch: 9 [33280/60000 (56%)]\tLoss: 0.769591\n",
      "Train Epoch: 9 [33408/60000 (56%)]\tLoss: 0.934168\n",
      "Train Epoch: 9 [33536/60000 (56%)]\tLoss: 0.800983\n",
      "Train Epoch: 9 [33664/60000 (56%)]\tLoss: 0.809622\n",
      "Train Epoch: 9 [33792/60000 (56%)]\tLoss: 0.692238\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.797263\n",
      "Train Epoch: 9 [34048/60000 (57%)]\tLoss: 0.828936\n",
      "Train Epoch: 9 [34176/60000 (57%)]\tLoss: 0.731798\n",
      "Train Epoch: 9 [34304/60000 (57%)]\tLoss: 0.897292\n",
      "Train Epoch: 9 [34432/60000 (57%)]\tLoss: 0.860534\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 1.049117\n",
      "Train Epoch: 9 [34688/60000 (58%)]\tLoss: 0.992773\n",
      "Train Epoch: 9 [34816/60000 (58%)]\tLoss: 1.070712\n",
      "Train Epoch: 9 [34944/60000 (58%)]\tLoss: 0.916463\n",
      "Train Epoch: 9 [35072/60000 (59%)]\tLoss: 0.804653\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.831868\n",
      "Train Epoch: 9 [35328/60000 (59%)]\tLoss: 0.700304\n",
      "Train Epoch: 9 [35456/60000 (59%)]\tLoss: 0.809247\n",
      "Train Epoch: 9 [35584/60000 (59%)]\tLoss: 0.866583\n",
      "Train Epoch: 9 [35712/60000 (60%)]\tLoss: 0.771217\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.747369\n",
      "Train Epoch: 9 [35968/60000 (60%)]\tLoss: 0.960256\n",
      "Train Epoch: 9 [36096/60000 (60%)]\tLoss: 0.881741\n",
      "Train Epoch: 9 [36224/60000 (60%)]\tLoss: 0.753062\n",
      "Train Epoch: 9 [36352/60000 (61%)]\tLoss: 0.873492\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.861031\n",
      "Train Epoch: 9 [36608/60000 (61%)]\tLoss: 0.840984\n",
      "Train Epoch: 9 [36736/60000 (61%)]\tLoss: 0.809681\n",
      "Train Epoch: 9 [36864/60000 (62%)]\tLoss: 0.835385\n",
      "Train Epoch: 9 [36992/60000 (62%)]\tLoss: 1.095000\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.871322\n",
      "Train Epoch: 9 [37248/60000 (62%)]\tLoss: 1.094231\n",
      "Train Epoch: 9 [37376/60000 (62%)]\tLoss: 1.136550\n",
      "Train Epoch: 9 [37504/60000 (63%)]\tLoss: 0.903190\n",
      "Train Epoch: 9 [37632/60000 (63%)]\tLoss: 0.832065\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.747148\n",
      "Train Epoch: 9 [37888/60000 (63%)]\tLoss: 0.868290\n",
      "Train Epoch: 9 [38016/60000 (63%)]\tLoss: 0.794749\n",
      "Train Epoch: 9 [38144/60000 (64%)]\tLoss: 1.004012\n",
      "Train Epoch: 9 [38272/60000 (64%)]\tLoss: 1.003214\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.686183\n",
      "Train Epoch: 9 [38528/60000 (64%)]\tLoss: 0.947844\n",
      "Train Epoch: 9 [38656/60000 (65%)]\tLoss: 0.944985\n",
      "Train Epoch: 9 [38784/60000 (65%)]\tLoss: 0.682558\n",
      "Train Epoch: 9 [38912/60000 (65%)]\tLoss: 0.925022\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.740569\n",
      "Train Epoch: 9 [39168/60000 (65%)]\tLoss: 0.842741\n",
      "Train Epoch: 9 [39296/60000 (66%)]\tLoss: 1.005414\n",
      "Train Epoch: 9 [39424/60000 (66%)]\tLoss: 1.018011\n",
      "Train Epoch: 9 [39552/60000 (66%)]\tLoss: 0.911287\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.993140\n",
      "Train Epoch: 9 [39808/60000 (66%)]\tLoss: 1.004425\n",
      "Train Epoch: 9 [39936/60000 (67%)]\tLoss: 0.730908\n",
      "Train Epoch: 9 [40064/60000 (67%)]\tLoss: 0.848365\n",
      "Train Epoch: 9 [40192/60000 (67%)]\tLoss: 0.900127\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.853540\n",
      "Train Epoch: 9 [40448/60000 (68%)]\tLoss: 0.736305\n",
      "Train Epoch: 9 [40576/60000 (68%)]\tLoss: 0.827988\n",
      "Train Epoch: 9 [40704/60000 (68%)]\tLoss: 0.824688\n",
      "Train Epoch: 9 [40832/60000 (68%)]\tLoss: 0.758494\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.845151\n",
      "Train Epoch: 9 [41088/60000 (69%)]\tLoss: 0.752604\n",
      "Train Epoch: 9 [41216/60000 (69%)]\tLoss: 1.230292\n",
      "Train Epoch: 9 [41344/60000 (69%)]\tLoss: 1.008136\n",
      "Train Epoch: 9 [41472/60000 (69%)]\tLoss: 1.031152\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.835109\n",
      "Train Epoch: 9 [41728/60000 (70%)]\tLoss: 0.836890\n",
      "Train Epoch: 9 [41856/60000 (70%)]\tLoss: 0.832800\n",
      "Train Epoch: 9 [41984/60000 (70%)]\tLoss: 0.894894\n",
      "Train Epoch: 9 [42112/60000 (70%)]\tLoss: 0.964661\n",
      "Train Epoch: 9 [42240/60000 (71%)]\tLoss: 1.075485\n",
      "Train Epoch: 9 [42368/60000 (71%)]\tLoss: 0.952742\n",
      "Train Epoch: 9 [42496/60000 (71%)]\tLoss: 0.923226\n",
      "Train Epoch: 9 [42624/60000 (71%)]\tLoss: 0.925851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [42752/60000 (71%)]\tLoss: 0.975184\n",
      "Train Epoch: 9 [42880/60000 (72%)]\tLoss: 1.004514\n",
      "Train Epoch: 9 [43008/60000 (72%)]\tLoss: 1.082426\n",
      "Train Epoch: 9 [43136/60000 (72%)]\tLoss: 0.844962\n",
      "Train Epoch: 9 [43264/60000 (72%)]\tLoss: 0.717296\n",
      "Train Epoch: 9 [43392/60000 (72%)]\tLoss: 0.690689\n",
      "Train Epoch: 9 [43520/60000 (73%)]\tLoss: 0.671771\n",
      "Train Epoch: 9 [43648/60000 (73%)]\tLoss: 0.942545\n",
      "Train Epoch: 9 [43776/60000 (73%)]\tLoss: 0.965612\n",
      "Train Epoch: 9 [43904/60000 (73%)]\tLoss: 0.884820\n",
      "Train Epoch: 9 [44032/60000 (74%)]\tLoss: 0.861668\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.986639\n",
      "Train Epoch: 9 [44288/60000 (74%)]\tLoss: 0.834007\n",
      "Train Epoch: 9 [44416/60000 (74%)]\tLoss: 1.026369\n",
      "Train Epoch: 9 [44544/60000 (74%)]\tLoss: 0.586651\n",
      "Train Epoch: 9 [44672/60000 (75%)]\tLoss: 0.829755\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.926782\n",
      "Train Epoch: 9 [44928/60000 (75%)]\tLoss: 0.913379\n",
      "Train Epoch: 9 [45056/60000 (75%)]\tLoss: 0.925028\n",
      "Train Epoch: 9 [45184/60000 (75%)]\tLoss: 0.655592\n",
      "Train Epoch: 9 [45312/60000 (76%)]\tLoss: 0.902141\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.929961\n",
      "Train Epoch: 9 [45568/60000 (76%)]\tLoss: 0.873852\n",
      "Train Epoch: 9 [45696/60000 (76%)]\tLoss: 0.848891\n",
      "Train Epoch: 9 [45824/60000 (76%)]\tLoss: 0.977990\n",
      "Train Epoch: 9 [45952/60000 (77%)]\tLoss: 1.039698\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.848175\n",
      "Train Epoch: 9 [46208/60000 (77%)]\tLoss: 1.020797\n",
      "Train Epoch: 9 [46336/60000 (77%)]\tLoss: 0.830852\n",
      "Train Epoch: 9 [46464/60000 (78%)]\tLoss: 0.738997\n",
      "Train Epoch: 9 [46592/60000 (78%)]\tLoss: 0.772683\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.789234\n",
      "Train Epoch: 9 [46848/60000 (78%)]\tLoss: 0.744426\n",
      "Train Epoch: 9 [46976/60000 (78%)]\tLoss: 0.848316\n",
      "Train Epoch: 9 [47104/60000 (79%)]\tLoss: 0.700893\n",
      "Train Epoch: 9 [47232/60000 (79%)]\tLoss: 0.966539\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.958384\n",
      "Train Epoch: 9 [47488/60000 (79%)]\tLoss: 0.955963\n",
      "Train Epoch: 9 [47616/60000 (79%)]\tLoss: 0.768486\n",
      "Train Epoch: 9 [47744/60000 (80%)]\tLoss: 0.762826\n",
      "Train Epoch: 9 [47872/60000 (80%)]\tLoss: 0.956916\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.793205\n",
      "Train Epoch: 9 [48128/60000 (80%)]\tLoss: 0.654168\n",
      "Train Epoch: 9 [48256/60000 (81%)]\tLoss: 0.807397\n",
      "Train Epoch: 9 [48384/60000 (81%)]\tLoss: 0.801476\n",
      "Train Epoch: 9 [48512/60000 (81%)]\tLoss: 0.771721\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.852241\n",
      "Train Epoch: 9 [48768/60000 (81%)]\tLoss: 0.622432\n",
      "Train Epoch: 9 [48896/60000 (82%)]\tLoss: 1.078344\n",
      "Train Epoch: 9 [49024/60000 (82%)]\tLoss: 0.981892\n",
      "Train Epoch: 9 [49152/60000 (82%)]\tLoss: 0.940994\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.613986\n",
      "Train Epoch: 9 [49408/60000 (82%)]\tLoss: 1.014259\n",
      "Train Epoch: 9 [49536/60000 (83%)]\tLoss: 1.133240\n",
      "Train Epoch: 9 [49664/60000 (83%)]\tLoss: 0.741205\n",
      "Train Epoch: 9 [49792/60000 (83%)]\tLoss: 0.971075\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.853960\n",
      "Train Epoch: 9 [50048/60000 (84%)]\tLoss: 1.032103\n",
      "Train Epoch: 9 [50176/60000 (84%)]\tLoss: 1.005606\n",
      "Train Epoch: 9 [50304/60000 (84%)]\tLoss: 1.399033\n",
      "Train Epoch: 9 [50432/60000 (84%)]\tLoss: 0.834052\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.901562\n",
      "Train Epoch: 9 [50688/60000 (85%)]\tLoss: 1.138393\n",
      "Train Epoch: 9 [50816/60000 (85%)]\tLoss: 0.806780\n",
      "Train Epoch: 9 [50944/60000 (85%)]\tLoss: 0.701988\n",
      "Train Epoch: 9 [51072/60000 (85%)]\tLoss: 0.866840\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.907537\n",
      "Train Epoch: 9 [51328/60000 (86%)]\tLoss: 0.737983\n",
      "Train Epoch: 9 [51456/60000 (86%)]\tLoss: 0.820993\n",
      "Train Epoch: 9 [51584/60000 (86%)]\tLoss: 0.667772\n",
      "Train Epoch: 9 [51712/60000 (86%)]\tLoss: 0.810422\n",
      "Train Epoch: 9 [51840/60000 (87%)]\tLoss: 0.817338\n",
      "Train Epoch: 9 [51968/60000 (87%)]\tLoss: 0.978536\n",
      "Train Epoch: 9 [52096/60000 (87%)]\tLoss: 1.052821\n",
      "Train Epoch: 9 [52224/60000 (87%)]\tLoss: 0.841898\n",
      "Train Epoch: 9 [52352/60000 (87%)]\tLoss: 0.709237\n",
      "Train Epoch: 9 [52480/60000 (88%)]\tLoss: 0.572554\n",
      "Train Epoch: 9 [52608/60000 (88%)]\tLoss: 0.910480\n",
      "Train Epoch: 9 [52736/60000 (88%)]\tLoss: 1.000309\n",
      "Train Epoch: 9 [52864/60000 (88%)]\tLoss: 1.202826\n",
      "Train Epoch: 9 [52992/60000 (88%)]\tLoss: 0.851291\n",
      "Train Epoch: 9 [53120/60000 (89%)]\tLoss: 0.910487\n",
      "Train Epoch: 9 [53248/60000 (89%)]\tLoss: 0.660380\n",
      "Train Epoch: 9 [53376/60000 (89%)]\tLoss: 0.723542\n",
      "Train Epoch: 9 [53504/60000 (89%)]\tLoss: 0.893774\n",
      "Train Epoch: 9 [53632/60000 (90%)]\tLoss: 0.763987\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.843965\n",
      "Train Epoch: 9 [53888/60000 (90%)]\tLoss: 0.857447\n",
      "Train Epoch: 9 [54016/60000 (90%)]\tLoss: 0.762577\n",
      "Train Epoch: 9 [54144/60000 (90%)]\tLoss: 0.674625\n",
      "Train Epoch: 9 [54272/60000 (91%)]\tLoss: 0.821908\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.763162\n",
      "Train Epoch: 9 [54528/60000 (91%)]\tLoss: 0.811036\n",
      "Train Epoch: 9 [54656/60000 (91%)]\tLoss: 0.686196\n",
      "Train Epoch: 9 [54784/60000 (91%)]\tLoss: 0.947791\n",
      "Train Epoch: 9 [54912/60000 (92%)]\tLoss: 1.003790\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.824139\n",
      "Train Epoch: 9 [55168/60000 (92%)]\tLoss: 0.812125\n",
      "Train Epoch: 9 [55296/60000 (92%)]\tLoss: 0.679452\n",
      "Train Epoch: 9 [55424/60000 (93%)]\tLoss: 0.710635\n",
      "Train Epoch: 9 [55552/60000 (93%)]\tLoss: 0.752085\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.743069\n",
      "Train Epoch: 9 [55808/60000 (93%)]\tLoss: 0.734133\n",
      "Train Epoch: 9 [55936/60000 (93%)]\tLoss: 0.791480\n",
      "Train Epoch: 9 [56064/60000 (94%)]\tLoss: 0.778450\n",
      "Train Epoch: 9 [56192/60000 (94%)]\tLoss: 0.987954\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.791995\n",
      "Train Epoch: 9 [56448/60000 (94%)]\tLoss: 0.964779\n",
      "Train Epoch: 9 [56576/60000 (94%)]\tLoss: 0.812170\n",
      "Train Epoch: 9 [56704/60000 (95%)]\tLoss: 0.719250\n",
      "Train Epoch: 9 [56832/60000 (95%)]\tLoss: 0.763645\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.894873\n",
      "Train Epoch: 9 [57088/60000 (95%)]\tLoss: 0.783551\n",
      "Train Epoch: 9 [57216/60000 (96%)]\tLoss: 1.058852\n",
      "Train Epoch: 9 [57344/60000 (96%)]\tLoss: 0.911550\n",
      "Train Epoch: 9 [57472/60000 (96%)]\tLoss: 0.826635\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.978515\n",
      "Train Epoch: 9 [57728/60000 (96%)]\tLoss: 0.877854\n",
      "Train Epoch: 9 [57856/60000 (97%)]\tLoss: 0.720691\n",
      "Train Epoch: 9 [57984/60000 (97%)]\tLoss: 0.813523\n",
      "Train Epoch: 9 [58112/60000 (97%)]\tLoss: 0.547444\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.725671\n",
      "Train Epoch: 9 [58368/60000 (97%)]\tLoss: 0.719881\n",
      "Train Epoch: 9 [58496/60000 (98%)]\tLoss: 0.710307\n",
      "Train Epoch: 9 [58624/60000 (98%)]\tLoss: 0.588578\n",
      "Train Epoch: 9 [58752/60000 (98%)]\tLoss: 0.834925\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.494075\n",
      "Train Epoch: 9 [59008/60000 (99%)]\tLoss: 0.607847\n",
      "Train Epoch: 9 [59136/60000 (99%)]\tLoss: 0.502260\n",
      "Train Epoch: 9 [59264/60000 (99%)]\tLoss: 0.986297\n",
      "Train Epoch: 9 [59392/60000 (99%)]\tLoss: 0.737252\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.637046\n",
      "Train Epoch: 9 [59648/60000 (100%)]\tLoss: 1.095796\n",
      "Train Epoch: 9 [59776/60000 (100%)]\tLoss: 0.603215\n",
      "================================================================\n",
      "Training: Average loss: 0.2773, Accuracy: 55545/60000 (93%)\n",
      "Test: Average loss: 0.2619, Accuracy: 9288/10000 (93%)\n",
      "================================================================\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.743218\n",
      "Train Epoch: 10 [128/60000 (0%)]\tLoss: 0.895491\n",
      "Train Epoch: 10 [256/60000 (0%)]\tLoss: 0.793303\n",
      "Train Epoch: 10 [384/60000 (1%)]\tLoss: 0.861158\n",
      "Train Epoch: 10 [512/60000 (1%)]\tLoss: 0.758650\n",
      "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.731485\n",
      "Train Epoch: 10 [768/60000 (1%)]\tLoss: 0.860109\n",
      "Train Epoch: 10 [896/60000 (1%)]\tLoss: 0.836231\n",
      "Train Epoch: 10 [1024/60000 (2%)]\tLoss: 1.182588\n",
      "Train Epoch: 10 [1152/60000 (2%)]\tLoss: 0.886384\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.972295\n",
      "Train Epoch: 10 [1408/60000 (2%)]\tLoss: 0.852641\n",
      "Train Epoch: 10 [1536/60000 (3%)]\tLoss: 0.951593\n",
      "Train Epoch: 10 [1664/60000 (3%)]\tLoss: 0.575484\n",
      "Train Epoch: 10 [1792/60000 (3%)]\tLoss: 0.679991\n",
      "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.773892\n",
      "Train Epoch: 10 [2048/60000 (3%)]\tLoss: 0.731608\n",
      "Train Epoch: 10 [2176/60000 (4%)]\tLoss: 0.658493\n",
      "Train Epoch: 10 [2304/60000 (4%)]\tLoss: 0.918844\n",
      "Train Epoch: 10 [2432/60000 (4%)]\tLoss: 0.720805\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.876108\n",
      "Train Epoch: 10 [2688/60000 (4%)]\tLoss: 0.826823\n",
      "Train Epoch: 10 [2816/60000 (5%)]\tLoss: 0.759742\n",
      "Train Epoch: 10 [2944/60000 (5%)]\tLoss: 0.884730\n",
      "Train Epoch: 10 [3072/60000 (5%)]\tLoss: 0.724067\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.747758\n",
      "Train Epoch: 10 [3328/60000 (6%)]\tLoss: 0.836987\n",
      "Train Epoch: 10 [3456/60000 (6%)]\tLoss: 0.837826\n",
      "Train Epoch: 10 [3584/60000 (6%)]\tLoss: 0.868994\n",
      "Train Epoch: 10 [3712/60000 (6%)]\tLoss: 0.905176\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.717353\n",
      "Train Epoch: 10 [3968/60000 (7%)]\tLoss: 0.839302\n",
      "Train Epoch: 10 [4096/60000 (7%)]\tLoss: 0.799994\n",
      "Train Epoch: 10 [4224/60000 (7%)]\tLoss: 0.772066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [4352/60000 (7%)]\tLoss: 0.772268\n",
      "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.846602\n",
      "Train Epoch: 10 [4608/60000 (8%)]\tLoss: 0.865307\n",
      "Train Epoch: 10 [4736/60000 (8%)]\tLoss: 0.792320\n",
      "Train Epoch: 10 [4864/60000 (8%)]\tLoss: 0.944879\n",
      "Train Epoch: 10 [4992/60000 (8%)]\tLoss: 0.812102\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.847820\n",
      "Train Epoch: 10 [5248/60000 (9%)]\tLoss: 0.872395\n",
      "Train Epoch: 10 [5376/60000 (9%)]\tLoss: 0.697886\n",
      "Train Epoch: 10 [5504/60000 (9%)]\tLoss: 0.893446\n",
      "Train Epoch: 10 [5632/60000 (9%)]\tLoss: 0.920152\n",
      "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.855448\n",
      "Train Epoch: 10 [5888/60000 (10%)]\tLoss: 0.695593\n",
      "Train Epoch: 10 [6016/60000 (10%)]\tLoss: 0.589952\n",
      "Train Epoch: 10 [6144/60000 (10%)]\tLoss: 0.766556\n",
      "Train Epoch: 10 [6272/60000 (10%)]\tLoss: 0.769606\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.963921\n",
      "Train Epoch: 10 [6528/60000 (11%)]\tLoss: 0.727961\n",
      "Train Epoch: 10 [6656/60000 (11%)]\tLoss: 0.744731\n",
      "Train Epoch: 10 [6784/60000 (11%)]\tLoss: 0.845074\n",
      "Train Epoch: 10 [6912/60000 (12%)]\tLoss: 1.005510\n",
      "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.867614\n",
      "Train Epoch: 10 [7168/60000 (12%)]\tLoss: 1.120693\n",
      "Train Epoch: 10 [7296/60000 (12%)]\tLoss: 0.857919\n",
      "Train Epoch: 10 [7424/60000 (12%)]\tLoss: 0.796210\n",
      "Train Epoch: 10 [7552/60000 (13%)]\tLoss: 0.776797\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.834221\n",
      "Train Epoch: 10 [7808/60000 (13%)]\tLoss: 0.901614\n",
      "Train Epoch: 10 [7936/60000 (13%)]\tLoss: 0.886828\n",
      "Train Epoch: 10 [8064/60000 (13%)]\tLoss: 0.815077\n",
      "Train Epoch: 10 [8192/60000 (14%)]\tLoss: 1.062810\n",
      "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.869714\n",
      "Train Epoch: 10 [8448/60000 (14%)]\tLoss: 0.858212\n",
      "Train Epoch: 10 [8576/60000 (14%)]\tLoss: 0.875013\n",
      "Train Epoch: 10 [8704/60000 (15%)]\tLoss: 1.105940\n",
      "Train Epoch: 10 [8832/60000 (15%)]\tLoss: 1.093044\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.646707\n",
      "Train Epoch: 10 [9088/60000 (15%)]\tLoss: 0.800375\n",
      "Train Epoch: 10 [9216/60000 (15%)]\tLoss: 0.782184\n",
      "Train Epoch: 10 [9344/60000 (16%)]\tLoss: 0.924283\n",
      "Train Epoch: 10 [9472/60000 (16%)]\tLoss: 0.929604\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.719807\n",
      "Train Epoch: 10 [9728/60000 (16%)]\tLoss: 0.716945\n",
      "Train Epoch: 10 [9856/60000 (16%)]\tLoss: 0.731312\n",
      "Train Epoch: 10 [9984/60000 (17%)]\tLoss: 0.862267\n",
      "Train Epoch: 10 [10112/60000 (17%)]\tLoss: 0.959129\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.932213\n",
      "Train Epoch: 10 [10368/60000 (17%)]\tLoss: 0.700883\n",
      "Train Epoch: 10 [10496/60000 (18%)]\tLoss: 0.759853\n",
      "Train Epoch: 10 [10624/60000 (18%)]\tLoss: 0.687237\n",
      "Train Epoch: 10 [10752/60000 (18%)]\tLoss: 0.863002\n",
      "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.837530\n",
      "Train Epoch: 10 [11008/60000 (18%)]\tLoss: 0.682351\n",
      "Train Epoch: 10 [11136/60000 (19%)]\tLoss: 0.833526\n",
      "Train Epoch: 10 [11264/60000 (19%)]\tLoss: 0.788564\n",
      "Train Epoch: 10 [11392/60000 (19%)]\tLoss: 0.855804\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.989852\n",
      "Train Epoch: 10 [11648/60000 (19%)]\tLoss: 1.048313\n",
      "Train Epoch: 10 [11776/60000 (20%)]\tLoss: 0.868774\n",
      "Train Epoch: 10 [11904/60000 (20%)]\tLoss: 0.799124\n",
      "Train Epoch: 10 [12032/60000 (20%)]\tLoss: 0.766968\n",
      "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.897544\n",
      "Train Epoch: 10 [12288/60000 (21%)]\tLoss: 0.954688\n",
      "Train Epoch: 10 [12416/60000 (21%)]\tLoss: 0.743050\n",
      "Train Epoch: 10 [12544/60000 (21%)]\tLoss: 0.982909\n",
      "Train Epoch: 10 [12672/60000 (21%)]\tLoss: 0.806994\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.774512\n",
      "Train Epoch: 10 [12928/60000 (22%)]\tLoss: 1.133021\n",
      "Train Epoch: 10 [13056/60000 (22%)]\tLoss: 1.088708\n",
      "Train Epoch: 10 [13184/60000 (22%)]\tLoss: 0.644801\n",
      "Train Epoch: 10 [13312/60000 (22%)]\tLoss: 0.863128\n",
      "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.744572\n",
      "Train Epoch: 10 [13568/60000 (23%)]\tLoss: 0.744936\n",
      "Train Epoch: 10 [13696/60000 (23%)]\tLoss: 0.883620\n",
      "Train Epoch: 10 [13824/60000 (23%)]\tLoss: 0.983808\n",
      "Train Epoch: 10 [13952/60000 (23%)]\tLoss: 1.031704\n",
      "Train Epoch: 10 [14080/60000 (24%)]\tLoss: 0.979513\n",
      "Train Epoch: 10 [14208/60000 (24%)]\tLoss: 1.203412\n",
      "Train Epoch: 10 [14336/60000 (24%)]\tLoss: 0.989082\n",
      "Train Epoch: 10 [14464/60000 (24%)]\tLoss: 0.918020\n",
      "Train Epoch: 10 [14592/60000 (24%)]\tLoss: 1.117373\n",
      "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 1.258591\n",
      "Train Epoch: 10 [14848/60000 (25%)]\tLoss: 0.713315\n",
      "Train Epoch: 10 [14976/60000 (25%)]\tLoss: 0.666253\n",
      "Train Epoch: 10 [15104/60000 (25%)]\tLoss: 0.990631\n",
      "Train Epoch: 10 [15232/60000 (25%)]\tLoss: 0.767483\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.656993\n",
      "Train Epoch: 10 [15488/60000 (26%)]\tLoss: 0.640273\n",
      "Train Epoch: 10 [15616/60000 (26%)]\tLoss: 0.830775\n",
      "Train Epoch: 10 [15744/60000 (26%)]\tLoss: 0.911656\n",
      "Train Epoch: 10 [15872/60000 (26%)]\tLoss: 0.827364\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 1.048665\n",
      "Train Epoch: 10 [16128/60000 (27%)]\tLoss: 0.867923\n",
      "Train Epoch: 10 [16256/60000 (27%)]\tLoss: 0.796034\n",
      "Train Epoch: 10 [16384/60000 (27%)]\tLoss: 0.661254\n",
      "Train Epoch: 10 [16512/60000 (28%)]\tLoss: 0.846864\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.840948\n",
      "Train Epoch: 10 [16768/60000 (28%)]\tLoss: 1.015096\n",
      "Train Epoch: 10 [16896/60000 (28%)]\tLoss: 0.897120\n",
      "Train Epoch: 10 [17024/60000 (28%)]\tLoss: 0.941981\n",
      "Train Epoch: 10 [17152/60000 (29%)]\tLoss: 0.944722\n",
      "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.782782\n",
      "Train Epoch: 10 [17408/60000 (29%)]\tLoss: 0.808483\n",
      "Train Epoch: 10 [17536/60000 (29%)]\tLoss: 1.048200\n",
      "Train Epoch: 10 [17664/60000 (29%)]\tLoss: 0.907455\n",
      "Train Epoch: 10 [17792/60000 (30%)]\tLoss: 0.852971\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.756250\n",
      "Train Epoch: 10 [18048/60000 (30%)]\tLoss: 0.817209\n",
      "Train Epoch: 10 [18176/60000 (30%)]\tLoss: 0.587676\n",
      "Train Epoch: 10 [18304/60000 (31%)]\tLoss: 0.722003\n",
      "Train Epoch: 10 [18432/60000 (31%)]\tLoss: 0.802284\n",
      "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.754894\n",
      "Train Epoch: 10 [18688/60000 (31%)]\tLoss: 0.783289\n",
      "Train Epoch: 10 [18816/60000 (31%)]\tLoss: 0.787679\n",
      "Train Epoch: 10 [18944/60000 (32%)]\tLoss: 0.735252\n",
      "Train Epoch: 10 [19072/60000 (32%)]\tLoss: 0.901432\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.960228\n",
      "Train Epoch: 10 [19328/60000 (32%)]\tLoss: 0.843859\n",
      "Train Epoch: 10 [19456/60000 (32%)]\tLoss: 0.745788\n",
      "Train Epoch: 10 [19584/60000 (33%)]\tLoss: 0.712846\n",
      "Train Epoch: 10 [19712/60000 (33%)]\tLoss: 0.591511\n",
      "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.783412\n",
      "Train Epoch: 10 [19968/60000 (33%)]\tLoss: 0.858907\n",
      "Train Epoch: 10 [20096/60000 (34%)]\tLoss: 1.055690\n",
      "Train Epoch: 10 [20224/60000 (34%)]\tLoss: 0.814340\n",
      "Train Epoch: 10 [20352/60000 (34%)]\tLoss: 0.637520\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.763203\n",
      "Train Epoch: 10 [20608/60000 (34%)]\tLoss: 0.998159\n",
      "Train Epoch: 10 [20736/60000 (35%)]\tLoss: 1.068150\n",
      "Train Epoch: 10 [20864/60000 (35%)]\tLoss: 1.091427\n",
      "Train Epoch: 10 [20992/60000 (35%)]\tLoss: 0.731076\n",
      "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.723208\n",
      "Train Epoch: 10 [21248/60000 (35%)]\tLoss: 0.804911\n",
      "Train Epoch: 10 [21376/60000 (36%)]\tLoss: 0.860403\n",
      "Train Epoch: 10 [21504/60000 (36%)]\tLoss: 0.767254\n",
      "Train Epoch: 10 [21632/60000 (36%)]\tLoss: 0.736178\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.609486\n",
      "Train Epoch: 10 [21888/60000 (37%)]\tLoss: 0.729228\n",
      "Train Epoch: 10 [22016/60000 (37%)]\tLoss: 0.907065\n",
      "Train Epoch: 10 [22144/60000 (37%)]\tLoss: 0.843151\n",
      "Train Epoch: 10 [22272/60000 (37%)]\tLoss: 0.767782\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 1.000688\n",
      "Train Epoch: 10 [22528/60000 (38%)]\tLoss: 1.051286\n",
      "Train Epoch: 10 [22656/60000 (38%)]\tLoss: 0.848783\n",
      "Train Epoch: 10 [22784/60000 (38%)]\tLoss: 0.688258\n",
      "Train Epoch: 10 [22912/60000 (38%)]\tLoss: 0.664178\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.865626\n",
      "Train Epoch: 10 [23168/60000 (39%)]\tLoss: 0.791945\n",
      "Train Epoch: 10 [23296/60000 (39%)]\tLoss: 0.757437\n",
      "Train Epoch: 10 [23424/60000 (39%)]\tLoss: 0.703081\n",
      "Train Epoch: 10 [23552/60000 (39%)]\tLoss: 0.883211\n",
      "Train Epoch: 10 [23680/60000 (40%)]\tLoss: 0.963916\n",
      "Train Epoch: 10 [23808/60000 (40%)]\tLoss: 0.876062\n",
      "Train Epoch: 10 [23936/60000 (40%)]\tLoss: 0.827745\n",
      "Train Epoch: 10 [24064/60000 (40%)]\tLoss: 0.631284\n",
      "Train Epoch: 10 [24192/60000 (40%)]\tLoss: 1.011376\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.881017\n",
      "Train Epoch: 10 [24448/60000 (41%)]\tLoss: 0.891778\n",
      "Train Epoch: 10 [24576/60000 (41%)]\tLoss: 0.860803\n",
      "Train Epoch: 10 [24704/60000 (41%)]\tLoss: 1.035143\n",
      "Train Epoch: 10 [24832/60000 (41%)]\tLoss: 0.890981\n",
      "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.714734\n",
      "Train Epoch: 10 [25088/60000 (42%)]\tLoss: 0.794291\n",
      "Train Epoch: 10 [25216/60000 (42%)]\tLoss: 0.890384\n",
      "Train Epoch: 10 [25344/60000 (42%)]\tLoss: 0.568469\n",
      "Train Epoch: 10 [25472/60000 (43%)]\tLoss: 0.692515\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.767083\n",
      "Train Epoch: 10 [25728/60000 (43%)]\tLoss: 0.844001\n",
      "Train Epoch: 10 [25856/60000 (43%)]\tLoss: 0.850769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [25984/60000 (43%)]\tLoss: 0.728790\n",
      "Train Epoch: 10 [26112/60000 (44%)]\tLoss: 0.756640\n",
      "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.785091\n",
      "Train Epoch: 10 [26368/60000 (44%)]\tLoss: 1.027460\n",
      "Train Epoch: 10 [26496/60000 (44%)]\tLoss: 0.854686\n",
      "Train Epoch: 10 [26624/60000 (44%)]\tLoss: 1.189771\n",
      "Train Epoch: 10 [26752/60000 (45%)]\tLoss: 0.815148\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.765471\n",
      "Train Epoch: 10 [27008/60000 (45%)]\tLoss: 0.831482\n",
      "Train Epoch: 10 [27136/60000 (45%)]\tLoss: 1.117274\n",
      "Train Epoch: 10 [27264/60000 (46%)]\tLoss: 0.773063\n",
      "Train Epoch: 10 [27392/60000 (46%)]\tLoss: 0.841708\n",
      "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.869107\n",
      "Train Epoch: 10 [27648/60000 (46%)]\tLoss: 0.763303\n",
      "Train Epoch: 10 [27776/60000 (46%)]\tLoss: 0.815671\n",
      "Train Epoch: 10 [27904/60000 (47%)]\tLoss: 0.739398\n",
      "Train Epoch: 10 [28032/60000 (47%)]\tLoss: 0.719395\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.713345\n",
      "Train Epoch: 10 [28288/60000 (47%)]\tLoss: 0.955935\n",
      "Train Epoch: 10 [28416/60000 (47%)]\tLoss: 0.917788\n",
      "Train Epoch: 10 [28544/60000 (48%)]\tLoss: 1.056237\n",
      "Train Epoch: 10 [28672/60000 (48%)]\tLoss: 0.892477\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.731626\n",
      "Train Epoch: 10 [28928/60000 (48%)]\tLoss: 0.874645\n",
      "Train Epoch: 10 [29056/60000 (49%)]\tLoss: 0.868102\n",
      "Train Epoch: 10 [29184/60000 (49%)]\tLoss: 0.907683\n",
      "Train Epoch: 10 [29312/60000 (49%)]\tLoss: 1.019683\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.746686\n",
      "Train Epoch: 10 [29568/60000 (49%)]\tLoss: 0.671973\n",
      "Train Epoch: 10 [29696/60000 (50%)]\tLoss: 0.918715\n",
      "Train Epoch: 10 [29824/60000 (50%)]\tLoss: 1.027122\n",
      "Train Epoch: 10 [29952/60000 (50%)]\tLoss: 0.964967\n",
      "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.927996\n",
      "Train Epoch: 10 [30208/60000 (50%)]\tLoss: 0.928968\n",
      "Train Epoch: 10 [30336/60000 (51%)]\tLoss: 0.826950\n",
      "Train Epoch: 10 [30464/60000 (51%)]\tLoss: 0.991706\n",
      "Train Epoch: 10 [30592/60000 (51%)]\tLoss: 1.004666\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.938945\n",
      "Train Epoch: 10 [30848/60000 (51%)]\tLoss: 0.978961\n",
      "Train Epoch: 10 [30976/60000 (52%)]\tLoss: 0.869434\n",
      "Train Epoch: 10 [31104/60000 (52%)]\tLoss: 0.958571\n",
      "Train Epoch: 10 [31232/60000 (52%)]\tLoss: 0.957039\n",
      "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.938781\n",
      "Train Epoch: 10 [31488/60000 (53%)]\tLoss: 0.816833\n",
      "Train Epoch: 10 [31616/60000 (53%)]\tLoss: 1.163362\n",
      "Train Epoch: 10 [31744/60000 (53%)]\tLoss: 0.969904\n",
      "Train Epoch: 10 [31872/60000 (53%)]\tLoss: 0.771748\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.782841\n",
      "Train Epoch: 10 [32128/60000 (54%)]\tLoss: 1.032638\n",
      "Train Epoch: 10 [32256/60000 (54%)]\tLoss: 0.984869\n",
      "Train Epoch: 10 [32384/60000 (54%)]\tLoss: 1.022472\n",
      "Train Epoch: 10 [32512/60000 (54%)]\tLoss: 0.692858\n",
      "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.874294\n",
      "Train Epoch: 10 [32768/60000 (55%)]\tLoss: 0.888933\n",
      "Train Epoch: 10 [32896/60000 (55%)]\tLoss: 0.845182\n",
      "Train Epoch: 10 [33024/60000 (55%)]\tLoss: 0.866001\n",
      "Train Epoch: 10 [33152/60000 (55%)]\tLoss: 0.856967\n",
      "Train Epoch: 10 [33280/60000 (56%)]\tLoss: 0.951711\n",
      "Train Epoch: 10 [33408/60000 (56%)]\tLoss: 0.923632\n",
      "Train Epoch: 10 [33536/60000 (56%)]\tLoss: 0.747890\n",
      "Train Epoch: 10 [33664/60000 (56%)]\tLoss: 0.794070\n",
      "Train Epoch: 10 [33792/60000 (56%)]\tLoss: 0.544621\n",
      "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.736544\n",
      "Train Epoch: 10 [34048/60000 (57%)]\tLoss: 0.810212\n",
      "Train Epoch: 10 [34176/60000 (57%)]\tLoss: 0.586345\n",
      "Train Epoch: 10 [34304/60000 (57%)]\tLoss: 0.831489\n",
      "Train Epoch: 10 [34432/60000 (57%)]\tLoss: 0.855094\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.805871\n",
      "Train Epoch: 10 [34688/60000 (58%)]\tLoss: 0.981583\n",
      "Train Epoch: 10 [34816/60000 (58%)]\tLoss: 0.875996\n",
      "Train Epoch: 10 [34944/60000 (58%)]\tLoss: 0.680433\n",
      "Train Epoch: 10 [35072/60000 (59%)]\tLoss: 0.703330\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.883515\n",
      "Train Epoch: 10 [35328/60000 (59%)]\tLoss: 0.828729\n",
      "Train Epoch: 10 [35456/60000 (59%)]\tLoss: 0.745303\n",
      "Train Epoch: 10 [35584/60000 (59%)]\tLoss: 0.862797\n",
      "Train Epoch: 10 [35712/60000 (60%)]\tLoss: 0.648810\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.827003\n",
      "Train Epoch: 10 [35968/60000 (60%)]\tLoss: 0.697493\n",
      "Train Epoch: 10 [36096/60000 (60%)]\tLoss: 0.806307\n",
      "Train Epoch: 10 [36224/60000 (60%)]\tLoss: 0.725046\n",
      "Train Epoch: 10 [36352/60000 (61%)]\tLoss: 0.883885\n",
      "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.759724\n",
      "Train Epoch: 10 [36608/60000 (61%)]\tLoss: 0.673488\n",
      "Train Epoch: 10 [36736/60000 (61%)]\tLoss: 0.836083\n",
      "Train Epoch: 10 [36864/60000 (62%)]\tLoss: 0.770886\n",
      "Train Epoch: 10 [36992/60000 (62%)]\tLoss: 0.861546\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.827319\n",
      "Train Epoch: 10 [37248/60000 (62%)]\tLoss: 0.987856\n",
      "Train Epoch: 10 [37376/60000 (62%)]\tLoss: 1.033860\n",
      "Train Epoch: 10 [37504/60000 (63%)]\tLoss: 0.846216\n",
      "Train Epoch: 10 [37632/60000 (63%)]\tLoss: 0.892175\n",
      "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.879586\n",
      "Train Epoch: 10 [37888/60000 (63%)]\tLoss: 0.809036\n",
      "Train Epoch: 10 [38016/60000 (63%)]\tLoss: 0.791756\n",
      "Train Epoch: 10 [38144/60000 (64%)]\tLoss: 0.844598\n",
      "Train Epoch: 10 [38272/60000 (64%)]\tLoss: 1.000370\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.870193\n",
      "Train Epoch: 10 [38528/60000 (64%)]\tLoss: 0.992815\n",
      "Train Epoch: 10 [38656/60000 (65%)]\tLoss: 0.766779\n",
      "Train Epoch: 10 [38784/60000 (65%)]\tLoss: 0.663737\n",
      "Train Epoch: 10 [38912/60000 (65%)]\tLoss: 0.780576\n",
      "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.598688\n",
      "Train Epoch: 10 [39168/60000 (65%)]\tLoss: 0.812246\n",
      "Train Epoch: 10 [39296/60000 (66%)]\tLoss: 1.260644\n",
      "Train Epoch: 10 [39424/60000 (66%)]\tLoss: 0.972166\n",
      "Train Epoch: 10 [39552/60000 (66%)]\tLoss: 0.926539\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.898404\n",
      "Train Epoch: 10 [39808/60000 (66%)]\tLoss: 1.006349\n",
      "Train Epoch: 10 [39936/60000 (67%)]\tLoss: 0.821581\n",
      "Train Epoch: 10 [40064/60000 (67%)]\tLoss: 0.679884\n",
      "Train Epoch: 10 [40192/60000 (67%)]\tLoss: 0.792810\n",
      "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.574817\n",
      "Train Epoch: 10 [40448/60000 (68%)]\tLoss: 0.782984\n",
      "Train Epoch: 10 [40576/60000 (68%)]\tLoss: 0.812854\n",
      "Train Epoch: 10 [40704/60000 (68%)]\tLoss: 0.761042\n",
      "Train Epoch: 10 [40832/60000 (68%)]\tLoss: 0.656882\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.905047\n",
      "Train Epoch: 10 [41088/60000 (69%)]\tLoss: 0.726158\n",
      "Train Epoch: 10 [41216/60000 (69%)]\tLoss: 1.088334\n",
      "Train Epoch: 10 [41344/60000 (69%)]\tLoss: 1.000655\n",
      "Train Epoch: 10 [41472/60000 (69%)]\tLoss: 0.924303\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.921897\n",
      "Train Epoch: 10 [41728/60000 (70%)]\tLoss: 0.841283\n",
      "Train Epoch: 10 [41856/60000 (70%)]\tLoss: 0.982820\n",
      "Train Epoch: 10 [41984/60000 (70%)]\tLoss: 0.818385\n",
      "Train Epoch: 10 [42112/60000 (70%)]\tLoss: 1.017615\n",
      "Train Epoch: 10 [42240/60000 (71%)]\tLoss: 0.944835\n",
      "Train Epoch: 10 [42368/60000 (71%)]\tLoss: 0.901438\n",
      "Train Epoch: 10 [42496/60000 (71%)]\tLoss: 0.816828\n",
      "Train Epoch: 10 [42624/60000 (71%)]\tLoss: 0.900229\n",
      "Train Epoch: 10 [42752/60000 (71%)]\tLoss: 0.966092\n",
      "Train Epoch: 10 [42880/60000 (72%)]\tLoss: 0.937578\n",
      "Train Epoch: 10 [43008/60000 (72%)]\tLoss: 0.945624\n",
      "Train Epoch: 10 [43136/60000 (72%)]\tLoss: 0.782363\n",
      "Train Epoch: 10 [43264/60000 (72%)]\tLoss: 0.566999\n",
      "Train Epoch: 10 [43392/60000 (72%)]\tLoss: 0.694588\n",
      "Train Epoch: 10 [43520/60000 (73%)]\tLoss: 0.727334\n",
      "Train Epoch: 10 [43648/60000 (73%)]\tLoss: 0.697969\n",
      "Train Epoch: 10 [43776/60000 (73%)]\tLoss: 0.858813\n",
      "Train Epoch: 10 [43904/60000 (73%)]\tLoss: 0.869679\n",
      "Train Epoch: 10 [44032/60000 (74%)]\tLoss: 0.869854\n",
      "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.952771\n",
      "Train Epoch: 10 [44288/60000 (74%)]\tLoss: 0.737423\n",
      "Train Epoch: 10 [44416/60000 (74%)]\tLoss: 0.796038\n",
      "Train Epoch: 10 [44544/60000 (74%)]\tLoss: 0.610007\n",
      "Train Epoch: 10 [44672/60000 (75%)]\tLoss: 0.797060\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.979769\n",
      "Train Epoch: 10 [44928/60000 (75%)]\tLoss: 1.000906\n",
      "Train Epoch: 10 [45056/60000 (75%)]\tLoss: 0.927753\n",
      "Train Epoch: 10 [45184/60000 (75%)]\tLoss: 0.708569\n",
      "Train Epoch: 10 [45312/60000 (76%)]\tLoss: 0.669131\n",
      "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.999038\n",
      "Train Epoch: 10 [45568/60000 (76%)]\tLoss: 0.892129\n",
      "Train Epoch: 10 [45696/60000 (76%)]\tLoss: 0.739719\n",
      "Train Epoch: 10 [45824/60000 (76%)]\tLoss: 0.890721\n",
      "Train Epoch: 10 [45952/60000 (77%)]\tLoss: 0.970611\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.945545\n",
      "Train Epoch: 10 [46208/60000 (77%)]\tLoss: 0.910244\n",
      "Train Epoch: 10 [46336/60000 (77%)]\tLoss: 0.925740\n",
      "Train Epoch: 10 [46464/60000 (78%)]\tLoss: 0.579498\n",
      "Train Epoch: 10 [46592/60000 (78%)]\tLoss: 0.787611\n",
      "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.713457\n",
      "Train Epoch: 10 [46848/60000 (78%)]\tLoss: 0.669502\n",
      "Train Epoch: 10 [46976/60000 (78%)]\tLoss: 0.658614\n",
      "Train Epoch: 10 [47104/60000 (79%)]\tLoss: 0.774643\n",
      "Train Epoch: 10 [47232/60000 (79%)]\tLoss: 0.963637\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.822458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [47488/60000 (79%)]\tLoss: 0.954622\n",
      "Train Epoch: 10 [47616/60000 (79%)]\tLoss: 0.809008\n",
      "Train Epoch: 10 [47744/60000 (80%)]\tLoss: 0.644200\n",
      "Train Epoch: 10 [47872/60000 (80%)]\tLoss: 1.041409\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.717706\n",
      "Train Epoch: 10 [48128/60000 (80%)]\tLoss: 0.678076\n",
      "Train Epoch: 10 [48256/60000 (81%)]\tLoss: 0.942967\n",
      "Train Epoch: 10 [48384/60000 (81%)]\tLoss: 0.677030\n",
      "Train Epoch: 10 [48512/60000 (81%)]\tLoss: 1.067687\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.640952\n",
      "Train Epoch: 10 [48768/60000 (81%)]\tLoss: 0.710992\n",
      "Train Epoch: 10 [48896/60000 (82%)]\tLoss: 1.041772\n",
      "Train Epoch: 10 [49024/60000 (82%)]\tLoss: 0.869199\n",
      "Train Epoch: 10 [49152/60000 (82%)]\tLoss: 0.876655\n",
      "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.725624\n",
      "Train Epoch: 10 [49408/60000 (82%)]\tLoss: 1.088197\n",
      "Train Epoch: 10 [49536/60000 (83%)]\tLoss: 1.196614\n",
      "Train Epoch: 10 [49664/60000 (83%)]\tLoss: 0.911537\n",
      "Train Epoch: 10 [49792/60000 (83%)]\tLoss: 1.017697\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.853329\n",
      "Train Epoch: 10 [50048/60000 (84%)]\tLoss: 0.878711\n",
      "Train Epoch: 10 [50176/60000 (84%)]\tLoss: 0.764930\n",
      "Train Epoch: 10 [50304/60000 (84%)]\tLoss: 1.051314\n",
      "Train Epoch: 10 [50432/60000 (84%)]\tLoss: 0.797542\n",
      "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.969400\n",
      "Train Epoch: 10 [50688/60000 (85%)]\tLoss: 0.823647\n",
      "Train Epoch: 10 [50816/60000 (85%)]\tLoss: 0.689478\n",
      "Train Epoch: 10 [50944/60000 (85%)]\tLoss: 0.594841\n",
      "Train Epoch: 10 [51072/60000 (85%)]\tLoss: 0.941681\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.872621\n",
      "Train Epoch: 10 [51328/60000 (86%)]\tLoss: 0.663510\n",
      "Train Epoch: 10 [51456/60000 (86%)]\tLoss: 0.692063\n",
      "Train Epoch: 10 [51584/60000 (86%)]\tLoss: 0.676058\n",
      "Train Epoch: 10 [51712/60000 (86%)]\tLoss: 0.827636\n",
      "Train Epoch: 10 [51840/60000 (87%)]\tLoss: 0.850284\n",
      "Train Epoch: 10 [51968/60000 (87%)]\tLoss: 0.974719\n",
      "Train Epoch: 10 [52096/60000 (87%)]\tLoss: 0.949777\n",
      "Train Epoch: 10 [52224/60000 (87%)]\tLoss: 0.891747\n",
      "Train Epoch: 10 [52352/60000 (87%)]\tLoss: 0.640067\n",
      "Train Epoch: 10 [52480/60000 (88%)]\tLoss: 0.529327\n",
      "Train Epoch: 10 [52608/60000 (88%)]\tLoss: 0.926428\n",
      "Train Epoch: 10 [52736/60000 (88%)]\tLoss: 1.021092\n",
      "Train Epoch: 10 [52864/60000 (88%)]\tLoss: 1.107033\n",
      "Train Epoch: 10 [52992/60000 (88%)]\tLoss: 0.807826\n",
      "Train Epoch: 10 [53120/60000 (89%)]\tLoss: 0.880110\n",
      "Train Epoch: 10 [53248/60000 (89%)]\tLoss: 0.629949\n",
      "Train Epoch: 10 [53376/60000 (89%)]\tLoss: 0.738525\n",
      "Train Epoch: 10 [53504/60000 (89%)]\tLoss: 0.950086\n",
      "Train Epoch: 10 [53632/60000 (90%)]\tLoss: 0.710947\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.693850\n",
      "Train Epoch: 10 [53888/60000 (90%)]\tLoss: 0.851445\n",
      "Train Epoch: 10 [54016/60000 (90%)]\tLoss: 0.783614\n",
      "Train Epoch: 10 [54144/60000 (90%)]\tLoss: 0.685656\n",
      "Train Epoch: 10 [54272/60000 (91%)]\tLoss: 0.710001\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.639752\n",
      "Train Epoch: 10 [54528/60000 (91%)]\tLoss: 0.752420\n",
      "Train Epoch: 10 [54656/60000 (91%)]\tLoss: 0.800301\n",
      "Train Epoch: 10 [54784/60000 (91%)]\tLoss: 0.896001\n",
      "Train Epoch: 10 [54912/60000 (92%)]\tLoss: 0.782610\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.726220\n",
      "Train Epoch: 10 [55168/60000 (92%)]\tLoss: 0.791429\n",
      "Train Epoch: 10 [55296/60000 (92%)]\tLoss: 0.816101\n",
      "Train Epoch: 10 [55424/60000 (93%)]\tLoss: 0.710020\n",
      "Train Epoch: 10 [55552/60000 (93%)]\tLoss: 0.655381\n",
      "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.763270\n",
      "Train Epoch: 10 [55808/60000 (93%)]\tLoss: 0.739919\n",
      "Train Epoch: 10 [55936/60000 (93%)]\tLoss: 0.623401\n",
      "Train Epoch: 10 [56064/60000 (94%)]\tLoss: 0.775568\n",
      "Train Epoch: 10 [56192/60000 (94%)]\tLoss: 0.884202\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.699903\n",
      "Train Epoch: 10 [56448/60000 (94%)]\tLoss: 0.745635\n",
      "Train Epoch: 10 [56576/60000 (94%)]\tLoss: 0.832852\n",
      "Train Epoch: 10 [56704/60000 (95%)]\tLoss: 0.602284\n",
      "Train Epoch: 10 [56832/60000 (95%)]\tLoss: 0.694752\n",
      "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.845553\n",
      "Train Epoch: 10 [57088/60000 (95%)]\tLoss: 0.771682\n",
      "Train Epoch: 10 [57216/60000 (96%)]\tLoss: 0.925096\n",
      "Train Epoch: 10 [57344/60000 (96%)]\tLoss: 0.781698\n",
      "Train Epoch: 10 [57472/60000 (96%)]\tLoss: 0.894975\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.866622\n",
      "Train Epoch: 10 [57728/60000 (96%)]\tLoss: 0.721661\n",
      "Train Epoch: 10 [57856/60000 (97%)]\tLoss: 0.689491\n",
      "Train Epoch: 10 [57984/60000 (97%)]\tLoss: 0.613760\n",
      "Train Epoch: 10 [58112/60000 (97%)]\tLoss: 0.632550\n",
      "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.652038\n",
      "Train Epoch: 10 [58368/60000 (97%)]\tLoss: 0.620674\n",
      "Train Epoch: 10 [58496/60000 (98%)]\tLoss: 0.620292\n",
      "Train Epoch: 10 [58624/60000 (98%)]\tLoss: 0.584261\n",
      "Train Epoch: 10 [58752/60000 (98%)]\tLoss: 0.651250\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.449169\n",
      "Train Epoch: 10 [59008/60000 (99%)]\tLoss: 0.553295\n",
      "Train Epoch: 10 [59136/60000 (99%)]\tLoss: 0.528515\n",
      "Train Epoch: 10 [59264/60000 (99%)]\tLoss: 0.898837\n",
      "Train Epoch: 10 [59392/60000 (99%)]\tLoss: 0.789055\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.571905\n",
      "Train Epoch: 10 [59648/60000 (100%)]\tLoss: 0.864385\n",
      "Train Epoch: 10 [59776/60000 (100%)]\tLoss: 0.593386\n",
      "================================================================\n",
      "Training: Average loss: 0.2576, Accuracy: 55800/60000 (93%)\n",
      "Test: Average loss: 0.2415, Accuracy: 9337/10000 (93%)\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "if TrainTRADES:\n",
    "    ## initialize model\n",
    "    model_TRADES = Net().to(DEVICE)\n",
    "    ## training params\n",
    "    lr = 0.01\n",
    "    optimizer = optim.SGD(model_TRADES.parameters(), lr=lr)\n",
    "    epochs = 10\n",
    "    ## train model\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # adjust learning rate for SGD\n",
    "        #adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        # adversarial training\n",
    "        train(args, model_TRADES, DEVICE, train_loader, optimizer, epoch)\n",
    "\n",
    "        # evaluation on natural examples\n",
    "        print('================================================================')\n",
    "        eval_train(model_TRADES, DEVICE, train_loader)\n",
    "        eval_test(model_TRADES, DEVICE, val_loader)\n",
    "        print('================================================================')\n",
    "\n",
    "        \n",
    "    '''\n",
    "    history_natural = olympic.fit(\n",
    "        model_TRADES,\n",
    "        optimiser,\n",
    "        nn.KLDivLoss(size_average=False),\n",
    "        dataloader=train_loader,\n",
    "        epochs=epochs,\n",
    "        metrics=['accuracy'],\n",
    "        prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)),\n",
    "        update_fn=trades_obj,\n",
    "        #update_fn_kwargs={'adversary': entropySmoothing, 'k': 30, 'step': 0.03, 'eps': 0.3, 'norm': 'inf', 'gamma':1e-5},\n",
    "        callbacks=[\n",
    "            olympic.callbacks.Evaluate(val_loader),\n",
    "            olympic.callbacks.ReduceLROnPlateau(patience=5)\n",
    "        ]\n",
    "    )\n",
    "    '''\n",
    "    ## verify validation accuracy\n",
    "    #print('final validation accuracy:')\n",
    "    #valscore = olympic.evaluate(model_TRADES, val_loader, metrics=['accuracy'],\n",
    "    #                 prepare_batch = lambda batch: (batch[0].to(DEVICE), batch[1].to(DEVICE)))\n",
    "    ## save model\n",
    "    modelname = '../trainedmodels/'+dataset+'/TRADES_ep'+str(epochs)+'_lr'+str(lr)+'.pt'\n",
    "    torch.save(model_TRADES,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING MART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL USING MMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD ALL PRE-TRAINED MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSGD = False\n",
    "TrainESGD = False\n",
    "TrainL2 = False\n",
    "TrainLInf = False\n",
    "TrainSAT2 = False\n",
    "TrainSATInf = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load all the pre-trained models\n",
    "if dataset=='MNIST':\n",
    "    if not TrainSGD:\n",
    "        model_SGD = torch.load('../trainedmodels/MNIST/SGD_ep10_lr0.1.pt').to(DEVICE)\n",
    "    if not TrainESGD:    \n",
    "        model_ESGD = torch.load('../trainedmodels/MNIST/ESGD_ep5_lr0.1.pt').to(DEVICE)\n",
    "    if not TrainLInf:\n",
    "        adv_model_linf = torch.load('../trainedmodels/MNIST/AT2_ep2_lr0.1.pt').to(DEVICE)\n",
    "    if not TrainL2:\n",
    "        adv_model_l2 = torch.load('../trainedmodels/MNIST/ATInf_ep2_lr0.1.pt').to(DEVICE)\n",
    "    if not TrainSAT2:\n",
    "        model_SAT2 = torch.load('../trainedmodels/MNIST/SAT2_ep2_lr0.1.pt').to(DEVICE)\n",
    "    if not TrainSATInf:\n",
    "        model_SATInf = torch.load('../trainedmodels/MNIST/SATInf_ep2_lr0.1.pt').to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE NETWORK OUTPUT AT DIFFERENT LEVELS OF ATTACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_adversarial_examples(model, x, y, l2_eps=5.0, linf_eps=0.2):\n",
    "    x = x.unsqueeze(0).to(DEVICE)\n",
    "    y =  torch.tensor([y]).to(DEVICE)\n",
    "    \n",
    "    ## l2 and linf attacks\n",
    "    x_adv_l2 = pgd(model, x, y, torch.nn.CrossEntropyLoss(), k=30, step=1.0, eps=l2_eps, norm=2)\n",
    "    x_adv_linf = iterated_fgsm(model, x, y, torch.nn.CrossEntropyLoss(), k=60, step=0.01, eps=linf_eps, norm='inf')\n",
    "    \n",
    "    y_pred = model(x)\n",
    "    y_pred_l2 = model(x_adv_l2)\n",
    "    y_pred_linf = model(x_adv_linf)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "    \n",
    "    axes[0].imshow(x[0, 0].cpu().numpy(), cmap='gray')\n",
    "    axes[0].set_title(\n",
    "        f'Natural, '\n",
    "        f'P({ y_pred.argmax(dim=1).item()}) = '\n",
    "        f'{np.round(y_pred.softmax(dim=1)[0, y_pred.argmax(dim=1).item()].item(), 3)}')\n",
    "    axes[0].set_xticks([])\n",
    "    axes[0].set_yticks([])\n",
    "    \n",
    "    axes[1].imshow(x_adv_l2[0, 0].cpu().numpy(), cmap='gray')\n",
    "    axes[1].set_title(\n",
    "        f'$L^2$ adversary, '\n",
    "        f'eps={l2_eps}, '\n",
    "        f'P({y_pred_l2.argmax(dim=1).item()}) = '\n",
    "        f'{np.round(y_pred_l2.softmax(dim=1)[0, y_pred_l2.argmax(dim=1).item()].item(), 3)}')\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "    \n",
    "    axes[2].imshow(x_adv_linf[0, 0].cpu().numpy(), cmap='gray')\n",
    "    axes[2].set_title(\n",
    "        '$L^{\\infty}$ adversary, '\n",
    "        f'eps={linf_eps}, '\n",
    "        f'P({y_pred_l2.argmax(dim=1).item()}) = '\n",
    "        f'{np.round(y_pred_linf.softmax(dim=1)[0, y_pred_linf.argmax(dim=1).item()].item(), 3)}')\n",
    "    axes[2].set_xticks([])\n",
    "    axes[2].set_yticks([])\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate sgd model with PGD attack and FGSM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    visualise_adversarial_examples(model_SGD, *val[1])\n",
    "    visualise_adversarial_examples(model_SGD, *val[2])\n",
    "    visualise_adversarial_examples(model_SGD, *val[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Adversarial L-2 model with PGD attack and FGSM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    visualise_adversarial_examples(adv_model_l2, *val[1])\n",
    "    visualise_adversarial_examples(adv_model_l2, *val[6])\n",
    "    visualise_adversarial_examples(adv_model_l2, *val[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying adversarial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infnorm(x):\n",
    "    infn = torch.max(torch.abs(x.detach().cpu()))\n",
    "    return infn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_against_adversary(model, k, eps, step, norm):\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    for x, y in val_loader:\n",
    "        total += x.size(0)\n",
    "        \n",
    "        if norm == 2:\n",
    "            x_adv = pgd(\n",
    "                model, x.to(DEVICE), y.to(DEVICE), torch.nn.CrossEntropyLoss(), k=k, step=step, eps=eps, norm=2)\n",
    "            print('rel. l2-norm of x_adv-x:',torch.norm(x_adv.detach().cpu()-x)/np.sqrt(x.size(0)))#/torch.norm(x))\n",
    "        elif norm == 'inf':\n",
    "            x_adv = iterated_fgsm(\n",
    "                model, x.to(DEVICE), y.to(DEVICE), torch.nn.CrossEntropyLoss(), k=k, step=step, eps=eps, norm='inf')\n",
    "            print('rel. linf-norm of x_adv-x:',infnorm(x_adv.detach().cpu()-x)/infnorm(x))\n",
    "        y_pred = model(x_adv)\n",
    "\n",
    "        acc += olympic.metrics.accuracy(y.to(DEVICE), y_pred) * x.size(0)\n",
    "\n",
    "    return acc/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate robust models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadResults = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps: 0.0\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "rel. l2-norm of x_adv-x: tensor(0.)\n",
      "eps: 0.3333333333333333\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.4000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(0.3333)\n",
      "eps: 0.6666666666666666\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(0.8000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(0.6667)\n",
      "eps: 1.0\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.2000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.0000)\n",
      "eps: 1.3333333333333333\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(1.3333)\n",
      "eps: 1.6666666666666665\n",
      "evaluating SGD network...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(1.6666)\n",
      "eps: 2.0\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.4000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.0000)\n",
      "eps: 2.333333333333333\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(2.8000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(2.3333)\n",
      "eps: 2.6666666666666665\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.2000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(2.6666)\n",
      "eps: 3.0\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.0000)\n",
      "eps: 3.333333333333333\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3323)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(3.3333)\n",
      "eps: 3.6666666666666665\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(3.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6665)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6663)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6633)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6661)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6652)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6652)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6656)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6649)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.4000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(3.6666)\n",
      "eps: 4.0\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9995)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9991)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9985)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9998)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9983)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9987)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9994)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9973)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9990)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9988)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9992)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9971)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9922)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9970)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9992)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9990)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9944)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9954)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9974)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9982)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9974)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9965)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9998)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9984)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9955)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9978)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9995)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9967)\n",
      "rel. l2-norm of x_adv-x: tensor(3.9982)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.8000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.7999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.0000)\n",
      "eps: 4.333333333333333\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.3319)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3323)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3327)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3309)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3303)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3284)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3321)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3289)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3323)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3332)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3286)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3311)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3270)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3306)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3332)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3325)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3282)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3287)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3293)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3294)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3323)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3306)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3330)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3314)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3327)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3317)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3298)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3317)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3319)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3327)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3323)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3324)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3328)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3314)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3324)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3327)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3296)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3302)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3283)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3320)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3329)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3318)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3307)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.3299)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3296)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3237)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3320)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3294)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3308)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3311)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3318)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3319)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3266)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3255)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3204)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3224)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3288)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3324)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3280)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3232)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3221)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3312)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3308)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3289)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3265)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3315)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3292)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3280)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3329)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3241)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3311)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3309)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3275)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3300)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3324)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3269)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3291)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3270)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3196)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3295)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3327)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3287)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3328)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3332)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3321)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3313)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3329)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3324)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3304)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3322)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3293)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3216)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3288)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3301)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2000)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(4.3333)\n",
      "eps: 4.666666666666666\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.6540)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6605)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6586)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6472)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6523)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6515)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6563)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6533)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6565)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6479)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6602)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6573)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6512)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6446)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6588)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6565)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6498)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6490)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6585)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6440)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6522)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6588)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6616)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6594)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6589)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6470)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6505)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6463)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6636)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6437)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6608)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6584)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6590)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6621)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6519)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6521)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6643)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6483)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6501)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6635)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6665)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6644)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6612)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6497)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6635)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6495)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6639)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6661)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6636)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6642)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6547)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6628)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6665)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6608)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6641)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6575)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6577)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6601)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6630)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6658)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6662)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(4.6625)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6662)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6651)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6626)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6633)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6647)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6615)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6579)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6639)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6651)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6601)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6584)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6590)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6651)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6641)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6651)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6650)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6641)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6607)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6659)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6636)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6596)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6648)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6593)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6639)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6647)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6629)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6651)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6652)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6632)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6627)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6647)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6652)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6662)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6664)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6635)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6617)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6644)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.6545)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6569)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6409)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6609)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6495)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6553)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6599)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6599)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6615)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6429)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6479)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6426)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6626)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6358)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6557)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6599)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6489)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6453)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6369)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6623)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6539)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6507)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6524)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6533)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6558)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6473)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6474)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6559)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6618)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6398)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6512)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6526)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6493)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6503)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6577)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6483)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6496)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6519)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6392)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6574)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(4.6660)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6647)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6616)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6559)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6657)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6629)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6615)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6662)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6611)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6557)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6596)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6599)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6643)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6575)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6645)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6659)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6632)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6641)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6611)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6602)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6639)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6647)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6639)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6660)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6656)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6653)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6631)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6647)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6631)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6639)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6559)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6422)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6504)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6545)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(4.6666)\n",
      "eps: 5.0\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.9454)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9590)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9495)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9393)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9515)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9509)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9323)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9418)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9326)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9468)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9528)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9342)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9346)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9557)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9438)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9464)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9331)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9529)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9327)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9449)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9424)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9554)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9518)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9647)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9337)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9417)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9325)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9656)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9289)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9611)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9528)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9551)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9634)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9414)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9379)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9696)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9226)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9367)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9844)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9680)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9890)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9791)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9727)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9516)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9791)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9390)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9789)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9840)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9816)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9796)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9412)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9819)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9835)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9737)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9837)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9526)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9594)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9754)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9624)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9814)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9870)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9960)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9790)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9856)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9766)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9840)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9841)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9939)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9856)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9877)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9736)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9598)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9811)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9835)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9673)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9463)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9491)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9960)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9898)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9992)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9965)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9971)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9991)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9934)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9902)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9905)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9890)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9971)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9952)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9845)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9879)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9938)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9978)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9964)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9908)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9965)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9987)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9971)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9864)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9935)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9931)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9960)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9903)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9936)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9992)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9927)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9983)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9916)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9887)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9925)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9973)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9980)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9993)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9987)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9956)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9980)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9988)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9939)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9970)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9991)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9953)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9984)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9994)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9980)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9986)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9979)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9972)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9976)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9992)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9980)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9907)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9850)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9901)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.9658)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9723)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9400)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9687)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9465)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9658)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9714)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9652)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9718)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9303)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9487)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9441)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9735)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9313)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9614)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9664)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9506)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9402)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9310)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9685)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9649)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9513)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9626)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9593)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9620)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9483)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9526)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9523)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9716)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9285)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9503)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9521)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9520)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9396)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9442)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9592)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9506)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9555)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9468)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9732)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9917)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9841)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9801)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9945)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9643)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9928)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9750)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9763)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9970)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9900)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9861)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9652)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9762)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9676)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9799)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9733)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9823)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9935)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9728)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9723)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9775)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9755)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9844)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9885)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9891)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9947)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9919)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9889)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9901)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9904)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9788)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9778)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9861)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9970)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9726)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9449)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9440)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9554)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.0000)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(4.9999)\n",
      "eps: 5.333333333333333\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.1725)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1992)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1696)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1664)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1663)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1912)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(5.1826)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1274)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1444)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1500)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1513)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1736)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1329)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1667)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1795)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1565)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1702)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1486)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1875)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1480)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1859)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1548)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1637)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1749)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2154)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1671)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1749)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1525)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2025)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1431)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2013)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1844)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1815)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1955)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1613)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1644)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2002)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1123)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1746)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2439)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2118)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2526)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2599)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2305)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2026)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2434)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1699)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2413)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2634)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2780)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2482)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1523)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2536)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2416)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2378)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2581)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1764)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2324)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2393)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1972)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2517)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2689)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3057)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2624)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2535)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2392)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2779)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2529)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3001)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2771)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2523)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2540)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2120)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2470)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2499)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2054)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1484)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1522)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.3300)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3222)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2983)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3255)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3148)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3193)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3289)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3227)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3300)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3186)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3145)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3061)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3119)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3082)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3235)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3274)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3175)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2991)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3121)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3156)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3225)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3202)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3101)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3234)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3191)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3225)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3216)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3076)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3237)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3114)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3143)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3238)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3157)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3099)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3227)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3141)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3181)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3097)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3005)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3170)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3211)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3265)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3301)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3294)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3259)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3245)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3297)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3280)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3329)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3332)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3266)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3167)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3209)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3276)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3267)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3216)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3315)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3332)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3249)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3258)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(5.3277)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3285)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3298)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3288)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3316)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3295)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3316)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3263)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3282)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3285)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3332)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3318)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3256)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3332)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3289)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3126)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2954)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3028)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.2299)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2381)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1977)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2004)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1864)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2367)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2354)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2233)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2186)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1744)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1931)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1898)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2166)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1689)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2117)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2274)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1950)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1758)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1894)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2215)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2264)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1997)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2278)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2232)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2246)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2113)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2196)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1885)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2341)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1616)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2015)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2052)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2042)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1786)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1583)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2313)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2159)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2004)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2028)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2345)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2692)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2896)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2728)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2743)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2083)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2673)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2316)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2591)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3107)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2919)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2760)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2322)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2629)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2221)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2516)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2620)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2640)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2905)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2306)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2358)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2585)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2545)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2821)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2851)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2790)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3033)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2879)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2811)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2909)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2929)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2639)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2578)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2710)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2952)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2552)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2010)\n",
      "rel. l2-norm of x_adv-x: tensor(5.1833)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2021)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.3999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3333)\n",
      "eps: 5.666666666666666\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.3102)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3537)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2940)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2883)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2927)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3133)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3180)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2415)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2629)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2802)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2667)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3034)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2419)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2966)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3135)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2672)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3088)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2898)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3339)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2769)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3415)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2955)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2807)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3077)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3607)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2780)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3136)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2783)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3527)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2730)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3412)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3131)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3273)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3334)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2838)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3222)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3427)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2184)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3267)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4228)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3622)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4439)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4591)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3960)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3558)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4139)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2957)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4449)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4515)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5176)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4443)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2635)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4522)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3968)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4296)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4508)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3098)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4192)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3990)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3408)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4461)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4743)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5539)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4530)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4257)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4246)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4931)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4437)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5303)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4935)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4627)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3895)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4208)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4407)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3623)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2537)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2803)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.6379)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6302)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5861)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6246)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6072)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6237)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6367)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6177)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6385)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5981)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6047)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6018)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6125)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6006)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6267)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6259)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6097)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5914)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6144)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6119)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6358)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6192)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6061)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6291)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6228)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6319)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6248)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6025)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6177)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6050)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6131)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6270)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6174)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6110)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6248)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6192)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6232)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6035)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5877)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6229)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6449)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6501)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6327)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6241)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6420)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6333)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6439)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6629)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6621)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6445)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6314)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6350)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6370)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6449)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6367)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6429)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6624)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6335)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6389)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6443)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6423)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6498)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6449)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6437)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6551)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6516)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6482)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6560)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6506)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6540)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6520)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6421)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6626)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6464)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6090)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5907)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5876)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.4265)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4248)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3925)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3567)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3429)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4352)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4434)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4209)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3967)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3354)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3798)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3591)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3826)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3379)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3914)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4097)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3548)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3459)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3901)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3871)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4174)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3803)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4141)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4148)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4040)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4083)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4149)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3449)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4258)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3306)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3777)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3847)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3774)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3444)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3024)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4319)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4117)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3562)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4019)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4142)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4723)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5371)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5035)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4549)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3726)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4705)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4016)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4659)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5527)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5224)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4680)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4196)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4703)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4070)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4623)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4848)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4720)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4930)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4106)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4211)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(5.4939)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4630)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5105)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5125)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4755)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5435)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5210)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5022)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5563)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5230)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4767)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4855)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4698)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5186)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4868)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3839)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3315)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3816)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7998)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7989)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7987)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7998)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "rel. l2-norm of x_adv-x: tensor(6.7999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6666)\n",
      "eps: 6.0\n",
      "evaluating SGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.3739)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4180)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3470)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3474)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3399)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3610)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3791)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2952)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3130)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3197)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3133)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3485)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2832)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3554)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3767)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3168)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3545)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3502)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3946)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3334)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3618)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3374)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3608)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4186)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3240)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3653)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3396)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4271)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3211)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3974)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3762)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3803)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3803)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3281)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3801)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4040)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2568)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4016)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5233)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4413)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5506)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5706)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4801)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4174)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4960)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3419)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5545)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5533)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6631)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5533)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2963)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5400)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4698)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5178)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5650)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3774)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5041)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4615)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4029)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5545)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5772)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6885)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5564)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5065)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5079)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6270)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5389)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6761)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6116)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5423)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5602)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4730)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5130)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5350)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4201)\n",
      "rel. l2-norm of x_adv-x: tensor(5.2925)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3231)\n",
      "evaluating ESGD network...\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "rel. l2-norm of x_adv-x: tensor(nan)\n",
      "evaluating SAT2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.8958)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8884)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8358)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8410)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8401)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8820)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9034)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8663)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(5.8906)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8148)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8334)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8242)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8474)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8408)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8683)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8822)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8489)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8427)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8682)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8478)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9067)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8634)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8475)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8805)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8776)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8984)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8863)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8258)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8705)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8457)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8541)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8684)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8478)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8581)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8503)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8862)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8921)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8304)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8339)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8632)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9083)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9239)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9266)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8746)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8788)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9173)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8781)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9296)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9647)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9702)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9180)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9066)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9122)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9026)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9160)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9182)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9040)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9659)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8937)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9134)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9272)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9107)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9428)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9329)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9088)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9449)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9396)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9277)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9569)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9429)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9376)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9207)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9118)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9582)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9220)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8383)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8380)\n",
      "rel. l2-norm of x_adv-x: tensor(5.8102)\n",
      "evaluating SATInf network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.5375)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5339)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5065)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4545)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4150)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5396)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5742)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5378)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4948)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4196)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4868)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4439)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4798)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4414)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5024)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5219)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4369)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4427)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5075)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4588)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5173)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4669)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5157)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5167)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5034)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5150)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5353)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4267)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5400)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4203)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4560)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4993)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4694)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4316)\n",
      "rel. l2-norm of x_adv-x: tensor(5.3672)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5497)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5224)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4397)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5174)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5392)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5887)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6913)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6410)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5566)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4734)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6060)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4882)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5885)\n",
      "rel. l2-norm of x_adv-x: tensor(5.7013)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6778)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5728)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5374)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5953)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5319)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5943)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6313)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5745)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6049)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5166)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5391)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6312)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5687)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6369)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6544)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5760)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6685)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6566)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6409)\n",
      "rel. l2-norm of x_adv-x: tensor(5.7351)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6744)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6069)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6116)\n",
      "rel. l2-norm of x_adv-x: tensor(5.5778)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6667)\n",
      "rel. l2-norm of x_adv-x: tensor(5.6318)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4806)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4103)\n",
      "rel. l2-norm of x_adv-x: tensor(5.4876)\n",
      "evaluating linf network...\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1989)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1988)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1997)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1989)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1984)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1998)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1967)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1929)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1987)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1931)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1982)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1998)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1983)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1996)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1995)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1998)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "rel. l2-norm of x_adv-x: tensor(7.1999)\n",
      "evaluating l2 network...\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "rel. l2-norm of x_adv-x: tensor(5.9999)\n",
      "time elapsed: 468.84591126441956\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "if not loadResults:\n",
    "    pgd_attack_range = np.arange(0, 6.1, 1./3)\n",
    "    acc_SGD = []\n",
    "    acc_ESGD = []\n",
    "    acc_l2 = []\n",
    "    acc_linf = []\n",
    "    acc_SAT2 = []\n",
    "    acc_SATInf = []\n",
    "    acc_TRADES = []\n",
    "    for eps in pgd_attack_range:\n",
    "        print('eps:',eps)\n",
    "        print('evaluating SGD network...')\n",
    "        acc_SGD.append(evaluate_against_adversary(model_SGD, k=20, eps=eps, step=0.5, norm=2))\n",
    "        print('evaluating ESGD network...')\n",
    "        acc_ESGD.append(evaluate_against_adversary(model_ESGD, k=20, eps=eps, step=0.5, norm=2))\n",
    "        print('evaluating SAT2 network...')\n",
    "        acc_SAT2.append(evaluate_against_adversary(model_SAT2, k=30, eps=eps, step=0.3, norm=2))\n",
    "        print('evaluating SATInf network...')\n",
    "        acc_SATInf.append(evaluate_against_adversary(model_SATInf, k=30, eps=eps, step=0.25, norm=2))        \n",
    "        print('evaluating linf network...')\n",
    "        acc_linf.append(evaluate_against_adversary(adv_model_linf, k=30, eps=eps*1.2, step=1.5, norm=2))\n",
    "        print('evaluating l2 network...')\n",
    "        acc_l2.append(evaluate_against_adversary(adv_model_l2, k=30, eps=eps*1.2, step=1.5, norm=2))\n",
    "        print('evaluating TRADES network...')\n",
    "        acc_TRADES.append(evaluate_against_adversary(model_TRADES, k=30, eps=eps, step=1.5, norm=2))        \n",
    "print(\"time elapsed:\",time.time()-t1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not loadResults:    \n",
    "    accData = [acc_SGD,acc_ESGD,acc_l2,acc_linf,acc_SAT2,acc_SATInf]\n",
    "    np.save('../results/accData_l2.npy',accData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadResults:\n",
    "    pgd_attack_range = np.arange(0.0, 6.1, 1./3)\n",
    "    accData2 = np.load('../results/accData_l2.npy')\n",
    "    [acc_SGD,acc_ESGD,acc_l2,acc_linf,acc_SAT2,acc_SATInf] = accData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'COLOURS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f6830c5d4aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpgd_attack_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_linf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'$L{\\infty}$ training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpgd_attack_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_TRADES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TRADES training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOLOURS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epsilon'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'COLOURS' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with plt.style.context('ggplot'):\n",
    "    plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelcolor\"] = \"black\"\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(15,10))\n",
    "    plt.figure(figsize=(14,7))\n",
    "    axes.set_title('$L^2$-bounded adversary')\n",
    "    axes.plot(pgd_attack_range, acc_SGD, label='SGD')\n",
    "    axes.plot(pgd_attack_range, acc_ESGD, label='Entropy-SGD')\n",
    "    axes.plot(pgd_attack_range, acc_SAT2, label='Data-Entropy-SGD ($L_2$)')\n",
    "    axes.plot(pgd_attack_range, acc_SATInf, label='Data-Entropy-SGD ($L_\\infty$)')\n",
    "    axes.plot(pgd_attack_range, acc_l2, label='$L2$ training')\n",
    "    axes.plot(pgd_attack_range, acc_linf, label='$L{\\infty}$ training')\n",
    "    axes.plot(pgd_attack_range, acc_TRADES, label='TRADES training')\n",
    "    axes.vlines([3], 0, 1, colors=COLOURS[1], linestyle='--')\n",
    "    axes.set_ylabel('Accuracy')\n",
    "    axes.set_xlabel('Epsilon')\n",
    "    axes.set_ylim((0,1))\n",
    "    axes.legend(['sgd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadResultsFGSM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "if not loadResultsFGSM:\n",
    "    fgsm_attack_range = np.arange(0.0, 0.52, 0.025)\n",
    "    fgsm_acc_linf = []\n",
    "    fgsm_acc_l2 = []\n",
    "    fgsm_acc_SGD = []\n",
    "    fgsm_acc_ESGD = []\n",
    "    fgsm_acc_SAT2 = []\n",
    "    fgsm_acc_SATInf = []\n",
    "    for eps in fgsm_attack_range:\n",
    "        print('eps:',eps)\n",
    "        print('evaluating SGD network...')\n",
    "        fgsm_acc_SGD.append(evaluate_against_adversary(model_SGD, k=20, eps=eps, step=0.1, norm='inf'))\n",
    "        print('evaluating ESGD network...')\n",
    "        fgsm_acc_ESGD.append(evaluate_against_adversary(model_ESGD, k=20, eps=eps, step=0.1, norm='inf'))\n",
    "        print('evaluating SAT2 network...')\n",
    "        fgsm_acc_SAT2.append(evaluate_against_adversary(model_SAT2, k=10, eps=eps, step=0.1, norm='inf'))\n",
    "        print('evaluating SATInf network...')\n",
    "        fgsm_acc_SATInf.append(evaluate_against_adversary(model_SATInf, k=10, eps=eps, step=0.1, norm='inf'))        \n",
    "        print('evaluating linf network...')\n",
    "        fgsm_acc_linf.append(evaluate_against_adversary(adv_model_linf, k=50, eps=eps, step=0.02, norm='inf'))\n",
    "        print('evaluating l2 network...')\n",
    "        fgsm_acc_l2.append(evaluate_against_adversary(adv_model_l2, k=50, eps=eps, step=0.02, norm='inf'))\n",
    "    \n",
    "print(\"time elapsed:\",time.time()-t1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not loadResultsFGSM:    \n",
    "    fgsmaccData = [fgsm_acc_SGD,fgsm_acc_ESGD,fgsm_acc_l2,fgsm_acc_linf,fgsm_acc_SAT2,fgsm_acc_SATInf]\n",
    "    np.save('../results/fgsmaccData.npy',fgsmaccData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadResultsFGSM:\n",
    "    fgsm_attack_range = np.arange(0.0, 0.52, 0.025)\n",
    "    accData2 = np.load('../results/fgsmaccData.npy')\n",
    "    [fgsm_acc_SGD,fgsm_acc_ESGD,fgsm_acc_l2,fgsm_acc_linf,fgsm_acc_SAT2,fgsm_acc_SATInf] = accData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('ggplot'):\n",
    "    plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelcolor\"] = \"black\"\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(15,10))\n",
    "    plt.figure(figsize=(14,7))\n",
    "    axes.set_title('$L^\\infty$-bounded adversary')\n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_SGD, label='SGD')\n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_ESGD, label='Entropy-SGD')\n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_SAT2, label='Data-Entropy-SGD ($L_2$)')\n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_SATInf, label='Data-Entropy-SGD ($L_\\infty$)')    \n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_l2, label='$L2$ training')\n",
    "    axes.plot(fgsm_attack_range, fgsm_acc_linf, label='$L{\\infty}$ training')\n",
    "    axes.vlines([0.25], 0, 1, colors=COLOURS[1], linestyle='--')\n",
    "    axes.set_ylabel('Accuracy')\n",
    "    axes.set_xlabel('Epsilon')\n",
    "    axes.set_ylim((0,1))\n",
    "    axes.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
